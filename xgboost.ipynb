{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfdcc9d0",
   "metadata": {
    "code_folding": [
     0
    ],
    "ExecuteTime": {
     "end_time": "2023-09-12T03:30:25.369637400Z",
     "start_time": "2023-09-12T03:30:24.982793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import IPython\n",
    "\n",
    "from data_pipeline import DataPipeline\n",
    "import model_hyperparams\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date range: 2019-01-01 00:00:00 - 2021-04-01 23:45:00\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the data\n",
    "data_upac08 = DataPipeline('data/upac08')\n",
    "\n",
    "# Track memory usage of the preprocessing\n",
    "preprocessing_memory_usage = memory_usage((data_upac08._do, ()), timestamps=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T03:31:40.177412300Z",
     "start_time": "2023-09-12T03:31:36.635434300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                               Memory Usage\nTimestamp                                  \n2023-09-12 03:31:41.799300608    209.453125\n2023-09-12 03:31:42.564902656    209.453125\n2023-09-12 03:31:42.678918912    217.703125\n2023-09-12 03:31:42.788772608    247.214844\n2023-09-12 03:31:42.896312576    252.300781\n2023-09-12 03:31:43.005580800    250.546875\n2023-09-12 03:31:43.114108928    255.128906\n2023-09-12 03:31:43.223678720    252.921875\n2023-09-12 03:31:43.331668992    259.550781\n2023-09-12 03:31:43.442321664    258.328125\n2023-09-12 03:31:43.551595520    255.085938\n2023-09-12 03:31:43.661953536    263.394531\n2023-09-12 03:31:43.772513280    256.398438\n2023-09-12 03:31:43.885286912    260.660156\n2023-09-12 03:31:43.993970688    268.679688\n2023-09-12 03:31:44.103134720    268.351562\n2023-09-12 03:31:44.211128320    264.046875\n2023-09-12 03:31:44.284924416    239.105469",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Memory Usage</th>\n    </tr>\n    <tr>\n      <th>Timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-09-12 03:31:41.799300608</th>\n      <td>209.453125</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:42.564902656</th>\n      <td>209.453125</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:42.678918912</th>\n      <td>217.703125</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:42.788772608</th>\n      <td>247.214844</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:42.896312576</th>\n      <td>252.300781</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.005580800</th>\n      <td>250.546875</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.114108928</th>\n      <td>255.128906</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.223678720</th>\n      <td>252.921875</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.331668992</th>\n      <td>259.550781</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.442321664</th>\n      <td>258.328125</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.551595520</th>\n      <td>255.085938</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.661953536</th>\n      <td>263.394531</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.772513280</th>\n      <td>256.398438</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.885286912</th>\n      <td>260.660156</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.993970688</th>\n      <td>268.679688</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:44.103134720</th>\n      <td>268.351562</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:44.211128320</th>\n      <td>264.046875</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:44.284924416</th>\n      <td>239.105469</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the memory usage to a dataframe\n",
    "\n",
    "mem_usage = pd.DataFrame(preprocessing_memory_usage, columns=['Memory Usage', 'Timestamp'])\n",
    "mem_usage.index = pd.to_datetime(mem_usage['Timestamp'], unit='s')\n",
    "mem_usage = mem_usage.drop('Timestamp', axis=1)\n",
    "\n",
    "mem_usage"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T03:33:59.808596900Z",
     "start_time": "2023-09-12T03:33:59.784454Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf6f415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T03:45:15.824005400Z",
     "start_time": "2023-09-12T03:34:39.354528700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-12 04:34:39,352] A new study created in memory with name: no-name-e972e7d4-a124-4fd8-9930-c84758b877c5\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "730176a7e1f34cb387314b2c52dd55a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-09-12 04:34:46,799] Trial 0 finished with value: 0.009477256263810522 and parameters: {'n_estimators': 4785, 'max_depth': 3285, 'reg_alpha': 0.00018816996119468417, 'reg_lambda': 0.0008805715142108432}. Best is trial 0 with value: 0.009477256263810522.\n",
      "[I 2023-09-12 04:34:54,009] Trial 1 finished with value: 0.008706706804132932 and parameters: {'n_estimators': 4671, 'max_depth': 286, 'reg_alpha': 0.0009756564133401358, 'reg_lambda': 4.5810115334178186e-05}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:01,799] Trial 2 finished with value: 0.00949985384059664 and parameters: {'n_estimators': 4913, 'max_depth': 4094, 'reg_alpha': 0.00026054673068951216, 'reg_lambda': 0.0002565046978320881}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:07,241] Trial 3 finished with value: 0.009345544458874982 and parameters: {'n_estimators': 2669, 'max_depth': 3106, 'reg_alpha': 0.00046634000786086494, 'reg_lambda': 0.0003691595943356122}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:10,984] Trial 4 finished with value: 0.008886781123061337 and parameters: {'n_estimators': 1362, 'max_depth': 3584, 'reg_alpha': 0.0008397706186896328, 'reg_lambda': 8.268522953390218e-05}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:16,805] Trial 5 finished with value: 0.009570630845748693 and parameters: {'n_estimators': 2612, 'max_depth': 4903, 'reg_alpha': 0.00025287191803280933, 'reg_lambda': 0.0009888737985736765}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:25,320] Trial 6 finished with value: 0.009630587798560726 and parameters: {'n_estimators': 4847, 'max_depth': 2767, 'reg_alpha': 0.00021741926837911282, 'reg_lambda': 0.00031391911948504205}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:33,385] Trial 7 finished with value: 0.00918327908190504 and parameters: {'n_estimators': 4424, 'max_depth': 343, 'reg_alpha': 0.0006522585692092597, 'reg_lambda': 0.000741550205333871}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:39,244] Trial 8 finished with value: 0.008672471351751756 and parameters: {'n_estimators': 3361, 'max_depth': 1142, 'reg_alpha': 0.0009184188755881578, 'reg_lambda': 0.0006554978935821488}. Best is trial 8 with value: 0.008672471351751756.\n",
      "[I 2023-09-12 04:35:41,743] Trial 9 finished with value: 0.0095857274526015 and parameters: {'n_estimators': 638, 'max_depth': 1723, 'reg_alpha': 0.0002525236510370627, 'reg_lambda': 6.299105021224335e-05}. Best is trial 8 with value: 0.008672471351751756.\n",
      "[I 2023-09-12 04:35:48,013] Trial 10 finished with value: 0.01026369776115724 and parameters: {'n_estimators': 3549, 'max_depth': 1698, 'reg_alpha': 1.157219458205452e-05, 'reg_lambda': 0.000593385244834639}. Best is trial 8 with value: 0.008672471351751756.\n",
      "[I 2023-09-12 04:35:54,026] Trial 11 finished with value: 0.00866918608664494 and parameters: {'n_estimators': 3611, 'max_depth': 86, 'reg_alpha': 0.0009458204191120538, 'reg_lambda': 0.000548580095532305}. Best is trial 11 with value: 0.00866918608664494.\n",
      "[I 2023-09-12 04:35:59,908] Trial 12 finished with value: 0.008632358169506249 and parameters: {'n_estimators': 3396, 'max_depth': 1292, 'reg_alpha': 0.0009948165835590823, 'reg_lambda': 0.0005459593128349326}. Best is trial 12 with value: 0.008632358169506249.\n",
      "[I 2023-09-12 04:36:06,567] Trial 13 finished with value: 0.008830251181608517 and parameters: {'n_estimators': 3659, 'max_depth': 987, 'reg_alpha': 0.000797740363907056, 'reg_lambda': 0.0005261697349577419}. Best is trial 12 with value: 0.008632358169506249.\n",
      "[I 2023-09-12 04:36:10,426] Trial 14 finished with value: 0.008651659687050981 and parameters: {'n_estimators': 1794, 'max_depth': 49, 'reg_alpha': 0.000984945676216374, 'reg_lambda': 0.0004674495345779937}. Best is trial 12 with value: 0.008632358169506249.\n",
      "[I 2023-09-12 04:36:14,100] Trial 15 finished with value: 0.008631862486357141 and parameters: {'n_estimators': 1687, 'max_depth': 2071, 'reg_alpha': 0.0009961394369962721, 'reg_lambda': 0.0004408836653068014}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:18,413] Trial 16 finished with value: 0.009093007600533226 and parameters: {'n_estimators': 1933, 'max_depth': 2156, 'reg_alpha': 0.0007342769879328879, 'reg_lambda': 0.0004237947773942813}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:20,299] Trial 17 finished with value: 0.009214749122710674 and parameters: {'n_estimators': 213, 'max_depth': 2359, 'reg_alpha': 0.0006503042102132578, 'reg_lambda': 0.0006968272714537602}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:23,284] Trial 18 finished with value: 0.008879869388062058 and parameters: {'n_estimators': 1208, 'max_depth': 1111, 'reg_alpha': 0.0008678652596181333, 'reg_lambda': 0.0002314786093384306}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:27,455] Trial 19 finished with value: 0.008702201197774472 and parameters: {'n_estimators': 2135, 'max_depth': 1787, 'reg_alpha': 0.0009883862946934196, 'reg_lambda': 0.0004441225412366277}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:33,313] Trial 20 finished with value: 0.008867584905922455 and parameters: {'n_estimators': 3130, 'max_depth': 830, 'reg_alpha': 0.0007924222795065304, 'reg_lambda': 0.0006162419399531739}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:37,221] Trial 21 finished with value: 0.00864221350510357 and parameters: {'n_estimators': 1592, 'max_depth': 638, 'reg_alpha': 0.0009971714060585972, 'reg_lambda': 0.0004726980138290653}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:40,469] Trial 22 finished with value: 0.008767528499029047 and parameters: {'n_estimators': 1215, 'max_depth': 1436, 'reg_alpha': 0.0008944527789171485, 'reg_lambda': 0.0005048803865319257}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:43,048] Trial 23 finished with value: 0.008788039614448098 and parameters: {'n_estimators': 761, 'max_depth': 637, 'reg_alpha': 0.0009005494736603685, 'reg_lambda': 0.00038851348643939343}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:49,677] Trial 24 finished with value: 0.00864140978535801 and parameters: {'n_estimators': 4028, 'max_depth': 2150, 'reg_alpha': 0.000987753432491292, 'reg_lambda': 0.0005580009116924414}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:56,469] Trial 25 finished with value: 0.008675969432255543 and parameters: {'n_estimators': 4164, 'max_depth': 2036, 'reg_alpha': 0.0008732909738618905, 'reg_lambda': 0.0007469076752131014}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:02,915] Trial 26 finished with value: 0.008970720299600735 and parameters: {'n_estimators': 3968, 'max_depth': 2628, 'reg_alpha': 0.0007496135824946515, 'reg_lambda': 0.0005550105403545444}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:08,078] Trial 27 finished with value: 0.008697137832575154 and parameters: {'n_estimators': 3019, 'max_depth': 1344, 'reg_alpha': 0.0009196015767620061, 'reg_lambda': 0.0005940038752940082}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:12,402] Trial 28 finished with value: 0.00877677633484111 and parameters: {'n_estimators': 2263, 'max_depth': 2900, 'reg_alpha': 0.0008404574453124658, 'reg_lambda': 0.0006584721343571649}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:18,900] Trial 29 finished with value: 0.008873078242161919 and parameters: {'n_estimators': 3972, 'max_depth': 3491, 'reg_alpha': 0.0009919493378664852, 'reg_lambda': 0.0008291592202642716}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:24,191] Trial 30 finished with value: 0.00869578089367409 and parameters: {'n_estimators': 2981, 'max_depth': 2206, 'reg_alpha': 0.0009165372596112932, 'reg_lambda': 0.0005029185189442107}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:27,858] Trial 31 finished with value: 0.008664011946871037 and parameters: {'n_estimators': 1645, 'max_depth': 610, 'reg_alpha': 0.0009999348012101439, 'reg_lambda': 0.00045408255429012863}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:31,798] Trial 32 finished with value: 0.0086614632208964 and parameters: {'n_estimators': 1499, 'max_depth': 1473, 'reg_alpha': 0.0009474495131489862, 'reg_lambda': 0.0005277833112065356}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:36,450] Trial 33 finished with value: 0.008646884637674436 and parameters: {'n_estimators': 2389, 'max_depth': 1839, 'reg_alpha': 0.000992835050845013, 'reg_lambda': 0.0003567591349150984}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:44,100] Trial 34 finished with value: 0.008734080101332458 and parameters: {'n_estimators': 4467, 'max_depth': 2554, 'reg_alpha': 0.0009349198162792675, 'reg_lambda': 0.0004763197335619238}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:46,803] Trial 35 finished with value: 0.0088269195206585 and parameters: {'n_estimators': 843, 'max_depth': 527, 'reg_alpha': 0.000851845924228963, 'reg_lambda': 0.00040936139203841433}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:51,766] Trial 36 finished with value: 0.009394481235844921 and parameters: {'n_estimators': 2704, 'max_depth': 3100, 'reg_alpha': 0.0004434640788821254, 'reg_lambda': 0.0005797703472201446}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:56,240] Trial 37 finished with value: 0.008677431079889112 and parameters: {'n_estimators': 2048, 'max_depth': 3862, 'reg_alpha': 0.0009425749595899117, 'reg_lambda': 0.0003188051443877666}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:01,153] Trial 38 finished with value: 0.008759261595345494 and parameters: {'n_estimators': 2683, 'max_depth': 853, 'reg_alpha': 0.0008138328539247161, 'reg_lambda': 0.00048622876256400197}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:06,702] Trial 39 finished with value: 0.008757628293468165 and parameters: {'n_estimators': 3238, 'max_depth': 1300, 'reg_alpha': 0.0008813315347560279, 'reg_lambda': 0.00039314050267100014}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:14,475] Trial 40 finished with value: 0.008636246082168076 and parameters: {'n_estimators': 4963, 'max_depth': 1973, 'reg_alpha': 0.0009443794055185072, 'reg_lambda': 0.0006435032856021477}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:21,920] Trial 41 finished with value: 0.008632531721077856 and parameters: {'n_estimators': 4715, 'max_depth': 1957, 'reg_alpha': 0.0009639600525763205, 'reg_lambda': 0.0006370529052834374}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:29,762] Trial 42 finished with value: 0.008664559194521158 and parameters: {'n_estimators': 4938, 'max_depth': 1940, 'reg_alpha': 0.0009423668147243484, 'reg_lambda': 0.0006217958475578395}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:36,991] Trial 43 finished with value: 0.008660559919569493 and parameters: {'n_estimators': 4637, 'max_depth': 2375, 'reg_alpha': 0.0009479080108091333, 'reg_lambda': 0.0005574904008222981}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:43,820] Trial 44 finished with value: 0.008726627671598243 and parameters: {'n_estimators': 4269, 'max_depth': 1660, 'reg_alpha': 0.0008797166596571181, 'reg_lambda': 0.000658367471312413}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:51,504] Trial 45 finished with value: 0.008800100727798209 and parameters: {'n_estimators': 4616, 'max_depth': 2239, 'reg_alpha': 0.0008349329379523893, 'reg_lambda': 0.0007201382908858945}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:58,068] Trial 46 finished with value: 0.008584016333725065 and parameters: {'n_estimators': 3847, 'max_depth': 1518, 'reg_alpha': 0.0009516687598526961, 'reg_lambda': 0.0007766192680045404}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:39:05,382] Trial 47 finished with value: 0.008685200486563825 and parameters: {'n_estimators': 3767, 'max_depth': 1564, 'reg_alpha': 0.0009146121466668882, 'reg_lambda': 0.000783358523892093}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:39:13,722] Trial 48 finished with value: 0.008797871951709602 and parameters: {'n_estimators': 4831, 'max_depth': 1269, 'reg_alpha': 0.0007827804854174188, 'reg_lambda': 0.0009339793965139457}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:39:19,424] Trial 49 finished with value: 0.00870596493398129 and parameters: {'n_estimators': 3426, 'max_depth': 1970, 'reg_alpha': 0.0009500418651694686, 'reg_lambda': 0.0007991855087456436}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:39:26,702] Trial 50 finished with value: 0.008783654835256862 and parameters: {'n_estimators': 4492, 'max_depth': 4662, 'reg_alpha': 0.0008482028869569205, 'reg_lambda': 0.0006897578515887172}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:39:34,836] Trial 51 finished with value: 0.008630508453547512 and parameters: {'n_estimators': 4997, 'max_depth': 2720, 'reg_alpha': 0.0009640064314305948, 'reg_lambda': 0.0006288824193404875}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:39:42,552] Trial 52 finished with value: 0.008636826171848877 and parameters: {'n_estimators': 4945, 'max_depth': 2871, 'reg_alpha': 0.0009620157627347731, 'reg_lambda': 0.0006292234687707547}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:39:49,923] Trial 53 finished with value: 0.008662735417849822 and parameters: {'n_estimators': 4278, 'max_depth': 2666, 'reg_alpha': 0.0008873533879963366, 'reg_lambda': 0.0007180966909785513}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:39:57,364] Trial 54 finished with value: 0.00860814217637666 and parameters: {'n_estimators': 4715, 'max_depth': 2437, 'reg_alpha': 0.0009568304686819382, 'reg_lambda': 0.0006482572343162261}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:40:04,760] Trial 55 finished with value: 0.008671039286742526 and parameters: {'n_estimators': 4689, 'max_depth': 3124, 'reg_alpha': 0.0009123694925053873, 'reg_lambda': 0.0006740103822498283}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:40:10,974] Trial 56 finished with value: 0.008658666001267466 and parameters: {'n_estimators': 3719, 'max_depth': 2461, 'reg_alpha': 0.0009635273309469539, 'reg_lambda': 0.0007560975808198376}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:40:18,141] Trial 57 finished with value: 0.008741264501665758 and parameters: {'n_estimators': 4304, 'max_depth': 1013, 'reg_alpha': 0.0008820452559797495, 'reg_lambda': 0.0006058764982145131}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:40:25,759] Trial 58 finished with value: 0.008726740249195038 and parameters: {'n_estimators': 4680, 'max_depth': 1611, 'reg_alpha': 0.0009964729952171905, 'reg_lambda': 0.0006942176983051296}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:40:32,618] Trial 59 finished with value: 0.008839333327428034 and parameters: {'n_estimators': 4110, 'max_depth': 2742, 'reg_alpha': 0.0008203448453880971, 'reg_lambda': 0.0005283037912902115}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:40:39,089] Trial 60 finished with value: 0.008734108944693683 and parameters: {'n_estimators': 3853, 'max_depth': 2361, 'reg_alpha': 0.0009100894492912624, 'reg_lambda': 0.0006400712780061729}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:40:46,985] Trial 61 finished with value: 0.008622867149154582 and parameters: {'n_estimators': 4994, 'max_depth': 2050, 'reg_alpha': 0.0009674204112687606, 'reg_lambda': 0.0005901346220183538}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:40:54,677] Trial 62 finished with value: 0.008646825327673862 and parameters: {'n_estimators': 4811, 'max_depth': 1785, 'reg_alpha': 0.0009694925997468239, 'reg_lambda': 0.0005876952168490975}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:41:01,898] Trial 63 finished with value: 0.008650392147882258 and parameters: {'n_estimators': 4505, 'max_depth': 2141, 'reg_alpha': 0.0009638138304349705, 'reg_lambda': 0.0005679132176317167}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:41:09,590] Trial 64 finished with value: 0.00875654779278375 and parameters: {'n_estimators': 4765, 'max_depth': 1202, 'reg_alpha': 0.0008659991844247013, 'reg_lambda': 0.0005952332676703484}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:41:15,849] Trial 65 finished with value: 0.008691956704485845 and parameters: {'n_estimators': 3515, 'max_depth': 1477, 'reg_alpha': 0.0009106598693908383, 'reg_lambda': 0.000662045827479822}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:41:23,703] Trial 66 finished with value: 0.008629212171293416 and parameters: {'n_estimators': 4995, 'max_depth': 2926, 'reg_alpha': 0.0009709131274913776, 'reg_lambda': 0.0005294101057244885}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:41:30,949] Trial 67 finished with value: 0.008633196146296497 and parameters: {'n_estimators': 4385, 'max_depth': 2954, 'reg_alpha': 0.0009755780746085164, 'reg_lambda': 0.0005156437388021028}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:41:38,334] Trial 68 finished with value: 0.008676001003186688 and parameters: {'n_estimators': 4550, 'max_depth': 2516, 'reg_alpha': 0.0009975598909862217, 'reg_lambda': 0.0005415909851558025}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:41:40,637] Trial 69 finished with value: 0.008765437098652502 and parameters: {'n_estimators': 445, 'max_depth': 3243, 'reg_alpha': 0.0008619344183532533, 'reg_lambda': 0.0004433565064267031}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:41:48,735] Trial 70 finished with value: 0.008682526301925248 and parameters: {'n_estimators': 5000, 'max_depth': 3426, 'reg_alpha': 0.0009160887556373423, 'reg_lambda': 0.0004925594569878142}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:41:56,400] Trial 71 finished with value: 0.008643288112924006 and parameters: {'n_estimators': 4750, 'max_depth': 2078, 'reg_alpha': 0.0009668812733686642, 'reg_lambda': 0.0006124217885911499}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:42:01,639] Trial 72 finished with value: 0.008703452418819571 and parameters: {'n_estimators': 2810, 'max_depth': 2276, 'reg_alpha': 0.0009287268799158526, 'reg_lambda': 0.0005763021444262794}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:42:08,608] Trial 73 finished with value: 0.0087611034556598 and parameters: {'n_estimators': 4154, 'max_depth': 1787, 'reg_alpha': 0.0008948232228080975, 'reg_lambda': 0.0005208895411887024}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:42:16,573] Trial 74 finished with value: 0.008657581684840055 and parameters: {'n_estimators': 4824, 'max_depth': 3769, 'reg_alpha': 0.000999503003442512, 'reg_lambda': 0.0005503871157649363}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:42:23,926] Trial 75 finished with value: 0.008683358594441953 and parameters: {'n_estimators': 4378, 'max_depth': 2724, 'reg_alpha': 0.0009335865033587024, 'reg_lambda': 0.0006409952676677709}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:42:32,002] Trial 76 finished with value: 0.00862356434604753 and parameters: {'n_estimators': 5000, 'max_depth': 1911, 'reg_alpha': 0.0009732579301429016, 'reg_lambda': 0.00046274927437417907}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:42:39,759] Trial 77 finished with value: 0.00863814098430189 and parameters: {'n_estimators': 4875, 'max_depth': 3015, 'reg_alpha': 0.000966797843891857, 'reg_lambda': 0.0004377970076297086}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:42:47,872] Trial 78 finished with value: 0.008650431619128056 and parameters: {'n_estimators': 4983, 'max_depth': 1446, 'reg_alpha': 0.0009254527137490856, 'reg_lambda': 0.00045953566057705146}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:42:53,311] Trial 79 finished with value: 0.008829105940109595 and parameters: {'n_estimators': 2462, 'max_depth': 2530, 'reg_alpha': 0.000846315303120118, 'reg_lambda': 0.0004895867681771365}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:42:57,165] Trial 80 finished with value: 0.008759799685826207 and parameters: {'n_estimators': 1763, 'max_depth': 2846, 'reg_alpha': 0.0009017848577299048, 'reg_lambda': 0.000496860019737836}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:43:04,552] Trial 81 finished with value: 0.008647539762005956 and parameters: {'n_estimators': 4638, 'max_depth': 2319, 'reg_alpha': 0.0009390161800533857, 'reg_lambda': 0.0005795710180864472}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:43:12,153] Trial 82 finished with value: 0.008651624909222912 and parameters: {'n_estimators': 4580, 'max_depth': 1879, 'reg_alpha': 0.0009738243651365911, 'reg_lambda': 0.0006136433260306252}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:43:20,001] Trial 83 finished with value: 0.008628503129410641 and parameters: {'n_estimators': 4750, 'max_depth': 1631, 'reg_alpha': 0.0009737214294391611, 'reg_lambda': 0.000551491406963557}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:43:23,115] Trial 84 finished with value: 0.008637634069113562 and parameters: {'n_estimators': 1132, 'max_depth': 1726, 'reg_alpha': 0.0009784657267019829, 'reg_lambda': 0.0004200080489904958}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:43:31,059] Trial 85 finished with value: 0.008670792801383777 and parameters: {'n_estimators': 4800, 'max_depth': 1560, 'reg_alpha': 0.0009434740288527325, 'reg_lambda': 0.0005393101755609761}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:43:38,442] Trial 86 finished with value: 0.008657884128342863 and parameters: {'n_estimators': 4431, 'max_depth': 840, 'reg_alpha': 0.0009991358302005374, 'reg_lambda': 0.00046889987820786916}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:43:44,354] Trial 87 finished with value: 0.008773003486697952 and parameters: {'n_estimators': 3232, 'max_depth': 2070, 'reg_alpha': 0.0008683402019721557, 'reg_lambda': 0.0005090064008463512}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:43:52,361] Trial 88 finished with value: 0.00872835179592458 and parameters: {'n_estimators': 4885, 'max_depth': 2410, 'reg_alpha': 0.00089572872946932, 'reg_lambda': 0.000563109732197181}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:44:00,034] Trial 89 finished with value: 0.008636957887128548 and parameters: {'n_estimators': 3965, 'max_depth': 1072, 'reg_alpha': 0.0009560223039727331, 'reg_lambda': 0.0006013704689912631}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:44:04,671] Trial 90 finished with value: 0.008683438309033304 and parameters: {'n_estimators': 2277, 'max_depth': 2204, 'reg_alpha': 0.0009303124764688612, 'reg_lambda': 0.0004732948381689299}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:44:12,404] Trial 91 finished with value: 0.008676110367680876 and parameters: {'n_estimators': 4724, 'max_depth': 1360, 'reg_alpha': 0.0009763565198412526, 'reg_lambda': 0.0006287800133966462}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:44:20,105] Trial 92 finished with value: 0.008624342329962929 and parameters: {'n_estimators': 4550, 'max_depth': 1976, 'reg_alpha': 0.0009596820059512104, 'reg_lambda': 0.0006647750516096066}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:44:28,441] Trial 93 finished with value: 0.008604287653273611 and parameters: {'n_estimators': 4993, 'max_depth': 2625, 'reg_alpha': 0.0009528845872506549, 'reg_lambda': 0.0006849039870028335}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:44:36,422] Trial 94 finished with value: 0.008664215550926582 and parameters: {'n_estimators': 4885, 'max_depth': 1865, 'reg_alpha': 0.0008841333414660196, 'reg_lambda': 0.0006972653505935498}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:44:44,565] Trial 95 finished with value: 0.008636687626249527 and parameters: {'n_estimators': 4991, 'max_depth': 2597, 'reg_alpha': 0.0009469561138815641, 'reg_lambda': 0.0006716543613873}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:44:52,201] Trial 96 finished with value: 0.008658754360398396 and parameters: {'n_estimators': 4604, 'max_depth': 2803, 'reg_alpha': 0.0009254771910177856, 'reg_lambda': 0.0006822469514679874}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:44:59,777] Trial 97 finished with value: 0.008665772226725854 and parameters: {'n_estimators': 4529, 'max_depth': 2104, 'reg_alpha': 0.0009776520668308346, 'reg_lambda': 0.0007347276869137403}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:45:08,115] Trial 98 finished with value: 0.008669197319570292 and parameters: {'n_estimators': 4726, 'max_depth': 1674, 'reg_alpha': 0.0008937998659120736, 'reg_lambda': 0.0007134746654317368}. Best is trial 46 with value: 0.008584016333725065.\n",
      "[I 2023-09-12 04:45:15,809] Trial 99 finished with value: 0.008647280561673472 and parameters: {'n_estimators': 4322, 'max_depth': 2647, 'reg_alpha': 0.0009476800305805492, 'reg_lambda': 0.0006542965884136468}. Best is trial 46 with value: 0.008584016333725065.\n"
     ]
    }
   ],
   "source": [
    "# Create the study for the UPAC parameter optimization\n",
    "\n",
    "xgb_study = model_hyperparams.parameter_sweep_xgb(train_x=data_upac08.train_data[0],\n",
    "                                                  train_y=data_upac08.train_data[1],\n",
    "                                                  val_x=data_upac08.val_data[0],\n",
    "                                                  val_y=data_upac08.val_data[1],\n",
    "                                                  n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Train the UPAC model and track memory usage\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=xgb_study.best_params['n_estimators'],\n",
    "                             max_depth=xgb_study.best_params['max_depth'],\n",
    "                             reg_alpha=xgb_study.best_params['reg_alpha'],\n",
    "                             reg_lambda=xgb_study.best_params['reg_lambda'])\n",
    "\n",
    "model_mem_usage = memory_usage((xgb_model.fit, (data_upac08.train_data[0], data_upac08.train_data[1])), timestamps=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T03:46:26.650667300Z",
     "start_time": "2023-09-12T03:46:19.565306100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                               Memory Usage\nTimestamp                                  \n2023-09-12 03:46:19.564298496    268.496094\n2023-09-12 03:46:20.389854208    268.496094\n2023-09-12 03:46:20.499237632    307.890625\n2023-09-12 03:46:20.609534720    311.355469\n2023-09-12 03:46:20.718945280    333.445312\n2023-09-12 03:46:20.830466304    311.046875\n2023-09-12 03:46:20.941032448    327.332031\n2023-09-12 03:46:21.050358784    314.343750\n2023-09-12 03:46:21.159698944    314.898438\n2023-09-12 03:46:21.270036480    329.363281\n2023-09-12 03:46:21.378929664    315.699219\n2023-09-12 03:46:21.488180224    316.113281\n2023-09-12 03:46:21.596950528    316.886719\n2023-09-12 03:46:21.706198016    317.539062\n2023-09-12 03:46:21.815613952    317.742188\n2023-09-12 03:46:21.924253696    317.742188\n2023-09-12 03:46:22.034498816    317.742188\n2023-09-12 03:46:22.144277248    317.742188\n2023-09-12 03:46:22.253703680    317.742188\n2023-09-12 03:46:22.362063104    317.742188\n2023-09-12 03:46:22.469947136    317.742188\n2023-09-12 03:46:22.579543808    317.742188\n2023-09-12 03:46:22.689793024    317.742188\n2023-09-12 03:46:22.800199680    317.746094\n2023-09-12 03:46:22.909536768    317.746094\n2023-09-12 03:46:23.018476288    317.746094\n2023-09-12 03:46:23.126315264    317.746094\n2023-09-12 03:46:23.237434624    317.746094\n2023-09-12 03:46:23.346261760    317.746094\n2023-09-12 03:46:23.455042560    317.746094\n2023-09-12 03:46:23.565404672    317.746094\n2023-09-12 03:46:23.673887232    317.746094\n2023-09-12 03:46:23.782761984    317.746094\n2023-09-12 03:46:23.891573504    317.746094\n2023-09-12 03:46:24.001935104    317.746094\n2023-09-12 03:46:24.111030016    317.746094\n2023-09-12 03:46:24.219781376    317.746094\n2023-09-12 03:46:24.330171904    317.746094\n2023-09-12 03:46:24.439578112    317.746094\n2023-09-12 03:46:24.549335040    317.746094\n2023-09-12 03:46:24.658912512    317.746094\n2023-09-12 03:46:24.766275840    317.746094\n2023-09-12 03:46:24.875141888    317.746094\n2023-09-12 03:46:24.985535488    317.746094\n2023-09-12 03:46:25.096804352    317.746094\n2023-09-12 03:46:25.208608256    317.746094\n2023-09-12 03:46:25.317907200    317.746094\n2023-09-12 03:46:25.426215680    317.746094\n2023-09-12 03:46:25.535474944    317.746094\n2023-09-12 03:46:25.643254528    317.746094\n2023-09-12 03:46:25.753723136    317.746094\n2023-09-12 03:46:25.863490304    317.746094\n2023-09-12 03:46:25.973873408    317.746094\n2023-09-12 03:46:26.084236800    317.746094\n2023-09-12 03:46:26.195543552    317.757812\n2023-09-12 03:46:26.304815104    317.761719\n2023-09-12 03:46:26.414710784    317.761719\n2023-09-12 03:46:26.523935488    349.542969\n2023-09-12 03:46:26.583055616    309.707031",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Memory Usage</th>\n    </tr>\n    <tr>\n      <th>Timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-09-12 03:46:19.564298496</th>\n      <td>268.496094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:20.389854208</th>\n      <td>268.496094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:20.499237632</th>\n      <td>307.890625</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:20.609534720</th>\n      <td>311.355469</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:20.718945280</th>\n      <td>333.445312</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:20.830466304</th>\n      <td>311.046875</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:20.941032448</th>\n      <td>327.332031</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:21.050358784</th>\n      <td>314.343750</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:21.159698944</th>\n      <td>314.898438</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:21.270036480</th>\n      <td>329.363281</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:21.378929664</th>\n      <td>315.699219</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:21.488180224</th>\n      <td>316.113281</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:21.596950528</th>\n      <td>316.886719</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:21.706198016</th>\n      <td>317.539062</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:21.815613952</th>\n      <td>317.742188</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:21.924253696</th>\n      <td>317.742188</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:22.034498816</th>\n      <td>317.742188</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:22.144277248</th>\n      <td>317.742188</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:22.253703680</th>\n      <td>317.742188</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:22.362063104</th>\n      <td>317.742188</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:22.469947136</th>\n      <td>317.742188</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:22.579543808</th>\n      <td>317.742188</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:22.689793024</th>\n      <td>317.742188</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:22.800199680</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:22.909536768</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:23.018476288</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:23.126315264</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:23.237434624</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:23.346261760</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:23.455042560</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:23.565404672</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:23.673887232</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:23.782761984</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:23.891573504</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:24.001935104</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:24.111030016</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:24.219781376</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:24.330171904</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:24.439578112</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:24.549335040</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:24.658912512</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:24.766275840</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:24.875141888</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:24.985535488</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:25.096804352</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:25.208608256</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:25.317907200</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:25.426215680</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:25.535474944</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:25.643254528</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:25.753723136</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:25.863490304</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:25.973873408</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:26.084236800</th>\n      <td>317.746094</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:26.195543552</th>\n      <td>317.757812</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:26.304815104</th>\n      <td>317.761719</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:26.414710784</th>\n      <td>317.761719</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:26.523935488</th>\n      <td>349.542969</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:46:26.583055616</th>\n      <td>309.707031</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the memory usage to a dataframe\n",
    "\n",
    "model_mem_usage = pd.DataFrame(model_mem_usage, columns=['Memory Usage', 'Timestamp'])\n",
    "model_mem_usage.index = pd.to_datetime(model_mem_usage['Timestamp'], unit='s')\n",
    "model_mem_usage = model_mem_usage.drop('Timestamp', axis=1)\n",
    "\n",
    "model_mem_usage"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T03:46:57.831357400Z",
     "start_time": "2023-09-12T03:46:57.802817400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGeCAYAAACZ2HuYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABqSUlEQVR4nO3deVzU1f7H8dewo4AKCK657yGYW1011/S6Ly1mV72WZabm7Vr3pllXy7yW/EoztfJa3UrTMrNsu1lqWplpGJqZmTuoqIAb6wDz/f2BM4CgMAjMDPN+Ph4+hJnvzJzPYYAP53zOOSbDMAxEREREKhEPRzdAREREpKwpwREREZFKRwmOiIiIVDpKcERERKTSUYIjIiIilY4SHBEREal0lOCIiIhIpaMER0RERCodJTgiIiJS6Xg5ugGOlpR0CVfey9lkgpCQQJePo7TcPX5QHyh+xe/O8YP79YE13uK4fYJjGFSKN0RliaO03D1+UB8ofsXvzvGD+uBKmqISERGRSkcJjoiIiFQ6SnBERESk0nH7GpxrsVgs5ORkO7oZ12QyQUZGBllZZrece3W2+D09vfDw0N8NIiKOpgSnCIZhcPFiMunpKY5uSokkJ3tgsVgc3QyHcbb4/f0DCAoKxmQyObopIiJuSwlOEazJTUBADXx8fJ3+F5Wnp4mcHCcYvnAQZ4nfMAzM5kxSUs4BUK1aiINbJCLivhya4Bw7doxnnnmGXbt2Ua1aNUaPHs39998PwLPPPss777xT4PqnnnqK0aNHA/Dpp5+ycOFCzp49S9euXZkzZw7BwcHX3SaLJceW3AQEBF3381UELy8PsrOdZwSjojlT/D4+vgCkpJwjMLCGpqtERBzEYQmOxWJhwoQJREREsG7dOo4dO8a0adMIDw9n8ODBHDp0iEcffZThw4fbHhMQEADAnj17mDlzJk8//TQtW7Zk7ty5zJgxg9dee+2625WTkwPk/aISsZf1vZOTk42Hh4+DWyMi4p4c9udlYmIirVq1Yvbs2TRs2JDu3btzyy23EBMTA8ChQ4do3bo1NWvWtP3z9/cHYMWKFfTv359hw4bRsmVL5s+fz5YtW4iLiyuz9jn7tJQ4L713REQcz2EjOGFhYSxcuBDIrV3YtWsXO3fuZNasWaSkpHD69GkaNmxY5GN3797NAw88YPu8du3a1KlTh927d1O/fn272nHl7yL9bpKyYjJVzPvJ+hru+t5V/AX/dzfuHj+4Xx+UNE6nKDLu1asXJ0+epGfPnvTr14+9e/diMpl49dVX2bp1K9WrV+fee++1TVedOXOGsLCwAs8REhJCQkKC3a995XkWGRkZJCd74OlpwsvLdeonvLw8uPnmmwD46KPPqFWrdoH7P/zwA+bP/zfjx0/ggQcmOqKJpTZs2EDuv/9BBg0aUuD2Tz9dz/Llr/HRR5851dfKYjHh4eFBjRpV8fPzq7DXLcnZLJWZ4lf87s7RfWAYhlONYDtFgrNo0SISExOZPXs28+bNo02bNphMJho3bszo0aPZuXMnTz31FAEBAdx2221kZGTg41OwtsHHxwez2Wz3a195OFlWlvny/jeG0xSuFid/ka2XlxdbtnzD7bePLHDNN99swmQyYbG4Tlz5FdVuiyXvC+dMMeXkGFgsFs6dS8XbO6vcX8/dDtq7kuJX/O4cPzhHH7yw6RBbDyWxcuxNBPiWb2rhUodtRkREAJCZmcljjz3Grl276NmzJ9WrVwegZcuWHD16lFWrVnHbbbfh6+tbKJkxm822Gh17XHk4mat/g0RG3sR3320tkOCkpqawd+8vNGvWwoEtcz8VffCdux+0p/gVvzvHD47tg40HznImxcyBM6m0q1fNMY24gsMSnMTERGJjY+nTp4/ttqZNm5KVlUVKSkqhJd+NGzdm+/btAISHh5OYmFjo+WrWrFn+DXdy3brdypIlL5GamkLVqrmrzrZt+47IyCjS09MLXPvRR2tZufItzp8/R4sWrfj73/9JkyZNAbjjjsGMG3c/H320lsOHDxEZGcXjjz/Jyy+/yPbt26hfvwH/+tccGjduAsDevXtYsuQl/vjjd2rUCOYvfxnLsGF3ADB37mwADhz4naSkREaMuJMtWzbx1lurbW1ZtWoF3377DUuXLi917GvWrGb16hWcO5dMo0ZNmDr1USIjowD47rstvP76axw7dhQfHx86d/4Tjz/+JFWqVAFgw4YvWL78VZKSEunWrQeGYXDDDQ0YP/5BDMPgrbdeZ926D8jMzKBt23ZMm/Y4tWrVKnVbRUQqk5TM3BXI5hznGU13WOFCfHw8U6ZM4fTp07bb9u7dS3BwMO+88w7jxo0rcP3+/ftp3LgxAJGRkbbVVgCnTp3i1KlTREZGllt7DcMgPSunQv8ZpUjFGzduSmhoGNu3/2C7bevWb+jWrUeB6777bitvvrmMRx75B2+8sZLIyHZMnfogFy9etF3zn/+8woMPTmbp0uX88cfv3HvvX+jYsTP/+c/b+Pn5sWzZEgCOHj3C1KkPERV1E2+8sYL77pvA4sUL2bJls+25vvzycx544CGioxfSr98ADh06yPHjx2z3b9r0Fb1797U7XqsDB/azdOlLPProdFau/IDIyCj+9a/HsVgsnDgRz5NPPs7w4XeycuUHPPPMc8TE7GD9+g8B2L07lnnznuGee8byxhsr8ff3Z9Omr2zPvXbte2zY8AWzZj3La6/9l+DgYKZNm0x2tnMf4yEiUhGyLQZpWbkJTrYTbLpq5bARnIiICNq0acMTTzzBjBkzOHHiBNHR0UycOJF27dqxbNkyXn/9dW677Ta+++47PvroI95++20ARo0axZgxY4iKiiIiIoK5c+fSo0cPu1dQlZRhGNy/ejd7Tl4s/uIyFFkniP/cHWl30Va3brfy/fdb6d37NsxmMzt3bmfatH+yYcMXtmveffdtxoy5ly5dugHwwAMP8cMP37Nhw+fcccfdAAwYMJiOHTsDcNNNHUlKSrSNyvTrN4D3338XgE8+WUfz5i148MHJANxwQ0OOHj3Cu+++TffuPQFo2bI1Xbveanv9Vq3asHnz1/z1r+NJSDjFgQP7mT9/QWm6CchNck0mE7Vq1aJ27To88MAk/vSnblgsFiwWC4888g+GDMktUq9duw7t23fiyJHDAKxbt4ZevW5j2LDbAXj00en8+GNegvjuu+8wbdrj3HRTBwD+8Y8nGDr0z2zfvq1ATCIi7ig1M++PPWcawXFYguPp6cnSpUuZM2cOI0eOxN/fnzFjxjB27FhMJhMvvfQSixYt4qWXXqJu3bq88MILtGvXDoB27drxzDPPsGjRIi5cuECXLl2YM2dOubbXeerCi9e1a3eefPJxsrOziYnZQePGTalRo+CU37FjR1i69GVee22J7Taz2Uxc3HHb53Xq1LV97OvrW2Bllq+vL1lZuQW0R48epXXrNgWePyKiLR9/vNb2ee3aBVd13XZbPz7//FP++tfxbNr0Fe3atS/URisvL68iz5qyWCx4eeW+hTt3voXGjZsyduzdNG/egq5duzNkyHC8vLyoX/8GvL19eOut1zl8+BBHjx7myJHD9Os3AIBDh/5g6NARBV6vZcvWAKSlpXHmzGlmzZpRYFfizMzMAn0lIuKuLuVLcLKU4OQKDw9n8eLFRd7Xp0+fAvU5VxoxYgQjRoy46v1lyWQy8Z+7I8mo4JU6fl4epVpy17ZtFAB79sSydesWbr21R6FrcnJymDp1Gh06dCpwe9WqVW0fe3p6FrjvascOXLmiLff5LeTke6NfuTN0r159Wbx4IfHxcWzevJGhQ4df+RQ2AQGBpKYWPvg0JeUSAQG5lfS5U2b/JTZ2F99/v5XPP/+Ejz5ay+uvv8P58+eZNOl+una9laiom7j77r/w/vur8sXpVagwzzo9aN3Zes6c57nhhgYFrgkKco2jPEREylPq5fobgCwnmqJyns1DnJzJZMLf27NC/5V2PwEvLy9uuaUL33+/lW3btnLrrT0LXVO/fgPOnj1DvXr1bf/efvsNfv31F7tf74YbGvDrr3sL3Pbrr3sKJQT5hYaG0q5dez77bD2HDv3Brbf2uuq1TZo0Ze/ewu3at+9X28qwvXv38M47b3LTTR14+OFpvPvuWszmTPbsieXLLz8nKqods2Y9y/Dhd9CqVRvi44/bkphGjRrz+++/2Z43JyeHgwcPABAYGEiNGsEkJyfa+ik8vBZLly4qUEMkIuKuLjnpFJUSnEqqW7fufPLJx9SoEVJgqsnKOorxv/99xokT8SxduohNm76iQYNGdr/W8OF38scfB3jttSUcP36ML774lA8/XMOIEXde83F9+vTjvffepUOHztccDRk+/A6+/fYb3nrrdeLj4zh06CBvvLGM77/fansNX19f3nzzP3zyyUecOnWSjRs3kJ6eTpMmzahWrRqHDh1k3769HD9+jJdfXsBvv+0jKyt3q4Hbb7+LjRs38OmnH3H8+FEWLXqBU6dO2hLMkSPvYdmyV/juu63ExR3nuefm8Msvu7nhhoZ295WISGWToikqqUidOt1CdnY23bp1L/L+3r37kpyczPLlr5KcnEyjRo15/vkF1K9/g92vVatWLebPX8DSpS+xevUKwsNrMWXK3xk4cMg1H9e9ey/+7//m0afPtVdPtWzZmujohbz55nJWrHgLk8lE8+YteOGFl2nWrDkAzZq1YMaMf/Hf/y5nwYL5hIfX4qmnnqFhw0aEh9fiwIHfeeSRyfj4+BAV1Y57732Ar7/+EoAbb2zLtGmP88Yb/+HChfP07NmHG29si7e3NwCjRo0hLS2N6Oi5pKam0rJla1588WVNUYmIACnm/AmO80xRmYzSrEWuRBITC+9knJR0ipCQ2nh7u8ZJ0Pl3MnYlcXHHuffee1i/foNtP5rSuN749+3bS0BAQIERmdGj7+Kee8YwYMBgu5+vot9DJhOEhgYWei+7C8Wv+N05fnB8H6zadYIXNx8CYFLXhtzb2f4/lO1hjbc4GsGRCpeWlsqPP/7Axx9/SJ8+/a4ruSkLe/f+wtq17/Hkk08TEhLK119/yZkzp+nc+RaHtktExBVoikokn+eff5Y6derxr3+V7/L+khgx4k5OnTrJzJn/JCUlhWbNmvN///cSISGhjm6aiIjTK5jgOM8wmhIcqXBVqlTlf//7xtHNsPHy8uJvf3uUv/3tUUc3RUTE5aRoFZWIiIhUNpe0D45rcfPaa7kOeu+IiDtx1hocJThXsO7eazZnOrgl4qqs7x1PT80Ai0jl56wJjn4CX8HDwxN//wBSUs4BuUcMlHZH4YpisZjIcaJhwYrmLPEbhoHZnElKyjn8/QOuerSFiEhlUrAGx/E/i62U4BQhKCj30EdrkuPsPDw8ijyM0l04W/z+/gG295CISGWXUqAGx3l+FivBKYLJZKJatRACA2uQk5Nd/AMcyGSCGjWqcu5cqltucuVs8Xt6emnkRkTchmEYV5wm7gQ/iC9TgnMNHh4eeHg4927GJlPuSdre3llO8Qu+orl7/CIijpSZbSHbkvfDV8vERURExOXlr78ByFaCIyIiIq4uf/0NOFeRsRIcERERKZVLV4zgaIpKREREXF6K+copKo3giIiIiIuzTlF5e+buF6cRHBEREXF51imqGv7egHPtg6MER0REREol9XKCE1wld0sVZ9oHRwmOiIiIlIptBKdK7giOpqhERETE5VlrcIKraIpKREREKom8EZy8KSrDSbaVd2iCc+zYMcaPH0+7du3o0aMHy5cvL3TNpUuX6NatGx9++GGB2z/99FP69OlDZGQkkydPJjk5uaKaLSIiIuTtZGwdwTGAHIubJzgWi4UJEyZQo0YN1q1bx9NPP80rr7zCJ598UuC66Ohozpw5U+C2PXv2MHPmTKZMmcJ7773HxYsXmTFjRkU2X0RExO1dWWQMzrObscMSnMTERFq1asXs2bNp2LAh3bt355ZbbiEmJsZ2zU8//cT27dupWbNmgceuWLGC/v37M2zYMFq2bMn8+fPZsmULcXFxFR2GiIiI27p0uQbHWmQMzlOH47AEJywsjIULFxIQEIBhGMTExLBz5046deoEgNls5qmnnuJf//oXPj4FT/TevXs3HTp0sH1eu3Zt6tSpw+7duys0BhEREXdmnaKq5u+N6fJtzpLgeDm6AQC9evXi5MmT9OzZk379+gHw6quv0rp1a7p27Vro+jNnzhAWFlbgtpCQEBISEux+bZOp+GucmbX9rh5Habl7/KA+UPwF/3c37h4/OLYPrEXGgb6e+Hh5kJltIctilGtbSvrcTpHgLFq0iMTERGbPns28efO4++67Wb16NevXry/y+oyMjEKjOj4+PpjNZrtfOyQksFRtdjaVJY7Scvf4QX2g+BW/u6voPrBYDNKycqeoGtSpbktwAoL8CQ0NqNC2FMUpEpyIiAgAMjMzeeyxx/jll1+YOnUqoaGhRV7v6+tbKJkxm834+/vb/dpJSZdwkhVtpWIy5b6pXT2O0nL3+EF9oPgVvzvHD47rg0sZ2bbXM6dk4HV5aOVMYgpBpvJriDXe4jgswUlMTCQ2NpY+ffrYbmvatClZWVnExsZy4MABnn/+eQDS09OZNWsWn3/+OcuXLyc8PJzExMRCz3dlMXJJGAaV4puissRRWu4eP6gPFL/id+f4oeL7wDo95evlgbenh+3Azcxsi1N8LRyW4MTHxzNlyhS2bNlCeHg4AHv37qVatWqsWbOmwLVjxoxhzJgxDBkyBIDIyEhiYmIYMWIEAKdOneLUqVNERkZWbBAiIiJu6lJGboJT1ccTAB+v3HVLbl9kHBERQZs2bXjiiSeYMWMGJ06cIDo6msmTJ9OgQYMC13p5eRESEmJLhEaNGsWYMWOIiooiIiKCuXPn0qNHD+rXr++IUERERNxOitlaYJybSnh7WBMcJxi+wYEJjqenJ0uXLmXOnDmMHDkSf39/xowZw9ixY4t9bLt27XjmmWdYtGgRFy5coEuXLsyZM6cCWi0iIiKQdw5VgDXBuTxF5SwHbjq0yDg8PJzFixcXe92mTZsK3TZixAjbFJWIiIhULOseOAG+V05ROccIjg7bFBEREbulZF45RZU7guMsNThKcERERMRu1lVUVW1TVLkphbNMUSnBEREREbtZa3CsIzjWKapsTVGJiIiIq7p0RQ2Ol4dzFRkrwRERERG7pV5Rg+OjKSoRERFxdYWWiWuKSkRERFydrcjYp+AqKo3giIiIiMuyLRP3u7wPjqdzHdWgBEdERETsZisy9im4TFwb/YmIiIjLSjVfXibu55xHNSjBEREREbuYsy1kZucmMtYRHB+N4IiIiIgrs54kbgKqXt4HxzqCoxocERERcUnWJeJVfDzxMOUmNjqqQURERFxa3i7GXrbbVGQsIiIiLu3Kk8QBfDRFJZIr2+IcWb6IiNgn5YpzqEAjOCIAvLj5ELct3capixmOboqIiNgppcgpKi0TF+GHo8mkZObwy8mLjm6KiIjY6dIV51CBlomLAJCcllXgfxERcR1F1eB466gGcXdZORYuZuR+c5xLMzu4NSIiYq+ia3A0RSVu7nx63qhNkkZwRERcTtGrqHJTCmdZQKIERypc/mmpc0pwRERcjnWjv6pFFRlnawRH3FRyvmkpTVGJiLievJPECy8T1xSVuK38ozaaohIRcT22KSo/TVGJ2BScotIIjoiIq7EVGfvkJThemqLKc+zYMcaPH0+7du3o0aMHy5cvt9337bffMmTIENq2bcuQIUPYsmVLgcdu27aNQYMGERkZydixY4mLi6vo5ksp5U9q0rMspGflOLA1IiJirxRz7s/tooqM3X6ZuMViYcKECdSoUYN169bx9NNP88orr/DJJ59w7NgxpkyZwogRI/jss88YPnw4kydPJj4+HoCTJ08yefJkRowYwQcffEBwcDCTJk3CMJxjWEyu7cppqWSN4oiIuAzDMIpcJm5NcHIMyHGCaSqHJTiJiYm0atWK2bNn07BhQ7p3784tt9xCTEwMCQkJ3HXXXYwbN4769etz7733UqVKFfbs2QPAmjVruPHGG7nvvvto1qwZ8+bN48SJE+zYscNR4YgdrpyW0koqERHXkZaVgzV/yb+TsXWKCpxjFMdhCU5YWBgLFy4kICAAwzCIiYlh586ddOrUic6dOzNz5kwAsrKyWLNmDWazmbZt2wKwe/duOnToYHsuf39/2rRpQ2xsrCNCETtdmdAkpSrBERFxFdYl4l4eJny98tII6wgOOMdxDV7FX1L+evXqxcmTJ+nZsyf9+vWz3X7s2DH69+9PTk4Ojz76KPXq1QPg7NmzhIWFFXiOkJAQEhIS7H5tk6n4a5yZtf2uFId1Siq4ijfJaVmcTzeXuv2uGH9Zc/c+UPwF/3c37h4/VHwf5D9o08Mj70V9vPI+zrZYyq09JX1ep0hwFi1aRGJiIrNnz2bevHk8+eSTAAQHB/PBBx/w888/89xzz9GgQQP69etHeno6Pj4+BZ7Dx8cHs9n+Wo6QkMAyicHRXCUOwzA4l5b7zdGqThDfH0wi0+RBaOj1tf96408zZ1PFxym+HUrNVd4D5UXxK353V1F9cDQld9S9ehXvQj+7vT1NZOUYBFSrQmh1/wppz9U4xU/0iIgIADIzM3nsscf45z//iY+PD4GBgbRu3ZrWrVtz6NAhVqxYQb9+/fD19S2UzJjNZoKCgux+7aSkS7hybbLJlPumdpU4UjKzbZtA3RDkx/dA3NlLJCZeKtXzlUX8v5y8yP2rYvlr5/pM6tqodE/iQK72Hihril/xu3P8UPF9EH/6IgD+Xh6FfnZ7e3iQlZPD6bOX8MnOLpfXt8ZbHIclOImJicTGxtKnTx/bbU2bNiUrK4vY2Fg8PDwK1Nk0adLEVkQcHh5OYmJioedr1aqV3e0wDCrFN4WrxGGtt6nq40mtIF8AklOzrrvt1xP/zuPnyTFg+9HzPNTl+trhSK7yHigvil/xu3P8UHF9cOlyDU6Ar1eh1/P2NEFW7m7Gjv56OKzIOD4+nilTpnD69GnbbXv37iU4OJjY2FiefPLJAsu+f/31Vxo3bgxAZGQkMTExtvvS09PZt28fkZGRFReAlEpyau7IW40q3gRXyZ1mTE53bJHxifMZAMSfT3doO0REXMGlfDU4V7Ie15CV7fhs02EJTkREBG3atOGJJ57g4MGDbNmyhejoaCZOnMiQIUM4e/Ys//d//8fRo0dZuXIl69ev58EHHwTg9ttvZ9euXSxbtow//viDGTNmUK9ePTp37uyocKSErMlMDX8falTxzr0t1bH74Jy4kJvYXMzI5oKDky0REWeXd5K4Z6H7fKy7GbvzMnFPT0+WLl2Kv78/I0eOZObMmYwZM4axY8dSq1YtXn/9dXbu3MnQoUNZuXIlL730Em3atAGgXr16vPzyy6xdu5Y77riD8+fPs2TJEkzuXEbvIqx74IRU9Sb4coLj6H1wTlzIsH0cn+9jEREpLKUkIzgWxyc4Di0yDg8PZ/HixUXeFxUVxfvvv3/Vx3bv3p3u3buXV9OknFjPoco/RXU+PYsci4GnR8UnqFk5Fk5fyrR9Hn8unTa1tBpDRORqrPvgBBSx8lRTVOK28mpwfKjm740JMMhNchzh1MVM8u8oHqc6HBGRa7KN4PgVleBoikrc1LnLiUywvzdeHiaq+9s3TXXiQjr//uoAx5LTyqQ91vobKxUai4hcm63I2KeoGhzrFJVGcMTNWKeogqvmTk9ZC42TSnjg5trYU6zbk8CqXSfKpD3WFVTW6bH486rBERG5FusUVWBRNThe1ikqjeCImzmX75iG/P+XdATn5MXcBKSsRnCsCU3bOrmbRGqKSkTk2q5ZZOyhKSpxU/mLjIG8vXBKOIJz6mJuQfDxc2WTiFinqG5uUMPWvlRz+ey+KSJSGaSYrcvECyc4mqISt5SVY+FiRu43RrB/wSmq5BKO4CRcHsE5k2ImPSvnuttkXSLeIizAVg+kaSoRkau7dPnneNUi9sHJW0WlERxxI9aVUp4mCPLPzfytIzjnSjCCk5ltKZAIxV3nKI5hGJy8nODUreZH/ep+AJzQNJWISJGycyxkXE5eit4Hx3mmqEq1D86BAwfYt28fSUlJeHh4EBoaSuvWrWnSpElZt08qEWtyUr2KDx6XN2UMtmMEJ/9+NZA7TdUiPKDU7TmfnkWqOQcTULuaH/Wq+/PLqUvEaQRHRKRIKea8kfOiEhzrFFW2E0xRlTjBuXDhAitXruS9994jMTGRevXqUaNGDSwWC+fOnePEiRPUqlWLu+66i1GjRlGtWrXybLe4oOQrCowhdz+c3PuKT3BOXSyYeFxvHY51eqpmgA++Xh7Ur+4PqNBYRORqrAXG/t4eeBWxOattBMcJpqhKlOCsWbOG1157jW7dujFnzhxuvvlmfHx8ClyTmprKzz//zGeffcbQoUN56KGHGDlyZLk0WlyTdaVUDf+8BCdvFVXxU1SnL145gnN9K6msS8TrXk5s6l6eotJeOCIiRcs7h6ro9MFag2POcZERnPj4eNatW0dg4NW3sK9atSpdu3ala9eunDt3jjfffLPMGimVw5V74OR+nDdFZRjGNc8Ts47gVPPz4kJGNsfPXd9UUvzlFVR1q+UmNrYRnDJaoSUiUtlYN/mrWkyCk+0EZ1GVqMj473//+zWTmyvVqFGDadOmlbpRUjlduQdO7se5yU5mtoW0YlZFnbpcg9PxhupAGY7gXJHgnEkxk1EGK7RERCqba23yB/lOE3eCKSq7VlGlpKSQkpJi+/zQoUPMnz+f5557jt27d5d546RySSpiisrf2xN/79y3YXGb/Z2+PIJjTXAuZGRf1xlW1hqcepcTm2r+XgRcXvZ48qIKjUVErmQ7pqGIJeKQb5m4E0xRlSjBSU5O5oEHHqBjx4506tSJyZMns3v3bu644w42bdrE5s2bGTVqFF999VV5t1dcWN4ITsH6LWuhcVLqtetwrJv8NQqpSlhA7mOuZzrpxIWCIzgmkynfNJUSHBGRKxVfg5M7gpPlKlNUTz/9NFlZWaxevZp169ZRpUoVxo4dy8iRI/nf//7Hl19+yUMPPcRrr71W3u0VF3bOVoPjXeD2khzXYDEM2zLxWkG+3FAjNxE5VsoEx5xt4czl57MWFwPUrZb7vCo0FhEp7FrHNEDeMnFztouM4Gzbto3p06cTGRlJixYtmD17NmazmcGDB9uuGTFiBAcPHiy3horryzumoeAIju24hmtMNyWlmsm2GHiYoGaALzfUqAKUfgTn5MUMDHKXOuafMqtfIzfZ0VJxEZHCrDU4VX2KGcFxgo3+SpTgXLp0iZCQENvnVatWxc/Pj6CgINttvr6+ZGZmFvVwEQzDKHIfHMh3XMM1pqgSLk9P1QzwxcvDRP3LIzil3Qsnf/1N/pVb1nqcE9rsT0SkkLwpqmJqcFxligrAw0OnOkjppZpzbEVn+UdMoGRTVNYl4rWDfAHyTVGVbiXVlSuorLTZn4jI1V0q6RSVExQZl3gn4y+++IKAgLxt8S0WC1999RXBwcFA7iiPyNVYp6eqeHvi510w8w8uwW7G1vqb8MCCCc7x5HQMw/5vJOsp4nUKJTi5n5+6mEFWjsX214iIiOQd1VBskbETLBMvUYJTp04d3njjjQK3hYSEsGLFigK31a5du+xaJpWKbQXVFQXGkP88qqtPUVlXUNUOyk1A6lbzw9MEGdkWTl/MtPtQtbwRHP8Ct4dU9cHPy4OMbAunLmbaEikREYGUjGuP4ORNUbnICM6mTZvKux1SyeXtgeNT6L68E8WvPoKTcHmKqtblKSpvTw/qVPMj7nwGRxJTaVat8PNeS14NTsERHJPJRL3q/hxMTCXufLoSHBGRfFLM194Hx8e2D46LjOCcPHmyxE9Yp06dUjdGKq+idjG2qlGCEZwE2xLxvITkhhpVSpXgGIZhm6K6sgYHcpOeg4mpnFAdjohIAZeKGcHxcqKdjEuU4PTq1avASpMrax5MJpPtHKHffvutbFsolULeEvGrT1FdyMgmO8eCVxF1L9ZVVLUu1+AAuSupjsCRxBRoUsOutqRnWTCRN+WVX16hsVZSiYhYGYZhq8EprsjYZaao2rZty6+//kpERAR9+/bl1ltvxd9fQ/dScueKOGjTqpq/Nx4msBhwPj2L0ADfAvenZGbbKvetU1SQV2h8JDHVrrZYp6fCA33x8SqcTNWroc3+RESulJltIedy4nL1s6icZ4qqREtE3n//fTZv3szQoUP5/vvvufvuu5kzZw7bt2+nSpUq1K1b1/bPHseOHWP8+PG0a9eOHj16sHz5ctt9sbGx3H333bRr145+/fqxZs2aAo/dtm0bgwYNIjIykrFjxxIXF2fXa0vFsu2B4194BMfDZKK6f96p4leyTk8F+XkV2FzKmuActjvBuTw9Vb3w6A1AvcvTVjpVXEQkj/UPTU8TtjMEr+RMU1QlXgMbFhbGqFGjeP311/nmm28YNGgQ3377LX379mXMmDG8/fbbdtXqWCwWJkyYQI0aNVi3bh1PP/00r7zyCp988glnz57lgQceoFOnTqxbt46pU6cyZ84cvvnmGyC3Jmjy5MmMGDGCDz74gODgYCZNmlSq5cJSMa41RQX5l4oXrsOxFRgHFhzZaXA5wYlLTiPbjuHQ+KvsgWNl3UTwxIUM218rIiLuzrqLcYCvV4GylfysIzj2/EwuL/aurgUgICCAQYMGMWjQIMxmM++88w4vvfQS8+bNK3ENTmJiIq1atWL27NkEBATQsGFDbrnlFmJiYkhJSSE0NJRp06YB0LBhQ3788Uc++eQTevTowZo1a7jxxhu57777AJg3bx5dunRhx44ddO7cuTQhSTm72kGbVnlLxYsYwblYuMAYICzQF18vDzKzLSRczCi05Ptq8g7ZLPr6sABfvD1NZOUYnEnJLLJOR0TE3VhHcKpeZXoK8vbBMTvBFFWpEpycnBx27NjBpk2b2LRpE4mJidxyyy307t27xM8RFhbGwoULgdzCpV27drFz505mzZpF27ZtadWqVaHHpKSkALB79246dOhgu93f3582bdoQGxurBMdJXe2gTasa10hw8vbAKTiC42EyUa+6H4cS0ziWnF7iBOfk5dqaK5eIW3l6mKhbzY+jyenEnUtXgiMiQvEniUO+fXByDNviI0cpcYKTkpLCli1b2LhxI99++y2enp707NmTGTNm0KVLl+sqOu7VqxcnT56kZ8+e9OvXD09PT+rVq2e7Pykpic8++4yHH34YgLNnzxIWFlbgOUJCQkhISLD7tR3Y92XC2n5njiM7x8KFy0sLQ6r4FNlWa/HxuTRzoftPX8rbA+fK+xrUqMKhxDSOn0+nSwn7wDaCU93vqv1Wv7o/R5PTib+QTmdTyVdoOYIrvAfKk+Iv+L+7cff4oeL6IP8eOFd7Ld98CzdyDANvj7JvVEnjLFGCM27cOH766Sfq1q1Lr169eOWVV2jfvn2ZZWaLFi0iMTGR2bNnM2/ePJ588knbfRkZGTz88MOEhoYycuRIANLT0/HxKTjV4ePjg9l89X1UriYkJPD6Gu8knDmO05draDxM0LheDTyKeMPXr5l7DEiaBUJDC8aSmJ77TdW8bo1C97WoW41NfyRyJi270H1FycjK4UxK7vukbeOaRa7qAmhaO4hvDyeTlGkp0fM6A2d+D1QExa/43V2594F3MgDBgX5X/bkYkJVj+ziwetWrLievCCV65e3bt+Pl5UVWVhZffvklGzZsuOq1GzdutLsRERERAGRmZvLYY4/xz3/+Ex8fH1JTU5k0aRJHjx7l3XfftY0S+fr6FkpmzGZzgdPNSyop6RKuXJtsMuW+qZ05joNncqcWa/h7k5ycUuQ1vpcbfzI5lcTEgueaxSfnrpKqarIUui/ML3c3zQOnLhS6ryhHknIP56zq40lOWgaJ6ZlFXhd6eZfOAydL9ryO5ArvgfKk+BW/O8cPFdcHpy6vWPU1cdWfi/kXZiScvkj1qywsuR7WeItTogRn3rx5192gKyUmJhIbG0ufPn1stzVt2pSsrCxSUlLw8fHh/vvv5/jx47z11ls0bNjQdl14eDiJiYmFnq+oup3iGAaV4pvCmeNISrWeQ+Vz1TbmP1E8/zXZORbOXh5xCQ/0K/R464qn4+fSSxS/dW+b3BVUpqs+pl516144GU7br1dy5vdARVD8it+d44fy7wNrDU5VH8+rvo6HyYSnCXKM3EJjR35NSpTgDBkyBE/Pos+duJrs7Gy8vK7+9PHx8UyZMoUtW7YQHh4OwN69ewkODqZ69ercd999xMfH884779CkSZMCj42MjCQmJsb2eXp6Ovv27WPKlCl2tVEqxjnbOVRXz+RrXOVE8TMpZixGbmV+Ucc83HA5EUm4mElGVk6hk8qvZFsiXv3aNWN5uxmnO7xQTkTEGZSkyBhyC41zsi0OX0lVon1w7rzzTj766COysq5+GKJVZmYma9as4c4777zmdREREbRp04YnnniCgwcPsmXLFqKjo5k4cSIffPABP/74I88++yxBQUGcPXuWs2fPcv78eQBuv/12du3axbJly/jjjz+YMWMG9erV0woqJ1XcHjhQ8ETx/PsZncq3B45HEUlGjSreBPp5YQDxF4o/WiFvifi1V0bVDvLF05S7c2diqv21XSIilY11mXhxdTW2lVTZjh1SK9EIzvLly4mOjmbevHl07dqVP/3pTzRp0oQaNWqQk5PD+fPn+f3334mJiWHr1q10796dZcuWXfM5PT09Wbp0KXPmzGHkyJH4+/szZswYxo4dy/3334/FYuHBBx8s8JhOnTrxzjvvUK9ePV5++WX+/e9/s2TJEtq1a8eSJUv0V7aTKm4PHMgb3cnKMUg159i+gU5f3sU4/CpLtU0mE41Dq7I7/gLHz6XTNLTqNdty4vzVD9nMz8vTg1pBfpy4kEHc+XRqXnF8hIiIu0m9fA5V8SM4ub+LsyyOHcEpUYITHBzMvHnziI+P5/3332fFihX8/vvvWC433tPTkxYtWtCtWzfWrl1L/fr1S/Ti4eHhLF68uNDtr7/+erGP7d69O927dy/R64hjJVn3wLnGCI6ftydVfTxJNeeQnJZlS3CsIzi1A6+eYDS6nOCU5GgF6wjO1fbAya9+dX9OXMgg/lwGN9Ur9nIRkUot7yTxa5cCWHczNue4wAiOVb169Zg2bRrTpk0jJyeHCxcuAFCjRg2NnshVlWQEB3Knm1LNOSSnmm3nTOXtYnytBCd3ifnxc2nXfH7DMIrdxTi/etX94BjEXyi/M6msy9bPpmRyJiWTs5fMJKaa7d7m3N/fm/T04qeQnYF1CvLKCEtdjGgCPz9vMjKyCj+pO1D87h0/FNkHBkZu0TG533OGARYAw8CS7/b8ivsePHx5FWrxU1SXR3AcfB5VqReoe3p6EhwcXJZtkUrqXAlqcCA3AYo/n0Fyvl/UVzumIb9GNXOnpY4XM4KTlGomM9uCh+naCZOVdYVW3Lnia3tK6khSGl/9foZvDyVz8mIGFy//RSQi4iqu9fMY8tXguMIUlcj1SC7BFFX++5PzFfUmXCr6oM38GoWULMGxjt6EB/ravgGvJW+p+PWN4MSfT+er38+yYf9ZDhZx8rmflwdhgb6EBfhQM8CXmgE+tiHekjCZwL+KL+lpmS6zTNa28yq2D/L/Z/dzVaniS5oLxV+WFL97xw9X7wOTCdviDA9T7nebyZRbu2j9uODzFP8deEN1f9sI+9W45BSViL0Mw7CdEH61XYOtrFNY1hEfwzDynUN19b8YGoZWAXITqZTM7KsOn+Yd0VCyY0WsdTqlWSqelGrm832n+er3s/x2Om9zQ08PEzc3qEGfFqG0Cg8kLMD38rbnpZ/iNZlyd39OTHTPjc4Uv+J35/jB+frA5aeoREoi1ZxD1uUs/lr74ED+AzdzE6IL6dlkXv4GCbvGCE6gnzchVX1ISjVz/Fw6rWsVvcNlfAlXUFnVreaP6XIM59OzbHv1XI1hGMTEXWDt7lN8czDRVkfjaYION1TnthY16dE0lGrF9IOIiCvLm6JywRGcnJwcvv32W44ePcqIESM4cuQIjRs3JjBQZ4FIQdbpqSrensVuwhd8xYnipy5PT4VU9SlwgFtRGtTwLzbBKekeOFa+l6eOTl/KJP58xlUTnPPpWXz262k+3HOqwDTZjbUDGdg6nN7NQ4tNjkREKgsf24niLjaCc+rUKcaPH8/58+e5cOECvXv3Zvny5fz888+8/vrrtGjRojzaKS7KuoKquAJjyD9FlfuYBNv0VPEFwTfU8GdX/IVrrqQ6cd66RLxkU1QA9av7cfpSJnHn04mok3vWWY7F4EhSGntPXeSnuPNs/iPRNtdcxduT/q3DGN62Ni3CAkr8OiIilYXX5Skqs6tNUT3zzDO0b9+e2bNn06FDBwBefPFFZs6cybPPPss777xT5o0U15W3B07xIxg1rhzBuVh8gbFV/jOpribezhEcyE2Gfoq7wNZDSRxOSuPXUxfZl5BCWr4TcwGa16zK7ZG16dcqjKo+mvkVEffl46pTVD/99BPvv/9+gbOpvL29mTRpEsOHDy/Txonry9sDp+QjONYEx7qLcXFLEiF3igqunuBkZOXYDv20N8EB2Hig4OGu/t4etK4VSJtaQfRsFkKbWoHaC0pEhHxFxq42ReXn50dSUhKNGjUqcPuRI0cICNCQvBRUknOorKxJ0KXMbLJyLLYVVCUZwbmhwKnihVc8WetvAnw9CfIr+du+e9MQ1sSeJMDXkxtrBdGmdiARtYNoFFIFTw8lNCIiV7IWGbvcFNXdd9/Nv/71L/75z38CuYnNjh07WLBgQbEHbIr7OVfCPXAAAv288PQwkWMxOJeWRYJ1iqoEIzj1queteEpOyyLkiiXptiMaqvnbNdLSMLgKn07QIa4iIiXlslNUkydPJigoiNmzZ5Oens6ECRMICQlh3LhxjB8/vjzaKC4suYTHNEDuRlQ1/L1JTDWTnGYu0TENVj5eHtSu5sfJCxkcP5dOSFUfUjKz2XHsHN8fSea7w8kA1C3BGVQiIlJ6LjtFBTBmzBjGjBlDWloaOTk5Wh4uV2XPFBXkjvQkppo5dTGTc5ePbCjJKirI3WHz5IUM3o2J57VtR4k9cZGcfH9BVPH2pH+rMDsjEBERe+RNUbnYCE5Rp39D7hbP3t7ehIWF0a1bN0JCQq67ceL6SnrQplXudan8dvoSkJuUBBZzsJvVDTX82X7sHN8cTLLd1qCGP10aB/OnRsG0q1sNn2L20xERkevjc3kEJ9vVzqI6cuQIn3/+ObVq1eLGG2/EMAx+++03Tp48SVRUFJcuXeLZZ59l+fLlREVFlUOTxZWU9KBNq+CqudftS8hNcGoF+Za4ZqZ/6zC2HztHvep+dGmUm9TYs+eNiIhcP9sIjitOUd1xxx3Mnj3btlTcYrEwd+5c0tLSmDdvHq+++irPPfccq1evLtPGimvJzrFw4fJp2SUpMgao4Z870mM9v6kk9TdWN9YOYu19He1spYiIlCXbUQ0OPmzT7vH6TZs2cd999xXYB8fDw4PRo0fzv//9D4CBAweyf//+smuluCRrDY2HiRKfv2RNhC5eToyudcimiIg4H2cpMrY7wQkNDeWnn34qdHtMTAzVq1cHIDExUXviiK3AuLq/Nx4lnGayTlFZhZdgDxwREXEePrYpKhcrMn744YeZOXMmMTExREREYBgGv/76K5999hn/+te/OHLkCI8//jgDBw4sj/aKC7G3wBgodCilRnBERFyLs4zg2J3gDBkyhDp16rBq1SpWr16Np6cnTZs25e233yYqKoo9e/YwevRo/vKXv5RHe8WF2LtEHArX6pRkF2MREXEe3q56mjhAhw4dbAdtXqlt27a0bdv2uhollUOyHbsYW1052mNPkbGIiDiey05Rpaen895773Hw4EFycvJOVDabzezbt48vvviiTBsorqtUU1T5ipE9TRAaoARHRMSVWKeosl2tyPjJJ59k2bJlpKens379erKysjh48CCfffaZ6m6kgNJMUfl4edg29gsL9MVLB1qKiLgUb1cdwdm6dSsvvfQSf/rTn/jjjz8YN24cN954I8899xx//PFHebRRXFTeOVQlT3AgNyG6lJmt+hsRERfk4yQb/dk9gpOZmUnDhg0BaNasGXv37gVg5MiRRS4fF/dkGAbx53NP8L5yZVRxrAlRSU4RFxER5+KyU1RNmjRh27ZtQG6CExMTA8ClS5fIzMy067mOHTvG+PHjadeuHT169GD58uVFXlNU0fK2bdsYNGgQkZGRjB07lri4OHtDkXL01e9nOX4uHX9vD26sbd9hrNaaHRUYi4i4HpedopoyZQp/+9vfsFgsDB06lIEDBzJx4kR+//13unXrVuLnsVgsTJgwgYiICNatW8exY8eYNm0a4eHhDB48GIBTp07x4IMPFkqcTp48yeTJk3n44Yfp1q0bS5YsYdKkSaxfv77E5xZJ+cnMtrDk2yMAjOlY364iY4Bbm4SwK/4CXRoFl0fzRESkHPm46jLx3r1788UXX2CxWKhduzbvvvsuH3/8MTfddBNjxowp8fMkJibSqlUrZs+eTUBAAA0bNuSWW24hJiaGwYMH8/XXX/PUU09Rs2bNQo9ds2YNN954I/fddx8A8+bNo0uXLuzYsYPOnTvbG5KUsfd/PsHJi5nUDPBhdId6dj9+YJtwBrQOU7IqIuKCvGwb/bnYWVQA9evXp379+gAEBwfTtm1b+vTpg79/yU9uDgsLY+HChQQEBGAYBjExMezcuZNOnToB8M033/C3v/2NmTNnFnrs7t27C+zD4+/vT5s2bYiNjS1NOFKGzqdl8caPxwF4qEtD/L09i3lE0ZTciIi4JmcpMrZ7BCcmJoZHHnmE6OhoGjduzIgRI8jMzCQ9PZ3o6Gj69+9vdyN69erFyZMn6dmzJ/369QPg2WefBeDHH38sdP3Zs2cJCwsrcFtISAgJCQl2v7ar/x61tt9Z4vjP9mOkZObQPKwqg24ML/d2OVv8juDufaD4C/7vbtw9fnC+PvD1yjuqoTzaVNLntDvBmTdvHgMGDCAyMpLXX38dX19fNm3axGeffcaiRYtKleAsWrSIxMREZs+ezbx583jyySeveX16ejo+PgXrOnx8fDCbzXa/dkiIfQWwzsoZ4jh0NoUPd58CYPaQGwmrGVRhr+0M8Tuau/eB4lf87s5Z+sCrSu4CEYsBNYID8HTQfmZ2JzgHDhxg0aJF+Pv7s2nTJvr27YuPjw+dOnVi9uzZpWpEREQEkLsE/bHHHuOf//xnoQQmP19f30LJjNlsJijI/l+oSUmXMBw7TXhdTKbcN7UzxPH0R7+SbTHo1jiY5tV9SUy8VO6v6UzxO4q794HiV/zuHD84Xx8YhkGf5qH4eHlwLjmlzJ/fGm9x7E5wQkNDOXjwIGlpaezbt4/p06cDucu2a9euXeLnSUxMJDY2lj59+thua9q0KVlZWaSkpBAcfPUVNOHh4SQmJhZ6vlatWtkZDRgGTvGGuF6OjiMm7jxbDyXhaYKptzau8LY4On5n4O59oPgVvzvHD87UBybmDW4NOLY9dhcZjxs3jsmTJ3P77bcTERFBp06dePXVV3n66aeZPHlyiZ8nPj6eKVOmcPr0adtte/fuJTg4+JrJDUBkZKRt/x3InbLat28fkZGR9oYjZcBiGCz85jAAw9vWpmFIFQe3SERE3J3dIzhjx46lQ4cOnDx5kq5duwJw880306NHD1q2bFni54mIiKBNmzY88cQTzJgxgxMnThAdHc3EiROLfeztt9/O66+/zrJly+jZsydLliyhXr16WiLuIF/sO8P+MylU9fFkwp8aOLo5IiIipVsm3rp1a/r06YOfX+5W+lFRUXYlNwCenp4sXboUf39/Ro4cycyZMxkzZgxjx44t9rH16tXj5ZdfZu3atdxxxx2cP3+eJUuWaGmxA2Rk5bD0u9xN/e7tfIPdxzKIiIiUhxKN4PTq1avI5MHLy4ugoCBatWrF6NGjad68uV0vHh4ezuLFi695TefOnfn9998L3d69e3e6d+9u1+tJ2VsZE8+ZFDO1g3y5+6a6jm6OiIgIUMIE5+GHHy7ydovFwqVLl9i9ezcjR45k+fLltG/fvkwbKM7toz25ew9N6toIX69SDQiKiIiUuRIlOMOHDy/2msWLF7Nw4ULeeeed626UuI4LGVkARNRxjv0XREREoJQ1OEXp27cvv/32W1k9nbgAi2GQnpW7FXeVUh7JICIiUh7KLMHx8/PDcI4F+FJB0rNybB9X8bF7QZ6IiEi5KbME54svvrB7JZW4tjRzboLjaQIfT61gExER51GiP7s/+uijIm+3FhnHxsby9ddfs2zZsrJsmzg5a4JTxcdLS/RFRMSplCjBWbRoUZG3e3t7ExgYSIsWLVi1ahU33nhjmTZOnFva5Skqf2+tnhIREedSogRn06ZN5d0OcUHWEZyqqr8REREnoz+9pdSsCY6/j1ZQiYiIc1GCI6VmXUVVRVNUIiLiZPSbSUotNV+RsYiIiDNRgiOllq4iYxERcVJ2/2YaPXo0q1atIjk5uTzaIy4kVUXGIiLipOxOcHr16sW6deu49dZbGT9+PGvXruXSpUvl0TZxcunWImMd0yAiIk7G7gTnvvvu4/333+fLL7/klltu4b333qNr165MmjSJzz77jPT09PJopzgh6z44VbWKSkREnEyp5xbq1q3L/fffT9++fVm7di3//e9/2bp1K97e3gwePJhHHnmE4ODgsmyrOBktExcREWdVqurQY8eO8dprrzF8+HD69+/Pnj17ePLJJ9m2bRvr1q0jPj6eCRMmlHVbxcnkHdWgBEdERJyL3SM4Q4YM4Y8//iAiIoJhw4YxYMAAatasabs/KCiIu+66i6eeeqpMGyrOJ822D44SHBERcS52Jzh9+/ZlyZIl1K9f/6rXdOvWjW+++eZ62iUuQCM4IiLirOyeolq1ahUXLly45jVVq1alatWqpW6UuAaN4IiIiLOyO8EJDQ0lKSmpPNoiLiZdIzgiIuKk7J6iat26NZMmTSIiIoK6devi4+NT4P558+aVWePEuWkER0REnFWplokPGTKkrNshLkg1OCIi4qzsTnA0QiMA5mwL2RYDUIIjIiLOp1QjOF9//TXLly/n8OHD5OTk0KhRI0aPHs2wYcPKuHnirKzTU6CjGkRExPnYXWS8evVq/vGPf9CxY0eee+45nn/+eTp16sTTTz/NmjVr7HquY8eOMX78eNq1a0ePHj1Yvny57b64uDjGjRtHVFQUAwYM4Lvvvivw2G3btjFo0CAiIyMZO3YscXFx9oYi18E6PeXr5YGnh8nBrRERESnI7hGc5cuXM2vWrAKjNX369KFZs2a8+uqr3HnnnSV6HovFwoQJE4iIiGDdunUcO3aMadOmER4ezqBBg5g8eTLNmzdn7dq1fP3110yZMoXPP/+cOnXqcPLkSSZPnszDDz9Mt27dWLJkCZMmTWL9+vWYTPplWxF0DpWIiDgzuxOcpKQkoqKiCt3erl07Tp06VeLnSUxMpFWrVsyePZuAgAAaNmzILbfcQkxMDKGhocTFxbF69WqqVKlCkyZN+OGHH1i7di0PP/wwa9as4cYbb+S+++4DcuuCunTpwo4dO+jcubO9IUkppOkkcRERcWJ2JzitWrXio48+4pFHHilw+7p162jatGmJnycsLIyFCxcCYBgGu3btYufOncyaNYvdu3fTunVrqlSpYru+ffv2xMbGArB79246dOhgu8/f3582bdoQGxtrd4Lj6gM+1vZXdBzpWXkrqBzZh46K35m4ex8o/oL/uxt3jx/crw9KGqfdCc4//vEPxo0bx48//khkZCQAsbGx7N+/n1dffdXepwOgV69enDx5kp49e9KvXz/+/e9/ExYWVuCakJAQEhISADh79uw177dHSEhgqdrsbCo6Dq+EFACqVfEhNNTxfVhZvo7Xw937QPErfnenPijI7gSnXbt2fPjhh7z//vscOnQIX19fOnbsyIIFC6hdu3apGrFo0SISExOZPXs28+bNIz09vdAGgj4+PpjNZoBi77dHUtIlDKNUzXYKJlPum7qi40hISgXA2wSJiZcq7oWv4Kj4nYm794HiV/zuHD+4Xx9Y4y1OqZaJN2nShBkzZpTmoUWKiIgAIDMzk8cee4zbb7+d9PT0AteYzWb8/PwA8PX1LZTMmM1mgoKC7H5tw6BSvCEqOo7UzLwpKmfov8rydbwe7t4Hil/xu3P8oD64kt0JzqFDh3jxxRc5fPhwkSMmGzduLNHzJCYmEhsbS58+fWy3NW3alKysLGrWrMnhw4cLXW+dlgoPDycxMbHQ/a1atbI3HCklaw2OioxFRMQZ2Z3gPProo/j5+TF27FjbiEppxMfHM2XKFLZs2UJ4eDgAe/fuJTg4mPbt2/PGG2+QkZFhe42YmBjat28PQGRkJDExMbbnSk9PZ9++fUyZMqXU7RH7pJmzAS0TFxER52R3gnP06FHWrl1LkyZNruuFIyIiaNOmDU888QQzZszgxIkTREdHM3HiRDp16kTt2rWZMWMGkyZNYvPmzezZs8d2TMTtt9/O66+/zrJly+jZsydLliyhXr16WiJegdKyLIBGcERExDnZvZPxrbfeWmD0pLQ8PT1ZunQp/v7+jBw5kpkzZzJmzBjGjh1ru+/s2bOMGDGC9evXs2TJEurUqQNAvXr1ePnll1m7di133HEH58+fZ8mSJdrkrwJZR3B0DpWIiDgju0dwpk+fzvDhw/nkk0+oW7duoaTCnsM4w8PDWbx4cZH3NWjQgBUrVlz1sd27d6d79+4lfi0pW2nm3BGcKhrBERERJ2T3CM5TTz2Fh4cHoaGhGjFxY2lZGsERERHnZfcIzk8//cSqVato3bp1ebRHXES6OW+ZuIiIiLOxewSnWbNmXLx4sTzaIi4kVQmOiIg4MbtHcEaNGsU///lPRowYQb169fDyKvgU+U8Zl8rLdhaVanBERMQJ2Z3gLFmyBC8vL9avX1/oPpPJpATHTViXiWsER0REnJHdCc6mTZvKox3iYqzLxLUPjoiIOCO7a3AALl26xMqVK5k7dy7Jycls3ryZuLi4sm6bOCmLYZB+eQRHOxmLiIgzsjvBOXDgAH379mXt2rWsWrWK1NRUNmzYwJAhQ9ixY0d5tFGcjLX+BjSCIyIizsnuBOfZZ59l1KhRfPjhh3h7ewO5m/vdc889zJ8/v8wbKM7HukTc0wS+XqUaBBQRESlXdv92+uWXX4osJL777rs5ePBgWbRJnJx1ibi/j6c2exQREadkd4ITHBzMkSNHCt2+a9cuQkJCyqRR4ty0RFxERJyd3auoHnjgAZ588kkmTpyIYRhs376ddevW8dZbb/H3v/+9PNooTkab/ImIiLOzO8G5++67CQsL4/XXX8fPz4/58+fTqFEj5syZw4ABA8qjjeJkrCM4KjAWERFnZXeCA9CrVy969epV1m0RF5F2eQRHS8RFRMRZlSjBWbx4cYmfcMqUKaVujLgGa4KjERwREXFWJU5wPDw8aNWqFVWrVsUwjCKv04oa95CWpRocERFxbiVKcGbNmsXXX39NbGwsHTt2pHfv3vTu3Zvg4ODybp84oTQVGYuIiJMrUYIzatQoRo0aRUpKClu2bOGrr74iOjqa5s2b06dPH2677Tbq1q1b3m0VJ2FLcLxLVcIlIiJS7uz6DRUQEMDAgQMZOHAgZrOZH374gY0bN3L33XcTGhpKnz59mDx5cnm1VZxE3hSVdjEWERHnVOrfUD4+PnTr1o3BgwczcOBAjh8/zn/+85+ybJs4qbwpKo3giIiIc7L7N1RqairffvstmzZtYuvWrQD06NGDefPm0bVr1zJvoDifvJ2MNYIjIiLOqUQJTkJCAhs3bmTTpk3s3LmT8PBwevXqxaJFi2jfvj2enio2dSepGsEREREnV6LfUD179sTLy4uOHTvy+OOP07x5c9t9u3btKnBtx44dy7aF4nS0k7GIiDi7EiU4hmGQlZXFtm3b2LZt21WvM5lM/Pbbb2XWOHFOqdrJWEREnFyJEpz9+/eXy4ufPn2auXPnsn37dnx9fRkwYADTpk3D19eXvXv3MmfOHA4cOECzZs144okniIqKsj1227Zt/Pvf/yYuLo7IyEjmzp1L/fr1y6WdUlC6dSdjJTgiIuKkHFYlahgGU6dOJT09nZUrV7JgwQI2b97MwoULSUpKYty4cTRv3pwPPviAAQMGcO+993Ly5EkATp48yeTJkxkxYgQffPABwcHBTJo06ao7LEvZsk5RVdUUlYiIOCmHVYkePnyY2NhYvv/+e0JDQwGYOnUqzz//PKGhoVSvXp3Zs2fj6elJkyZN+O6771i1ahWPPvooa9as4cYbb+S+++4DYN68eXTp0oUdO3bQuXNnR4XkNlI1giMiIk7OYSM4NWvWZPny5bbkxiolJYW4uDjatGlTYHVWixYtiI2NBWD37t106NDBdp+/vz9t2rSx3S/lJyvHQrYld6RMNTgiIuKsHDaCExQURLdu3WyfWywWVqxYwc0330xoaGihup+EhATOnTsHwNmzZwkLCytwf0hICAkJCXa3w9XPB7W2v6LisO5iDLkjOI7uv4qO3xm5ex8o/oL/uxt3jx/crw9KGqfTbGQSHR3Nvn37+OCDDwBYunQp77//PiNGjLAdCREeHg5Aeno6Pj4+BR7v4+OD2Wy2+3VDQgKvv/FOoKLiyDiXBoCvlwe1woIq5DVLorJ8Ha+Hu/eB4lf87k59UJBTJDjR0dG89dZbLFiwwLbHzpw5c3j22WeZNWsWrVq1YtSoUfz4448A+Pr6FkpmzGYzQUH2/8JNSrqEK9cmm0y5b+qKiiP+bCoAVbw9SUy8VP4vWIyKjt8ZuXsfKH7F787xg/v1gTXe4jg8wZkzZw6rVq0iOjqafv362W6//fbbGTZsGElJSYSFhTF//nzq1asHQHh4OImJiQWeJzExkVatWtn9+oZBpXhDVFQcafkKjJ2p3yrL1/F6uHsfKH7F787xg/rgSg49TGjx4sWsXr2aF198kYEDB9pu3759O3//+9/x9PQkLCwMwzD49ttvbSukIiMjiYmJsV2fnp7Ovn37iIyMrPAY3E2aNvkTEREX4LAE59ChQyxdupQHHniA9u3bc/bsWdu/Ro0asXnzZt59913i4uJ4+umnuXDhAsOGDQNyR3d27drFsmXL+OOPP5gxYwb16tXTEvEKkKZjGkRExAU4LMHZuHEjOTk5vPLKK3Tt2rXAv/DwcBYuXMg777zD4MGDOXLkCG+++SZVq1YFoF69erz88susXbuWO+64g/Pnz7NkyRJM7lJC7kBptoM2leCIiIjzclgNzoQJE5gwYcJV7+/Rowc9evS46v3du3ene/fu5dAyuRbrCE4VjeCIiIgTc2gNjrgejeCIiIgrUIIjdtEIjoiIuAIlOGIXjeCIiIgrUIIjdklXgiMiIi5ACY7YxXqSuKaoRETEmSnBEbukZ+XtZCwiIuKslOCIXdLM2YB2MhYREeemBEfskpZlAbSTsYiIODclOGIXjeCIiIgrUIIjdtEIjoiIuAIlOGIXLRMXERFXoARHSsxiGHk7GSvBERERJ6YER0os4/L0FGgfHBERcW5KcKTErAXGHibw9dJbR0REnJd+S0mJ5S8wNplMDm6NiIjI1SnBkRLTEnEREXEVSnCkxKwFxloiLiIizk4JjpRYmpaIi4iIi1CCIyWmBEdERFyFEhwpMVuCoykqERFxckpwpMS0yZ+IiLgKJThSYpqiEhERV6EER0osXauoRETERSjBkRJLvTyCo31wRETE2SnBkRLTCI6IiLgKhyY4p0+fZurUqXTq1Ilu3boxb948MjMzAfjpp58YMWIEUVFRDB06lG3bthV47KeffkqfPn2IjIxk8uTJJCcnOyIEt5KmERwREXERDktwDMNg6tSppKens3LlShYsWMDmzZtZuHAhSUlJTJw4kQEDBvDJJ5/Qv39/Jk2aREJCAgB79uxh5syZTJkyhffee4+LFy8yY8YMR4XiNqwJjr8SHBERcXIOS3AOHz5MbGws8+bNo1mzZnTo0IGpU6fy6aefsmvXLjw9Pbn//vupX78+EydOxNfXl9jYWABWrFhB//79GTZsGC1btmT+/Pls2bKFuLg4R4XjFmzLxL29HNwSERGRa3NYglOzZk2WL19OaGhogdtTUlKoXr0658+fZ8OGDRiGwddff01qairNmzcHYPfu3XTo0MH2mNq1a1OnTh12795doTG4m7xl4irdEhER5+awP8WDgoLo1q2b7XOLxcKKFSu4+eab6dChA3/5y1+YOnUqHh4e5OTkMG/ePBo3bgzAmTNnCAsLK/B8ISEhtikse5hM1xeHo1nbXxFx5N8Hx1n6rSLjd1bu3geKv+D/7sbd4wf364OSxuk0cw3R0dHs27ePDz74gNTUVOLi4pgyZQo9e/Zkw4YNPPvss0RGRtKkSRMyMjLw8fEp8HgfHx/MZrPdrxsSElhWIThURcSRkWMBoF54EKGhztVvleXreD3cvQ8Uv+J3d+qDgpwiwYmOjuatt95iwYIFNG/enIULF2IYBlOmTAGgTZs27Nmzh7fffpunn34aX1/fQsmM2WzG39/f7tdOSrqEYZRJGA5hMuW+qSsijtTMbAAyUjJIdJJZqoqM31m5ex8ofsXvzvGD+/WBNd7iODzBmTNnDqtWrSI6Opp+/foB8Ouvv9KyZcsC17Vq1Yo//vgDgPDwcBITEwvcn5iYSM2aNe1+fcOgUrwhyjuOrBwLWTm5L1DF28vp+qyyfB2vh7v3geJX/O4cP6gPruTQv8MXL17M6tWrefHFFxk4cKDt9rCwMA4ePFjg2sOHD1OvXj0AIiMjiYmJsd136tQpTp06RWRkZMU03A1Z629Ay8RFRMT5OWwE59ChQyxdupQJEybQvn17zp49a7vvzjvv5J577uG///0vvXv3ZuPGjXz33XesW7cOgFGjRjFmzBiioqKIiIhg7ty59OjRg/r16zsqnErPukTc18sDLw83qWQTERGX5bAEZ+PGjeTk5PDKK6/wyiuvFLjv999/5+WXX2bRokW89NJLNGrUiGXLltGsWTMA2rVrxzPPPMOiRYu4cOECXbp0Yc6cOY4Iw23YNvnTMQ0iIuICTIbh3jN2iYmuXZRlMkFoaGC5x/HLyYvctyqWOtX8+Pj+TuX3QnaqqPidmbv3geJX/O4cP7hfH1jjLY6TrIURZ5e3i7FGcERExPkpwZESyb/Jn4iIiLNTgiMlkq4RHBERcSFKcKREUjWCIyIiLkQJjpRIunUVlRIcERFxAUpwpERSL09RVdUUlYiIuAAlOFIiGsERERFXogRHSsS6iqqqEhwREXEBSnCkRKz74GgnYxERcQVKcKREtA+OiIi4EiU4UiLayVhERFyJEhwpkTQVGYuIiAtRgiMlkq5l4iIi4kKU4EiJaARHRERciRIcKREtExcREVeiBEeKZTEM2xSVlomLiIgrUIIjxcrIsmBc/lgjOCIi4gqU4EixrEvEPUzg66W3jIiIOD/9tpJi2QqMvT0xmUwObo2IiEjxlOBIsdK1i7GIiLgYJThSrNSsbEC7GIuIiOtQgiPFSjdbAI3giIiI61CCI8VKNV8ewVGCIyIiLkIJjhRLe+CIiIirUYIjxUrVLsYiIuJiHJrgnD59mqlTp9KpUye6devGvHnzyMzMZPr06bRo0aLQv7Fjx9oe++mnn9KnTx8iIyOZPHkyycnJDoykctMIjoiIuBqHJTiGYTB16lTS09NZuXIlCxYsYPPmzSxcuJCZM2fy3Xff2f699957+Pj42BKcPXv2MHPmTKZMmcJ7773HxYsXmTFjhqNCqfTStExcRERcjJejXvjw4cPExsby/fffExoaCsDUqVN5/vnnefzxxwkMDLRdO336dP785z/Tp08fAFasWEH//v0ZNmwYAPPnz6dnz57ExcVRv379Co+lsrMlOBrBERERF+GwBKdmzZosX77cltxYpaSkFPj8hx9+YOfOnXz55Ze223bv3s0DDzxg+7x27drUqVOH3bt3253guPrGvNb2l2cc1qMaqvp6Ol1/VUT8zs7d+0DxF/zf3bh7/OB+fVDSOB2W4AQFBdGtWzfb5xaLhRUrVnDzzTcXuG7ZsmUMHz6c2rVr2247c+YMYWFhBa4LCQkhISHB7naEhAQWf5ELKM84ci6/m2rWqEpoqHP2V2X5Ol4Pd+8Dxa/43Z36oCCHJThXio6OZt++fXzwwQe22+Li4ti+fTszZ84scG1GRgY+Pj4FbvPx8cFsNtv9uklJlzCM4q9zViZT7pu6POM4l5IJgMWcRWLipfJ5kVKqiPidnbv3geJX/O4cP7hfH1jjLY5TJDjR0dG89dZbLFiwgObNm9tu//LLL2nVqhVNmzYtcL2vr2+hZMZsNuPv72/3axsGleINUZ5xpOerwXHWvqosX8fr4e59oPgVvzvHD+qDKzk8wZkzZw6rVq0iOjqafv36Fbjv22+/pXfv3oUeEx4eTmJiYoHbEhMTqVmzZrm21V2lmrVMXEREXItDE5zFixezevVqXnzxRf785z8XuM8wDH755RcmTpxY6HGRkZHExMQwYsQIAE6dOsWpU6eIjIyskHZfy/m0LPadrrhpHJMJgpLSuXgxvdwy9/PpWYA2+hMREdfhsATn0KFDLF26lAkTJtC+fXvOnj1ru69mzZqcOHGC1NTUQtNTAKNGjWLMmDFERUURERHB3Llz6dGjh1MsEX/gvViOJqc7uhnloqqPwwf8RERESsRhv7E2btxITk4Or7zyCq+88kqB+37//XeSkpIAqFatWqHHtmvXjmeeeYZFixZx4cIFunTpwpw5cyqk3cUZ0DqcjQcSi7+wDHl5eZCdbSnX12hWsyo3BNtf4yQiIuIIJsNw75KkxETXrjo3mSA0NNDl4ygtd48f1AeKX/G7c/zgfn1gjbc4OmxTREREKh0lOCIiIlLpKMERERGRSkcJjoiIiFQ6SnBERESk0lGCIyIiIpWOEhwRERGpdJTgiIiISKWjBEdEREQqHSU4IiIiUukowREREZFKRwmOiIiIVDoOO03cWZhMjm7B9bG239XjKC13jx/UB4q/4P/uxt3jB/frg5LG6faniYuIiEjloykqERERqXSU4IiIiEilowRHREREKh0lOCIiIlLpKMERERGRSkcJjoiIiFQ6SnBERESk0lGCIyIiIpWOEhwRERGpdJTgiIiIU9OG+1IaSnBERMRpnTp1CovF4uhmiAtSguOEDMNg3bp1/PTTTyQlJQG41Te49a+1zZs3c+DAAQe3xjEMw2DlypVs2LCB3377zXabuzAMg48++oiffvqJ06dPA+71PWD11ltv8fHHHwOQk5Pj4NZULMMwmD17Nj179mTz5s2Obk6FMwyDVatWsWXLFuLj4wH3/B64Hm5/mriziYmJYdKkSYSFhZGWlkZISAhz586lWbNmjm5ahTGZTBw+fJjnn3+eu+++m2bNmmFyl2NygW3btvH4448TFhaGh4cHR44cYcGCBXTr1s3RTasQmzdvZvr06dSpU4f09HRq1KjB//3f/1G3bl0Mw3Cb90JycjLvvvsuPj4+DBw4EC8vL7eJf+XKlSxYsIBGjRrx/vvv07ZtW0c3qUL9/PPPTJkyhZo1a2I2m8nJyeG1116jYcOGjm6aS9EIjpP5+OOPGTx4MJ988gmvvvoqTZs2ZdKkSRw7dszRTatQqampxMXF8cMPP7Br1y5HN6fCWP9qGzFiBGvXruXtt99m5MiRzJo1i5SUFEc3r9xZLBZWrFjBX//6V9atW8ecOXPw8vJi/fr1AG7xy90qODgYPz8/jh07xquvvgq4xyheQkICc+bMYcqUKaxZs8aW3LjT6MX69evp3bs3H330EQsXLuSee+4hJyfHLb7+ZUkJjhPJyMjgyJEjVK9eHYBmzZrx73//Gw8PD/773//apqsqM+sw/Nq1awkJCSE5OZmtW7e6xS93gPj4eA4dOkTz5s0B8Pf3569//Stnzpxh7969Dm5d+fv1119JSEigTZs2AHTo0IHU1FRat25tu8ZdfsgnJCRgMpm47777+PDDD4mLi8PDw6PST1WFh4dz22232aZlIPcPnqysLNvnlfk9kJ6ezm+//UaNGjUAaN68OSNHjqRJkya2BL8yx1+WNEXlQMuXL8disVCnTh0GDRqEyWTCZDJRtWpVDMMgJycHLy8vpk+fztNPP03Xrl3p3bu3o5tdpq7sA09PT1JTU9m/fz8vvvgiv//+O1988QWRkZH06tXL0c0tc9b4a9euzeDBgwkMDOTChQuEh4fbrjl//jzVq1cnOzvbgS0tH1fG36BBAzp06ECrVq0AWLJkCfv27eM///kPH3/8Mf/6179sfwBUFld+D1gFBgZSrVo1oqKi+PXXX3nxxRdZsGABnp6eDmxt2bvyPWAymejRoweff/45cXFxfP3116xdu5YaNWoQFhbG7NmzCQwMdHSzy0xRvweys7OpVasWAC+//DJff/01oaGhNG/enMcff9ytRjKvh0ZwHODgwYP8+c9/5tNPP+XIkSNMnz6d6OhovL296dSpE++//z6ZmZl4eeXmnz179qRly5asW7eOtLQ0B7e+bBTVBy+88AKnTp2iatWqjB8/nrZt2zJkyBC8vb355ptvbMWmlcGV8c+YMYP58+dTpUoV3nzzTRo0aGD7Ky0nJ4e0tDRCQ0Md3OqyU1T80dHRADz99NOEhYWRmJjI6dOneeGFF+jfvz979+5l+vTpJCQkOLj1ZaOo74EXX3yRU6dOAXD06FHOnTvHn/70JwYPHszu3bv59ddfOXLkCJcuXXJw669fUe+BF154gfPnz9OyZUu8vb157rnn+OGHH3jooYfo3bs3e/fu5fHHH68U74Gr/R7w8fGhY8eOrF27lt9++42dO3cyYcIEIiIi+Oyzz3jiiScq5R875cKQCrdkyRLjkUceMSwWi2EYhrFp0yajb9++xsaNG42UlBQjKirKeO+99wzDMIzs7GzDMAzj999/N1q0aGEcOXLEUc0uU0X1wZ///Gfjf//7X6FrP/nkE+POO+801qxZU9HNLDdFxd+vX78C8Vvve+WVV4zu3bsb6enpRk5OjkPaW9au9vX/4osvDMMwjKysLMMwDOPSpUu2xxw5csTo2LGj8c0331R8g8vB1frg888/NwzDMM6cOWPcfffdRmZmpmEYhjFx4kQjIiLC6NWrl3Hy5EmHtbusXO174KuvvjIMwzAefPBBo23btgW+J6zvgc2bNzuiyWXqar8HvvrqK+PIkSNGVFSU0adPH+Ptt9+2PWb37t1GixYtjF9++cVRzXYpGsFxgP3799umoyB3hMZkMrFr1y7b6MVLL73E2bNn8fT0xDAMmjdvTlRUFBs2bHBw68tGUX0AsG/fPiC3oNBaVDho0CDq1avHt99+W2mWjV/tPZA/futQ9Q8//ED79u3x8/PDwyP3W9bV6zCu9vW3Lom3xhkQEADk9kfDhg2JiIjg22+/dUCLy15xfXD48GGqVKmCyWTi8ccf54cffqBKlSqMHDmS2rVrV8r3gMlk4ueffwZg1KhRPPzww/Tr1w/Iew+0bduWb775xlHNLjNXi/+XX36hYcOG/OUvfyEuLo7GjRsDuXU3bdu2JSoqis8++8yRTXcZSnAqiPWHUU5ODlWrVqVt27ZkZGRgsVjIyckhNDSU1NRUACZPnkxgYCAvvvgi586dw2Qycf78eVJTU6lXr54jw7guxfVBSEgIFy9eBHJ/weUvqPzLX/7C6dOn2bp1q8sOz9obP0BSUhKHDh2iS5cuQG6x5axZs1i7dq3L/YKzN/5Lly5x6NAh2+dpaWmkpqbalsoaLlhoaU8fBAcHs2vXLtq1a0dSUhLLly9n9OjRrFu3jpSUFJesxSlJ/Nafg927d+f++++3PdbDw4OMjAzS09O54YYbANd7D5Tk94B1+vGuu+6idu3a/O9//8NsNmMymUhLS7PV64DrxV/RVGRcTtLT0/H397d9bv1h5OnpycMPP4y3tze+vr627P3o0aMMHToUyF0KGx0dzfTp05k1axaDBg3i9OnTmM1mGjVqVPHBlFJp+mDYsGEFnsP6mPbt29OiRQs2bNhAt27daNGiRcUEcR2uJ36LxYKHhwcnTpwgIyODdu3asXbtWubPn09QUBBjx451+l9w1/v1T0pK4r777qNfv378+c9/Zv/+/SQlJREVFQW4xpLx6/k5kJOTw+DBg+nduzfdu3cHwMfHh08//ZRPP/2Uu+++u4Kjsd/1fg9cuHCBBx54gL59+3Lrrbfy888/c+bMGTp06AA4/3vger7+N9xwA7NmzeLRRx/FZDLRt29fjh8/TmJiIpGRkYDzx+9wDp0gq4QOHTpkTJw40Zg0aZLxzjvvGMePHzcMwzCSkpKMv/zlL8Zvv/1W6DE//fST0aZNG2P//v2GxWKx1R/s2LHD+Mc//mGMGDHC6NWrl/Hll19WaCylVRZ9YJ2XNoy8OqSEhAQjJiamYoK4DmUZ/wcffGC0aNHC6NKli9GhQwfj448/rtBYSqMs4rd+zZcvX27ce++9xtChQ43evXsXWaPljK6nD3777Tfb19/aD9baq8zMTCM+Pr6Coii9sngPWGOeM2eOMXz4cGPAgAFGz549XeI9UJbfA59++qkxadIk44477jB69eplq1OT4mkEpwzt37+fqVOncvPNN1O9enXee+894uLimDFjBgEBAXTo0IEGDRrYrjcu70r6/fffU7NmTerXr4/JZMLLywuz2UzHjh3p2LEjCQkJtiWDzq6s+gDy/vqx/tUTHh5eYPm0MyrL+CF3LyR/f3/uueceJk2a5IiQ7FJW8Xt6epKdnc348eMZP348hw8fttUiOLvr7QPr9AuA2WzG39/fNmXp4+ND3bp1Kzwme5TFewByp6QsFgtPPvkkGRkZHD58uMB+SM6qLL8HzGYzAwcOZODAgZw8edI2NSUl5MDkqtKw/qWxdu1aY9CgQUZaWpphGIZx+vRp28dFsf6VNnr0aOPRRx81DCP3L7TnnnvO+Pvf/26cOnWqnFtedsqrDxISEsq55WWjPOKfNm2acfjwYSM9Pb2cW3/9yuvr70qrhfQ9UPbxP/LIIy7zHtD3gPNRkfF12L9/P5BXELpnzx4aNGhgm3M9e/YsP//8MwkJCbbC2PyFodaisUOHDtGrVy+++uorevTowYYNG/jrX//qEqM25d0HrjBiA2Uf/5dffsnYsWNp1KgRfn5+FRxVyZX317927doVHJH99D1QfvGPGzfO6d8D+h5wYo7OsFxVXFyc0aJFiwJ1MevWrTM6d+5sWCwW47nnnjP+9Kc/GQMHDjQGDRpkvPzyy4ZhGAVqSwzDMA4fPmy0a9fOuPHGG42oqCjj3XffrdA4roe794Hid+/4DUN9oPjdO35npxqcUkpOTgZyt9Hu27cvAC1btqRu3bo8//zzXLhwgXfeeQdPT0++++47FixYQEREBN27dycnJ8dWV1K/fn2CgoIYOnQof//73x0WT2m4ex8ofveOH9QHit+943d2mqIqJS8vL2666SZOnDjBggULAAgNDeXmm2/m448/JjU1lcaNG9OgQQOGDx/OwIEDWbZsGZC7RPCNN95g7ty5eHl58eWXX7rkm9rd+0Dxu3f8oD5Q/O4dv7NTglNKR48excPDg3//+98sX76cpKQkQkNDueWWWwgKCsJsNgO5FfJVqlShTp06+Pr6cuHCBSB3E68ePXoA4Ovr66gwrou794Hid+/4QX2g+N07fmenBKcEitoxtnr16txwww107NiRFi1a8PTTTwPQtm1bRo8ezbZt29i6dattye+ZM2cICQmhWrVqAAwbNsy2O60rcPc+UPzuHT+oDxS/e8fvilSDU4SDBw8SGhpK9erVgbzdJ48fP27bo+LIkSOcPn2akJAQZs+ezV133cWjjz5KzZo1bccK/OMf/yAqKorAwEA2b97Mc889B+Tte+DM3L0PFL97xw/qA8Xv3vFXBkpw8vnyyy+ZN28ewcHBJCcn8+STT3Lrrbfi7e3NI488gslkYsGCBZhMJnx8fGjfvj0ABw4coGrVqnz++eesXr2a+vXr89hjj9G2bVsOHjxIQkIC77//Pk2aNAGce3ttd+8Dxe/e8YP6QPG7d/yViiOWbjkT63K9Y8eOGYMHDzbefPNN48SJE8aTTz5p/PnPfzbOnz9vGIZhnDlzpsDjli1bZvTv39+47777jC5duhjPP/+80a5dO2P9+vUFntcVuHsfKH73jt8w1AeK373jr6zcegTHeqAhwObNm0lPT2f06NF4eXkxceJEhg4dSkpKCtWqVaNmzZq2k1tNJhOhoaGkpKTQsGFDoqOjCQ4OxsfHh3/84x8MHjzYZbJzd+8Dxe/e8YP6QPG7d/yVmdsmOK+99hq7d+/mhhtu4Pbbb6d169Z07tzZ9uZdsGABtWvXZs2aNfTs2ZPIyEhMJhPZ2dl4eXnRsWNHVq5caTs3BXKPt7eeH+Lt7e30b2537wPF797xg/pA8bt3/JWdybB+Jd2AYRhYLBbmzJnD9u3bufPOO/n0008JCgri5ptv5qGHHgIgNjaWv/3tbwwePJhvvvkGb29vhg4dyrhx42xv7Cuf11XexO7eB4rfveMH9YHid+/43UpFzIM5k/T0dOOOO+4wPv74Y8MwDCM5Odl48803jcjISNuhdhkZGcaFCxcMwzCM8+fPGy+//LIxaNAg4+zZs7bnOXDgQMU3voy4ex8ofveO3zDUB4rfveN3F263D058fDxJSUm0bNkSgBo1ajBq1CjatWvH9OnTgdwNl4KCggCoVq0aXbp0ITAwkBMnTgC5h6kNGTKEQ4cOOSaI6+TufaD43Tt+UB8ofveO3124XYLTtGlTAL755hsAsrOz8fX1ZcaMGezYsYPvvvsOgNOnT9se4+/vz549e6hatSoAzZs3Z8eOHbblfq7G3ftA8bt3/KA+UPzuHb+7cLsEB+Cee+7h3XffxWw24+XlhcVioXnz5tx+++08//zz7Nq1i1mzZrFv3z7S09PZtm0bt9xyC7Vq1QLAz8+PwMBAB0dxfdy9DxS/e8cP6gPF797xuwO3THD69etHaGgoixcvBrBVzN9xxx0YhsFPP/1ETk4ODz74IHfddRfLli3jzjvvJCAgwJHNLlPu3geK373jB/WB4nfv+N2CIwp/HC0nJ8dYsWKFccsttxiHDh2y3f7HH38Yw4cPN2JjY42srCzjwIEDxldffeXAlpYfd+8Dxe/e8RuG+kDxu3f87sAtR3A8PDwYOnQoN910E48++igpKSlAbgZ/8eJFqlSpgpeXF82aNaNPnz4Obm35cPc+UPzuHT+oDxS/e8fvDtxqH5wrpaWlMXLkSABatmxJTEwMkZGRzJ07lypVqji4dRXD3ftA8bt3/KA+UPzuHX9l5tYJDsCJEyfYvXs327dvp3nz5owePdrRTapw7t4Hit+94wf1geJ37/grK7dPcERERKTyccsaHBEREanclOCIiIhIpaMER0RERCodJTgiIiJS6SjBERERkUpHCY6IiIhUOkpwREREpNJRgiMiIiKVjpejGyAicjXTp09n3bp117xm48aN1KtXr4JaJCKuQjsZi4jTunTpEhkZGQB8/vnnvPHGG3zwwQcAWCwWcnJyCA8Px9PT05HNFBEnpBEcEXFagYGBBAYG2j729PSkZs2aDm6ViLgC1eCIiEuKj4+nRYsWxMfHA9CiRQu++OIL+vfvT2RkJNOmTSMuLo6xY8cSGRnJPffcw+nTp22P/+qrrxgwYACRkZHccccd7Nixw1GhiEg5UIIjIpXGokWLeO6553jttdfYsGEDo0aNYtSoUaxevZqzZ8/yn//8B4D9+/fz+OOP89BDD7F+/XqGDBnCAw88wLFjxxwcgYiUFU1RiUilMW7cOCIjIwFo1aoVjRo1on///gD07duX/fv3A/D6669z1113MXjwYADGjh3Lzp07WbVqFdOnT3dM40WkTCnBEZFKo379+raP/fz8qFu3boHPzWYzAIcOHeKLL77gvffes92flZVF165dK66xIlKulOCISKVx5WoqD4+iZ+FzcnJ44IEHGDZsWIHb/fz8yqtpIlLBVIMjIm6nUaNGxMfH06BBA9u/9957j61btzq6aSJSRpTgiIjbGTduHJ9//jlvv/02x48f57///S///e9/adiwoaObJiJlRAmOiLidqKgo5s+fz7vvvsuAAQN4//33eeGFF+jYsaOjmyYiZUQ7GYuIiEiloxEcERERqXSU4IiIiEilowRHREREKh0lOCIiIlLpKMERERGRSkcJjoiIiFQ6SnBERESk0lGCIyIiIpWOEhwRERGpdJTgiIiISKWjBEdEREQqnf8H7KKe9zJojdYAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_mem_usage.plot()\n",
    "\n",
    "plt.ylabel('Memory Usage (MB)')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T03:49:35.923579Z",
     "start_time": "2023-09-12T03:49:35.710530200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d387bc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T19:11:12.304912700Z",
     "start_time": "2023-09-11T19:11:11.592260500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a training loop for UPACs\n",
    "\n",
    "from joblib import dump, load\n",
    "import optuna\n",
    "\n",
    "def train_upac(upac_name, trainx, trainy, valx, valy, testx, testy, ntrials=100, nruns=10):\n",
    "    # First do a parameter sweep with Optuna\n",
    "    def create_model(trial):\n",
    "        # Do search for n_estimators, max_depth, reg_alpha and reg_lambda\n",
    "        sug_estimators = trial.suggest_int('n_estimators', 50, 5000)\n",
    "        sug_depth = trial.suggest_int('max_depth', 10, 5000)\n",
    "        sug_alpha = trial.suggest_float('reg_alpha', 1e-5, 1e-3)\n",
    "        sug_lambda = trial.suggest_float('reg_lambda', 1e-5, 1e-3)\n",
    "\n",
    "        sug_model = xgb.XGBRegressor(n_estimators=sug_estimators,\n",
    "                                     max_depth=sug_depth,\n",
    "                                     reg_alpha=sug_alpha,\n",
    "                                     reg_lambda=sug_lambda)\n",
    "\n",
    "        return sug_model\n",
    "\n",
    "\n",
    "    def create_training(model):\n",
    "        model.fit(trainx[upac_name], trainy[upac_name])\n",
    "    \n",
    "    \n",
    "    def create_evaluation(model):\n",
    "        temp_yhat = model.predict(valx[upac_name])\n",
    "        return sklearn.metrics.mean_squared_error(valy[upac_name], temp_yhat)\n",
    "    \n",
    "    \n",
    "    def create_objective(trial):\n",
    "        # Instantiate the model\n",
    "        temp_model = create_model(trial)\n",
    "\n",
    "        # Train the model\n",
    "        create_training(temp_model)\n",
    "\n",
    "        # Evaluate model\n",
    "        metrics_val = create_evaluation(temp_model)\n",
    "\n",
    "        return metrics_val\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(create_objective, n_trials=ntrials, show_progress_bar=True)\n",
    "    \n",
    "    IPython.display.clear_output()\n",
    "\n",
    "    @profile\n",
    "    def train_xgb(current_study):\n",
    "        inner_model = xgb.XGBRegressor(n_estimators=current_study.best_params['n_estimators'],\n",
    "                                       max_depth=current_study.best_params['max_depth'],\n",
    "                                       reg_alpha=current_study.best_params['reg_alpha'],\n",
    "                                       reg_lambda=current_study.best_params['reg_lambda'])\n",
    "        return inner_model\n",
    "    \n",
    "    # Then train different models using the best parameters found\n",
    "    model_dictionary = {}\n",
    "\n",
    "    for i in np.arange(nruns):\n",
    "        temp_model = train_xgb(study)\n",
    "        \n",
    "        # Train the model\n",
    "        temp_model.fit(trainx[upac_name],#['Ghi'].values.reshape(trainx[upac_name].values.shape[0], 1),\n",
    "                       trainy[upac_name])\n",
    "        \n",
    "        # Save -> dump(example_model, 'example_model.joblib')\n",
    "        dump(temp_model, 'models/xgboost/{}_all/Model {:02d}.joblib'.format(upac_name, i+1))\n",
    "        \n",
    "        # Add it to the dictionary to return\n",
    "        model_dictionary['Model {:02d}'.format(i+1)] = temp_model\n",
    "        \n",
    "    return study, model_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df04342f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T01:02:15.141114200Z",
     "start_time": "2023-09-12T01:02:15.110047700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Function for predicting and storing values\n",
    "\n",
    "def do_predictions(dictionary, save_path, X, y, index, scaler=None):\n",
    "\n",
    "    # Create a scaler for only the first variable\n",
    "    temp_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    temp_scaler.min\n",
    "\n",
    "    # Go through each model in the dictionary\n",
    "    for model in dictionary.keys():\n",
    "        print('Doing {}'.format(model))\n",
    "        \n",
    "        temp_path = '{}/{}.csv'.format(save_path, model)\n",
    "        \n",
    "        y_pred = dictionary[model].predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['PV'],\n",
    "                              index=index)\n",
    "\n",
    "        if scaler is not None:\n",
    "            # Use only the scaler's first column for the inverse transform\n",
    "            y_pred = scaler.inverse_transform(y_pred)\n",
    "\n",
    "        y_pred.to_csv(temp_path)\n",
    "        \n",
    "    # Also save ground-truth data at the end of the loop\n",
    "    y_true = pd.DataFrame(y, columns=['PV'],\n",
    "                          index=index)\n",
    "    \n",
    "    temp_path_gt = '{}/gt.csv'.format(save_path)\n",
    "    y_true.to_csv(temp_path_gt)\n",
    "    \n",
    "    \n",
    "def predict_upacs(model_dictionary, scaler_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Simply call the function above for each of the settings to simplify\n",
    "    \n",
    "    print('Doing training for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_all/train'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_train[upac_name],#[['CloudOpacity', 'GtiFixedTilt', 'Day Y', 'Year X']], \n",
    "                   y=y_train[upac_name],\n",
    "                   index=normalized_train[upac_name].index,\n",
    "                   scaler=scaler_dictionary[upac_name])\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing validation for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_all/val'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_val[upac_name],#[['CloudOpacity', 'GtiFixedTilt', 'Day Y', 'Year X']], \n",
    "                   y=y_val[upac_name],\n",
    "                   index=normalized_val[upac_name].index,\n",
    "                   scaler=scaler_dictionary[upac_name])\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing testing for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_all/test'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_test[upac_name],#[['CloudOpacity', 'GtiFixedTilt', 'Day Y', 'Year X']], \n",
    "                   y=y_test[upac_name],\n",
    "                   index=normalized_test[upac_name].index,\n",
    "                   scaler=scaler_dictionary[upac_name])\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d69fdc33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T01:02:22.846176200Z",
     "start_time": "2023-09-12T01:02:18.700414Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-12 02:02:18,704] A new study created in memory with name: no-name-85fc71df-2d70-4a72-b549-1f998be38e9c\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4dfbdb8a2cff4e31ac249dcafed779e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2023-09-12 02:02:21,500] Trial 0 failed with parameters: {'n_estimators': 3974, 'max_depth': 3725, 'reg_alpha': 0.0009189958152627335, 'reg_lambda': 0.0004990061089832175} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\camar\\AppData\\Local\\Temp\\ipykernel_26048\\3934146206.py\", line 37, in create_objective\n",
      "    create_training(temp_model)\n",
      "  File \"C:\\Users\\camar\\AppData\\Local\\Temp\\ipykernel_26048\\3934146206.py\", line 24, in create_training\n",
      "    model.fit(trainx[upac_name], trainy[upac_name])\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 1915, in update\n",
      "    self._validate_dmatrix_features(dtrain)\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2747, in _validate_dmatrix_features\n",
      "    self._validate_features(fn)\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2750, in _validate_features\n",
      "    if self.feature_names is None:\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 1868, in feature_names\n",
      "    return self._get_feature_info(\"feature_name\")\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 1826, in _get_feature_info\n",
      "    _LIB.XGBoosterGetStrFeatureInfo(\n",
      "KeyboardInterrupt\n",
      "[W 2023-09-12 02:02:21,562] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train UPAC08 - all features\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m upac08_study, upac08_models \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_upac\u001B[49m\u001B[43m(\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mupac08\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mtrainx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mtrainy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mvalx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvaly\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mtestx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtesty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[16], line 45\u001B[0m, in \u001B[0;36mtrain_upac\u001B[1;34m(upac_name, trainx, trainy, valx, valy, testx, testy, ntrials, nruns)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m metrics_val\n\u001B[0;32m     44\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminimize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 45\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcreate_objective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mntrials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m IPython\u001B[38;5;241m.\u001B[39mdisplay\u001B[38;5;241m.\u001B[39mclear_output()\n\u001B[0;32m     49\u001B[0m \u001B[38;5;129m@profile\u001B[39m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_xgb\u001B[39m(current_study):\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\study.py:442\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    341\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    348\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    349\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    350\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    351\u001B[0m \n\u001B[0;32m    352\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    441\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 442\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    444\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    445\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    446\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    447\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    448\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    449\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    450\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    451\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    250\u001B[0m ):\n\u001B[1;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[16], line 37\u001B[0m, in \u001B[0;36mtrain_upac.<locals>.create_objective\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m     34\u001B[0m temp_model \u001B[38;5;241m=\u001B[39m create_model(trial)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m \u001B[43mcreate_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtemp_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# Evaluate model\u001B[39;00m\n\u001B[0;32m     40\u001B[0m metrics_val \u001B[38;5;241m=\u001B[39m create_evaluation(temp_model)\n",
      "Cell \u001B[1;32mIn[16], line 24\u001B[0m, in \u001B[0;36mtrain_upac.<locals>.create_training\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_training\u001B[39m(model):\n\u001B[1;32m---> 24\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainx\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainy\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1025\u001B[0m, in \u001B[0;36mXGBModel.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[0;32m   1014\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1016\u001B[0m (\n\u001B[0;32m   1017\u001B[0m     model,\n\u001B[0;32m   1018\u001B[0m     metric,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1023\u001B[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001B[0;32m   1024\u001B[0m )\n\u001B[1;32m-> 1025\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1026\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1027\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1028\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1029\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1030\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1031\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1032\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1034\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1035\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1036\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1037\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_evaluation_result(evals_result)\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\training.py:185\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m--> 185\u001B[0m \u001B[43mbst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:1915\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[0;32m   1913\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtrain, DMatrix):\n\u001B[0;32m   1914\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minvalid training matrix: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(dtrain)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1915\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_dmatrix_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1917\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1918\u001B[0m     _check_call(_LIB\u001B[38;5;241m.\u001B[39mXGBoosterUpdateOneIter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[0;32m   1919\u001B[0m                                             ctypes\u001B[38;5;241m.\u001B[39mc_int(iteration),\n\u001B[0;32m   1920\u001B[0m                                             dtrain\u001B[38;5;241m.\u001B[39mhandle))\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:2747\u001B[0m, in \u001B[0;36mBooster._validate_dmatrix_features\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   2744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2745\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types \u001B[38;5;241m=\u001B[39m ft\n\u001B[1;32m-> 2747\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:2750\u001B[0m, in \u001B[0;36mBooster._validate_features\u001B[1;34m(self, feature_names)\u001B[0m\n\u001B[0;32m   2749\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_features\u001B[39m(\u001B[38;5;28mself\u001B[39m, feature_names: Optional[FeatureNames]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 2750\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_names\u001B[49m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2751\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   2753\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m feature_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:1868\u001B[0m, in \u001B[0;36mBooster.feature_names\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1862\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m   1863\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfeature_names\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[FeatureNames]:\n\u001B[0;32m   1864\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Feature names for this booster.  Can be directly set by input data or by\u001B[39;00m\n\u001B[0;32m   1865\u001B[0m \u001B[38;5;124;03m    assignment.\u001B[39;00m\n\u001B[0;32m   1866\u001B[0m \n\u001B[0;32m   1867\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1868\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_feature_info\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfeature_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:1826\u001B[0m, in \u001B[0;36mBooster._get_feature_info\u001B[1;34m(self, field)\u001B[0m\n\u001B[0;32m   1823\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhandle\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1825\u001B[0m _check_call(\n\u001B[1;32m-> 1826\u001B[0m     \u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterGetStrFeatureInfo\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1827\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfield\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43msarr\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1828\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1829\u001B[0m )\n\u001B[0;32m   1830\u001B[0m feature_info \u001B[38;5;241m=\u001B[39m from_cstr_to_pystr(sarr, length)\n\u001B[0;32m   1831\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m feature_info \u001B[38;5;28;01mif\u001B[39;00m feature_info \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train UPAC08 - all features\n",
    "\n",
    "upac08_study, upac08_models = train_upac(upac_name='upac08', \n",
    "                                         trainx=X_train, \n",
    "                                         trainy=y_train,\n",
    "                                         valx=X_val, valy=y_val,\n",
    "                                         testx=X_test, testy=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "001ed764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T19:30:56.433655900Z",
     "start_time": "2023-09-11T19:30:56.419063700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_estimators': 2460,\n 'max_depth': 10,\n 'reg_alpha': 0.0008393587688220376,\n 'reg_lambda': 0.000408292306694367}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UPAC08 best params\n",
    "\n",
    "upac08_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99e960cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T01:02:32.770286600Z",
     "start_time": "2023-09-12T01:02:32.425674200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing training for upac08\n",
      "Doing Model 01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (34848,1) doesn't match the broadcast shape (34848,23)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Predict UPAC08 - All features\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mpredict_upacs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_dictionary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupac08_models\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m              \u001B[49m\u001B[43mupac_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mupac08\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m              \u001B[49m\u001B[43mX_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m              \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m              \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m              \u001B[49m\u001B[43mscaler_dictionary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaler_dict\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[19], line 33\u001B[0m, in \u001B[0;36mpredict_upacs\u001B[1;34m(model_dictionary, scaler_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDoing training for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(upac_name))\n\u001B[0;32m     32\u001B[0m temp_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresults/xgboost/\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_all/train\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(upac_name)\n\u001B[1;32m---> 33\u001B[0m \u001B[43mdo_predictions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdictionary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_dictionary\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m               \u001B[49m\u001B[43msave_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtemp_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[43m               \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;66;43;03m#[['CloudOpacity', 'GtiFixedTilt', 'Day Y', 'Year X']], \u001B[39;49;00m\n\u001B[0;32m     36\u001B[0m \u001B[43m               \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m               \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnormalized_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m               \u001B[49m\u001B[43mscaler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaler_dictionary\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m IPython\u001B[38;5;241m.\u001B[39mdisplay\u001B[38;5;241m.\u001B[39mclear_output()\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDoing validation for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(upac_name))\n",
      "Cell \u001B[1;32mIn[19], line 16\u001B[0m, in \u001B[0;36mdo_predictions\u001B[1;34m(dictionary, save_path, X, y, index, scaler)\u001B[0m\n\u001B[0;32m     11\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(y_pred, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPV\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     12\u001B[0m                           index\u001B[38;5;241m=\u001B[39mindex)\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m scaler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     15\u001B[0m         \u001B[38;5;66;03m# Use only the scaler's first column for the inverse transform\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m         y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minverse_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m     y_pred\u001B[38;5;241m.\u001B[39mto_csv(temp_path)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# Also save ground-truth data at the end of the loop\u001B[39;00m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:547\u001B[0m, in \u001B[0;36mMinMaxScaler.inverse_transform\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    541\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    543\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m    544\u001B[0m     X, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy, dtype\u001B[38;5;241m=\u001B[39mFLOAT_DTYPES, force_all_finite\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    545\u001B[0m )\n\u001B[1;32m--> 547\u001B[0m X \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_\n\u001B[0;32m    548\u001B[0m X \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale_\n\u001B[0;32m    549\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X\n",
      "\u001B[1;31mValueError\u001B[0m: non-broadcastable output operand with shape (34848,1) doesn't match the broadcast shape (34848,23)"
     ]
    }
   ],
   "source": [
    "# Predict UPAC08 - All features\n",
    "predict_upacs(model_dictionary=upac08_models, \n",
    "              upac_name='upac08',\n",
    "              X_train=X_train, y_train=y_train,\n",
    "              X_val=X_val, y_val=y_val,\n",
    "              X_test=X_test, y_test=y_test,\n",
    "              scaler_dictionary=scaler_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "686e5c60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T09:29:54.508894Z",
     "start_time": "2022-08-01T09:29:54.494890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a training loop for UPACs\n",
    "\n",
    "from joblib import dump, load\n",
    "import optuna\n",
    "\n",
    "def train_upac_top1(upac_name, trainx, trainy, valx, valy, testx, testy, ntrials=100, nruns=10):\n",
    "    # First do a parameter sweep with Optuna\n",
    "    def create_model(trial):\n",
    "        # Do search for n_estimators, max_depth, reg_alpha and reg_lambda\n",
    "        sug_estimators = trial.suggest_int('n_estimators', 50, 5000)\n",
    "        sug_depth = trial.suggest_int('max_depth', 10, 5000)\n",
    "        sug_alpha = trial.suggest_float('reg_alpha', 1e-5, 1e-3)\n",
    "        sug_lambda = trial.suggest_float('reg_lambda', 1e-5, 1e-3)\n",
    "\n",
    "        sug_model = xgb.XGBRegressor(n_estimators=sug_estimators,\n",
    "                                     max_depth=sug_depth,\n",
    "                                     reg_alpha=sug_alpha,\n",
    "                                     reg_lambda=sug_lambda)\n",
    "\n",
    "        return sug_model\n",
    "\n",
    "\n",
    "    def create_training(model):\n",
    "        model.fit(trainx[upac_name], trainy[upac_name])\n",
    "    \n",
    "    \n",
    "    def create_evaluation(model):\n",
    "        temp_yhat = model.predict(valx[upac_name])\n",
    "        return sklearn.metrics.mean_squared_error(valy[upac_name], temp_yhat)\n",
    "    \n",
    "    \n",
    "    def create_objective(trial):\n",
    "        # Instantiate the model\n",
    "        temp_model = create_model(trial)\n",
    "\n",
    "        # Train the model\n",
    "        create_training(temp_model)\n",
    "\n",
    "        # Evaluate model\n",
    "        metrics_val = create_evaluation(temp_model)\n",
    "\n",
    "        return metrics_val\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(create_objective, n_trials=ntrials, show_progress_bar=True)\n",
    "    \n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    \n",
    "    # Then train different models using the best parameters found\n",
    "    model_dictionary = {}\n",
    "    for i in np.arange(nruns):\n",
    "        temp_model = xgb.XGBRegressor(n_estimators=study.best_params['n_estimators'],\n",
    "                                      max_depth=study.best_params['max_depth'],\n",
    "                                      reg_alpha=study.best_params['reg_alpha'],\n",
    "                                      reg_lambda=study.best_params['reg_lambda'])\n",
    "        \n",
    "        # Train the model\n",
    "        temp_model.fit(trainx[upac_name]['GtiFixedTilt'].values.reshape(trainx[upac_name].values.shape[0], 1),\n",
    "                       trainy[upac_name])\n",
    "        \n",
    "        # Save -> dump(example_model, 'example_model.joblib')\n",
    "        dump(temp_model, 'models/xgboost/{}_top1/Model {:02d}.joblib'.format(upac_name, i+1))\n",
    "        \n",
    "        # Add it to the dictionary to return\n",
    "        model_dictionary['Model {:02d}'.format(i+1)] = temp_model\n",
    "        \n",
    "    return study, model_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b4e587b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:27:45.077916Z",
     "start_time": "2022-08-01T11:27:45.063913Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Function for predicting and storing values\n",
    "\n",
    "def do_predictions(dictionary, save_path, X, y, index):\n",
    "    # Go through each model in the dictionary\n",
    "    for model in dictionary.keys():\n",
    "        print('Doing {}'.format(model))\n",
    "        \n",
    "        temp_path = '{}/{}.csv'.format(save_path, model)\n",
    "        \n",
    "        y_pred = dictionary[model].predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['PV'],\n",
    "                              index=index)\n",
    "        \n",
    "        y_pred.to_csv(temp_path)\n",
    "        \n",
    "    # Also save ground-truth data at the end of the loop\n",
    "    y_true = pd.DataFrame(y, columns=['PV'],\n",
    "                          index=index)\n",
    "    \n",
    "    temp_path_gt = '{}/gt.csv'.format(save_path)\n",
    "    y_true.to_csv(temp_path_gt)\n",
    "    \n",
    "    \n",
    "def predict_upacs_top1(model_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Simply call the function above for each of the settings to simplify\n",
    "    \n",
    "    print('Doing training for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/train'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_train[upac_name]['GtiFixedTilt'].values.reshape(-1, 1), \n",
    "                   y=y_train[upac_name],\n",
    "                   index=normalized_train[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing validation for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/val'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_val[upac_name]['GtiFixedTilt'].values.reshape(-1, 1),\n",
    "                   y=y_val[upac_name],\n",
    "                   index=normalized_val[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing testing for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/test'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_test[upac_name]['GtiFixedTilt'].values.reshape(-1, 1), \n",
    "                   y=y_test[upac_name],\n",
    "                   index=normalized_test[upac_name].index)\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b5945b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:51:59.971150Z",
     "start_time": "2022-08-01T11:28:28.296603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train UPAC08 - top 1\n",
    "\n",
    "upac08_study_top1, upac08_models_top1 = train_upac_top1(upac_name='upac08', \n",
    "                                                        trainx=X_train, \n",
    "                                                        trainy=y_train,\n",
    "                                                        valx=X_val, valy=y_val,\n",
    "                                                        testx=X_test, testy=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ba50edec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:27:47.498459Z",
     "start_time": "2022-08-01T11:27:47.481454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing training for upac08\n",
      "Doing Model 01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 8, got 34848",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16028/1432200141.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Predict UPAC08 - All features\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m predict_upacs_top1(model_dictionary=upac08_models_top1, \n\u001B[0m\u001B[0;32m      3\u001B[0m                    \u001B[0mupac_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'upac08'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m                    \u001B[0mX_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m                    \u001B[0mX_val\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my_val\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16028/913354552.py\u001B[0m in \u001B[0;36mpredict_upacs_top1\u001B[1;34m(model_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test)\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Doing training for {}'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mupac_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m     \u001B[0mtemp_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'results/xgboost/{}_top1/train'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mupac_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 29\u001B[1;33m     do_predictions(dictionary=model_dictionary, \n\u001B[0m\u001B[0;32m     30\u001B[0m                    \u001B[0msave_path\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtemp_path\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m                    \u001B[0mX\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mupac_name\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'GtiFixedTilt'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16028/913354552.py\u001B[0m in \u001B[0;36mdo_predictions\u001B[1;34m(dictionary, save_path, X, y, index)\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[0mtemp_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'{}/{}.csv'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msave_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m         \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdictionary\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m         y_pred = pd.DataFrame(y_pred, columns=['PV'],\n\u001B[0;32m     12\u001B[0m                               index=index)\n",
      "\u001B[1;32mc:\\users\\feel\\jupyter\\ecgomes\\upacs_study\\venv\\lib\\site-packages\\xgboost\\sklearn.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001B[0m\n\u001B[0;32m    818\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_can_use_inplace_predict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    819\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 820\u001B[1;33m                 predts = self.get_booster().inplace_predict(\n\u001B[0m\u001B[0;32m    821\u001B[0m                     \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    822\u001B[0m                     \u001B[0miteration_range\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0miteration_range\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\feel\\jupyter\\ecgomes\\upacs_study\\venv\\lib\\site-packages\\xgboost\\core.py\u001B[0m in \u001B[0;36minplace_predict\u001B[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001B[0m\n\u001B[0;32m   1839\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mvalidate_features\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1840\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_features\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1841\u001B[1;33m                 raise ValueError(\n\u001B[0m\u001B[0;32m   1842\u001B[0m                     \u001B[1;34mf\"Feature shape mismatch, expected: {self.num_features()}, \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1843\u001B[0m                     \u001B[1;34mf\"got {data.shape[0]}\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Feature shape mismatch, expected: 8, got 34848"
     ]
    }
   ],
   "source": [
    "# Predict UPAC08 - All features\n",
    "predict_upacs_top1(model_dictionary=upac08_models_top1, \n",
    "                   upac_name='upac08',\n",
    "                   X_train=X_train, y_train=y_train,\n",
    "                   X_val=X_val, y_val=y_val,\n",
    "                   X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49583e8",
   "metadata": {},
   "source": [
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c63ac7a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:10:53.743439Z",
     "start_time": "2022-08-04T15:10:53.723444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a training loop for UPACs\n",
    "\n",
    "from joblib import dump, load\n",
    "import optuna\n",
    "\n",
    "def train_upac_gti(upac_name, trainx, trainy, valx, valy, testx, testy, ntrials=100, nruns=10):\n",
    "    # First do a parameter sweep with Optuna\n",
    "    def create_model(trial):\n",
    "        # Do search for n_estimators, max_depth, reg_alpha and reg_lambda\n",
    "        sug_estimators = trial.suggest_int('n_estimators', 50, 5000)\n",
    "        sug_depth = trial.suggest_int('max_depth', 10, 5000)\n",
    "        sug_alpha = trial.suggest_float('reg_alpha', 1e-5, 1e-3)\n",
    "        sug_lambda = trial.suggest_float('reg_lambda', 1e-5, 1e-3)\n",
    "\n",
    "        sug_model = xgb.XGBRegressor(n_estimators=sug_estimators,\n",
    "                                     max_depth=sug_depth,\n",
    "                                     reg_alpha=sug_alpha,\n",
    "                                     reg_lambda=sug_lambda)\n",
    "\n",
    "        return sug_model\n",
    "\n",
    "\n",
    "    def create_training(model):\n",
    "        model.fit(trainx[upac_name], trainy[upac_name])\n",
    "    \n",
    "    \n",
    "    def create_evaluation(model):\n",
    "        temp_yhat = model.predict(valx[upac_name])\n",
    "        return sklearn.metrics.mean_squared_error(valy[upac_name], temp_yhat)\n",
    "    \n",
    "    \n",
    "    def create_objective(trial):\n",
    "        # Instantiate the model\n",
    "        temp_model = create_model(trial)\n",
    "\n",
    "        # Train the model\n",
    "        create_training(temp_model)\n",
    "\n",
    "        # Evaluate model\n",
    "        metrics_val = create_evaluation(temp_model)\n",
    "\n",
    "        return metrics_val\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(create_objective, n_trials=ntrials, show_progress_bar=True)\n",
    "    \n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    \n",
    "    # Then train different models using the best parameters found\n",
    "    model_dictionary = {}\n",
    "    for i in np.arange(nruns):\n",
    "        temp_model = xgb.XGBRegressor(n_estimators=study.best_params['n_estimators'],\n",
    "                                      max_depth=study.best_params['max_depth'],\n",
    "                                      reg_alpha=study.best_params['reg_alpha'],\n",
    "                                      reg_lambda=study.best_params['reg_lambda'])\n",
    "        \n",
    "        # Train the model\n",
    "        temp_model.fit(trainx[upac_name].drop('Ghi', axis=1),\n",
    "                       trainy[upac_name])\n",
    "        \n",
    "        # Save -> dump(example_model, 'example_model.joblib')\n",
    "        dump(temp_model, 'models/xgboost/{}_gti/Model {:02d}.joblib'.format(upac_name, i+1))\n",
    "        \n",
    "        # Add it to the dictionary to return\n",
    "        model_dictionary['Model {:02d}'.format(i+1)] = temp_model\n",
    "        \n",
    "    return study, model_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f442af33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:12:00.660252Z",
     "start_time": "2022-08-04T15:12:00.650258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Function for predicting and storing values\n",
    "\n",
    "def do_predictions(dictionary, save_path, X, y, index):\n",
    "    # Go through each model in the dictionary\n",
    "    for model in dictionary.keys():\n",
    "        print('Doing {}'.format(model))\n",
    "        \n",
    "        temp_path = '{}/{}.csv'.format(save_path, model)\n",
    "        \n",
    "        y_pred = dictionary[model].predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['PV'],\n",
    "                              index=index)\n",
    "        \n",
    "        y_pred.to_csv(temp_path)\n",
    "        \n",
    "    # Also save ground-truth data at the end of the loop\n",
    "    y_true = pd.DataFrame(y, columns=['PV'],\n",
    "                          index=index)\n",
    "    \n",
    "    temp_path_gt = '{}/gt.csv'.format(save_path)\n",
    "    y_true.to_csv(temp_path_gt)\n",
    "    \n",
    "    \n",
    "def predict_upacs_gti(model_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Simply call the function above for each of the settings to simplify\n",
    "    \n",
    "    print('Doing training for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_gti/train'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_train[upac_name].drop('Ghi', axis=1), \n",
    "                   y=y_train[upac_name],\n",
    "                   index=normalized_train[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing validation for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_gti/val'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_val[upac_name].drop('Ghi', axis=1),\n",
    "                   y=y_val[upac_name],\n",
    "                   index=normalized_val[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing testing for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_gti/test'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_test[upac_name].drop('Ghi', axis=1), \n",
    "                   y=y_test[upac_name],\n",
    "                   index=normalized_test[upac_name].index)\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc6678e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:35:49.627660Z",
     "start_time": "2022-08-04T15:12:51.225648Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train UPAC08 - Gti, no Ghi\n",
    "\n",
    "upac08_study_gti, upac08_models_gti = train_upac_gti(upac_name='upac08', \n",
    "                                                        trainx=X_train, \n",
    "                                                        trainy=y_train,\n",
    "                                                        valx=X_val, valy=y_val,\n",
    "                                                        testx=X_test, testy=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "839955ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:43:32.370119Z",
     "start_time": "2022-08-04T15:43:27.438005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict UPAC08 - Gti\n",
    "predict_upacs_gti(model_dictionary=upac08_models_gti, \n",
    "                  upac_name='upac08',\n",
    "                  X_train=X_train, y_train=y_train,\n",
    "                  X_val=X_val, y_val=y_val,\n",
    "                  X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205dd90",
   "metadata": {},
   "source": [
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8b67d3d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:46:30.013929Z",
     "start_time": "2022-08-04T15:46:30.002924Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a training loop for UPACs\n",
    "\n",
    "from joblib import dump, load\n",
    "import optuna\n",
    "\n",
    "def train_upac_ghi(upac_name, trainx, trainy, valx, valy, testx, testy, ntrials=100, nruns=10):\n",
    "    # First do a parameter sweep with Optuna\n",
    "    def create_model(trial):\n",
    "        # Do search for n_estimators, max_depth, reg_alpha and reg_lambda\n",
    "        sug_estimators = trial.suggest_int('n_estimators', 50, 5000)\n",
    "        sug_depth = trial.suggest_int('max_depth', 10, 5000)\n",
    "        sug_alpha = trial.suggest_float('reg_alpha', 1e-5, 1e-3)\n",
    "        sug_lambda = trial.suggest_float('reg_lambda', 1e-5, 1e-3)\n",
    "\n",
    "        sug_model = xgb.XGBRegressor(n_estimators=sug_estimators,\n",
    "                                     max_depth=sug_depth,\n",
    "                                     reg_alpha=sug_alpha,\n",
    "                                     reg_lambda=sug_lambda)\n",
    "\n",
    "        return sug_model\n",
    "\n",
    "\n",
    "    def create_training(model):\n",
    "        model.fit(trainx[upac_name], trainy[upac_name])\n",
    "    \n",
    "    \n",
    "    def create_evaluation(model):\n",
    "        temp_yhat = model.predict(valx[upac_name])\n",
    "        return sklearn.metrics.mean_squared_error(valy[upac_name], temp_yhat)\n",
    "    \n",
    "    \n",
    "    def create_objective(trial):\n",
    "        # Instantiate the model\n",
    "        temp_model = create_model(trial)\n",
    "\n",
    "        # Train the model\n",
    "        create_training(temp_model)\n",
    "\n",
    "        # Evaluate model\n",
    "        metrics_val = create_evaluation(temp_model)\n",
    "\n",
    "        return metrics_val\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(create_objective, n_trials=ntrials, show_progress_bar=True)\n",
    "    \n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    \n",
    "    # Then train different models using the best parameters found\n",
    "    model_dictionary = {}\n",
    "    for i in np.arange(nruns):\n",
    "        temp_model = xgb.XGBRegressor(n_estimators=study.best_params['n_estimators'],\n",
    "                                      max_depth=study.best_params['max_depth'],\n",
    "                                      reg_alpha=study.best_params['reg_alpha'],\n",
    "                                      reg_lambda=study.best_params['reg_lambda'])\n",
    "        \n",
    "        # Train the model\n",
    "        temp_model.fit(trainx[upac_name].drop('GtiFixedTilt', axis=1),\n",
    "                       trainy[upac_name])\n",
    "        \n",
    "        # Save -> dump(example_model, 'example_model.joblib')\n",
    "        dump(temp_model, 'models/xgboost/{}_ghi/Model {:02d}.joblib'.format(upac_name, i+1))\n",
    "        \n",
    "        # Add it to the dictionary to return\n",
    "        model_dictionary['Model {:02d}'.format(i+1)] = temp_model\n",
    "        \n",
    "    return study, model_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c71ec1ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:46:02.917061Z",
     "start_time": "2022-08-04T15:46:02.901058Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Function for predicting and storing values\n",
    "\n",
    "def do_predictions(dictionary, save_path, X, y, index):\n",
    "    # Go through each model in the dictionary\n",
    "    for model in dictionary.keys():\n",
    "        print('Doing {}'.format(model))\n",
    "        \n",
    "        temp_path = '{}/{}.csv'.format(save_path, model)\n",
    "        \n",
    "        y_pred = dictionary[model].predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['PV'],\n",
    "                              index=index)\n",
    "        \n",
    "        y_pred.to_csv(temp_path)\n",
    "        \n",
    "    # Also save ground-truth data at the end of the loop\n",
    "    y_true = pd.DataFrame(y, columns=['PV'],\n",
    "                          index=index)\n",
    "    \n",
    "    temp_path_gt = '{}/gt.csv'.format(save_path)\n",
    "    y_true.to_csv(temp_path_gt)\n",
    "    \n",
    "    \n",
    "def predict_upacs_ghi(model_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Simply call the function above for each of the settings to simplify\n",
    "    \n",
    "    print('Doing training for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_ghi/train'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_train[upac_name].drop('GtiFixedTilt', axis=1), \n",
    "                   y=y_train[upac_name],\n",
    "                   index=normalized_train[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing validation for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_ghi/val'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_val[upac_name].drop('GtiFixedTilt', axis=1),\n",
    "                   y=y_val[upac_name],\n",
    "                   index=normalized_val[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing testing for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_ghi/test'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_test[upac_name].drop('GtiFixedTilt', axis=1), \n",
    "                   y=y_test[upac_name],\n",
    "                   index=normalized_test[upac_name].index)\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eddc75f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T16:06:49.504030Z",
     "start_time": "2022-08-04T15:46:33.829097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train UPAC08 - Gti, no Ghi\n",
    "\n",
    "upac08_study_ghi, upac08_models_ghi = train_upac_ghi(upac_name='upac08', \n",
    "                                                        trainx=X_train, \n",
    "                                                        trainy=y_train,\n",
    "                                                        valx=X_val, valy=y_val,\n",
    "                                                        testx=X_test, testy=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e7a56969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T02:09:45.988019Z",
     "start_time": "2022-08-05T02:09:41.893101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict UPAC08 - Gti\n",
    "predict_upacs_ghi(model_dictionary=upac08_models_ghi, \n",
    "                  upac_name='upac08',\n",
    "                  X_train=X_train, y_train=y_train,\n",
    "                  X_val=X_val, y_val=y_val,\n",
    "                  X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfa335ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T14:51:17.640654Z",
     "start_time": "2022-08-19T14:51:14.425509Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGBoost model loading\n",
    "\n",
    "xgb_top1_models = {}\n",
    "for i in range(1, 11):\n",
    "    xgb_top1_models['Model {:02d}'.format(i)] = load('models/xgboost/upac08_top1/Model {:02d}.joblib'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c5e4c5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T14:53:18.582848Z",
     "start_time": "2022-08-19T14:53:18.571846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Function for predicting and storing values\n",
    "\n",
    "def do_predictions(dictionary, save_path, X, y, index):\n",
    "    # Go through each model in the dictionary\n",
    "    for model in dictionary.keys():\n",
    "        print('Doing {}'.format(model))\n",
    "        \n",
    "        temp_path = '{}/{}.csv'.format(save_path, model)\n",
    "        \n",
    "        y_pred = dictionary[model].predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['PV'],\n",
    "                              index=index)\n",
    "        \n",
    "        y_pred.to_csv(temp_path)\n",
    "        \n",
    "    # Also save ground-truth data at the end of the loop\n",
    "    y_true = pd.DataFrame(y, columns=['PV'],\n",
    "                          index=index)\n",
    "    \n",
    "    temp_path_gt = '{}/gt.csv'.format(save_path)\n",
    "    y_true.to_csv(temp_path_gt)\n",
    "    \n",
    "    \n",
    "def predict_upacs_top1(model_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Simply call the function above for each of the settings to simplify\n",
    "    \n",
    "    print('Doing training for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/train'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_train[upac_name]['Ghi'].values.reshape(-1, 1), \n",
    "                   y=y_train[upac_name],\n",
    "                   index=normalized_train[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing validation for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/val'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_val[upac_name]['Ghi'].values.reshape(-1, 1),\n",
    "                   y=y_val[upac_name],\n",
    "                   index=normalized_val[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing testing for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/test'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_test[upac_name]['Ghi'].values.reshape(-1, 1), \n",
    "                   y=y_test[upac_name],\n",
    "                   index=normalized_test[upac_name].index)\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72b636e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T14:53:52.690908Z",
     "start_time": "2022-08-19T14:53:48.695008Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict UPAC08 - Gti\n",
    "predict_upacs_top1(model_dictionary=xgb_top1_models, \n",
    "                   upac_name='upac08',\n",
    "                   X_train=X_train, y_train=y_train,\n",
    "                   X_val=X_val, y_val=y_val,\n",
    "                   X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87775022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
