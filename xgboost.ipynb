{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfdcc9d0",
   "metadata": {
    "code_folding": [
     0
    ],
    "ExecuteTime": {
     "end_time": "2023-09-12T03:30:25.369637400Z",
     "start_time": "2023-09-12T03:30:24.982793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import IPython\n",
    "\n",
    "from data_pipeline import DataPipeline\n",
    "import model_hyperparams\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date range: 2019-01-01 00:00:00 - 2021-04-01 23:45:00\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the data\n",
    "data_upac08 = DataPipeline('data/upac08')\n",
    "\n",
    "# Track memory usage of the preprocessing\n",
    "preprocessing_memory_usage = memory_usage((data_upac08._do, ()), timestamps=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T03:31:40.177412300Z",
     "start_time": "2023-09-12T03:31:36.635434300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                               Memory Usage\nTimestamp                                  \n2023-09-12 03:31:41.799300608    209.453125\n2023-09-12 03:31:42.564902656    209.453125\n2023-09-12 03:31:42.678918912    217.703125\n2023-09-12 03:31:42.788772608    247.214844\n2023-09-12 03:31:42.896312576    252.300781\n2023-09-12 03:31:43.005580800    250.546875\n2023-09-12 03:31:43.114108928    255.128906\n2023-09-12 03:31:43.223678720    252.921875\n2023-09-12 03:31:43.331668992    259.550781\n2023-09-12 03:31:43.442321664    258.328125\n2023-09-12 03:31:43.551595520    255.085938\n2023-09-12 03:31:43.661953536    263.394531\n2023-09-12 03:31:43.772513280    256.398438\n2023-09-12 03:31:43.885286912    260.660156\n2023-09-12 03:31:43.993970688    268.679688\n2023-09-12 03:31:44.103134720    268.351562\n2023-09-12 03:31:44.211128320    264.046875\n2023-09-12 03:31:44.284924416    239.105469",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Memory Usage</th>\n    </tr>\n    <tr>\n      <th>Timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-09-12 03:31:41.799300608</th>\n      <td>209.453125</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:42.564902656</th>\n      <td>209.453125</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:42.678918912</th>\n      <td>217.703125</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:42.788772608</th>\n      <td>247.214844</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:42.896312576</th>\n      <td>252.300781</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.005580800</th>\n      <td>250.546875</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.114108928</th>\n      <td>255.128906</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.223678720</th>\n      <td>252.921875</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.331668992</th>\n      <td>259.550781</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.442321664</th>\n      <td>258.328125</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.551595520</th>\n      <td>255.085938</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.661953536</th>\n      <td>263.394531</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.772513280</th>\n      <td>256.398438</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.885286912</th>\n      <td>260.660156</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:43.993970688</th>\n      <td>268.679688</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:44.103134720</th>\n      <td>268.351562</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:44.211128320</th>\n      <td>264.046875</td>\n    </tr>\n    <tr>\n      <th>2023-09-12 03:31:44.284924416</th>\n      <td>239.105469</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the memory usage to a dataframe\n",
    "\n",
    "mem_usage = pd.DataFrame(preprocessing_memory_usage, columns=['Memory Usage', 'Timestamp'])\n",
    "mem_usage.index = pd.to_datetime(mem_usage['Timestamp'], unit='s')\n",
    "mem_usage = mem_usage.drop('Timestamp', axis=1)\n",
    "\n",
    "mem_usage"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T03:33:59.808596900Z",
     "start_time": "2023-09-12T03:33:59.784454Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6f415",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-12T03:34:39.354528700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-12 04:34:39,352] A new study created in memory with name: no-name-e972e7d4-a124-4fd8-9930-c84758b877c5\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "730176a7e1f34cb387314b2c52dd55a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-09-12 04:34:46,799] Trial 0 finished with value: 0.009477256263810522 and parameters: {'n_estimators': 4785, 'max_depth': 3285, 'reg_alpha': 0.00018816996119468417, 'reg_lambda': 0.0008805715142108432}. Best is trial 0 with value: 0.009477256263810522.\n",
      "[I 2023-09-12 04:34:54,009] Trial 1 finished with value: 0.008706706804132932 and parameters: {'n_estimators': 4671, 'max_depth': 286, 'reg_alpha': 0.0009756564133401358, 'reg_lambda': 4.5810115334178186e-05}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:01,799] Trial 2 finished with value: 0.00949985384059664 and parameters: {'n_estimators': 4913, 'max_depth': 4094, 'reg_alpha': 0.00026054673068951216, 'reg_lambda': 0.0002565046978320881}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:07,241] Trial 3 finished with value: 0.009345544458874982 and parameters: {'n_estimators': 2669, 'max_depth': 3106, 'reg_alpha': 0.00046634000786086494, 'reg_lambda': 0.0003691595943356122}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:10,984] Trial 4 finished with value: 0.008886781123061337 and parameters: {'n_estimators': 1362, 'max_depth': 3584, 'reg_alpha': 0.0008397706186896328, 'reg_lambda': 8.268522953390218e-05}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:16,805] Trial 5 finished with value: 0.009570630845748693 and parameters: {'n_estimators': 2612, 'max_depth': 4903, 'reg_alpha': 0.00025287191803280933, 'reg_lambda': 0.0009888737985736765}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:25,320] Trial 6 finished with value: 0.009630587798560726 and parameters: {'n_estimators': 4847, 'max_depth': 2767, 'reg_alpha': 0.00021741926837911282, 'reg_lambda': 0.00031391911948504205}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:33,385] Trial 7 finished with value: 0.00918327908190504 and parameters: {'n_estimators': 4424, 'max_depth': 343, 'reg_alpha': 0.0006522585692092597, 'reg_lambda': 0.000741550205333871}. Best is trial 1 with value: 0.008706706804132932.\n",
      "[I 2023-09-12 04:35:39,244] Trial 8 finished with value: 0.008672471351751756 and parameters: {'n_estimators': 3361, 'max_depth': 1142, 'reg_alpha': 0.0009184188755881578, 'reg_lambda': 0.0006554978935821488}. Best is trial 8 with value: 0.008672471351751756.\n",
      "[I 2023-09-12 04:35:41,743] Trial 9 finished with value: 0.0095857274526015 and parameters: {'n_estimators': 638, 'max_depth': 1723, 'reg_alpha': 0.0002525236510370627, 'reg_lambda': 6.299105021224335e-05}. Best is trial 8 with value: 0.008672471351751756.\n",
      "[I 2023-09-12 04:35:48,013] Trial 10 finished with value: 0.01026369776115724 and parameters: {'n_estimators': 3549, 'max_depth': 1698, 'reg_alpha': 1.157219458205452e-05, 'reg_lambda': 0.000593385244834639}. Best is trial 8 with value: 0.008672471351751756.\n",
      "[I 2023-09-12 04:35:54,026] Trial 11 finished with value: 0.00866918608664494 and parameters: {'n_estimators': 3611, 'max_depth': 86, 'reg_alpha': 0.0009458204191120538, 'reg_lambda': 0.000548580095532305}. Best is trial 11 with value: 0.00866918608664494.\n",
      "[I 2023-09-12 04:35:59,908] Trial 12 finished with value: 0.008632358169506249 and parameters: {'n_estimators': 3396, 'max_depth': 1292, 'reg_alpha': 0.0009948165835590823, 'reg_lambda': 0.0005459593128349326}. Best is trial 12 with value: 0.008632358169506249.\n",
      "[I 2023-09-12 04:36:06,567] Trial 13 finished with value: 0.008830251181608517 and parameters: {'n_estimators': 3659, 'max_depth': 987, 'reg_alpha': 0.000797740363907056, 'reg_lambda': 0.0005261697349577419}. Best is trial 12 with value: 0.008632358169506249.\n",
      "[I 2023-09-12 04:36:10,426] Trial 14 finished with value: 0.008651659687050981 and parameters: {'n_estimators': 1794, 'max_depth': 49, 'reg_alpha': 0.000984945676216374, 'reg_lambda': 0.0004674495345779937}. Best is trial 12 with value: 0.008632358169506249.\n",
      "[I 2023-09-12 04:36:14,100] Trial 15 finished with value: 0.008631862486357141 and parameters: {'n_estimators': 1687, 'max_depth': 2071, 'reg_alpha': 0.0009961394369962721, 'reg_lambda': 0.0004408836653068014}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:18,413] Trial 16 finished with value: 0.009093007600533226 and parameters: {'n_estimators': 1933, 'max_depth': 2156, 'reg_alpha': 0.0007342769879328879, 'reg_lambda': 0.0004237947773942813}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:20,299] Trial 17 finished with value: 0.009214749122710674 and parameters: {'n_estimators': 213, 'max_depth': 2359, 'reg_alpha': 0.0006503042102132578, 'reg_lambda': 0.0006968272714537602}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:23,284] Trial 18 finished with value: 0.008879869388062058 and parameters: {'n_estimators': 1208, 'max_depth': 1111, 'reg_alpha': 0.0008678652596181333, 'reg_lambda': 0.0002314786093384306}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:27,455] Trial 19 finished with value: 0.008702201197774472 and parameters: {'n_estimators': 2135, 'max_depth': 1787, 'reg_alpha': 0.0009883862946934196, 'reg_lambda': 0.0004441225412366277}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:33,313] Trial 20 finished with value: 0.008867584905922455 and parameters: {'n_estimators': 3130, 'max_depth': 830, 'reg_alpha': 0.0007924222795065304, 'reg_lambda': 0.0006162419399531739}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:37,221] Trial 21 finished with value: 0.00864221350510357 and parameters: {'n_estimators': 1592, 'max_depth': 638, 'reg_alpha': 0.0009971714060585972, 'reg_lambda': 0.0004726980138290653}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:40,469] Trial 22 finished with value: 0.008767528499029047 and parameters: {'n_estimators': 1215, 'max_depth': 1436, 'reg_alpha': 0.0008944527789171485, 'reg_lambda': 0.0005048803865319257}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:43,048] Trial 23 finished with value: 0.008788039614448098 and parameters: {'n_estimators': 761, 'max_depth': 637, 'reg_alpha': 0.0009005494736603685, 'reg_lambda': 0.00038851348643939343}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:49,677] Trial 24 finished with value: 0.00864140978535801 and parameters: {'n_estimators': 4028, 'max_depth': 2150, 'reg_alpha': 0.000987753432491292, 'reg_lambda': 0.0005580009116924414}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:36:56,469] Trial 25 finished with value: 0.008675969432255543 and parameters: {'n_estimators': 4164, 'max_depth': 2036, 'reg_alpha': 0.0008732909738618905, 'reg_lambda': 0.0007469076752131014}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:02,915] Trial 26 finished with value: 0.008970720299600735 and parameters: {'n_estimators': 3968, 'max_depth': 2628, 'reg_alpha': 0.0007496135824946515, 'reg_lambda': 0.0005550105403545444}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:08,078] Trial 27 finished with value: 0.008697137832575154 and parameters: {'n_estimators': 3019, 'max_depth': 1344, 'reg_alpha': 0.0009196015767620061, 'reg_lambda': 0.0005940038752940082}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:12,402] Trial 28 finished with value: 0.00877677633484111 and parameters: {'n_estimators': 2263, 'max_depth': 2900, 'reg_alpha': 0.0008404574453124658, 'reg_lambda': 0.0006584721343571649}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:18,900] Trial 29 finished with value: 0.008873078242161919 and parameters: {'n_estimators': 3972, 'max_depth': 3491, 'reg_alpha': 0.0009919493378664852, 'reg_lambda': 0.0008291592202642716}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:24,191] Trial 30 finished with value: 0.00869578089367409 and parameters: {'n_estimators': 2981, 'max_depth': 2206, 'reg_alpha': 0.0009165372596112932, 'reg_lambda': 0.0005029185189442107}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:27,858] Trial 31 finished with value: 0.008664011946871037 and parameters: {'n_estimators': 1645, 'max_depth': 610, 'reg_alpha': 0.0009999348012101439, 'reg_lambda': 0.00045408255429012863}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:31,798] Trial 32 finished with value: 0.0086614632208964 and parameters: {'n_estimators': 1499, 'max_depth': 1473, 'reg_alpha': 0.0009474495131489862, 'reg_lambda': 0.0005277833112065356}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:36,450] Trial 33 finished with value: 0.008646884637674436 and parameters: {'n_estimators': 2389, 'max_depth': 1839, 'reg_alpha': 0.000992835050845013, 'reg_lambda': 0.0003567591349150984}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:44,100] Trial 34 finished with value: 0.008734080101332458 and parameters: {'n_estimators': 4467, 'max_depth': 2554, 'reg_alpha': 0.0009349198162792675, 'reg_lambda': 0.0004763197335619238}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:46,803] Trial 35 finished with value: 0.0088269195206585 and parameters: {'n_estimators': 843, 'max_depth': 527, 'reg_alpha': 0.000851845924228963, 'reg_lambda': 0.00040936139203841433}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:51,766] Trial 36 finished with value: 0.009394481235844921 and parameters: {'n_estimators': 2704, 'max_depth': 3100, 'reg_alpha': 0.0004434640788821254, 'reg_lambda': 0.0005797703472201446}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:37:56,240] Trial 37 finished with value: 0.008677431079889112 and parameters: {'n_estimators': 2048, 'max_depth': 3862, 'reg_alpha': 0.0009425749595899117, 'reg_lambda': 0.0003188051443877666}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:01,153] Trial 38 finished with value: 0.008759261595345494 and parameters: {'n_estimators': 2683, 'max_depth': 853, 'reg_alpha': 0.0008138328539247161, 'reg_lambda': 0.00048622876256400197}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:06,702] Trial 39 finished with value: 0.008757628293468165 and parameters: {'n_estimators': 3238, 'max_depth': 1300, 'reg_alpha': 0.0008813315347560279, 'reg_lambda': 0.00039314050267100014}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:14,475] Trial 40 finished with value: 0.008636246082168076 and parameters: {'n_estimators': 4963, 'max_depth': 1973, 'reg_alpha': 0.0009443794055185072, 'reg_lambda': 0.0006435032856021477}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:21,920] Trial 41 finished with value: 0.008632531721077856 and parameters: {'n_estimators': 4715, 'max_depth': 1957, 'reg_alpha': 0.0009639600525763205, 'reg_lambda': 0.0006370529052834374}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:29,762] Trial 42 finished with value: 0.008664559194521158 and parameters: {'n_estimators': 4938, 'max_depth': 1940, 'reg_alpha': 0.0009423668147243484, 'reg_lambda': 0.0006217958475578395}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:36,991] Trial 43 finished with value: 0.008660559919569493 and parameters: {'n_estimators': 4637, 'max_depth': 2375, 'reg_alpha': 0.0009479080108091333, 'reg_lambda': 0.0005574904008222981}. Best is trial 15 with value: 0.008631862486357141.\n",
      "[I 2023-09-12 04:38:43,820] Trial 44 finished with value: 0.008726627671598243 and parameters: {'n_estimators': 4269, 'max_depth': 1660, 'reg_alpha': 0.0008797166596571181, 'reg_lambda': 0.000658367471312413}. Best is trial 15 with value: 0.008631862486357141.\n"
     ]
    }
   ],
   "source": [
    "# Create the study for the UPAC parameter optimization\n",
    "\n",
    "xgb_study = model_hyperparams.parameter_sweep_xgb(train_x=data_upac08.train_data[0],\n",
    "                                                  train_y=data_upac08.train_data[1],\n",
    "                                                  val_x=data_upac08.val_data[0],\n",
    "                                                  val_y=data_upac08.val_data[1],\n",
    "                                                  n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the UPAC model and track memory usage\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=xgb_study.best_params['n_estimators'],\n",
    "                             max_depth=xgb_study.best_params['max_depth'],\n",
    "                             reg_alpha=xgb_study.best_params['reg_alpha'],\n",
    "                             reg_lambda=xgb_study.best_params['reg_lambda'])\n",
    "\n",
    "model_mem_usage = memory_usage((xgb_model.fit, (data_upac08.train_data[0], data_upac08.train_data[1])), timestamps=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d387bc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T19:11:12.304912700Z",
     "start_time": "2023-09-11T19:11:11.592260500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a training loop for UPACs\n",
    "\n",
    "from joblib import dump, load\n",
    "import optuna\n",
    "\n",
    "def train_upac(upac_name, trainx, trainy, valx, valy, testx, testy, ntrials=100, nruns=10):\n",
    "    # First do a parameter sweep with Optuna\n",
    "    def create_model(trial):\n",
    "        # Do search for n_estimators, max_depth, reg_alpha and reg_lambda\n",
    "        sug_estimators = trial.suggest_int('n_estimators', 50, 5000)\n",
    "        sug_depth = trial.suggest_int('max_depth', 10, 5000)\n",
    "        sug_alpha = trial.suggest_float('reg_alpha', 1e-5, 1e-3)\n",
    "        sug_lambda = trial.suggest_float('reg_lambda', 1e-5, 1e-3)\n",
    "\n",
    "        sug_model = xgb.XGBRegressor(n_estimators=sug_estimators,\n",
    "                                     max_depth=sug_depth,\n",
    "                                     reg_alpha=sug_alpha,\n",
    "                                     reg_lambda=sug_lambda)\n",
    "\n",
    "        return sug_model\n",
    "\n",
    "\n",
    "    def create_training(model):\n",
    "        model.fit(trainx[upac_name], trainy[upac_name])\n",
    "    \n",
    "    \n",
    "    def create_evaluation(model):\n",
    "        temp_yhat = model.predict(valx[upac_name])\n",
    "        return sklearn.metrics.mean_squared_error(valy[upac_name], temp_yhat)\n",
    "    \n",
    "    \n",
    "    def create_objective(trial):\n",
    "        # Instantiate the model\n",
    "        temp_model = create_model(trial)\n",
    "\n",
    "        # Train the model\n",
    "        create_training(temp_model)\n",
    "\n",
    "        # Evaluate model\n",
    "        metrics_val = create_evaluation(temp_model)\n",
    "\n",
    "        return metrics_val\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(create_objective, n_trials=ntrials, show_progress_bar=True)\n",
    "    \n",
    "    IPython.display.clear_output()\n",
    "\n",
    "    @profile\n",
    "    def train_xgb(current_study):\n",
    "        inner_model = xgb.XGBRegressor(n_estimators=current_study.best_params['n_estimators'],\n",
    "                                       max_depth=current_study.best_params['max_depth'],\n",
    "                                       reg_alpha=current_study.best_params['reg_alpha'],\n",
    "                                       reg_lambda=current_study.best_params['reg_lambda'])\n",
    "        return inner_model\n",
    "    \n",
    "    # Then train different models using the best parameters found\n",
    "    model_dictionary = {}\n",
    "\n",
    "    for i in np.arange(nruns):\n",
    "        temp_model = train_xgb(study)\n",
    "        \n",
    "        # Train the model\n",
    "        temp_model.fit(trainx[upac_name],#['Ghi'].values.reshape(trainx[upac_name].values.shape[0], 1),\n",
    "                       trainy[upac_name])\n",
    "        \n",
    "        # Save -> dump(example_model, 'example_model.joblib')\n",
    "        dump(temp_model, 'models/xgboost/{}_all/Model {:02d}.joblib'.format(upac_name, i+1))\n",
    "        \n",
    "        # Add it to the dictionary to return\n",
    "        model_dictionary['Model {:02d}'.format(i+1)] = temp_model\n",
    "        \n",
    "    return study, model_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df04342f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T01:02:15.141114200Z",
     "start_time": "2023-09-12T01:02:15.110047700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Function for predicting and storing values\n",
    "\n",
    "def do_predictions(dictionary, save_path, X, y, index, scaler=None):\n",
    "\n",
    "    # Create a scaler for only the first variable\n",
    "    temp_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    temp_scaler.min\n",
    "\n",
    "    # Go through each model in the dictionary\n",
    "    for model in dictionary.keys():\n",
    "        print('Doing {}'.format(model))\n",
    "        \n",
    "        temp_path = '{}/{}.csv'.format(save_path, model)\n",
    "        \n",
    "        y_pred = dictionary[model].predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['PV'],\n",
    "                              index=index)\n",
    "\n",
    "        if scaler is not None:\n",
    "            # Use only the scaler's first column for the inverse transform\n",
    "            y_pred = scaler.inverse_transform(y_pred)\n",
    "\n",
    "        y_pred.to_csv(temp_path)\n",
    "        \n",
    "    # Also save ground-truth data at the end of the loop\n",
    "    y_true = pd.DataFrame(y, columns=['PV'],\n",
    "                          index=index)\n",
    "    \n",
    "    temp_path_gt = '{}/gt.csv'.format(save_path)\n",
    "    y_true.to_csv(temp_path_gt)\n",
    "    \n",
    "    \n",
    "def predict_upacs(model_dictionary, scaler_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Simply call the function above for each of the settings to simplify\n",
    "    \n",
    "    print('Doing training for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_all/train'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_train[upac_name],#[['CloudOpacity', 'GtiFixedTilt', 'Day Y', 'Year X']], \n",
    "                   y=y_train[upac_name],\n",
    "                   index=normalized_train[upac_name].index,\n",
    "                   scaler=scaler_dictionary[upac_name])\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing validation for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_all/val'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_val[upac_name],#[['CloudOpacity', 'GtiFixedTilt', 'Day Y', 'Year X']], \n",
    "                   y=y_val[upac_name],\n",
    "                   index=normalized_val[upac_name].index,\n",
    "                   scaler=scaler_dictionary[upac_name])\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing testing for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_all/test'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_test[upac_name],#[['CloudOpacity', 'GtiFixedTilt', 'Day Y', 'Year X']], \n",
    "                   y=y_test[upac_name],\n",
    "                   index=normalized_test[upac_name].index,\n",
    "                   scaler=scaler_dictionary[upac_name])\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d69fdc33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T01:02:22.846176200Z",
     "start_time": "2023-09-12T01:02:18.700414Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-12 02:02:18,704] A new study created in memory with name: no-name-85fc71df-2d70-4a72-b549-1f998be38e9c\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4dfbdb8a2cff4e31ac249dcafed779e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2023-09-12 02:02:21,500] Trial 0 failed with parameters: {'n_estimators': 3974, 'max_depth': 3725, 'reg_alpha': 0.0009189958152627335, 'reg_lambda': 0.0004990061089832175} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\camar\\AppData\\Local\\Temp\\ipykernel_26048\\3934146206.py\", line 37, in create_objective\n",
      "    create_training(temp_model)\n",
      "  File \"C:\\Users\\camar\\AppData\\Local\\Temp\\ipykernel_26048\\3934146206.py\", line 24, in create_training\n",
      "    model.fit(trainx[upac_name], trainy[upac_name])\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 1915, in update\n",
      "    self._validate_dmatrix_features(dtrain)\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2747, in _validate_dmatrix_features\n",
      "    self._validate_features(fn)\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 2750, in _validate_features\n",
      "    if self.feature_names is None:\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 1868, in feature_names\n",
      "    return self._get_feature_info(\"feature_name\")\n",
      "  File \"C:\\Users\\camar\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py\", line 1826, in _get_feature_info\n",
      "    _LIB.XGBoosterGetStrFeatureInfo(\n",
      "KeyboardInterrupt\n",
      "[W 2023-09-12 02:02:21,562] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train UPAC08 - all features\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m upac08_study, upac08_models \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_upac\u001B[49m\u001B[43m(\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mupac08\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mtrainx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mtrainy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mvalx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvaly\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mtestx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtesty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[16], line 45\u001B[0m, in \u001B[0;36mtrain_upac\u001B[1;34m(upac_name, trainx, trainy, valx, valy, testx, testy, ntrials, nruns)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m metrics_val\n\u001B[0;32m     44\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminimize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 45\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcreate_objective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mntrials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m IPython\u001B[38;5;241m.\u001B[39mdisplay\u001B[38;5;241m.\u001B[39mclear_output()\n\u001B[0;32m     49\u001B[0m \u001B[38;5;129m@profile\u001B[39m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_xgb\u001B[39m(current_study):\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\study.py:442\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    341\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    348\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    349\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    350\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    351\u001B[0m \n\u001B[0;32m    352\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    441\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 442\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    444\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    445\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    446\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    447\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    448\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    449\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    450\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    451\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    250\u001B[0m ):\n\u001B[1;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[16], line 37\u001B[0m, in \u001B[0;36mtrain_upac.<locals>.create_objective\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m     34\u001B[0m temp_model \u001B[38;5;241m=\u001B[39m create_model(trial)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m \u001B[43mcreate_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtemp_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# Evaluate model\u001B[39;00m\n\u001B[0;32m     40\u001B[0m metrics_val \u001B[38;5;241m=\u001B[39m create_evaluation(temp_model)\n",
      "Cell \u001B[1;32mIn[16], line 24\u001B[0m, in \u001B[0;36mtrain_upac.<locals>.create_training\u001B[1;34m(model)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_training\u001B[39m(model):\n\u001B[1;32m---> 24\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainx\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainy\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1025\u001B[0m, in \u001B[0;36mXGBModel.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[0;32m   1014\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1016\u001B[0m (\n\u001B[0;32m   1017\u001B[0m     model,\n\u001B[0;32m   1018\u001B[0m     metric,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1023\u001B[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001B[0;32m   1024\u001B[0m )\n\u001B[1;32m-> 1025\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1026\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1027\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1028\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1029\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1030\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1031\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1032\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1034\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1035\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1036\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1037\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_evaluation_result(evals_result)\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\training.py:185\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m--> 185\u001B[0m \u001B[43mbst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:1915\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[0;32m   1913\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtrain, DMatrix):\n\u001B[0;32m   1914\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minvalid training matrix: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(dtrain)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1915\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_dmatrix_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1917\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1918\u001B[0m     _check_call(_LIB\u001B[38;5;241m.\u001B[39mXGBoosterUpdateOneIter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[0;32m   1919\u001B[0m                                             ctypes\u001B[38;5;241m.\u001B[39mc_int(iteration),\n\u001B[0;32m   1920\u001B[0m                                             dtrain\u001B[38;5;241m.\u001B[39mhandle))\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:2747\u001B[0m, in \u001B[0;36mBooster._validate_dmatrix_features\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   2744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2745\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types \u001B[38;5;241m=\u001B[39m ft\n\u001B[1;32m-> 2747\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:2750\u001B[0m, in \u001B[0;36mBooster._validate_features\u001B[1;34m(self, feature_names)\u001B[0m\n\u001B[0;32m   2749\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_features\u001B[39m(\u001B[38;5;28mself\u001B[39m, feature_names: Optional[FeatureNames]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 2750\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_names\u001B[49m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2751\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m   2753\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m feature_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:1868\u001B[0m, in \u001B[0;36mBooster.feature_names\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1862\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m   1863\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfeature_names\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[FeatureNames]:\n\u001B[0;32m   1864\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Feature names for this booster.  Can be directly set by input data or by\u001B[39;00m\n\u001B[0;32m   1865\u001B[0m \u001B[38;5;124;03m    assignment.\u001B[39;00m\n\u001B[0;32m   1866\u001B[0m \n\u001B[0;32m   1867\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1868\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_feature_info\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfeature_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\xgboost\\core.py:1826\u001B[0m, in \u001B[0;36mBooster._get_feature_info\u001B[1;34m(self, field)\u001B[0m\n\u001B[0;32m   1823\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhandle\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1825\u001B[0m _check_call(\n\u001B[1;32m-> 1826\u001B[0m     \u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterGetStrFeatureInfo\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1827\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfield\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43msarr\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1828\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1829\u001B[0m )\n\u001B[0;32m   1830\u001B[0m feature_info \u001B[38;5;241m=\u001B[39m from_cstr_to_pystr(sarr, length)\n\u001B[0;32m   1831\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m feature_info \u001B[38;5;28;01mif\u001B[39;00m feature_info \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Train UPAC08 - all features\n",
    "\n",
    "upac08_study, upac08_models = train_upac(upac_name='upac08', \n",
    "                                         trainx=X_train, \n",
    "                                         trainy=y_train,\n",
    "                                         valx=X_val, valy=y_val,\n",
    "                                         testx=X_test, testy=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "001ed764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T19:30:56.433655900Z",
     "start_time": "2023-09-11T19:30:56.419063700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'n_estimators': 2460,\n 'max_depth': 10,\n 'reg_alpha': 0.0008393587688220376,\n 'reg_lambda': 0.000408292306694367}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UPAC08 best params\n",
    "\n",
    "upac08_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99e960cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T01:02:32.770286600Z",
     "start_time": "2023-09-12T01:02:32.425674200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing training for upac08\n",
      "Doing Model 01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (34848,1) doesn't match the broadcast shape (34848,23)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Predict UPAC08 - All features\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mpredict_upacs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_dictionary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupac08_models\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m              \u001B[49m\u001B[43mupac_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mupac08\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m              \u001B[49m\u001B[43mX_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m              \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m              \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m              \u001B[49m\u001B[43mscaler_dictionary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaler_dict\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[19], line 33\u001B[0m, in \u001B[0;36mpredict_upacs\u001B[1;34m(model_dictionary, scaler_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDoing training for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(upac_name))\n\u001B[0;32m     32\u001B[0m temp_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresults/xgboost/\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_all/train\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(upac_name)\n\u001B[1;32m---> 33\u001B[0m \u001B[43mdo_predictions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdictionary\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_dictionary\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m               \u001B[49m\u001B[43msave_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtemp_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[43m               \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;66;43;03m#[['CloudOpacity', 'GtiFixedTilt', 'Day Y', 'Year X']], \u001B[39;49;00m\n\u001B[0;32m     36\u001B[0m \u001B[43m               \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m               \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnormalized_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m               \u001B[49m\u001B[43mscaler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaler_dictionary\u001B[49m\u001B[43m[\u001B[49m\u001B[43mupac_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m IPython\u001B[38;5;241m.\u001B[39mdisplay\u001B[38;5;241m.\u001B[39mclear_output()\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDoing validation for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(upac_name))\n",
      "Cell \u001B[1;32mIn[19], line 16\u001B[0m, in \u001B[0;36mdo_predictions\u001B[1;34m(dictionary, save_path, X, y, index, scaler)\u001B[0m\n\u001B[0;32m     11\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(y_pred, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPV\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     12\u001B[0m                           index\u001B[38;5;241m=\u001B[39mindex)\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m scaler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     15\u001B[0m         \u001B[38;5;66;03m# Use only the scaler's first column for the inverse transform\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m         y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minverse_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m     y_pred\u001B[38;5;241m.\u001B[39mto_csv(temp_path)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# Also save ground-truth data at the end of the loop\u001B[39;00m\n",
      "File \u001B[1;32m~\\DataspellProjects\\pv_forecast\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:547\u001B[0m, in \u001B[0;36mMinMaxScaler.inverse_transform\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    541\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    543\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m    544\u001B[0m     X, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy, dtype\u001B[38;5;241m=\u001B[39mFLOAT_DTYPES, force_all_finite\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    545\u001B[0m )\n\u001B[1;32m--> 547\u001B[0m X \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_\n\u001B[0;32m    548\u001B[0m X \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale_\n\u001B[0;32m    549\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X\n",
      "\u001B[1;31mValueError\u001B[0m: non-broadcastable output operand with shape (34848,1) doesn't match the broadcast shape (34848,23)"
     ]
    }
   ],
   "source": [
    "# Predict UPAC08 - All features\n",
    "predict_upacs(model_dictionary=upac08_models, \n",
    "              upac_name='upac08',\n",
    "              X_train=X_train, y_train=y_train,\n",
    "              X_val=X_val, y_val=y_val,\n",
    "              X_test=X_test, y_test=y_test,\n",
    "              scaler_dictionary=scaler_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "686e5c60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T09:29:54.508894Z",
     "start_time": "2022-08-01T09:29:54.494890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a training loop for UPACs\n",
    "\n",
    "from joblib import dump, load\n",
    "import optuna\n",
    "\n",
    "def train_upac_top1(upac_name, trainx, trainy, valx, valy, testx, testy, ntrials=100, nruns=10):\n",
    "    # First do a parameter sweep with Optuna\n",
    "    def create_model(trial):\n",
    "        # Do search for n_estimators, max_depth, reg_alpha and reg_lambda\n",
    "        sug_estimators = trial.suggest_int('n_estimators', 50, 5000)\n",
    "        sug_depth = trial.suggest_int('max_depth', 10, 5000)\n",
    "        sug_alpha = trial.suggest_float('reg_alpha', 1e-5, 1e-3)\n",
    "        sug_lambda = trial.suggest_float('reg_lambda', 1e-5, 1e-3)\n",
    "\n",
    "        sug_model = xgb.XGBRegressor(n_estimators=sug_estimators,\n",
    "                                     max_depth=sug_depth,\n",
    "                                     reg_alpha=sug_alpha,\n",
    "                                     reg_lambda=sug_lambda)\n",
    "\n",
    "        return sug_model\n",
    "\n",
    "\n",
    "    def create_training(model):\n",
    "        model.fit(trainx[upac_name], trainy[upac_name])\n",
    "    \n",
    "    \n",
    "    def create_evaluation(model):\n",
    "        temp_yhat = model.predict(valx[upac_name])\n",
    "        return sklearn.metrics.mean_squared_error(valy[upac_name], temp_yhat)\n",
    "    \n",
    "    \n",
    "    def create_objective(trial):\n",
    "        # Instantiate the model\n",
    "        temp_model = create_model(trial)\n",
    "\n",
    "        # Train the model\n",
    "        create_training(temp_model)\n",
    "\n",
    "        # Evaluate model\n",
    "        metrics_val = create_evaluation(temp_model)\n",
    "\n",
    "        return metrics_val\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(create_objective, n_trials=ntrials, show_progress_bar=True)\n",
    "    \n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    \n",
    "    # Then train different models using the best parameters found\n",
    "    model_dictionary = {}\n",
    "    for i in np.arange(nruns):\n",
    "        temp_model = xgb.XGBRegressor(n_estimators=study.best_params['n_estimators'],\n",
    "                                      max_depth=study.best_params['max_depth'],\n",
    "                                      reg_alpha=study.best_params['reg_alpha'],\n",
    "                                      reg_lambda=study.best_params['reg_lambda'])\n",
    "        \n",
    "        # Train the model\n",
    "        temp_model.fit(trainx[upac_name]['GtiFixedTilt'].values.reshape(trainx[upac_name].values.shape[0], 1),\n",
    "                       trainy[upac_name])\n",
    "        \n",
    "        # Save -> dump(example_model, 'example_model.joblib')\n",
    "        dump(temp_model, 'models/xgboost/{}_top1/Model {:02d}.joblib'.format(upac_name, i+1))\n",
    "        \n",
    "        # Add it to the dictionary to return\n",
    "        model_dictionary['Model {:02d}'.format(i+1)] = temp_model\n",
    "        \n",
    "    return study, model_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b4e587b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:27:45.077916Z",
     "start_time": "2022-08-01T11:27:45.063913Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Function for predicting and storing values\n",
    "\n",
    "def do_predictions(dictionary, save_path, X, y, index):\n",
    "    # Go through each model in the dictionary\n",
    "    for model in dictionary.keys():\n",
    "        print('Doing {}'.format(model))\n",
    "        \n",
    "        temp_path = '{}/{}.csv'.format(save_path, model)\n",
    "        \n",
    "        y_pred = dictionary[model].predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['PV'],\n",
    "                              index=index)\n",
    "        \n",
    "        y_pred.to_csv(temp_path)\n",
    "        \n",
    "    # Also save ground-truth data at the end of the loop\n",
    "    y_true = pd.DataFrame(y, columns=['PV'],\n",
    "                          index=index)\n",
    "    \n",
    "    temp_path_gt = '{}/gt.csv'.format(save_path)\n",
    "    y_true.to_csv(temp_path_gt)\n",
    "    \n",
    "    \n",
    "def predict_upacs_top1(model_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Simply call the function above for each of the settings to simplify\n",
    "    \n",
    "    print('Doing training for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/train'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_train[upac_name]['GtiFixedTilt'].values.reshape(-1, 1), \n",
    "                   y=y_train[upac_name],\n",
    "                   index=normalized_train[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing validation for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/val'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_val[upac_name]['GtiFixedTilt'].values.reshape(-1, 1),\n",
    "                   y=y_val[upac_name],\n",
    "                   index=normalized_val[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing testing for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/test'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_test[upac_name]['GtiFixedTilt'].values.reshape(-1, 1), \n",
    "                   y=y_test[upac_name],\n",
    "                   index=normalized_test[upac_name].index)\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b5945b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:51:59.971150Z",
     "start_time": "2022-08-01T11:28:28.296603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train UPAC08 - top 1\n",
    "\n",
    "upac08_study_top1, upac08_models_top1 = train_upac_top1(upac_name='upac08', \n",
    "                                                        trainx=X_train, \n",
    "                                                        trainy=y_train,\n",
    "                                                        valx=X_val, valy=y_val,\n",
    "                                                        testx=X_test, testy=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ba50edec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:27:47.498459Z",
     "start_time": "2022-08-01T11:27:47.481454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing training for upac08\n",
      "Doing Model 01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 8, got 34848",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16028/1432200141.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Predict UPAC08 - All features\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m predict_upacs_top1(model_dictionary=upac08_models_top1, \n\u001B[0m\u001B[0;32m      3\u001B[0m                    \u001B[0mupac_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'upac08'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m                    \u001B[0mX_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m                    \u001B[0mX_val\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my_val\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16028/913354552.py\u001B[0m in \u001B[0;36mpredict_upacs_top1\u001B[1;34m(model_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test)\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Doing training for {}'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mupac_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m     \u001B[0mtemp_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'results/xgboost/{}_top1/train'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mupac_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 29\u001B[1;33m     do_predictions(dictionary=model_dictionary, \n\u001B[0m\u001B[0;32m     30\u001B[0m                    \u001B[0msave_path\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtemp_path\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m                    \u001B[0mX\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mupac_name\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'GtiFixedTilt'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16028/913354552.py\u001B[0m in \u001B[0;36mdo_predictions\u001B[1;34m(dictionary, save_path, X, y, index)\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[0mtemp_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'{}/{}.csv'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msave_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m         \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdictionary\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m         y_pred = pd.DataFrame(y_pred, columns=['PV'],\n\u001B[0;32m     12\u001B[0m                               index=index)\n",
      "\u001B[1;32mc:\\users\\feel\\jupyter\\ecgomes\\upacs_study\\venv\\lib\\site-packages\\xgboost\\sklearn.py\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001B[0m\n\u001B[0;32m    818\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_can_use_inplace_predict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    819\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 820\u001B[1;33m                 predts = self.get_booster().inplace_predict(\n\u001B[0m\u001B[0;32m    821\u001B[0m                     \u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    822\u001B[0m                     \u001B[0miteration_range\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0miteration_range\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\feel\\jupyter\\ecgomes\\upacs_study\\venv\\lib\\site-packages\\xgboost\\core.py\u001B[0m in \u001B[0;36minplace_predict\u001B[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001B[0m\n\u001B[0;32m   1839\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mvalidate_features\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1840\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_features\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1841\u001B[1;33m                 raise ValueError(\n\u001B[0m\u001B[0;32m   1842\u001B[0m                     \u001B[1;34mf\"Feature shape mismatch, expected: {self.num_features()}, \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1843\u001B[0m                     \u001B[1;34mf\"got {data.shape[0]}\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Feature shape mismatch, expected: 8, got 34848"
     ]
    }
   ],
   "source": [
    "# Predict UPAC08 - All features\n",
    "predict_upacs_top1(model_dictionary=upac08_models_top1, \n",
    "                   upac_name='upac08',\n",
    "                   X_train=X_train, y_train=y_train,\n",
    "                   X_val=X_val, y_val=y_val,\n",
    "                   X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49583e8",
   "metadata": {},
   "source": [
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c63ac7a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:10:53.743439Z",
     "start_time": "2022-08-04T15:10:53.723444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a training loop for UPACs\n",
    "\n",
    "from joblib import dump, load\n",
    "import optuna\n",
    "\n",
    "def train_upac_gti(upac_name, trainx, trainy, valx, valy, testx, testy, ntrials=100, nruns=10):\n",
    "    # First do a parameter sweep with Optuna\n",
    "    def create_model(trial):\n",
    "        # Do search for n_estimators, max_depth, reg_alpha and reg_lambda\n",
    "        sug_estimators = trial.suggest_int('n_estimators', 50, 5000)\n",
    "        sug_depth = trial.suggest_int('max_depth', 10, 5000)\n",
    "        sug_alpha = trial.suggest_float('reg_alpha', 1e-5, 1e-3)\n",
    "        sug_lambda = trial.suggest_float('reg_lambda', 1e-5, 1e-3)\n",
    "\n",
    "        sug_model = xgb.XGBRegressor(n_estimators=sug_estimators,\n",
    "                                     max_depth=sug_depth,\n",
    "                                     reg_alpha=sug_alpha,\n",
    "                                     reg_lambda=sug_lambda)\n",
    "\n",
    "        return sug_model\n",
    "\n",
    "\n",
    "    def create_training(model):\n",
    "        model.fit(trainx[upac_name], trainy[upac_name])\n",
    "    \n",
    "    \n",
    "    def create_evaluation(model):\n",
    "        temp_yhat = model.predict(valx[upac_name])\n",
    "        return sklearn.metrics.mean_squared_error(valy[upac_name], temp_yhat)\n",
    "    \n",
    "    \n",
    "    def create_objective(trial):\n",
    "        # Instantiate the model\n",
    "        temp_model = create_model(trial)\n",
    "\n",
    "        # Train the model\n",
    "        create_training(temp_model)\n",
    "\n",
    "        # Evaluate model\n",
    "        metrics_val = create_evaluation(temp_model)\n",
    "\n",
    "        return metrics_val\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(create_objective, n_trials=ntrials, show_progress_bar=True)\n",
    "    \n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    \n",
    "    # Then train different models using the best parameters found\n",
    "    model_dictionary = {}\n",
    "    for i in np.arange(nruns):\n",
    "        temp_model = xgb.XGBRegressor(n_estimators=study.best_params['n_estimators'],\n",
    "                                      max_depth=study.best_params['max_depth'],\n",
    "                                      reg_alpha=study.best_params['reg_alpha'],\n",
    "                                      reg_lambda=study.best_params['reg_lambda'])\n",
    "        \n",
    "        # Train the model\n",
    "        temp_model.fit(trainx[upac_name].drop('Ghi', axis=1),\n",
    "                       trainy[upac_name])\n",
    "        \n",
    "        # Save -> dump(example_model, 'example_model.joblib')\n",
    "        dump(temp_model, 'models/xgboost/{}_gti/Model {:02d}.joblib'.format(upac_name, i+1))\n",
    "        \n",
    "        # Add it to the dictionary to return\n",
    "        model_dictionary['Model {:02d}'.format(i+1)] = temp_model\n",
    "        \n",
    "    return study, model_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f442af33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:12:00.660252Z",
     "start_time": "2022-08-04T15:12:00.650258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Function for predicting and storing values\n",
    "\n",
    "def do_predictions(dictionary, save_path, X, y, index):\n",
    "    # Go through each model in the dictionary\n",
    "    for model in dictionary.keys():\n",
    "        print('Doing {}'.format(model))\n",
    "        \n",
    "        temp_path = '{}/{}.csv'.format(save_path, model)\n",
    "        \n",
    "        y_pred = dictionary[model].predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['PV'],\n",
    "                              index=index)\n",
    "        \n",
    "        y_pred.to_csv(temp_path)\n",
    "        \n",
    "    # Also save ground-truth data at the end of the loop\n",
    "    y_true = pd.DataFrame(y, columns=['PV'],\n",
    "                          index=index)\n",
    "    \n",
    "    temp_path_gt = '{}/gt.csv'.format(save_path)\n",
    "    y_true.to_csv(temp_path_gt)\n",
    "    \n",
    "    \n",
    "def predict_upacs_gti(model_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Simply call the function above for each of the settings to simplify\n",
    "    \n",
    "    print('Doing training for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_gti/train'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_train[upac_name].drop('Ghi', axis=1), \n",
    "                   y=y_train[upac_name],\n",
    "                   index=normalized_train[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing validation for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_gti/val'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_val[upac_name].drop('Ghi', axis=1),\n",
    "                   y=y_val[upac_name],\n",
    "                   index=normalized_val[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing testing for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_gti/test'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_test[upac_name].drop('Ghi', axis=1), \n",
    "                   y=y_test[upac_name],\n",
    "                   index=normalized_test[upac_name].index)\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc6678e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:35:49.627660Z",
     "start_time": "2022-08-04T15:12:51.225648Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train UPAC08 - Gti, no Ghi\n",
    "\n",
    "upac08_study_gti, upac08_models_gti = train_upac_gti(upac_name='upac08', \n",
    "                                                        trainx=X_train, \n",
    "                                                        trainy=y_train,\n",
    "                                                        valx=X_val, valy=y_val,\n",
    "                                                        testx=X_test, testy=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "839955ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:43:32.370119Z",
     "start_time": "2022-08-04T15:43:27.438005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict UPAC08 - Gti\n",
    "predict_upacs_gti(model_dictionary=upac08_models_gti, \n",
    "                  upac_name='upac08',\n",
    "                  X_train=X_train, y_train=y_train,\n",
    "                  X_val=X_val, y_val=y_val,\n",
    "                  X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205dd90",
   "metadata": {},
   "source": [
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8b67d3d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:46:30.013929Z",
     "start_time": "2022-08-04T15:46:30.002924Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a training loop for UPACs\n",
    "\n",
    "from joblib import dump, load\n",
    "import optuna\n",
    "\n",
    "def train_upac_ghi(upac_name, trainx, trainy, valx, valy, testx, testy, ntrials=100, nruns=10):\n",
    "    # First do a parameter sweep with Optuna\n",
    "    def create_model(trial):\n",
    "        # Do search for n_estimators, max_depth, reg_alpha and reg_lambda\n",
    "        sug_estimators = trial.suggest_int('n_estimators', 50, 5000)\n",
    "        sug_depth = trial.suggest_int('max_depth', 10, 5000)\n",
    "        sug_alpha = trial.suggest_float('reg_alpha', 1e-5, 1e-3)\n",
    "        sug_lambda = trial.suggest_float('reg_lambda', 1e-5, 1e-3)\n",
    "\n",
    "        sug_model = xgb.XGBRegressor(n_estimators=sug_estimators,\n",
    "                                     max_depth=sug_depth,\n",
    "                                     reg_alpha=sug_alpha,\n",
    "                                     reg_lambda=sug_lambda)\n",
    "\n",
    "        return sug_model\n",
    "\n",
    "\n",
    "    def create_training(model):\n",
    "        model.fit(trainx[upac_name], trainy[upac_name])\n",
    "    \n",
    "    \n",
    "    def create_evaluation(model):\n",
    "        temp_yhat = model.predict(valx[upac_name])\n",
    "        return sklearn.metrics.mean_squared_error(valy[upac_name], temp_yhat)\n",
    "    \n",
    "    \n",
    "    def create_objective(trial):\n",
    "        # Instantiate the model\n",
    "        temp_model = create_model(trial)\n",
    "\n",
    "        # Train the model\n",
    "        create_training(temp_model)\n",
    "\n",
    "        # Evaluate model\n",
    "        metrics_val = create_evaluation(temp_model)\n",
    "\n",
    "        return metrics_val\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(create_objective, n_trials=ntrials, show_progress_bar=True)\n",
    "    \n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    \n",
    "    # Then train different models using the best parameters found\n",
    "    model_dictionary = {}\n",
    "    for i in np.arange(nruns):\n",
    "        temp_model = xgb.XGBRegressor(n_estimators=study.best_params['n_estimators'],\n",
    "                                      max_depth=study.best_params['max_depth'],\n",
    "                                      reg_alpha=study.best_params['reg_alpha'],\n",
    "                                      reg_lambda=study.best_params['reg_lambda'])\n",
    "        \n",
    "        # Train the model\n",
    "        temp_model.fit(trainx[upac_name].drop('GtiFixedTilt', axis=1),\n",
    "                       trainy[upac_name])\n",
    "        \n",
    "        # Save -> dump(example_model, 'example_model.joblib')\n",
    "        dump(temp_model, 'models/xgboost/{}_ghi/Model {:02d}.joblib'.format(upac_name, i+1))\n",
    "        \n",
    "        # Add it to the dictionary to return\n",
    "        model_dictionary['Model {:02d}'.format(i+1)] = temp_model\n",
    "        \n",
    "    return study, model_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c71ec1ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T15:46:02.917061Z",
     "start_time": "2022-08-04T15:46:02.901058Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Function for predicting and storing values\n",
    "\n",
    "def do_predictions(dictionary, save_path, X, y, index):\n",
    "    # Go through each model in the dictionary\n",
    "    for model in dictionary.keys():\n",
    "        print('Doing {}'.format(model))\n",
    "        \n",
    "        temp_path = '{}/{}.csv'.format(save_path, model)\n",
    "        \n",
    "        y_pred = dictionary[model].predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['PV'],\n",
    "                              index=index)\n",
    "        \n",
    "        y_pred.to_csv(temp_path)\n",
    "        \n",
    "    # Also save ground-truth data at the end of the loop\n",
    "    y_true = pd.DataFrame(y, columns=['PV'],\n",
    "                          index=index)\n",
    "    \n",
    "    temp_path_gt = '{}/gt.csv'.format(save_path)\n",
    "    y_true.to_csv(temp_path_gt)\n",
    "    \n",
    "    \n",
    "def predict_upacs_ghi(model_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Simply call the function above for each of the settings to simplify\n",
    "    \n",
    "    print('Doing training for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_ghi/train'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_train[upac_name].drop('GtiFixedTilt', axis=1), \n",
    "                   y=y_train[upac_name],\n",
    "                   index=normalized_train[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing validation for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_ghi/val'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_val[upac_name].drop('GtiFixedTilt', axis=1),\n",
    "                   y=y_val[upac_name],\n",
    "                   index=normalized_val[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing testing for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_ghi/test'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_test[upac_name].drop('GtiFixedTilt', axis=1), \n",
    "                   y=y_test[upac_name],\n",
    "                   index=normalized_test[upac_name].index)\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eddc75f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-04T16:06:49.504030Z",
     "start_time": "2022-08-04T15:46:33.829097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train UPAC08 - Gti, no Ghi\n",
    "\n",
    "upac08_study_ghi, upac08_models_ghi = train_upac_ghi(upac_name='upac08', \n",
    "                                                        trainx=X_train, \n",
    "                                                        trainy=y_train,\n",
    "                                                        valx=X_val, valy=y_val,\n",
    "                                                        testx=X_test, testy=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e7a56969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T02:09:45.988019Z",
     "start_time": "2022-08-05T02:09:41.893101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict UPAC08 - Gti\n",
    "predict_upacs_ghi(model_dictionary=upac08_models_ghi, \n",
    "                  upac_name='upac08',\n",
    "                  X_train=X_train, y_train=y_train,\n",
    "                  X_val=X_val, y_val=y_val,\n",
    "                  X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfa335ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T14:51:17.640654Z",
     "start_time": "2022-08-19T14:51:14.425509Z"
    }
   },
   "outputs": [],
   "source": [
    "# XGBoost model loading\n",
    "\n",
    "xgb_top1_models = {}\n",
    "for i in range(1, 11):\n",
    "    xgb_top1_models['Model {:02d}'.format(i)] = load('models/xgboost/upac08_top1/Model {:02d}.joblib'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c5e4c5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T14:53:18.582848Z",
     "start_time": "2022-08-19T14:53:18.571846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Function for predicting and storing values\n",
    "\n",
    "def do_predictions(dictionary, save_path, X, y, index):\n",
    "    # Go through each model in the dictionary\n",
    "    for model in dictionary.keys():\n",
    "        print('Doing {}'.format(model))\n",
    "        \n",
    "        temp_path = '{}/{}.csv'.format(save_path, model)\n",
    "        \n",
    "        y_pred = dictionary[model].predict(X)\n",
    "        y_pred = pd.DataFrame(y_pred, columns=['PV'],\n",
    "                              index=index)\n",
    "        \n",
    "        y_pred.to_csv(temp_path)\n",
    "        \n",
    "    # Also save ground-truth data at the end of the loop\n",
    "    y_true = pd.DataFrame(y, columns=['PV'],\n",
    "                          index=index)\n",
    "    \n",
    "    temp_path_gt = '{}/gt.csv'.format(save_path)\n",
    "    y_true.to_csv(temp_path_gt)\n",
    "    \n",
    "    \n",
    "def predict_upacs_top1(model_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Simply call the function above for each of the settings to simplify\n",
    "    \n",
    "    print('Doing training for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/train'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_train[upac_name]['Ghi'].values.reshape(-1, 1), \n",
    "                   y=y_train[upac_name],\n",
    "                   index=normalized_train[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing validation for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/val'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_val[upac_name]['Ghi'].values.reshape(-1, 1),\n",
    "                   y=y_val[upac_name],\n",
    "                   index=normalized_val[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing testing for {}'.format(upac_name))\n",
    "    temp_path = 'results/xgboost/{}_top1/test'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_test[upac_name]['Ghi'].values.reshape(-1, 1), \n",
    "                   y=y_test[upac_name],\n",
    "                   index=normalized_test[upac_name].index)\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72b636e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T14:53:52.690908Z",
     "start_time": "2022-08-19T14:53:48.695008Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict UPAC08 - Gti\n",
    "predict_upacs_top1(model_dictionary=xgb_top1_models, \n",
    "                   upac_name='upac08',\n",
    "                   X_train=X_train, y_train=y_train,\n",
    "                   X_val=X_val, y_val=y_val,\n",
    "                   X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87775022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
