{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b44b64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T15:56:32.008559Z",
     "start_time": "2022-07-28T15:56:26.649046Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import scipy.signal\n",
    "import holidays\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "import seaborn as sb\n",
    "\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a152a0da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T15:56:36.226211Z",
     "start_time": "2022-07-28T15:56:36.217210Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Aux Functions for Solcast and PV data processing\n",
    "\n",
    "def get_solcast(path):\n",
    "    file = pd.read_csv(path)\n",
    "    file.index = pd.to_datetime(file['PeriodEnd'])\n",
    "    file = file.resample('15T').pad()\n",
    "    \n",
    "    return file\n",
    "\n",
    "\n",
    "def get_pv(path):\n",
    "    file = pd.read_csv(path)\n",
    "    file.index = pd.to_datetime(file['datetime_utc'])\n",
    "    file = file.resample('15T').mean()\n",
    "    \n",
    "    return file\n",
    "\n",
    "\n",
    "def get_solcastPV(df1, df2):\n",
    "    '''\n",
    "    df1: PV dataframe\n",
    "    df2: Solcast dataframe\n",
    "    '''\n",
    "    \n",
    "    # Filter both dataframes for 2019 and 2020\n",
    "    try:\n",
    "        temp_df1 = df1['2019':'2021-04-01']\n",
    "        temp_df2 = df2['2019':'2021-04-01']\n",
    "        \n",
    "        # Check if data is complete. If not, match the smaller indexes\n",
    "        if temp_df2.shape[0] < temp_df1.shape[0]:\n",
    "            last_entry = temp_df2.index\n",
    "            temp_df1 = temp_df1['2019':'{}'.format(temp_df2.index[-1].tz_convert(None))]\n",
    "\n",
    "\n",
    "        # Only considering 2019 and 2020 since data is complete for that period\n",
    "        temp_data = pd.DataFrame({'PV': temp_df1['pv'].values}, index=temp_df1.index)\n",
    "        for i in np.arange(3, len(temp_df2.columns)):\n",
    "            temp_data[temp_df2.columns[i]] = temp_df2[temp_df2.columns[i]].shift(-1).values\n",
    "            \n",
    "        return temp_data\n",
    "    except:\n",
    "        temp_df1 = df1['2019':'2020']\n",
    "        temp_df2 = df2['2019':'2020']\n",
    "        \n",
    "        # Check if data is complete. If not, match the smaller indexes\n",
    "        if temp_df2.shape[0] < temp_df1.shape[0]:\n",
    "            last_entry = temp_df2.index\n",
    "            temp_df1 = temp_df1['2019':'{}'.format(temp_df2.index[-1].tz_convert(None))]\n",
    "\n",
    "\n",
    "        # Only considering 2019 and 2020 since data is complete for that period\n",
    "        temp_data = pd.DataFrame({'PV': temp_df1['pv'].values}, index=temp_df1.index)\n",
    "        for i in np.arange(3, len(temp_df2.columns)):\n",
    "            temp_data[temp_df2.columns[i]] = temp_df2[temp_df2.columns[i]].shift(-1).values\n",
    "            \n",
    "        return temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5120862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:24:51.027484Z",
     "start_time": "2022-07-28T16:24:40.084030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upac02 date range: 2019-01-01 00:00:00 - 2020-06-15 22:30:00\n",
      "upac06 date range: 2019-01-01 00:00:00 - 2020-06-15 22:30:00\n",
      "upac08 date range: 2019-01-01 00:00:00 - 2021-04-01 23:45:00\n",
      "upac09 date range: 2019-01-01 00:00:00 - 2020-12-31 23:45:00\n",
      "upac13 date range: 2019-01-01 00:00:00 - 2020-12-31 23:45:00\n"
     ]
    }
   ],
   "source": [
    "# Get data and build a dictionary for preprocessing\n",
    "\n",
    "data = {}\n",
    "\n",
    "folders = glob.glob('C:/Users/FEEL/Jupyter/ecgomes/upacs_study/data/*')\n",
    "for folder in folders:\n",
    "    # Load each of the files inside the folder\n",
    "    temp_pv = get_pv('{}/pv.csv'.format(folder))\n",
    "    temp_solcast = get_solcast('{}/solcast.csv'.format(folder))\n",
    "    \n",
    "    # Join the files into a single dataframe\n",
    "    temp_upac = get_solcastPV(temp_pv, temp_solcast)\n",
    "    \n",
    "    temp_name = folder.split('\\\\')[1]\n",
    "    data[temp_name] = temp_upac\n",
    "    \n",
    "    print('{} date range: {} - {}'.format(temp_name, temp_upac.index[0], temp_upac.index[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd0eb3ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:24:54.802329Z",
     "start_time": "2022-07-28T16:24:54.783325Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Aux Functions for adding 2D time information\n",
    "\n",
    "import datetime\n",
    "\n",
    "def days_2d(df):\n",
    "    '''\n",
    "    Adds 2D time information for single days\n",
    "    df: dataframe to add the information\n",
    "    '''\n",
    "    # Map the index into seconds\n",
    "    timestamp_s = pd.to_datetime(df.index.values).map(datetime.datetime.timestamp)\n",
    "    \n",
    "    # Since we're calculating the cos and sin values from seconds, it's 60 seconds into 60 min into 24 hours per day\n",
    "    day_calc = 24*60*60\n",
    "    \n",
    "    # Calculate the values\n",
    "    dayx = np.cos((2*np.pi/day_calc) * timestamp_s)\n",
    "    dayy = np.sin((2*np.pi/day_calc) * timestamp_s)\n",
    "    \n",
    "    return dayx, dayy\n",
    "    \n",
    "\n",
    "def years_2d(df):\n",
    "    '''\n",
    "    Adds 2D time representation throught a year\n",
    "    df: dataframe to add the information\n",
    "    '''\n",
    "    # Add Year Information\n",
    "\n",
    "    day_year = df.index.dayofyear\n",
    "    year_constant = 365.2524\n",
    "\n",
    "    yearx = np.cos((2*np.pi/year_constant) * day_year)\n",
    "    yeary = np.sin((2*np.pi/year_constant) * day_year)\n",
    "    \n",
    "    return yearx, yeary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39a2b9fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:24:57.680975Z",
     "start_time": "2022-07-28T16:24:56.045608Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Add the 2D time information to the data\n",
    "\n",
    "for upac in data.keys():\n",
    "    dayx, dayy = days_2d(data[upac])\n",
    "    yearx, yeary = years_2d(data[upac])\n",
    "    \n",
    "    data[upac]['Day X'] = dayx\n",
    "    data[upac]['Day Y'] = dayy\n",
    "    \n",
    "    data[upac]['Year X'] = yearx\n",
    "    data[upac]['Year Y'] = yeary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "628a9f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:24:59.119297Z",
     "start_time": "2022-07-28T16:24:59.088290Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FEEL\\AppData\\Local\\Temp/ipykernel_9884/2785044146.py:8: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  data_train[upac] = data[upac]['2019']\n"
     ]
    }
   ],
   "source": [
    "# Split the data for training, validation and testing\n",
    "\n",
    "data_train = {}\n",
    "data_val = {}\n",
    "data_test = {}\n",
    "\n",
    "for upac in data.keys():\n",
    "    data_train[upac] = data[upac]['2019']\n",
    "    data_val[upac] = data[upac]['2020-01':'2020-03']\n",
    "    data_test[upac] = data[upac]['2020-04':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c76592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:25:01.939930Z",
     "start_time": "2022-07-28T16:25:01.925927Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Aux Function for filtering data\n",
    "\n",
    "def filter_by_points(df, frequency='D', num_points=1440, return_dictionary=False):\n",
    "    \n",
    "    df_dropped = df.dropna()\n",
    "    grouper = df_dropped.groupby(pd.Grouper(freq=frequency))\n",
    "    \n",
    "    output = 0\n",
    "    if return_dictionary:\n",
    "        new_dict = {}\n",
    "        for i in grouper:\n",
    "            if (len(i[1]) != num_points):\n",
    "                pass\n",
    "            else:\n",
    "                new_dict[i[0]] = pd.DataFrame(i[1])\n",
    "        output = new_dict\n",
    "    else:\n",
    "        new_df = pd.DataFrame({})\n",
    "        for i in grouper:\n",
    "            if (len(i[1]) != num_points):\n",
    "                pass\n",
    "            else:\n",
    "                new_df = new_df.append(pd.DataFrame(i[1]))\n",
    "        output = new_df\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d3c7c8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:25:05.164653Z",
     "start_time": "2022-07-28T16:25:02.981163Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Filter the data by number of points that should be present in a single day\n",
    "\n",
    "filtered_train = {}\n",
    "filtered_val = {}\n",
    "filtered_test = {}\n",
    "\n",
    "for upac in data_train.keys():\n",
    "    filtered_train[upac] = filter_by_points(data_train[upac], frequency='D', num_points=1440/15)\n",
    "    filtered_val[upac] = filter_by_points(data_val[upac], frequency='D', num_points=1440/15)\n",
    "    filtered_test[upac] = filter_by_points(data_test[upac], frequency='D', num_points=1440/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5c6853e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:25:11.056973Z",
     "start_time": "2022-07-28T16:25:11.043970Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Select columns to use\n",
    "\n",
    "USED_COLUMNS = ['PV', \n",
    "                'AirTemp', \n",
    "                'CloudOpacity',\n",
    "                'Ghi',\n",
    "                'GtiFixedTilt', \n",
    "                'Day Y', 'Day X',\n",
    "                'Year Y', 'Year X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e701b466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:25:19.905956Z",
     "start_time": "2022-07-28T16:25:19.864947Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "# We don't want to normalize PV so we can capture diferences more easily\n",
    "\n",
    "# Feature range\n",
    "# PV - greater than 0\n",
    "# AirTemp - Unchanged\n",
    "# Cloud Opacity and Ghi - between 0 and 1\n",
    "# Day X, Y and Year X and Y - already between -1 and 1\n",
    "\n",
    "MAX_OPACITY = 100\n",
    "MAX_GHI = 1023\n",
    "MAX_GTI = 1071\n",
    "\n",
    "normalized_train = {}\n",
    "normalized_val = {}\n",
    "normalized_test = {}\n",
    "\n",
    "for upac in filtered_train.keys():\n",
    "    normalized_train[upac] = filtered_train[upac][USED_COLUMNS].copy(deep=True)\n",
    "    normalized_val[upac] = filtered_val[upac][USED_COLUMNS].copy(deep=True)\n",
    "    normalized_test[upac] = filtered_test[upac][USED_COLUMNS].copy(deep=True)\n",
    "    \n",
    "    normalized_train[upac]['CloudOpacity'] = normalized_train[upac]['CloudOpacity'] / MAX_OPACITY\n",
    "    normalized_val[upac]['CloudOpacity'] = normalized_val[upac]['CloudOpacity'] / MAX_OPACITY\n",
    "    normalized_test[upac]['CloudOpacity'] = normalized_test[upac]['CloudOpacity'] / MAX_OPACITY\n",
    "    \n",
    "    normalized_train[upac]['Ghi'] = normalized_train[upac]['Ghi'] / MAX_GHI\n",
    "    normalized_val[upac]['Ghi'] = normalized_val[upac]['Ghi'] / MAX_GHI\n",
    "    normalized_test[upac]['Ghi'] = normalized_test[upac]['Ghi'] / MAX_GHI\n",
    "    \n",
    "    normalized_train[upac]['GtiFixedTilt'] = normalized_train[upac]['GtiFixedTilt'] / MAX_GTI\n",
    "    normalized_val[upac]['GtiFixedTilt'] = normalized_val[upac]['GtiFixedTilt'] / MAX_GTI\n",
    "    normalized_test[upac]['GtiFixedTilt'] = normalized_test[upac]['GtiFixedTilt'] / MAX_GTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba1dbd29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:25:37.699945Z",
     "start_time": "2022-07-28T16:25:37.684942Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Aux Function DNN Specific - Data Reshaping and Windowing\n",
    "\n",
    "def split_sequence(sequence, n_steps, n_intervals):\n",
    "    X = list()\n",
    "    for i in np.arange(0, len(sequence), n_intervals):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence) - 1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = sequence[i:end_ix]\n",
    "        X.append(seq_x)\n",
    "    return np.array(X)\n",
    "\n",
    "def split_dataframe(df, input_width):\n",
    "    current_list = []\n",
    "    for i in df.columns[1:]:\n",
    "        current_sequence = split_sequence(df[i], input_width, 1)\n",
    "        current_list.append(current_sequence)\n",
    "        \n",
    "    stacked_list = np.stack(current_list, axis=-1)\n",
    "    \n",
    "    return stacked_list\n",
    "\n",
    "\n",
    "def do_windowing(df, input_width=1, y_col='PV'):\n",
    "    '''\n",
    "    Perform the windowing on the dataframe\n",
    "    df: input dataframe to perform windowing\n",
    "    input_width: temporal dimension size or number of timesteps\n",
    "    y_col: name of column for the prediction\n",
    "    '''\n",
    "    \n",
    "    temp_x = split_dataframe(df, input_width)\n",
    "    temp_y = df[y_col].values[input_width-1:-1]\n",
    "    \n",
    "    return temp_x, temp_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8de69fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:25:38.688167Z",
     "start_time": "2022-07-28T16:25:38.673165Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Do windowing on the data\n",
    "\n",
    "X_train = {}\n",
    "y_train = {}\n",
    "\n",
    "X_val = {}\n",
    "y_val = {}\n",
    "\n",
    "X_test = {}\n",
    "y_test = {}\n",
    "\n",
    "for upac in normalized_train.keys():\n",
    "    trainx = normalized_train[upac].drop('PV', axis=1)\n",
    "    trainy = normalized_train[upac]['PV']\n",
    "    valx = normalized_val[upac].drop('PV', axis=1)\n",
    "    valy = normalized_val[upac]['PV']\n",
    "    testx = normalized_test[upac].drop('PV', axis=1)\n",
    "    testy = normalized_test[upac]['PV']\n",
    "    \n",
    "    X_train[upac] = trainx\n",
    "    X_val[upac] = valx\n",
    "    X_test[upac] = testx\n",
    "    \n",
    "    y_train[upac] = trainy\n",
    "    y_val[upac] = valy\n",
    "    y_test[upac] = testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6b0a12c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:25:39.949450Z",
     "start_time": "2022-07-28T16:25:39.933447Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Functions to compile the model and add necessary info\n",
    "\n",
    "def compile_and_fit(model, train_x, train_y, val_x, val_y,\n",
    "                    max_epochs=1000, es_patience=200, rlr_patience=100, \n",
    "                    adam_lr=0.001):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=es_patience,\n",
    "                                                      mode='min')\n",
    "    \n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                     patience=rlr_patience)\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.mean_squared_error,\n",
    "                  optimizer=tf.optimizers.Adam(learning_rate=adam_lr),\n",
    "                  metrics=[tf.metrics.MeanAbsoluteError(name='mae')])\n",
    "\n",
    "    history = model.fit(train_x, train_y,\n",
    "                        batch_size=32,\n",
    "                        epochs=max_epochs,\n",
    "                        validation_data=(val_x, val_y),\n",
    "                        callbacks=[early_stopping, reduce_lr])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd0dd450",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T10:49:28.105435Z",
     "start_time": "2022-08-01T10:49:28.088439Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aux Function for predicting and storing values\n",
    "\n",
    "def do_predictions(dictionary, save_path, X, y, index):\n",
    "    # Go through each model in the dictionary\n",
    "    for model in dictionary.keys():\n",
    "        print('Doing {}'.format(model))\n",
    "        \n",
    "        temp_path = '{}/{}.csv'.format(save_path, model)\n",
    "        \n",
    "        y_pred = dictionary[model].predict(X, verbose=1)\n",
    "        y_pred = pd.DataFrame(y_pred[:, :], columns=['PV'],\n",
    "                              index=index)\n",
    "        \n",
    "        y_pred.to_csv(temp_path)\n",
    "        \n",
    "    # Also save ground-truth data at the end of the loop\n",
    "    y_true = pd.DataFrame(y, columns=['PV'],\n",
    "                          index=index)\n",
    "    \n",
    "    temp_path_gt = '{}/gt.csv'.format(save_path)\n",
    "    y_true.to_csv(temp_path_gt)\n",
    "    \n",
    "    \n",
    "def predict_upacs(model_dictionary, upac_name, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Simply call the function above for each of the settings to simplify\n",
    "    \n",
    "    print('Doing training for {}'.format(upac_name))\n",
    "    temp_path = 'results/tabnet/{}_ghi+gti/train'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_train[upac_name], \n",
    "                   y=y_train[upac_name],\n",
    "                   index=normalized_train[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing validation for {}'.format(upac_name))\n",
    "    temp_path = 'results/tabnet/{}_ghi+gti/val'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_val[upac_name], \n",
    "                   y=y_val[upac_name],\n",
    "                   index=normalized_val[upac_name].index)\n",
    "    IPython.display.clear_output()\n",
    "    \n",
    "    print('Doing testing for {}'.format(upac_name))\n",
    "    temp_path = 'results/tabnet/{}_ghi+gti/test'.format(upac_name)\n",
    "    do_predictions(dictionary=model_dictionary, \n",
    "                   save_path=temp_path, \n",
    "                   X=X_test[upac_name], \n",
    "                   y=y_test[upac_name],\n",
    "                   index=normalized_test[upac_name].index)\n",
    "    IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcf21b10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T16:25:42.973127Z",
     "start_time": "2022-07-28T16:25:42.963125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the TabNet implementation\n",
    "\n",
    "# From: https://github.com/titu1994/tf-TabNet\n",
    "from tabnet import StackedTabNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17d96dc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-28T18:15:20.904913Z",
     "start_time": "2022-07-28T16:25:52.325726Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-28 17:25:53,444]\u001b[0m A new study created in memory with name: no-name-27e8e2e1-11b9-4e22-a84f-9c9608c59f9b\u001b[0m\n",
      "c:\\users\\feel\\jupyter\\ecgomes\\upacs_study\\venv\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd34126920664f57ab812edc742c468d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 1ms/step - loss: 1644220.8750 - mae: 712.5095 - val_loss: 1243517.1250 - val_mae: 571.9921 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1270171.1250 - mae: 588.8021 - val_loss: 869593.1875 - val_mae: 448.4728 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 846714.3750 - mae: 457.0482 - val_loss: 545072.2500 - val_mae: 345.8116 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 520005.1562 - mae: 349.7375 - val_loss: 334833.6562 - val_mae: 275.8424 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 314046.1562 - mae: 275.6707 - val_loss: 220491.6094 - val_mae: 234.6279 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 201929.0312 - mae: 226.8295 - val_loss: 171013.5469 - val_mae: 203.2840 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 150179.2969 - mae: 198.5364 - val_loss: 146328.0000 - val_mae: 196.1453 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 127484.0312 - mae: 182.2279 - val_loss: 131967.8594 - val_mae: 176.2371 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 116540.6797 - mae: 172.6573 - val_loss: 126643.6562 - val_mae: 174.8634 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 112394.3203 - mae: 167.0709 - val_loss: 128574.7891 - val_mae: 171.1475 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109114.7500 - mae: 163.3477 - val_loss: 128056.3125 - val_mae: 174.3374 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108316.7656 - mae: 161.7934 - val_loss: 127491.0547 - val_mae: 167.8245 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106605.9844 - mae: 160.0058 - val_loss: 121165.2500 - val_mae: 171.2281 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105948.5078 - mae: 158.6638 - val_loss: 139855.4688 - val_mae: 179.6323 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105105.4922 - mae: 157.4877 - val_loss: 116050.4531 - val_mae: 161.4479 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104476.8906 - mae: 156.7560 - val_loss: 124537.0078 - val_mae: 166.3100 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104348.7031 - mae: 155.6772 - val_loss: 120710.3594 - val_mae: 161.4725 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104445.7891 - mae: 155.7057 - val_loss: 121500.5703 - val_mae: 166.9996 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104392.5391 - mae: 155.4576 - val_loss: 120888.9844 - val_mae: 161.5549 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103125.8594 - mae: 154.0680 - val_loss: 119708.4141 - val_mae: 159.7793 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102897.6172 - mae: 153.2102 - val_loss: 117351.7422 - val_mae: 159.4364 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103524.0000 - mae: 153.8846 - val_loss: 118058.4453 - val_mae: 163.0773 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102336.9375 - mae: 152.5323 - val_loss: 123080.7891 - val_mae: 163.1285 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102159.9141 - mae: 152.2565 - val_loss: 116306.3047 - val_mae: 161.6905 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102343.8438 - mae: 151.9025 - val_loss: 116171.1797 - val_mae: 158.6859 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98785.7656 - mae: 147.2952 - val_loss: 114296.9922 - val_mae: 155.9618 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98578.9297 - mae: 146.8033 - val_loss: 114239.1328 - val_mae: 155.0561 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98587.8828 - mae: 146.6345 - val_loss: 114956.4219 - val_mae: 156.0310 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98567.8516 - mae: 146.7119 - val_loss: 114339.6953 - val_mae: 156.1338 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98380.3906 - mae: 146.6066 - val_loss: 115579.7109 - val_mae: 156.7414 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98360.9375 - mae: 146.4176 - val_loss: 116599.2734 - val_mae: 157.4782 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98361.8203 - mae: 146.4160 - val_loss: 116860.8438 - val_mae: 157.0794 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98341.1328 - mae: 146.3821 - val_loss: 115026.6562 - val_mae: 154.8690 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98293.8516 - mae: 146.2153 - val_loss: 115530.7734 - val_mae: 156.3589 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98259.2422 - mae: 146.2169 - val_loss: 115166.1719 - val_mae: 156.1446 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98201.4766 - mae: 146.1843 - val_loss: 114629.2578 - val_mae: 156.0315 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98213.6172 - mae: 146.2378 - val_loss: 113429.2734 - val_mae: 154.5312 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98184.8125 - mae: 146.2056 - val_loss: 114657.2188 - val_mae: 155.8979 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98133.4062 - mae: 146.1331 - val_loss: 115021.7734 - val_mae: 155.5654 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97957.6875 - mae: 146.1583 - val_loss: 114152.7188 - val_mae: 154.1131 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98032.2656 - mae: 145.8216 - val_loss: 116346.8672 - val_mae: 156.4138 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97982.0547 - mae: 145.7418 - val_loss: 113659.1328 - val_mae: 154.6600 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98068.9062 - mae: 146.0062 - val_loss: 114011.3203 - val_mae: 154.1933 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97945.2031 - mae: 145.9460 - val_loss: 113518.3125 - val_mae: 153.8622 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97923.1875 - mae: 145.7201 - val_loss: 113950.2578 - val_mae: 154.9069 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97937.6016 - mae: 146.0131 - val_loss: 114613.6016 - val_mae: 154.6969 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97898.2578 - mae: 145.7884 - val_loss: 113820.5391 - val_mae: 155.7237 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97579.8359 - mae: 145.5600 - val_loss: 114712.4766 - val_mae: 155.6304 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97524.8438 - mae: 145.2189 - val_loss: 114095.5000 - val_mae: 154.7005 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97502.3750 - mae: 145.2408 - val_loss: 114181.0469 - val_mae: 154.5724 - lr: 1.0000e-05\n",
      "\u001b[32m[I 2022-07-28 17:26:57,577]\u001b[0m Trial 0 finished with value: 114181.04341464395 and parameters: {'feature_dim': 48, 'output_dim': 12, 'num_decision_steps': 1}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "[TabNet]: 46 features will be used for decision steps.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 6s 3ms/step - loss: 1539332.6250 - mae: 709.8397 - val_loss: 1071315.5000 - val_mae: 590.7015 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 1017943.6875 - mae: 603.5064 - val_loss: 652014.4375 - val_mae: 487.1116 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 633206.5625 - mae: 506.7497 - val_loss: 412604.8438 - val_mae: 408.3971 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 423297.4062 - mae: 422.4138 - val_loss: 275590.8438 - val_mae: 332.1918 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 318977.4375 - mae: 357.9543 - val_loss: 266444.7500 - val_mae: 301.8371 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 264648.6562 - mae: 313.6446 - val_loss: 189899.2812 - val_mae: 256.7070 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 241381.7344 - mae: 291.7286 - val_loss: 183104.4375 - val_mae: 243.7996 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 222806.2812 - mae: 275.5478 - val_loss: 175558.9062 - val_mae: 233.8232 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 218316.9531 - mae: 268.1007 - val_loss: 164991.3281 - val_mae: 223.7916 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 212422.2031 - mae: 263.4739 - val_loss: 164913.8281 - val_mae: 222.2698 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 211157.6250 - mae: 259.6852 - val_loss: 203352.9531 - val_mae: 238.1788 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 208584.6250 - mae: 257.8214 - val_loss: 174939.6875 - val_mae: 215.7659 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 207833.7031 - mae: 256.0727 - val_loss: 213398.1406 - val_mae: 245.2276 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 208563.0469 - mae: 256.3279 - val_loss: 176294.4688 - val_mae: 217.3659 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 202999.1094 - mae: 252.8798 - val_loss: 173529.2500 - val_mae: 217.4502 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 201512.2188 - mae: 251.1753 - val_loss: 204836.5781 - val_mae: 230.1031 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 199850.0000 - mae: 249.9095 - val_loss: 199150.7031 - val_mae: 231.5681 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 201740.1875 - mae: 249.7359 - val_loss: 179447.4844 - val_mae: 221.4844 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 199007.8750 - mae: 248.8252 - val_loss: 200606.5625 - val_mae: 236.0653 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 197448.2656 - mae: 246.6831 - val_loss: 160415.5781 - val_mae: 202.6831 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 196696.8594 - mae: 246.6583 - val_loss: 171870.4375 - val_mae: 208.9370 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 196304.4219 - mae: 245.6468 - val_loss: 167619.5781 - val_mae: 206.2841 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 197858.3438 - mae: 246.0258 - val_loss: 225366.2031 - val_mae: 239.4091 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 193985.5312 - mae: 243.3765 - val_loss: 244092.7188 - val_mae: 251.7515 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 195133.8594 - mae: 243.4002 - val_loss: 219423.5938 - val_mae: 234.9519 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 194516.0156 - mae: 243.3275 - val_loss: 194211.7344 - val_mae: 232.3979 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 194659.4844 - mae: 242.5119 - val_loss: 181509.2656 - val_mae: 222.1776 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 192776.9062 - mae: 242.0564 - val_loss: 193168.9219 - val_mae: 221.5524 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 193637.3906 - mae: 241.8458 - val_loss: 247337.3125 - val_mae: 250.3345 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 192384.5938 - mae: 241.1405 - val_loss: 187560.8906 - val_mae: 218.1140 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 188064.5938 - mae: 237.5946 - val_loss: 192757.7188 - val_mae: 221.8619 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 187642.3125 - mae: 237.4395 - val_loss: 193961.0938 - val_mae: 222.1522 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 187738.1875 - mae: 237.9582 - val_loss: 190430.5625 - val_mae: 220.6091 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 187624.5625 - mae: 237.7774 - val_loss: 190142.4375 - val_mae: 220.3478 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 187744.6875 - mae: 237.9278 - val_loss: 190878.4688 - val_mae: 220.9691 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 187858.7031 - mae: 237.6686 - val_loss: 190652.6094 - val_mae: 222.1809 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 187532.7031 - mae: 237.6586 - val_loss: 187305.5000 - val_mae: 219.2018 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 187684.6562 - mae: 237.7249 - val_loss: 190120.3750 - val_mae: 221.2807 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 187534.1250 - mae: 237.4344 - val_loss: 191669.3750 - val_mae: 221.8871 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 187171.3281 - mae: 237.1695 - val_loss: 193377.7344 - val_mae: 224.3159 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 17:29:01,918]\u001b[0m Trial 1 finished with value: 193377.66906419868 and parameters: {'feature_dim': 53, 'output_dim': 7, 'num_decision_steps': 3}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1724253.5000 - mae: 737.8030 - val_loss: 1408484.6250 - val_mae: 653.6066 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1588382.8750 - mae: 687.8132 - val_loss: 1254230.0000 - val_mae: 571.3217 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1388448.5000 - mae: 622.8145 - val_loss: 1061129.6250 - val_mae: 508.4128 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1127466.3750 - mae: 543.4133 - val_loss: 810300.9375 - val_mae: 426.7278 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 848287.5625 - mae: 454.9776 - val_loss: 594459.8125 - val_mae: 359.4717 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 617056.7500 - mae: 378.8164 - val_loss: 437388.1250 - val_mae: 309.1453 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 440093.7500 - mae: 317.7686 - val_loss: 313667.1875 - val_mae: 267.3727 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 315659.0625 - mae: 272.5900 - val_loss: 238403.8906 - val_mae: 236.0831 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 230660.8125 - mae: 237.4475 - val_loss: 183594.6406 - val_mae: 215.0117 - lr: 0.0010\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 961us/step - loss: 177707.5781 - mae: 211.6880 - val_loss: 164371.8906 - val_mae: 195.0402 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 146464.0781 - mae: 193.3767 - val_loss: 141752.0625 - val_mae: 183.3438 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 130319.1797 - mae: 183.2485 - val_loss: 141103.8594 - val_mae: 180.3042 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 120939.0312 - mae: 176.2142 - val_loss: 131289.8281 - val_mae: 171.2925 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 115419.4531 - mae: 170.4010 - val_loss: 140682.7344 - val_mae: 178.7161 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111087.3203 - mae: 165.2586 - val_loss: 118843.2734 - val_mae: 165.1264 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108536.1172 - mae: 162.4630 - val_loss: 125766.8438 - val_mae: 164.7048 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106976.2422 - mae: 160.2483 - val_loss: 122163.2266 - val_mae: 161.1084 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106369.6484 - mae: 158.8882 - val_loss: 121520.5469 - val_mae: 165.1724 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105831.5000 - mae: 158.1611 - val_loss: 119921.5938 - val_mae: 161.7310 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104556.4922 - mae: 156.8600 - val_loss: 120549.2578 - val_mae: 160.0202 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104275.5078 - mae: 155.7686 - val_loss: 121001.2188 - val_mae: 161.1898 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 104492.3047 - mae: 155.7540 - val_loss: 118912.0234 - val_mae: 159.5861 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 103266.2969 - mae: 154.5158 - val_loss: 132364.9531 - val_mae: 169.7778 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 102719.9375 - mae: 153.8507 - val_loss: 119672.8125 - val_mae: 161.6744 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 103222.1953 - mae: 153.8433 - val_loss: 119079.5391 - val_mae: 158.0696 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 99678.1484 - mae: 149.2672 - val_loss: 117141.4141 - val_mae: 157.0228 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99518.4141 - mae: 149.0341 - val_loss: 117228.3438 - val_mae: 156.6856 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99511.3125 - mae: 148.8692 - val_loss: 117705.8750 - val_mae: 157.2880 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99469.2500 - mae: 148.8339 - val_loss: 116844.4766 - val_mae: 157.0431 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99257.8281 - mae: 148.8988 - val_loss: 118612.3125 - val_mae: 158.4973 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99320.0312 - mae: 148.6997 - val_loss: 119299.2422 - val_mae: 157.9769 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99309.1641 - mae: 148.7189 - val_loss: 120151.6641 - val_mae: 159.4172 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99249.2344 - mae: 148.6129 - val_loss: 118092.2109 - val_mae: 156.6152 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99237.9844 - mae: 148.4998 - val_loss: 118399.0078 - val_mae: 158.0890 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99184.4531 - mae: 148.6089 - val_loss: 117955.7969 - val_mae: 156.6703 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99119.0078 - mae: 148.4976 - val_loss: 117805.4375 - val_mae: 157.5123 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99123.3516 - mae: 148.6216 - val_loss: 116246.3594 - val_mae: 156.4031 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 99085.7734 - mae: 148.4880 - val_loss: 117045.4219 - val_mae: 157.0565 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 99039.3125 - mae: 148.4050 - val_loss: 118039.5859 - val_mae: 157.4078 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 98925.9922 - mae: 148.4623 - val_loss: 117009.1797 - val_mae: 156.3257 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 98939.1406 - mae: 148.2192 - val_loss: 119456.9297 - val_mae: 158.1096 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 98826.3750 - mae: 148.0792 - val_loss: 116700.4844 - val_mae: 156.8095 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98936.9922 - mae: 148.1580 - val_loss: 116934.2578 - val_mae: 156.2421 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98836.8594 - mae: 148.1463 - val_loss: 116936.8984 - val_mae: 156.1595 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98857.4141 - mae: 148.0616 - val_loss: 117673.8047 - val_mae: 157.7791 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98853.6719 - mae: 148.1847 - val_loss: 117970.1719 - val_mae: 157.2674 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98830.8281 - mae: 148.0825 - val_loss: 117711.1641 - val_mae: 157.9232 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98445.6328 - mae: 147.7070 - val_loss: 118188.8203 - val_mae: 157.7523 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98399.1562 - mae: 147.4734 - val_loss: 117693.8047 - val_mae: 157.1281 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 98383.2969 - mae: 147.5024 - val_loss: 117791.4609 - val_mae: 157.1080 - lr: 1.0000e-05\n",
      "\u001b[32m[I 2022-07-28 17:30:00,100]\u001b[0m Trial 2 finished with value: 117791.4791661134 and parameters: {'feature_dim': 32, 'output_dim': 10, 'num_decision_steps': 1}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "[TabNet]: 34 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1662547.1250 - mae: 706.5178 - val_loss: 1287412.6250 - val_mae: 582.5446 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1358700.8750 - mae: 613.4961 - val_loss: 976363.8125 - val_mae: 482.7269 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 994907.5625 - mae: 504.7836 - val_loss: 680362.0000 - val_mae: 393.0862 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 691920.1250 - mae: 413.2204 - val_loss: 466960.3125 - val_mae: 322.7248 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 495612.1250 - mae: 357.7969 - val_loss: 369197.9375 - val_mae: 289.0715 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 383899.5625 - mae: 323.3721 - val_loss: 330419.0312 - val_mae: 305.7087 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 310598.2188 - mae: 294.3640 - val_loss: 246395.5938 - val_mae: 252.2771 - lr: 0.0010\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 2ms/step - loss: 280268.1562 - mae: 281.8712 - val_loss: 217199.6094 - val_mae: 235.4008 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 247236.1094 - mae: 264.1925 - val_loss: 220198.1094 - val_mae: 236.7154 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 231402.6094 - mae: 255.2322 - val_loss: 210764.6719 - val_mae: 230.2850 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 222363.7812 - mae: 249.0459 - val_loss: 184446.1875 - val_mae: 213.0794 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 208086.3750 - mae: 240.8534 - val_loss: 181763.8125 - val_mae: 211.7211 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 205158.1562 - mae: 238.5462 - val_loss: 179697.5469 - val_mae: 209.0798 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 199878.9688 - mae: 236.0536 - val_loss: 201361.2812 - val_mae: 218.8649 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 194300.9531 - mae: 232.5123 - val_loss: 179424.5469 - val_mae: 209.3692 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 191995.2031 - mae: 231.0357 - val_loss: 210120.0938 - val_mae: 222.9566 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 191139.1094 - mae: 230.1106 - val_loss: 170174.9531 - val_mae: 204.6014 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 183157.0312 - mae: 224.7459 - val_loss: 198575.4531 - val_mae: 214.3798 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 181610.9062 - mae: 224.1974 - val_loss: 209046.8906 - val_mae: 222.8056 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 178674.4688 - mae: 222.3469 - val_loss: 169943.2969 - val_mae: 200.2511 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 179942.6250 - mae: 222.6275 - val_loss: 170237.7656 - val_mae: 200.6663 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 177975.1719 - mae: 221.3701 - val_loss: 174093.3281 - val_mae: 201.9958 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 176506.2344 - mae: 220.5081 - val_loss: 172103.3594 - val_mae: 199.3741 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 176178.2500 - mae: 219.9190 - val_loss: 167351.3125 - val_mae: 203.6447 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 174100.9844 - mae: 218.5676 - val_loss: 176205.1250 - val_mae: 203.4978 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 174368.2656 - mae: 218.7209 - val_loss: 162988.3125 - val_mae: 199.7278 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 172697.2500 - mae: 217.4691 - val_loss: 162628.3750 - val_mae: 199.0110 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 170835.8281 - mae: 216.4633 - val_loss: 169594.7656 - val_mae: 200.6607 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 172419.4531 - mae: 217.0157 - val_loss: 162852.7188 - val_mae: 197.4916 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 168326.4219 - mae: 214.2625 - val_loss: 183602.7188 - val_mae: 206.8403 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 168772.8125 - mae: 214.5037 - val_loss: 179566.3281 - val_mae: 206.2754 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 167043.8906 - mae: 213.2039 - val_loss: 169897.6875 - val_mae: 199.7000 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 166619.3594 - mae: 213.2881 - val_loss: 169044.9375 - val_mae: 199.5116 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 166132.3906 - mae: 212.4815 - val_loss: 168120.9688 - val_mae: 197.5301 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 167207.3594 - mae: 213.1115 - val_loss: 166060.7344 - val_mae: 200.1736 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 167673.9844 - mae: 213.4961 - val_loss: 204487.8281 - val_mae: 223.4169 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 165144.7344 - mae: 211.5844 - val_loss: 165987.5000 - val_mae: 197.1667 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157834.4688 - mae: 206.2725 - val_loss: 163664.7656 - val_mae: 196.8165 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157254.8906 - mae: 205.8431 - val_loss: 163283.7656 - val_mae: 196.4929 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157049.5469 - mae: 205.7863 - val_loss: 162169.2812 - val_mae: 196.7517 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157072.9219 - mae: 205.8039 - val_loss: 164648.5469 - val_mae: 196.6370 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157416.5938 - mae: 205.7539 - val_loss: 163231.6406 - val_mae: 196.6722 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157228.9375 - mae: 205.4512 - val_loss: 162188.6406 - val_mae: 196.3781 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 156866.1094 - mae: 205.4153 - val_loss: 164559.2969 - val_mae: 196.9460 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 156563.2656 - mae: 205.1377 - val_loss: 163485.7031 - val_mae: 196.3839 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 156677.6406 - mae: 205.1604 - val_loss: 162844.6562 - val_mae: 196.3925 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 156653.8906 - mae: 205.0032 - val_loss: 163071.6562 - val_mae: 196.2481 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 156865.3594 - mae: 205.2005 - val_loss: 165949.0000 - val_mae: 197.6572 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 156522.1250 - mae: 204.6545 - val_loss: 162626.8438 - val_mae: 196.8834 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 156436.2188 - mae: 204.9517 - val_loss: 163596.7188 - val_mae: 196.5526 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 17:31:43,560]\u001b[0m Trial 3 finished with value: 163596.7117287056 and parameters: {'feature_dim': 43, 'output_dim': 9, 'num_decision_steps': 2}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "[TabNet]: 65 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 6s 3ms/step - loss: 1573862.1250 - mae: 683.0525 - val_loss: 1139635.3750 - val_mae: 548.4274 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 1120905.8750 - mae: 552.6124 - val_loss: 733763.6250 - val_mae: 430.7880 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 700017.1250 - mae: 432.3121 - val_loss: 449078.5312 - val_mae: 347.9091 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 471627.4688 - mae: 365.4490 - val_loss: 336319.8438 - val_mae: 329.1176 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 328862.3438 - mae: 322.7041 - val_loss: 276543.1562 - val_mae: 293.6367 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 269819.8750 - mae: 296.2284 - val_loss: 229964.9688 - val_mae: 275.6187 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 230292.3125 - mae: 273.1445 - val_loss: 204828.9375 - val_mae: 255.6999 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 211670.0312 - mae: 260.5885 - val_loss: 203801.5156 - val_mae: 253.4000 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 200992.3750 - mae: 255.6024 - val_loss: 184582.3281 - val_mae: 242.7872 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 199883.1094 - mae: 252.8747 - val_loss: 196498.4688 - val_mae: 241.6936 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 189696.5312 - mae: 243.9742 - val_loss: 182096.2344 - val_mae: 228.1571 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 187196.5312 - mae: 239.0491 - val_loss: 189285.2969 - val_mae: 230.0224 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 182851.9219 - mae: 234.5328 - val_loss: 173791.1875 - val_mae: 217.4474 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 180339.9531 - mae: 231.1673 - val_loss: 170636.7188 - val_mae: 214.4448 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 171701.0156 - mae: 224.8853 - val_loss: 175331.1719 - val_mae: 215.8125 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 171561.4219 - mae: 223.0443 - val_loss: 172225.7969 - val_mae: 210.4103 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 168047.9688 - mae: 220.5530 - val_loss: 163943.3438 - val_mae: 206.1919 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 168665.2812 - mae: 220.1100 - val_loss: 165665.4062 - val_mae: 205.1800 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 167103.5469 - mae: 218.6741 - val_loss: 170460.5000 - val_mae: 207.8445 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 164069.2344 - mae: 216.2377 - val_loss: 190329.5781 - val_mae: 216.8445 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 163699.8281 - mae: 216.0180 - val_loss: 175568.2500 - val_mae: 210.1866 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 163862.6094 - mae: 216.4841 - val_loss: 168929.4688 - val_mae: 205.5122 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 162373.4062 - mae: 214.8497 - val_loss: 177931.3438 - val_mae: 212.2758 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 159334.5781 - mae: 214.0329 - val_loss: 162577.9531 - val_mae: 204.0188 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 158733.1250 - mae: 212.5534 - val_loss: 170130.0312 - val_mae: 206.5995 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 160479.6094 - mae: 213.4929 - val_loss: 159704.8438 - val_mae: 203.1923 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 159535.9219 - mae: 213.3100 - val_loss: 161851.0469 - val_mae: 203.7290 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 157134.4375 - mae: 211.9025 - val_loss: 175393.6875 - val_mae: 212.8565 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 157455.5625 - mae: 211.9220 - val_loss: 173555.2188 - val_mae: 214.2319 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 156266.4375 - mae: 211.0207 - val_loss: 165712.6406 - val_mae: 205.8069 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 156641.0156 - mae: 211.2186 - val_loss: 167659.2969 - val_mae: 206.2952 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 155267.1094 - mae: 210.1499 - val_loss: 168063.7969 - val_mae: 206.5435 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 155486.0625 - mae: 210.8541 - val_loss: 167785.7344 - val_mae: 205.3674 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 154730.3906 - mae: 210.0560 - val_loss: 165666.6719 - val_mae: 208.3228 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153937.5312 - mae: 209.0509 - val_loss: 163397.2344 - val_mae: 203.0951 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153423.8750 - mae: 208.9458 - val_loss: 171313.7031 - val_mae: 208.2200 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 150564.9062 - mae: 205.3258 - val_loss: 161453.8906 - val_mae: 202.4508 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 150201.0781 - mae: 205.5923 - val_loss: 161087.7500 - val_mae: 201.4338 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 149931.1094 - mae: 205.3171 - val_loss: 164314.2344 - val_mae: 203.9491 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 149507.1250 - mae: 204.9761 - val_loss: 161456.7188 - val_mae: 201.8593 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 149531.7344 - mae: 205.3200 - val_loss: 169657.2031 - val_mae: 208.0869 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 149564.3125 - mae: 205.3008 - val_loss: 164563.0938 - val_mae: 203.3067 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 149414.7500 - mae: 205.0667 - val_loss: 162085.9688 - val_mae: 202.1399 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 149246.3750 - mae: 204.9538 - val_loss: 161179.1250 - val_mae: 201.2528 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 149109.8125 - mae: 204.9713 - val_loss: 163246.4375 - val_mae: 202.6008 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 149140.7500 - mae: 204.9975 - val_loss: 167640.5312 - val_mae: 205.3447 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 17:34:27,314]\u001b[0m Trial 4 finished with value: 167640.5134700707 and parameters: {'feature_dim': 70, 'output_dim': 5, 'num_decision_steps': 3}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "[TabNet]: 37 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 7s 4ms/step - loss: 1471842.2500 - mae: 673.8867 - val_loss: 921455.0625 - val_mae: 520.3132 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 833910.5625 - mae: 510.7325 - val_loss: 621067.3750 - val_mae: 473.6576 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 547565.0000 - mae: 432.3248 - val_loss: 404253.8750 - val_mae: 391.3033 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 375989.6562 - mae: 372.5570 - val_loss: 342697.5000 - val_mae: 364.3010 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 321887.9062 - mae: 345.3105 - val_loss: 296956.0000 - val_mae: 327.2247 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 288324.9375 - mae: 328.4104 - val_loss: 293337.0625 - val_mae: 322.4658 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 259973.7031 - mae: 304.0943 - val_loss: 241822.0781 - val_mae: 296.7614 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 242688.0781 - mae: 290.1026 - val_loss: 253758.3438 - val_mae: 281.2581 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 228511.8281 - mae: 278.8997 - val_loss: 216981.8594 - val_mae: 261.7693 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 219374.0625 - mae: 270.9940 - val_loss: 234734.0781 - val_mae: 262.1013 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 209274.9219 - mae: 261.8020 - val_loss: 223822.6406 - val_mae: 248.2250 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 204400.7188 - mae: 255.7809 - val_loss: 223379.1406 - val_mae: 246.8529 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 199274.3281 - mae: 250.8726 - val_loss: 193940.9531 - val_mae: 232.0346 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 197171.8438 - mae: 248.5557 - val_loss: 204019.7656 - val_mae: 233.3185 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 193725.9062 - mae: 243.7129 - val_loss: 180260.2344 - val_mae: 220.4253 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 193185.6719 - mae: 242.1811 - val_loss: 188315.8125 - val_mae: 220.6623 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 191287.6562 - mae: 240.1083 - val_loss: 187138.4062 - val_mae: 220.2715 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 191724.2812 - mae: 239.5398 - val_loss: 188078.6719 - val_mae: 220.5212 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 190143.0000 - mae: 238.2757 - val_loss: 202858.1250 - val_mae: 225.8176 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 190130.8281 - mae: 237.7537 - val_loss: 181502.9219 - val_mae: 213.2584 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 189842.9531 - mae: 237.2927 - val_loss: 173869.7188 - val_mae: 208.1476 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 190291.5000 - mae: 237.9893 - val_loss: 188455.7969 - val_mae: 242.6999 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 185867.1875 - mae: 236.2439 - val_loss: 218930.2031 - val_mae: 235.6631 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 166666.4531 - mae: 221.2676 - val_loss: 183319.6562 - val_mae: 213.9292 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 159568.5312 - mae: 212.5966 - val_loss: 158922.1094 - val_mae: 192.7660 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 156106.2969 - mae: 207.9504 - val_loss: 160527.7969 - val_mae: 193.4844 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 154309.1562 - mae: 207.1702 - val_loss: 147723.1094 - val_mae: 184.7539 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 151259.8281 - mae: 203.5329 - val_loss: 168455.5781 - val_mae: 197.4336 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 150708.3125 - mae: 203.1733 - val_loss: 162972.5781 - val_mae: 193.3241 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 149779.4375 - mae: 201.9922 - val_loss: 153793.4844 - val_mae: 188.9270 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 148139.1719 - mae: 200.2849 - val_loss: 157761.0781 - val_mae: 189.3646 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 127284.8203 - mae: 182.7500 - val_loss: 148208.6719 - val_mae: 185.4837 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 122939.5234 - mae: 178.5379 - val_loss: 131254.5000 - val_mae: 171.3968 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 122226.2266 - mae: 176.9208 - val_loss: 133316.2188 - val_mae: 175.5749 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 121391.3828 - mae: 176.4805 - val_loss: 127754.0000 - val_mae: 170.5180 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 120938.0547 - mae: 175.2725 - val_loss: 132715.3281 - val_mae: 174.0506 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 120473.6250 - mae: 175.4934 - val_loss: 129915.9375 - val_mae: 168.9550 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 119594.2891 - mae: 174.7375 - val_loss: 130165.7188 - val_mae: 171.6223 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 119729.4297 - mae: 174.0485 - val_loss: 124194.6328 - val_mae: 165.2933 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 118960.8750 - mae: 173.9815 - val_loss: 127453.7344 - val_mae: 173.2866 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 118739.6562 - mae: 173.5602 - val_loss: 130220.8906 - val_mae: 167.1644 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 118948.0703 - mae: 173.5352 - val_loss: 129179.6328 - val_mae: 170.2557 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 119203.7734 - mae: 173.6748 - val_loss: 143065.8125 - val_mae: 185.7376 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 118699.7969 - mae: 172.9799 - val_loss: 122984.6875 - val_mae: 162.2332 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 117757.1250 - mae: 172.2126 - val_loss: 126017.7500 - val_mae: 165.7017 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 118371.8125 - mae: 172.7074 - val_loss: 131978.2500 - val_mae: 169.9253 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 117721.8672 - mae: 172.3816 - val_loss: 124088.5000 - val_mae: 167.5963 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 118128.5781 - mae: 172.1492 - val_loss: 129967.0391 - val_mae: 169.5851 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 117729.8906 - mae: 171.5509 - val_loss: 121958.3672 - val_mae: 163.4866 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 117608.8125 - mae: 171.9646 - val_loss: 125165.1406 - val_mae: 164.8774 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 17:37:38,158]\u001b[0m Trial 5 finished with value: 125165.13658287462 and parameters: {'feature_dim': 45, 'output_dim': 8, 'num_decision_steps': 4}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "[TabNet]: 29 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 7s 4ms/step - loss: 1510822.2500 - mae: 673.9032 - val_loss: 1014124.5625 - val_mae: 517.2116 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 945458.3125 - mae: 507.6632 - val_loss: 581490.6250 - val_mae: 391.6931 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 583927.2500 - mae: 417.9349 - val_loss: 335077.6562 - val_mae: 290.5242 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 305626.2188 - mae: 298.7127 - val_loss: 215250.5000 - val_mae: 242.5979 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 212274.2188 - mae: 253.5721 - val_loss: 169144.1250 - val_mae: 209.0634 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 176754.8594 - mae: 232.4262 - val_loss: 171254.4219 - val_mae: 212.4935 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 156108.2656 - mae: 217.1754 - val_loss: 142056.9375 - val_mae: 188.5764 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 145619.1719 - mae: 206.2664 - val_loss: 133587.7188 - val_mae: 184.9007 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 138304.2500 - mae: 197.0222 - val_loss: 131546.8438 - val_mae: 175.0925 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 134402.7500 - mae: 192.0646 - val_loss: 127950.0625 - val_mae: 176.8526 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 132203.6875 - mae: 190.0635 - val_loss: 145355.1094 - val_mae: 189.0784 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 130462.0938 - mae: 189.1469 - val_loss: 137156.1406 - val_mae: 175.2584 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 127867.4297 - mae: 186.7313 - val_loss: 131643.2969 - val_mae: 175.0628 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 126999.0781 - mae: 185.9173 - val_loss: 137598.9688 - val_mae: 178.1623 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 126645.8438 - mae: 185.1032 - val_loss: 131924.8438 - val_mae: 175.9759 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 125130.2266 - mae: 183.8083 - val_loss: 146287.3125 - val_mae: 185.1087 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 123370.2422 - mae: 181.8390 - val_loss: 129478.6484 - val_mae: 176.8324 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 124613.5859 - mae: 183.1217 - val_loss: 130492.4453 - val_mae: 175.1937 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 123369.0781 - mae: 181.7744 - val_loss: 129990.9609 - val_mae: 175.3246 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 121706.1094 - mae: 180.3534 - val_loss: 126233.5547 - val_mae: 171.6178 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 121967.8438 - mae: 180.6347 - val_loss: 128051.7344 - val_mae: 171.7881 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 122868.0547 - mae: 181.6270 - val_loss: 130255.2031 - val_mae: 179.4429 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 122018.3594 - mae: 180.5972 - val_loss: 137476.8906 - val_mae: 174.9405 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 120799.9844 - mae: 179.8059 - val_loss: 129939.1719 - val_mae: 178.4532 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 121776.7500 - mae: 179.5790 - val_loss: 131781.1719 - val_mae: 169.7874 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 121047.9766 - mae: 177.4765 - val_loss: 124122.8125 - val_mae: 165.8758 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 120775.0859 - mae: 177.1354 - val_loss: 124260.7734 - val_mae: 165.2440 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 120065.0938 - mae: 176.1282 - val_loss: 142946.2812 - val_mae: 182.5324 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 119944.4375 - mae: 175.1602 - val_loss: 143377.0625 - val_mae: 182.0344 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 119454.4219 - mae: 174.8084 - val_loss: 128861.6016 - val_mae: 166.5722 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 119370.7812 - mae: 174.2202 - val_loss: 133380.8594 - val_mae: 170.7257 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 119219.0391 - mae: 173.9825 - val_loss: 136875.5000 - val_mae: 172.8379 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 119144.7500 - mae: 174.5142 - val_loss: 128531.1562 - val_mae: 172.6182 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 119074.3984 - mae: 174.1915 - val_loss: 126940.3281 - val_mae: 168.5042 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 118797.8125 - mae: 173.9026 - val_loss: 125901.6328 - val_mae: 169.6625 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 118553.7500 - mae: 173.3023 - val_loss: 125710.5156 - val_mae: 169.7876 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 115230.1094 - mae: 171.5779 - val_loss: 124988.0000 - val_mae: 166.0066 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 114759.2188 - mae: 169.8074 - val_loss: 125642.7109 - val_mae: 165.1553 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 114551.1953 - mae: 169.3712 - val_loss: 127413.8047 - val_mae: 166.4170 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 114345.7500 - mae: 168.8886 - val_loss: 125080.0703 - val_mae: 166.3475 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 114335.1641 - mae: 168.9234 - val_loss: 127407.3047 - val_mae: 165.5484 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 114263.0547 - mae: 168.0018 - val_loss: 125770.2188 - val_mae: 164.5213 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 114344.8047 - mae: 168.5330 - val_loss: 126378.9609 - val_mae: 165.7906 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 114184.8516 - mae: 168.4336 - val_loss: 127151.9844 - val_mae: 166.5277 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 4s 4ms/step - loss: 114162.4609 - mae: 168.2968 - val_loss: 126950.5312 - val_mae: 165.9823 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 114196.9453 - mae: 168.4861 - val_loss: 127116.2500 - val_mae: 165.0125 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 17:40:29,462]\u001b[0m Trial 6 finished with value: 127116.30522017328 and parameters: {'feature_dim': 41, 'output_dim': 12, 'num_decision_steps': 4}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "[TabNet]: 42 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 4s 2ms/step - loss: 1653462.3750 - mae: 742.1438 - val_loss: 1272671.1250 - val_mae: 679.3219 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1390000.6250 - mae: 782.2833 - val_loss: 1093051.3750 - val_mae: 760.4371 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1244242.8750 - mae: 847.7615 - val_loss: 1070007.6250 - val_mae: 834.0014 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219394.6250 - mae: 884.0888 - val_loss: 1079194.6250 - val_mae: 859.6934 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1218021.3750 - mae: 893.8326 - val_loss: 1080155.2500 - val_mae: 861.6583 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217934.0000 - mae: 894.4683 - val_loss: 1082202.6250 - val_mae: 865.5585 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217859.3750 - mae: 894.6871 - val_loss: 1084076.5000 - val_mae: 868.8708 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217905.6250 - mae: 896.0759 - val_loss: 1082193.6250 - val_mae: 865.6569 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217798.7500 - mae: 894.6486 - val_loss: 1084107.1250 - val_mae: 869.0258 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217795.3750 - mae: 896.3940 - val_loss: 1080290.1250 - val_mae: 862.2914 - lr: 0.0010\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217690.6250 - mae: 896.1171 - val_loss: 1077088.3750 - val_mae: 855.9023 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217802.5000 - mae: 893.8638 - val_loss: 1081409.6250 - val_mae: 864.5127 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217649.8750 - mae: 894.5013 - val_loss: 1084128.0000 - val_mae: 869.3134 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217629.2500 - mae: 897.7147 - val_loss: 1083504.7500 - val_mae: 868.2722 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217596.0000 - mae: 896.8561 - val_loss: 1082848.3750 - val_mae: 867.1555 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217576.7500 - mae: 896.1054 - val_loss: 1082559.8750 - val_mae: 866.6649 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217562.1250 - mae: 895.8647 - val_loss: 1082124.7500 - val_mae: 865.9122 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217551.6250 - mae: 895.3699 - val_loss: 1081927.2500 - val_mae: 865.5737 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217543.1250 - mae: 895.3661 - val_loss: 1081744.6250 - val_mae: 865.2582 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217539.0000 - mae: 895.1288 - val_loss: 1081569.7500 - val_mae: 864.9548 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217536.5000 - mae: 895.1399 - val_loss: 1081551.0000 - val_mae: 864.9319 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217524.1250 - mae: 895.0834 - val_loss: 1081405.7500 - val_mae: 864.6796 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217523.0000 - mae: 894.6660 - val_loss: 1081595.3750 - val_mae: 865.0329 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 17:41:23,490]\u001b[0m Trial 7 finished with value: 1081595.5392736979 and parameters: {'feature_dim': 54, 'output_dim': 12, 'num_decision_steps': 2}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1632655.1250 - mae: 707.1736 - val_loss: 1238926.8750 - val_mae: 572.0483 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1278049.6250 - mae: 591.1024 - val_loss: 890478.0625 - val_mae: 460.0867 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 876862.5000 - mae: 466.1488 - val_loss: 573858.8750 - val_mae: 354.4146 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 556145.2500 - mae: 361.6345 - val_loss: 360007.1250 - val_mae: 282.1509 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 342181.3125 - mae: 284.1591 - val_loss: 234738.3906 - val_mae: 234.1482 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 218739.2344 - mae: 232.2546 - val_loss: 176798.6406 - val_mae: 203.7394 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 157252.0000 - mae: 199.8473 - val_loss: 149476.3125 - val_mae: 187.9810 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 130321.8359 - mae: 181.9702 - val_loss: 132975.3281 - val_mae: 173.0273 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 117612.8281 - mae: 171.1537 - val_loss: 126043.4844 - val_mae: 165.7685 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 111596.6953 - mae: 164.1216 - val_loss: 129630.0469 - val_mae: 169.6673 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 107288.5547 - mae: 159.2767 - val_loss: 130890.4609 - val_mae: 170.7735 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 105952.4297 - mae: 157.1484 - val_loss: 131608.1406 - val_mae: 166.7572 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 104528.7578 - mae: 155.6839 - val_loss: 122616.8984 - val_mae: 165.5137 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 103669.8281 - mae: 153.7941 - val_loss: 132907.7812 - val_mae: 169.6514 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 103110.9531 - mae: 153.0054 - val_loss: 115297.2109 - val_mae: 156.6876 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102867.2578 - mae: 152.8270 - val_loss: 121439.6328 - val_mae: 156.8269 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102152.6641 - mae: 151.5277 - val_loss: 121115.0469 - val_mae: 155.7853 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102353.0625 - mae: 151.6361 - val_loss: 119210.5391 - val_mae: 159.2200 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102292.4141 - mae: 151.4709 - val_loss: 117130.7891 - val_mae: 158.0241 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 101503.1172 - mae: 150.6280 - val_loss: 122222.5469 - val_mae: 158.9513 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 101339.5781 - mae: 150.4068 - val_loss: 120488.5391 - val_mae: 160.0684 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 101480.6016 - mae: 150.2778 - val_loss: 120147.4844 - val_mae: 157.2790 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 100684.7656 - mae: 149.7339 - val_loss: 122986.1016 - val_mae: 158.4993 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 100490.5234 - mae: 149.0807 - val_loss: 117493.3203 - val_mae: 158.0261 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 100835.8516 - mae: 149.2769 - val_loss: 116777.3906 - val_mae: 156.0263 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 97313.4062 - mae: 144.6975 - val_loss: 114918.0703 - val_mae: 152.9356 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 97048.7812 - mae: 144.0939 - val_loss: 115917.2266 - val_mae: 153.8433 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96995.3672 - mae: 144.0109 - val_loss: 115866.9375 - val_mae: 153.4759 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96964.8359 - mae: 143.9500 - val_loss: 115006.8984 - val_mae: 153.3521 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96784.1875 - mae: 143.9562 - val_loss: 116772.7344 - val_mae: 154.8236 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96821.4844 - mae: 143.7304 - val_loss: 117213.6406 - val_mae: 155.2493 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96757.5547 - mae: 143.8914 - val_loss: 118394.0469 - val_mae: 155.9197 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96742.1016 - mae: 143.7512 - val_loss: 116362.2812 - val_mae: 153.6516 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 96703.6562 - mae: 143.6871 - val_loss: 116673.9062 - val_mae: 154.4042 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 96685.8672 - mae: 143.7923 - val_loss: 115950.5312 - val_mae: 153.5200 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 96650.4609 - mae: 143.6654 - val_loss: 115982.4688 - val_mae: 153.7664 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 96189.4141 - mae: 143.2048 - val_loss: 115884.9922 - val_mae: 153.5510 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 96172.7500 - mae: 143.0304 - val_loss: 116070.9062 - val_mae: 153.8483 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 96167.2812 - mae: 143.1813 - val_loss: 115878.9453 - val_mae: 153.5900 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 96150.2656 - mae: 143.1141 - val_loss: 115829.0312 - val_mae: 153.6552 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 96145.4453 - mae: 143.0985 - val_loss: 116454.8438 - val_mae: 154.1901 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96141.7031 - mae: 143.0658 - val_loss: 116034.4141 - val_mae: 153.9099 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96141.5859 - mae: 143.1753 - val_loss: 115981.6484 - val_mae: 153.8094 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96139.0156 - mae: 143.0966 - val_loss: 116050.8906 - val_mae: 153.8543 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96121.4609 - mae: 143.1442 - val_loss: 115898.5391 - val_mae: 153.6758 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96135.8594 - mae: 143.0452 - val_loss: 115906.8281 - val_mae: 153.7523 - lr: 1.0000e-05\n",
      "\u001b[32m[I 2022-07-28 17:42:33,884]\u001b[0m Trial 8 finished with value: 115906.81377945801 and parameters: {'feature_dim': 67, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "[TabNet]: 54 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 7s 4ms/step - loss: 1542694.7500 - mae: 677.0881 - val_loss: 1078188.6250 - val_mae: 533.2031 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 1030888.9375 - mae: 529.3171 - val_loss: 654407.1875 - val_mae: 413.0836 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 613720.1875 - mae: 409.2320 - val_loss: 394232.9062 - val_mae: 335.7101 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 380250.2188 - mae: 335.0667 - val_loss: 273586.3125 - val_mae: 297.3718 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 278972.1250 - mae: 297.5430 - val_loss: 227821.3281 - val_mae: 269.4116 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 226523.1875 - mae: 270.8414 - val_loss: 214431.1562 - val_mae: 263.4722 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 202843.5625 - mae: 258.0688 - val_loss: 206561.6250 - val_mae: 259.1407 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 190900.0625 - mae: 253.4588 - val_loss: 194870.3906 - val_mae: 250.6615 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 181007.4062 - mae: 244.7688 - val_loss: 179561.4531 - val_mae: 236.3859 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 175786.8906 - mae: 236.2031 - val_loss: 176423.0938 - val_mae: 226.1967 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 171110.3906 - mae: 229.1240 - val_loss: 183711.2656 - val_mae: 224.5767 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 168943.5469 - mae: 224.8731 - val_loss: 172553.5469 - val_mae: 215.2577 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 164913.1719 - mae: 220.2321 - val_loss: 166695.2969 - val_mae: 208.9886 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 164865.3594 - mae: 218.1689 - val_loss: 173380.3750 - val_mae: 212.7713 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 162202.8281 - mae: 215.1790 - val_loss: 161807.2188 - val_mae: 207.0395 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 162251.2031 - mae: 214.8518 - val_loss: 168146.5156 - val_mae: 204.6369 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 161078.0781 - mae: 213.4862 - val_loss: 168315.7969 - val_mae: 204.8604 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 161470.8438 - mae: 213.1937 - val_loss: 166129.7500 - val_mae: 202.5272 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 160132.0781 - mae: 211.8883 - val_loss: 169751.7656 - val_mae: 202.6457 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 158781.4844 - mae: 209.9531 - val_loss: 168704.6875 - val_mae: 202.2746 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 159056.5000 - mae: 210.5643 - val_loss: 164934.0000 - val_mae: 202.4954 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 159722.5781 - mae: 210.7034 - val_loss: 164619.2344 - val_mae: 198.8961 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 158614.5312 - mae: 209.2353 - val_loss: 177006.6875 - val_mae: 204.4217 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 158333.1094 - mae: 210.0105 - val_loss: 163722.7656 - val_mae: 207.3736 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 158384.8438 - mae: 209.9561 - val_loss: 170957.2656 - val_mae: 204.6226 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 155319.4062 - mae: 205.3488 - val_loss: 162465.0156 - val_mae: 199.3022 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 155192.3594 - mae: 205.3288 - val_loss: 163310.0938 - val_mae: 199.1798 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 155111.1406 - mae: 205.2020 - val_loss: 162528.6250 - val_mae: 198.9073 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 155117.0469 - mae: 205.0845 - val_loss: 161700.9375 - val_mae: 198.8884 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 154845.2969 - mae: 205.2553 - val_loss: 163387.8594 - val_mae: 199.5969 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 154918.9219 - mae: 205.2857 - val_loss: 163984.9219 - val_mae: 199.9043 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 154792.2656 - mae: 205.5079 - val_loss: 164822.2031 - val_mae: 200.4677 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 154767.5469 - mae: 205.3480 - val_loss: 164464.1719 - val_mae: 200.6405 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 154812.3281 - mae: 205.6936 - val_loss: 164478.6250 - val_mae: 201.0058 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 154537.5469 - mae: 205.3556 - val_loss: 164624.3125 - val_mae: 201.3495 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 154670.3438 - mae: 205.5292 - val_loss: 162448.3438 - val_mae: 200.2239 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 154609.7031 - mae: 205.8271 - val_loss: 161812.9062 - val_mae: 200.2178 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 154561.9531 - mae: 205.8029 - val_loss: 162680.9844 - val_mae: 200.8643 - lr: 1.0000e-04\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 3s 3ms/step - loss: 154329.8125 - mae: 205.9206 - val_loss: 163408.7969 - val_mae: 201.5781 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153936.6719 - mae: 205.3392 - val_loss: 162696.1562 - val_mae: 201.0998 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153951.0625 - mae: 205.6522 - val_loss: 163623.8594 - val_mae: 201.6349 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153944.5312 - mae: 205.4078 - val_loss: 162970.7188 - val_mae: 201.2223 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153949.7812 - mae: 205.4310 - val_loss: 162998.2031 - val_mae: 201.2776 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153935.8438 - mae: 205.5299 - val_loss: 163573.7344 - val_mae: 201.6664 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153915.2656 - mae: 205.3716 - val_loss: 163282.7812 - val_mae: 201.5381 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153907.0000 - mae: 205.4045 - val_loss: 163380.8906 - val_mae: 201.6193 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153918.7500 - mae: 205.5588 - val_loss: 163448.4219 - val_mae: 201.6606 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153895.7500 - mae: 205.5334 - val_loss: 163537.2812 - val_mae: 201.7651 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 153894.6250 - mae: 205.3326 - val_loss: 163109.3906 - val_mae: 201.5324 - lr: 1.0000e-05\n",
      "\u001b[32m[I 2022-07-28 17:45:15,466]\u001b[0m Trial 9 finished with value: 163109.41631229254 and parameters: {'feature_dim': 60, 'output_dim': 6, 'num_decision_steps': 3}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1718583.6250 - mae: 731.0156 - val_loss: 1399551.5000 - val_mae: 622.8102 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 1578935.7500 - mae: 683.0630 - val_loss: 1245261.1250 - val_mae: 571.0679 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 909us/step - loss: 1378253.1250 - mae: 620.6390 - val_loss: 1056255.7500 - val_mae: 509.6036 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 1154610.0000 - mae: 551.1622 - val_loss: 863113.9375 - val_mae: 449.0224 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 912us/step - loss: 933091.3125 - mae: 481.5102 - val_loss: 682428.5625 - val_mae: 389.1997 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 910us/step - loss: 727906.6875 - mae: 418.5779 - val_loss: 519284.8125 - val_mae: 342.9126 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 907us/step - loss: 537661.6250 - mae: 356.8666 - val_loss: 379528.2812 - val_mae: 297.5818 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 910us/step - loss: 384888.9375 - mae: 305.6066 - val_loss: 277851.7188 - val_mae: 263.4381 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 915us/step - loss: 275172.6875 - mae: 262.6549 - val_loss: 210936.5156 - val_mae: 235.7186 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 915us/step - loss: 205161.0781 - mae: 231.6891 - val_loss: 175678.7188 - val_mae: 210.4519 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 915us/step - loss: 162682.8906 - mae: 209.4263 - val_loss: 153249.5469 - val_mae: 196.0083 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 914us/step - loss: 139161.5938 - mae: 193.6301 - val_loss: 145008.9688 - val_mae: 189.9959 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 904us/step - loss: 126550.0703 - mae: 184.9956 - val_loss: 130803.7500 - val_mae: 179.3555 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 118281.3906 - mae: 176.6643 - val_loss: 132385.4375 - val_mae: 177.1691 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 909us/step - loss: 113084.8828 - mae: 171.1707 - val_loss: 123441.0156 - val_mae: 172.5891 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 915us/step - loss: 110058.7656 - mae: 166.4987 - val_loss: 126306.0625 - val_mae: 169.4761 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 107951.7969 - mae: 163.3245 - val_loss: 130886.5469 - val_mae: 170.0176 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 107037.2578 - mae: 161.1443 - val_loss: 122750.2969 - val_mae: 166.4428 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 911us/step - loss: 106253.4922 - mae: 159.6610 - val_loss: 120204.8750 - val_mae: 162.6613 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 914us/step - loss: 104664.8281 - mae: 157.8837 - val_loss: 123489.0469 - val_mae: 164.9973 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 909us/step - loss: 104754.3594 - mae: 157.3478 - val_loss: 122714.3906 - val_mae: 165.7911 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 907us/step - loss: 104708.1250 - mae: 156.7623 - val_loss: 121275.5625 - val_mae: 162.0983 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 911us/step - loss: 103436.4609 - mae: 155.3679 - val_loss: 125217.3906 - val_mae: 163.9513 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 102955.7031 - mae: 154.6324 - val_loss: 124952.3828 - val_mae: 169.7721 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 103432.7578 - mae: 154.6787 - val_loss: 121353.8672 - val_mae: 162.2434 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 910us/step - loss: 102482.5312 - mae: 153.4196 - val_loss: 115986.4375 - val_mae: 161.9083 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 912us/step - loss: 102387.3828 - mae: 153.2897 - val_loss: 118397.0156 - val_mae: 157.8949 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 911us/step - loss: 102096.1562 - mae: 152.5650 - val_loss: 125961.5234 - val_mae: 168.1712 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 912us/step - loss: 102129.0859 - mae: 152.5622 - val_loss: 124116.4766 - val_mae: 164.1419 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 914us/step - loss: 101699.4375 - mae: 151.7739 - val_loss: 121754.0703 - val_mae: 163.5815 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 905us/step - loss: 101871.9453 - mae: 151.6724 - val_loss: 119774.9922 - val_mae: 157.6159 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 907us/step - loss: 101244.8281 - mae: 150.9999 - val_loss: 123062.8984 - val_mae: 159.3821 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 922us/step - loss: 101193.2734 - mae: 151.1778 - val_loss: 116643.5000 - val_mae: 153.8159 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 100955.6016 - mae: 150.0044 - val_loss: 118145.6406 - val_mae: 155.9757 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 922us/step - loss: 100849.7266 - mae: 149.8779 - val_loss: 115850.0703 - val_mae: 155.0458 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 100587.8672 - mae: 149.5462 - val_loss: 116509.4766 - val_mae: 153.9601 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 100592.9844 - mae: 149.7874 - val_loss: 117504.3906 - val_mae: 155.2744 - lr: 0.0010\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 940us/step - loss: 100471.1328 - mae: 149.7613 - val_loss: 117070.8672 - val_mae: 154.7458 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 920us/step - loss: 100308.6250 - mae: 149.5167 - val_loss: 116407.2969 - val_mae: 156.0736 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 916us/step - loss: 99944.4375 - mae: 148.9559 - val_loss: 113946.8594 - val_mae: 154.1310 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 921us/step - loss: 99523.3125 - mae: 148.2257 - val_loss: 116652.9219 - val_mae: 155.0601 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 911us/step - loss: 99743.0781 - mae: 148.3609 - val_loss: 113797.7656 - val_mae: 151.1846 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 922us/step - loss: 100221.8125 - mae: 148.7227 - val_loss: 121356.1641 - val_mae: 159.3118 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 99733.4531 - mae: 148.4526 - val_loss: 113379.1875 - val_mae: 152.7556 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 924us/step - loss: 99583.6016 - mae: 147.9104 - val_loss: 118257.7734 - val_mae: 153.9737 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 931us/step - loss: 99177.9375 - mae: 148.1284 - val_loss: 117232.5391 - val_mae: 153.8172 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 99367.0625 - mae: 147.8691 - val_loss: 114972.2031 - val_mae: 153.6492 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 99346.6328 - mae: 148.0184 - val_loss: 121089.5469 - val_mae: 156.5510 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 910us/step - loss: 99311.4453 - mae: 147.5072 - val_loss: 115063.0234 - val_mae: 153.1870 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 99261.7266 - mae: 147.7571 - val_loss: 115104.9531 - val_mae: 153.6666 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 17:46:06,354]\u001b[0m Trial 10 finished with value: 115104.9346129226 and parameters: {'feature_dim': 33, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1707611.0000 - mae: 731.6491 - val_loss: 1370603.2500 - val_mae: 615.0091 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 1511613.2500 - mae: 664.2270 - val_loss: 1155074.6250 - val_mae: 542.3488 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 1239403.7500 - mae: 578.1865 - val_loss: 910025.3750 - val_mae: 462.4281 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 931us/step - loss: 959475.8125 - mae: 491.0401 - val_loss: 681381.2500 - val_mae: 390.1520 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 709225.2500 - mae: 410.8418 - val_loss: 492779.6875 - val_mae: 327.9450 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 504541.0312 - mae: 340.6661 - val_loss: 353506.6875 - val_mae: 277.1663 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 353242.4375 - mae: 286.2426 - val_loss: 257556.5312 - val_mae: 242.2774 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 926us/step - loss: 252039.5469 - mae: 246.5185 - val_loss: 196651.3281 - val_mae: 215.8791 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 187733.6094 - mae: 217.1729 - val_loss: 156979.4219 - val_mae: 193.5531 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 151225.9375 - mae: 196.3251 - val_loss: 144794.5781 - val_mae: 180.2231 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 923us/step - loss: 129895.5547 - mae: 181.6928 - val_loss: 134150.2656 - val_mae: 173.6563 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 120072.1328 - mae: 173.5281 - val_loss: 131930.2969 - val_mae: 168.5249 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 921us/step - loss: 113698.8984 - mae: 167.2711 - val_loss: 129085.8828 - val_mae: 165.9216 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 925us/step - loss: 109587.5312 - mae: 162.0282 - val_loss: 135307.0781 - val_mae: 171.2085 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 924us/step - loss: 107377.9062 - mae: 158.7134 - val_loss: 121562.5234 - val_mae: 162.3417 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 106174.9141 - mae: 157.4263 - val_loss: 128154.9453 - val_mae: 164.4377 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 104875.3047 - mae: 155.5261 - val_loss: 125020.9922 - val_mae: 162.8259 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 104958.6016 - mae: 155.0374 - val_loss: 127003.0703 - val_mae: 166.2494 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 104653.0781 - mae: 154.7650 - val_loss: 125545.1094 - val_mae: 162.3364 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 103541.2109 - mae: 153.5021 - val_loss: 122018.2422 - val_mae: 161.0249 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 103321.7266 - mae: 152.8055 - val_loss: 124034.2500 - val_mae: 162.0273 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 103846.0156 - mae: 153.3006 - val_loss: 123183.9297 - val_mae: 159.2001 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 102674.4609 - mae: 152.1270 - val_loss: 128598.5781 - val_mae: 162.4933 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 102325.9062 - mae: 151.3454 - val_loss: 121340.5000 - val_mae: 160.8673 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 930us/step - loss: 102800.4219 - mae: 151.7191 - val_loss: 122461.9453 - val_mae: 159.5600 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 926us/step - loss: 102316.4609 - mae: 151.0809 - val_loss: 115867.5625 - val_mae: 155.5974 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 101918.7969 - mae: 150.8673 - val_loss: 120421.5156 - val_mae: 156.6296 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 922us/step - loss: 101698.4688 - mae: 150.4800 - val_loss: 126150.9297 - val_mae: 163.9608 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 101736.2734 - mae: 150.7002 - val_loss: 122531.2656 - val_mae: 161.0616 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 101331.9844 - mae: 149.6698 - val_loss: 123933.9453 - val_mae: 161.0932 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 101383.3594 - mae: 149.7070 - val_loss: 120415.5078 - val_mae: 156.0654 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 926us/step - loss: 100894.9219 - mae: 149.2230 - val_loss: 123093.0781 - val_mae: 158.2643 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 921us/step - loss: 100991.9062 - mae: 149.8606 - val_loss: 118041.9375 - val_mae: 153.3380 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 100724.6406 - mae: 148.9659 - val_loss: 117770.2109 - val_mae: 154.1193 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 928us/step - loss: 100571.8594 - mae: 148.5863 - val_loss: 115887.1875 - val_mae: 153.2922 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 924us/step - loss: 100470.8438 - mae: 148.4434 - val_loss: 116986.4375 - val_mae: 154.1422 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 926us/step - loss: 97974.1562 - mae: 145.7003 - val_loss: 115110.9219 - val_mae: 152.1365 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 920us/step - loss: 97634.4844 - mae: 144.9513 - val_loss: 115654.2656 - val_mae: 152.8297 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 925us/step - loss: 97565.6562 - mae: 144.7671 - val_loss: 115895.6875 - val_mae: 152.7278 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 931us/step - loss: 97400.5938 - mae: 144.8280 - val_loss: 115277.7891 - val_mae: 151.8554 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 97473.8281 - mae: 144.4981 - val_loss: 116490.2109 - val_mae: 153.3054 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 97365.9531 - mae: 144.3613 - val_loss: 114799.3125 - val_mae: 152.5082 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 97481.7500 - mae: 144.7362 - val_loss: 114985.6172 - val_mae: 151.8562 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 97352.9219 - mae: 144.4523 - val_loss: 114768.7812 - val_mae: 151.5540 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 933us/step - loss: 97343.3594 - mae: 144.3923 - val_loss: 115302.5000 - val_mae: 152.5734 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 97342.0312 - mae: 144.6209 - val_loss: 115351.6953 - val_mae: 152.7130 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 97370.3984 - mae: 144.4995 - val_loss: 115430.4062 - val_mae: 152.8895 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 930us/step - loss: 97333.5859 - mae: 144.5578 - val_loss: 116980.6406 - val_mae: 154.0276 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 97243.2734 - mae: 144.4479 - val_loss: 114626.8516 - val_mae: 151.5945 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 925us/step - loss: 97279.2422 - mae: 144.3641 - val_loss: 114817.5547 - val_mae: 151.7409 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 17:46:58,131]\u001b[0m Trial 11 finished with value: 114817.59729473674 and parameters: {'feature_dim': 34, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 0 with value: 114181.04341464395.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1704725.8750 - mae: 727.4239 - val_loss: 1381409.6250 - val_mae: 615.7885 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 1552344.3750 - mae: 674.5213 - val_loss: 1217048.0000 - val_mae: 561.9507 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 1340530.7500 - mae: 608.7584 - val_loss: 1020097.8750 - val_mae: 496.5305 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 1109081.6250 - mae: 537.8895 - val_loss: 823060.8750 - val_mae: 432.9994 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 884195.9375 - mae: 467.2303 - val_loss: 643021.6250 - val_mae: 377.3877 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 684796.8750 - mae: 404.9455 - val_loss: 489793.4688 - val_mae: 330.7776 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 515734.2188 - mae: 349.2354 - val_loss: 370602.8125 - val_mae: 289.6476 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 384069.1875 - mae: 303.6250 - val_loss: 285408.2812 - val_mae: 257.9307 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 285171.9062 - mae: 263.1004 - val_loss: 219384.4219 - val_mae: 228.6283 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 217872.5781 - mae: 233.3857 - val_loss: 181513.4844 - val_mae: 208.8964 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 174188.4219 - mae: 211.3658 - val_loss: 161970.4844 - val_mae: 197.6383 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 147699.9844 - mae: 195.0432 - val_loss: 154251.2031 - val_mae: 192.0285 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 132415.5000 - mae: 184.8961 - val_loss: 138291.6719 - val_mae: 183.4505 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 123924.7891 - mae: 177.4412 - val_loss: 140758.4844 - val_mae: 181.4061 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 119324.7812 - mae: 173.1485 - val_loss: 130251.6719 - val_mae: 179.3004 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 116897.2656 - mae: 171.0596 - val_loss: 138565.2188 - val_mae: 175.9427 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 114023.6797 - mae: 167.9316 - val_loss: 130882.9297 - val_mae: 173.3321 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 112130.0625 - mae: 165.8061 - val_loss: 128060.5156 - val_mae: 174.9379 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 110114.1562 - mae: 163.6221 - val_loss: 127988.8594 - val_mae: 171.3479 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 108086.4062 - mae: 161.7683 - val_loss: 127827.5547 - val_mae: 168.5316 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 107068.5156 - mae: 159.9596 - val_loss: 125566.6250 - val_mae: 172.6557 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 107049.8984 - mae: 159.8620 - val_loss: 123241.8438 - val_mae: 168.1606 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 105861.9688 - mae: 158.2801 - val_loss: 128694.0469 - val_mae: 170.6775 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 105005.7656 - mae: 157.1363 - val_loss: 121695.9609 - val_mae: 173.5413 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 105239.5625 - mae: 156.6949 - val_loss: 121900.1328 - val_mae: 165.4878 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 104379.3906 - mae: 156.0694 - val_loss: 118671.4062 - val_mae: 167.6290 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 103841.2891 - mae: 154.9430 - val_loss: 121786.5078 - val_mae: 162.2216 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 103316.7578 - mae: 153.8026 - val_loss: 126990.4609 - val_mae: 171.1391 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 103022.7422 - mae: 153.5890 - val_loss: 124465.6719 - val_mae: 168.5716 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 102515.5000 - mae: 152.7562 - val_loss: 123894.8906 - val_mae: 166.0547 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 102659.5781 - mae: 152.3586 - val_loss: 117279.1875 - val_mae: 159.9657 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 102104.7344 - mae: 151.8247 - val_loss: 122113.7891 - val_mae: 160.5488 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 101718.9844 - mae: 151.7194 - val_loss: 117012.0391 - val_mae: 157.4172 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 101586.5547 - mae: 150.6146 - val_loss: 116691.1953 - val_mae: 156.9803 - lr: 0.0010\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 967us/step - loss: 101502.2969 - mae: 150.3144 - val_loss: 113617.0234 - val_mae: 156.5639 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 101149.4609 - mae: 149.7555 - val_loss: 116091.6328 - val_mae: 155.4647 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 101094.3750 - mae: 149.8066 - val_loss: 119195.3594 - val_mae: 157.4189 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 100950.0000 - mae: 149.8160 - val_loss: 118064.2109 - val_mae: 159.0999 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 100706.2734 - mae: 149.5576 - val_loss: 115217.1172 - val_mae: 157.8384 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 100301.6328 - mae: 148.5441 - val_loss: 113234.4609 - val_mae: 154.1287 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 99766.8750 - mae: 147.8219 - val_loss: 115275.3828 - val_mae: 155.3757 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 99997.7188 - mae: 147.6950 - val_loss: 112366.2812 - val_mae: 151.2496 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 100210.5234 - mae: 148.2896 - val_loss: 120774.7969 - val_mae: 160.4545 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 99859.7031 - mae: 148.0867 - val_loss: 111245.7188 - val_mae: 150.3448 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 99601.1016 - mae: 147.0381 - val_loss: 115661.0391 - val_mae: 152.5169 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 99545.8438 - mae: 147.5522 - val_loss: 117649.8516 - val_mae: 152.5954 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 99359.8047 - mae: 147.4443 - val_loss: 111856.9609 - val_mae: 152.4370 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 99218.9062 - mae: 147.3224 - val_loss: 116170.3359 - val_mae: 151.7946 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 99161.5234 - mae: 146.8053 - val_loss: 112156.2422 - val_mae: 151.5622 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 99091.3125 - mae: 147.0545 - val_loss: 112079.7812 - val_mae: 149.5412 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 17:47:51,684]\u001b[0m Trial 12 finished with value: 112079.77023798117 and parameters: {'feature_dim': 38, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 12 with value: 112079.77023798117.\u001b[0m\n",
      "[TabNet]: 40 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1662277.2500 - mae: 740.9215 - val_loss: 1306044.5000 - val_mae: 672.1526 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1409297.1250 - mae: 774.5805 - val_loss: 1126722.0000 - val_mae: 734.0866 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1250107.0000 - mae: 834.1712 - val_loss: 1071390.7500 - val_mae: 796.3030 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1212406.8750 - mae: 873.2092 - val_loss: 1068122.2500 - val_mae: 815.3494 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1207537.2500 - mae: 884.1042 - val_loss: 1068500.0000 - val_mae: 805.1801 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1206470.5000 - mae: 885.4197 - val_loss: 1068142.8750 - val_mae: 807.0526 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1206063.7500 - mae: 886.6223 - val_loss: 1067886.5000 - val_mae: 811.8323 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1205946.2500 - mae: 887.5441 - val_loss: 1068357.6250 - val_mae: 808.8351 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1205698.0000 - mae: 886.4232 - val_loss: 1068412.2500 - val_mae: 808.5378 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1205687.6250 - mae: 886.7590 - val_loss: 1068509.1250 - val_mae: 808.8663 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1205335.6250 - mae: 887.0466 - val_loss: 1071148.7500 - val_mae: 796.8601 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1205249.6250 - mae: 886.2273 - val_loss: 1069537.1250 - val_mae: 804.6168 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1204794.2500 - mae: 885.9636 - val_loss: 1068954.6250 - val_mae: 812.7726 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1204578.2500 - mae: 887.1503 - val_loss: 1070842.8750 - val_mae: 803.3066 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1204347.5000 - mae: 885.9395 - val_loss: 1070100.0000 - val_mae: 808.0781 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1204329.3750 - mae: 885.5558 - val_loss: 1069791.8750 - val_mae: 812.3758 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1204025.8750 - mae: 885.7890 - val_loss: 1069342.3750 - val_mae: 825.9752 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1203300.3750 - mae: 888.8235 - val_loss: 1069848.8750 - val_mae: 811.9257 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1202823.2500 - mae: 885.1274 - val_loss: 1070549.8750 - val_mae: 807.5457 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1202672.5000 - mae: 883.9896 - val_loss: 1070501.7500 - val_mae: 807.5068 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1202520.3750 - mae: 883.6153 - val_loss: 1070570.3750 - val_mae: 806.7651 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1202343.5000 - mae: 884.0743 - val_loss: 1070866.0000 - val_mae: 805.0167 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1202216.2500 - mae: 882.3759 - val_loss: 1069602.0000 - val_mae: 809.8534 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1201963.1250 - mae: 882.7947 - val_loss: 1068990.8750 - val_mae: 812.0037 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1201877.3750 - mae: 883.3397 - val_loss: 1069641.6250 - val_mae: 806.5737 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1201641.7500 - mae: 882.0080 - val_loss: 1069354.2500 - val_mae: 806.1536 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1201442.0000 - mae: 881.8316 - val_loss: 1070258.2500 - val_mae: 801.3272 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 17:48:43,247]\u001b[0m Trial 13 finished with value: 1070258.2399639832 and parameters: {'feature_dim': 48, 'output_dim': 8, 'num_decision_steps': 2}. Best is trial 12 with value: 112079.77023798117.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1657799.1250 - mae: 716.8972 - val_loss: 1274514.5000 - val_mae: 580.4544 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 1331475.1250 - mae: 607.9368 - val_loss: 942507.3125 - val_mae: 475.4869 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 945157.4375 - mae: 488.2016 - val_loss: 631216.8125 - val_mae: 375.3595 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 620684.2500 - mae: 384.2249 - val_loss: 406563.1250 - val_mae: 303.1611 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 393501.7812 - mae: 307.5483 - val_loss: 268752.6562 - val_mae: 252.3067 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 252736.2344 - mae: 251.3784 - val_loss: 197046.6094 - val_mae: 225.9459 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 176607.2188 - mae: 214.5283 - val_loss: 155257.6562 - val_mae: 204.1457 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 141166.2188 - mae: 193.9269 - val_loss: 139344.1406 - val_mae: 185.5282 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 124198.6094 - mae: 181.5470 - val_loss: 131548.4062 - val_mae: 182.8494 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 117265.9219 - mae: 174.6470 - val_loss: 134983.0000 - val_mae: 175.0768 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 112417.4062 - mae: 169.3852 - val_loss: 128776.4609 - val_mae: 175.3148 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 111020.0000 - mae: 166.7486 - val_loss: 130584.8281 - val_mae: 171.8216 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 945us/step - loss: 108304.9766 - mae: 163.6787 - val_loss: 122486.6250 - val_mae: 173.9608 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 107206.1875 - mae: 161.8461 - val_loss: 132953.7344 - val_mae: 173.1433 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 105997.3438 - mae: 160.5182 - val_loss: 117951.5234 - val_mae: 166.0747 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 105736.7422 - mae: 160.3414 - val_loss: 125019.2734 - val_mae: 165.1982 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 104637.3359 - mae: 158.4814 - val_loss: 119924.0000 - val_mae: 163.0082 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 104806.0156 - mae: 158.9262 - val_loss: 119331.1406 - val_mae: 163.2909 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 104584.1250 - mae: 157.9356 - val_loss: 122449.4297 - val_mae: 166.6431 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 103498.2578 - mae: 157.2879 - val_loss: 118645.9453 - val_mae: 158.6750 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 103477.6328 - mae: 156.6949 - val_loss: 119621.5703 - val_mae: 161.8322 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 103734.7891 - mae: 156.9275 - val_loss: 118080.4688 - val_mae: 160.1962 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 102560.0078 - mae: 155.6693 - val_loss: 125780.0312 - val_mae: 163.6256 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 101978.5234 - mae: 154.8503 - val_loss: 118446.0703 - val_mae: 163.7041 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 102447.0312 - mae: 155.1340 - val_loss: 116994.8438 - val_mae: 158.8708 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 101799.9609 - mae: 154.3999 - val_loss: 113298.6406 - val_mae: 159.6474 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 101602.2188 - mae: 154.2592 - val_loss: 116827.8828 - val_mae: 156.3139 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 101515.9688 - mae: 153.8065 - val_loss: 125799.7344 - val_mae: 166.8554 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 101344.2578 - mae: 153.2518 - val_loss: 126708.5312 - val_mae: 166.2092 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 100811.0312 - mae: 152.6591 - val_loss: 120595.8672 - val_mae: 160.6833 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 945us/step - loss: 101088.0703 - mae: 152.6997 - val_loss: 119341.6250 - val_mae: 158.7492 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 100638.3047 - mae: 152.0676 - val_loss: 120915.3047 - val_mae: 158.9255 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 100443.9062 - mae: 152.1633 - val_loss: 115148.2266 - val_mae: 154.9809 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 100253.9844 - mae: 151.2926 - val_loss: 114368.1953 - val_mae: 154.4247 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 100268.0156 - mae: 151.4950 - val_loss: 112047.8516 - val_mae: 153.6358 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 99920.5469 - mae: 150.5475 - val_loss: 114933.0156 - val_mae: 156.3452 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 99676.4766 - mae: 150.7115 - val_loss: 114939.4688 - val_mae: 157.0287 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 99856.6094 - mae: 151.1148 - val_loss: 115031.0547 - val_mae: 156.9638 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 99463.9141 - mae: 150.7827 - val_loss: 114046.7578 - val_mae: 154.4080 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 98979.2969 - mae: 150.1452 - val_loss: 113360.5000 - val_mae: 155.8146 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 98654.9766 - mae: 149.5229 - val_loss: 114390.7422 - val_mae: 154.3227 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 99026.3984 - mae: 149.7910 - val_loss: 111922.8438 - val_mae: 152.6172 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 99148.3672 - mae: 149.8229 - val_loss: 121515.2891 - val_mae: 164.9073 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 98621.1719 - mae: 149.4834 - val_loss: 111027.4609 - val_mae: 153.0865 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 98661.6953 - mae: 148.8736 - val_loss: 115985.4766 - val_mae: 153.6135 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 98400.8281 - mae: 149.2939 - val_loss: 117787.4766 - val_mae: 157.4437 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 98143.9062 - mae: 149.2045 - val_loss: 112186.9844 - val_mae: 154.0786 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 98254.6250 - mae: 149.0408 - val_loss: 113866.7188 - val_mae: 152.9186 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 98121.7812 - mae: 148.6074 - val_loss: 111253.2812 - val_mae: 152.9807 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 98006.5859 - mae: 148.7015 - val_loss: 113192.3906 - val_mae: 151.9133 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 17:49:35,878]\u001b[0m Trial 14 finished with value: 113192.36308255458 and parameters: {'feature_dim': 38, 'output_dim': 10, 'num_decision_steps': 1}. Best is trial 12 with value: 112079.77023798117.\u001b[0m\n",
      "[TabNet]: 28 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1658512.0000 - mae: 741.1146 - val_loss: 1286509.1250 - val_mae: 672.1769 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1404304.1250 - mae: 773.7476 - val_loss: 1091490.7500 - val_mae: 735.8063 - lr: 0.0010\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1238004.6250 - mae: 828.0309 - val_loss: 1015929.1250 - val_mae: 784.2551 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1179894.6250 - mae: 847.5849 - val_loss: 980346.2500 - val_mae: 799.2938 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1157629.7500 - mae: 852.5857 - val_loss: 956055.0625 - val_mae: 774.8939 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1152126.0000 - mae: 852.8035 - val_loss: 947390.5625 - val_mae: 779.9716 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1144102.3750 - mae: 849.0283 - val_loss: 935625.6875 - val_mae: 769.4235 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1139097.7500 - mae: 846.5988 - val_loss: 964984.4375 - val_mae: 805.6848 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1140634.3750 - mae: 848.8579 - val_loss: 952179.1875 - val_mae: 791.5739 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1136819.5000 - mae: 847.4359 - val_loss: 924000.5000 - val_mae: 727.8036 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1138258.0000 - mae: 846.8467 - val_loss: 942866.1250 - val_mae: 767.7879 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1134715.6250 - mae: 846.9928 - val_loss: 935286.8125 - val_mae: 767.8201 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1134675.7500 - mae: 846.9341 - val_loss: 939416.2500 - val_mae: 774.7214 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1135048.8750 - mae: 847.5486 - val_loss: 934665.0625 - val_mae: 764.8390 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1137062.0000 - mae: 848.6089 - val_loss: 950142.2500 - val_mae: 766.9301 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1137968.2500 - mae: 849.4198 - val_loss: 923665.1875 - val_mae: 745.6880 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1129851.3750 - mae: 843.4827 - val_loss: 936644.0000 - val_mae: 773.5903 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1127076.2500 - mae: 842.4233 - val_loss: 924619.1875 - val_mae: 751.0858 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1131502.0000 - mae: 843.5959 - val_loss: 936214.5000 - val_mae: 761.5930 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1133400.2500 - mae: 847.0337 - val_loss: 942748.0625 - val_mae: 779.4100 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1137248.2500 - mae: 851.0532 - val_loss: 928269.5625 - val_mae: 755.9484 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1128799.3750 - mae: 842.8367 - val_loss: 938728.4375 - val_mae: 774.7498 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1134755.5000 - mae: 846.5743 - val_loss: 941067.8750 - val_mae: 755.0720 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1132687.5000 - mae: 847.1964 - val_loss: 938250.8750 - val_mae: 773.8560 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1133782.5000 - mae: 845.9228 - val_loss: 940848.1250 - val_mae: 775.5140 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1136481.0000 - mae: 848.5390 - val_loss: 966097.6250 - val_mae: 806.5582 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1119958.2500 - mae: 848.2989 - val_loss: 937068.8125 - val_mae: 765.3083 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1109329.6250 - mae: 828.2620 - val_loss: 926939.6250 - val_mae: 741.1738 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1107724.1250 - mae: 827.2533 - val_loss: 930236.5000 - val_mae: 743.9503 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1107197.0000 - mae: 825.7485 - val_loss: 932055.3125 - val_mae: 749.8516 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1106904.7500 - mae: 825.7469 - val_loss: 940794.4375 - val_mae: 765.7819 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1105586.0000 - mae: 824.2509 - val_loss: 930586.1875 - val_mae: 746.7682 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1106974.7500 - mae: 825.8981 - val_loss: 926782.8750 - val_mae: 738.0458 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1106638.6250 - mae: 825.3107 - val_loss: 931667.0625 - val_mae: 749.3774 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1107877.1250 - mae: 825.9792 - val_loss: 940711.6875 - val_mae: 766.8606 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1106450.6250 - mae: 825.2957 - val_loss: 945112.7500 - val_mae: 773.1608 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 17:50:39,010]\u001b[0m Trial 15 finished with value: 945112.8771650965 and parameters: {'feature_dim': 38, 'output_dim': 10, 'num_decision_steps': 2}. Best is trial 12 with value: 112079.77023798117.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1674527.1250 - mae: 722.3926 - val_loss: 1315899.2500 - val_mae: 597.7117 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 915us/step - loss: 1417740.1250 - mae: 633.9973 - val_loss: 1048590.8750 - val_mae: 508.1854 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 909us/step - loss: 1093008.0000 - mae: 532.7019 - val_loss: 771227.4375 - val_mae: 415.2081 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 914us/step - loss: 786864.7500 - mae: 435.2698 - val_loss: 535910.9375 - val_mae: 339.4641 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 538711.0000 - mae: 352.3850 - val_loss: 366573.4375 - val_mae: 286.3040 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 923us/step - loss: 361149.4062 - mae: 289.0899 - val_loss: 260773.0312 - val_mae: 244.7440 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 916us/step - loss: 245751.1719 - mae: 243.0517 - val_loss: 189610.6875 - val_mae: 215.9530 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 916us/step - loss: 179343.2812 - mae: 212.1888 - val_loss: 154585.5156 - val_mae: 194.7926 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 914us/step - loss: 143020.6719 - mae: 190.8802 - val_loss: 143626.6875 - val_mae: 182.9823 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 126901.1250 - mae: 178.8806 - val_loss: 140129.0469 - val_mae: 178.5934 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 923us/step - loss: 116706.6953 - mae: 170.0796 - val_loss: 132852.9531 - val_mae: 175.7719 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 923us/step - loss: 111850.8984 - mae: 164.9632 - val_loss: 130600.3672 - val_mae: 168.1583 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 108265.2188 - mae: 161.0192 - val_loss: 125759.6328 - val_mae: 166.4831 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 106638.3828 - mae: 158.5448 - val_loss: 134808.3125 - val_mae: 169.0580 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 105632.8750 - mae: 157.0595 - val_loss: 119717.0469 - val_mae: 160.9102 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 104843.3594 - mae: 155.9716 - val_loss: 122494.5547 - val_mae: 160.0016 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 103786.2031 - mae: 154.5362 - val_loss: 123490.2109 - val_mae: 160.4101 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 923us/step - loss: 104232.7656 - mae: 154.6530 - val_loss: 119781.7656 - val_mae: 161.2204 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 103576.9219 - mae: 153.6970 - val_loss: 117346.8984 - val_mae: 158.3559 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 914us/step - loss: 102602.2969 - mae: 152.7113 - val_loss: 119458.6406 - val_mae: 158.1351 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 915us/step - loss: 102513.1719 - mae: 152.5702 - val_loss: 120239.8984 - val_mae: 157.4479 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 102903.7734 - mae: 152.1563 - val_loss: 118344.6016 - val_mae: 155.3698 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 916us/step - loss: 101671.7891 - mae: 151.4487 - val_loss: 125315.4219 - val_mae: 161.3754 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 101392.0625 - mae: 150.8695 - val_loss: 118773.5000 - val_mae: 158.2488 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 921us/step - loss: 101647.9453 - mae: 150.6086 - val_loss: 116880.4297 - val_mae: 155.4433 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 101090.1328 - mae: 150.4427 - val_loss: 113292.0078 - val_mae: 157.0818 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 100944.3594 - mae: 150.1344 - val_loss: 115014.8984 - val_mae: 150.8765 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 924us/step - loss: 100582.4141 - mae: 149.7959 - val_loss: 123166.6250 - val_mae: 163.1535 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 920us/step - loss: 100564.1641 - mae: 149.6132 - val_loss: 120328.7422 - val_mae: 158.7020 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 100288.1328 - mae: 149.2660 - val_loss: 121687.6406 - val_mae: 158.6919 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 100603.7812 - mae: 149.4484 - val_loss: 117596.3594 - val_mae: 152.4554 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 100021.8438 - mae: 148.8874 - val_loss: 118723.3672 - val_mae: 154.5718 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 100106.6328 - mae: 149.5678 - val_loss: 114206.7812 - val_mae: 151.1104 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 99861.3203 - mae: 148.6053 - val_loss: 114921.4609 - val_mae: 150.1551 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 99784.2891 - mae: 148.2131 - val_loss: 112516.9297 - val_mae: 151.9054 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 99592.2734 - mae: 148.1115 - val_loss: 114076.5078 - val_mae: 151.4519 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 920us/step - loss: 99523.8047 - mae: 148.5111 - val_loss: 115979.7578 - val_mae: 152.9680 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 920us/step - loss: 99565.1250 - mae: 148.5286 - val_loss: 115439.7969 - val_mae: 154.2892 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 924us/step - loss: 99239.1719 - mae: 148.3324 - val_loss: 115243.1562 - val_mae: 152.9791 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 921us/step - loss: 98859.3672 - mae: 147.7669 - val_loss: 112389.3125 - val_mae: 153.4734 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 923us/step - loss: 98519.7656 - mae: 147.2579 - val_loss: 116130.4297 - val_mae: 153.7481 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 922us/step - loss: 98788.8125 - mae: 147.2564 - val_loss: 111565.5156 - val_mae: 149.8104 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 921us/step - loss: 99032.8828 - mae: 147.6852 - val_loss: 119755.7891 - val_mae: 159.3835 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 98696.5703 - mae: 147.6238 - val_loss: 110457.8281 - val_mae: 149.0329 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 920us/step - loss: 98514.9297 - mae: 146.7349 - val_loss: 116178.1875 - val_mae: 151.3883 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 922us/step - loss: 98172.6562 - mae: 147.3112 - val_loss: 117486.6406 - val_mae: 152.8285 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 920us/step - loss: 98244.3516 - mae: 147.1021 - val_loss: 112266.5000 - val_mae: 151.1015 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 925us/step - loss: 98225.4922 - mae: 147.2131 - val_loss: 114228.3906 - val_mae: 148.6840 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 921us/step - loss: 98143.3750 - mae: 146.6843 - val_loss: 111168.3516 - val_mae: 149.5251 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 98143.8047 - mae: 146.9931 - val_loss: 112047.1094 - val_mae: 150.0586 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 17:51:30,131]\u001b[0m Trial 16 finished with value: 112047.12673578341 and parameters: {'feature_dim': 37, 'output_dim': 10, 'num_decision_steps': 1}. Best is trial 16 with value: 112047.12673578341.\u001b[0m\n",
      "[TabNet]: 31 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1680373.2500 - mae: 712.1365 - val_loss: 1336843.3750 - val_mae: 598.6282 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1467119.1250 - mae: 646.8463 - val_loss: 1112256.6250 - val_mae: 527.8245 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1189491.0000 - mae: 564.3698 - val_loss: 868672.1250 - val_mae: 450.5584 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 917431.6875 - mae: 482.5626 - val_loss: 649037.3750 - val_mae: 381.4737 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 690887.3750 - mae: 416.1895 - val_loss: 486325.3125 - val_mae: 334.9019 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 531837.0000 - mae: 372.4363 - val_loss: 370041.6875 - val_mae: 294.2236 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 411566.6875 - mae: 331.7816 - val_loss: 300617.5000 - val_mae: 275.1227 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 345073.2188 - mae: 309.0273 - val_loss: 275035.6562 - val_mae: 254.8918 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 293361.7500 - mae: 286.3246 - val_loss: 241963.5625 - val_mae: 250.0829 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 252177.7500 - mae: 266.5947 - val_loss: 212667.7969 - val_mae: 227.9268 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 236442.1875 - mae: 258.3270 - val_loss: 200623.1406 - val_mae: 223.6327 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 223880.5000 - mae: 251.0102 - val_loss: 195068.8750 - val_mae: 221.4014 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 218519.0781 - mae: 247.7057 - val_loss: 178603.1719 - val_mae: 211.6105 - lr: 0.0010\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 2ms/step - loss: 213403.9844 - mae: 244.0537 - val_loss: 183923.2031 - val_mae: 212.2663 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 208776.5312 - mae: 240.7066 - val_loss: 191482.4844 - val_mae: 218.2914 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 207454.7188 - mae: 240.9325 - val_loss: 197394.3438 - val_mae: 218.8768 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 200489.5000 - mae: 235.9359 - val_loss: 178352.5469 - val_mae: 211.7355 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 198538.5625 - mae: 234.3481 - val_loss: 174717.9219 - val_mae: 204.9726 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 191817.6562 - mae: 230.1957 - val_loss: 188309.0469 - val_mae: 211.2748 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 189411.3125 - mae: 228.4676 - val_loss: 237654.6250 - val_mae: 235.7214 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 186883.3906 - mae: 227.0683 - val_loss: 175359.0312 - val_mae: 204.1531 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 188121.8594 - mae: 227.6368 - val_loss: 181975.5469 - val_mae: 207.3239 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 181915.1250 - mae: 224.0384 - val_loss: 171308.1562 - val_mae: 200.9470 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 180297.6094 - mae: 222.3006 - val_loss: 175676.2969 - val_mae: 203.3787 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 179350.2344 - mae: 221.4741 - val_loss: 169235.7500 - val_mae: 200.2379 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 176523.1406 - mae: 219.8343 - val_loss: 166550.3125 - val_mae: 200.2150 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 181429.7656 - mae: 223.1416 - val_loss: 165278.8906 - val_mae: 200.0842 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 173315.0625 - mae: 217.8639 - val_loss: 167814.6094 - val_mae: 200.4097 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 174691.7812 - mae: 218.7000 - val_loss: 162703.7031 - val_mae: 198.4145 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 171248.0469 - mae: 216.8676 - val_loss: 179708.2500 - val_mae: 205.9848 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 169232.9062 - mae: 215.5934 - val_loss: 166403.0469 - val_mae: 198.7590 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 169619.7656 - mae: 215.3819 - val_loss: 172415.7188 - val_mae: 201.6421 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 168925.1250 - mae: 215.2757 - val_loss: 169177.2812 - val_mae: 199.8621 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 168733.1875 - mae: 214.4294 - val_loss: 167867.8594 - val_mae: 198.8949 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 168270.4219 - mae: 214.5721 - val_loss: 167577.8906 - val_mae: 202.0381 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 169321.2500 - mae: 214.8342 - val_loss: 181703.4531 - val_mae: 210.1438 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 167456.7031 - mae: 213.8986 - val_loss: 166902.3125 - val_mae: 198.9584 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 163989.4844 - mae: 211.5180 - val_loss: 176701.0938 - val_mae: 204.4207 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 166749.6562 - mae: 213.0029 - val_loss: 165155.4688 - val_mae: 197.7600 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157639.0469 - mae: 206.7033 - val_loss: 163069.3281 - val_mae: 197.8907 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157529.4062 - mae: 207.2049 - val_loss: 164222.8594 - val_mae: 197.4524 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157774.8438 - mae: 206.6929 - val_loss: 162976.8594 - val_mae: 197.4674 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157645.9844 - mae: 206.7916 - val_loss: 162999.5625 - val_mae: 197.4335 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157288.4219 - mae: 206.6184 - val_loss: 164450.7812 - val_mae: 197.5788 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157105.4062 - mae: 206.3402 - val_loss: 163586.7344 - val_mae: 197.2966 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157014.3906 - mae: 206.1917 - val_loss: 163094.5312 - val_mae: 197.3207 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157124.8750 - mae: 206.2243 - val_loss: 163268.2188 - val_mae: 197.1455 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 157188.0469 - mae: 206.1846 - val_loss: 165321.1406 - val_mae: 197.9844 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 156961.6250 - mae: 205.6691 - val_loss: 163235.3750 - val_mae: 197.1477 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 17:52:55,278]\u001b[0m Trial 17 finished with value: 163235.41203308967 and parameters: {'feature_dim': 37, 'output_dim': 6, 'num_decision_steps': 2}. Best is trial 16 with value: 112047.12673578341.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1671300.1250 - mae: 726.1412 - val_loss: 1295286.1250 - val_mae: 591.4749 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 901us/step - loss: 1366401.0000 - mae: 619.7904 - val_loss: 982119.6875 - val_mae: 491.0979 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 900us/step - loss: 993404.0000 - mae: 504.2245 - val_loss: 673008.0625 - val_mae: 389.7168 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 902us/step - loss: 667810.1250 - mae: 400.1599 - val_loss: 440757.7188 - val_mae: 316.8574 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 903us/step - loss: 431032.3750 - mae: 320.4290 - val_loss: 294310.2500 - val_mae: 262.9470 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 907us/step - loss: 278979.8438 - mae: 261.6317 - val_loss: 213263.2812 - val_mae: 226.8682 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 192567.0625 - mae: 222.3514 - val_loss: 170050.4531 - val_mae: 217.4223 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 899us/step - loss: 150169.0156 - mae: 198.7804 - val_loss: 145247.6406 - val_mae: 186.5031 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 897us/step - loss: 130082.3203 - mae: 184.3014 - val_loss: 139256.0938 - val_mae: 189.0377 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 903us/step - loss: 122006.7969 - mae: 176.6873 - val_loss: 139691.4062 - val_mae: 176.1499 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 116893.7031 - mae: 171.8629 - val_loss: 132578.6406 - val_mae: 176.2670 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 114626.4922 - mae: 169.2779 - val_loss: 132965.8594 - val_mae: 172.6010 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 911us/step - loss: 112334.2500 - mae: 168.1583 - val_loss: 128114.0156 - val_mae: 176.9841 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 905us/step - loss: 110821.5859 - mae: 166.4007 - val_loss: 139362.7812 - val_mae: 178.8573 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 903us/step - loss: 109565.6875 - mae: 165.1089 - val_loss: 126033.4375 - val_mae: 177.5646 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 908us/step - loss: 108996.8516 - mae: 164.3328 - val_loss: 130996.3828 - val_mae: 170.7267 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 904us/step - loss: 108072.3828 - mae: 162.2900 - val_loss: 126054.1797 - val_mae: 168.8573 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 903us/step - loss: 108035.0234 - mae: 161.4879 - val_loss: 124569.7500 - val_mae: 167.9577 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 903us/step - loss: 107425.7891 - mae: 160.2177 - val_loss: 124962.2656 - val_mae: 167.9445 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 902us/step - loss: 105992.9219 - mae: 158.2158 - val_loss: 123666.2344 - val_mae: 164.5954 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 894us/step - loss: 105296.7344 - mae: 156.9154 - val_loss: 122379.9141 - val_mae: 164.3228 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 895us/step - loss: 105321.7578 - mae: 156.6587 - val_loss: 121868.3750 - val_mae: 163.7728 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 901us/step - loss: 103922.0156 - mae: 155.0967 - val_loss: 127556.4141 - val_mae: 165.2356 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 904us/step - loss: 103414.8750 - mae: 154.4672 - val_loss: 119217.0625 - val_mae: 164.7573 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 907us/step - loss: 103734.6172 - mae: 154.7278 - val_loss: 122768.6406 - val_mae: 165.6232 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 902us/step - loss: 103234.3828 - mae: 153.8150 - val_loss: 116022.3359 - val_mae: 160.6099 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 897us/step - loss: 102884.3125 - mae: 153.4044 - val_loss: 117906.3906 - val_mae: 159.7085 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 898us/step - loss: 102579.2812 - mae: 153.0140 - val_loss: 122856.5234 - val_mae: 165.6329 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 102572.7344 - mae: 153.1648 - val_loss: 125150.8125 - val_mae: 166.4014 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 900us/step - loss: 102410.1094 - mae: 152.6880 - val_loss: 122889.0312 - val_mae: 164.6185 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 900us/step - loss: 102288.7812 - mae: 152.3958 - val_loss: 119852.3125 - val_mae: 161.8419 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 898us/step - loss: 101965.5000 - mae: 152.4536 - val_loss: 122268.2188 - val_mae: 162.1094 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 898us/step - loss: 101826.2031 - mae: 152.3789 - val_loss: 118437.6016 - val_mae: 156.1940 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 897us/step - loss: 101639.4922 - mae: 151.3979 - val_loss: 117822.3906 - val_mae: 157.9865 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 898us/step - loss: 101650.1562 - mae: 151.4067 - val_loss: 114965.7578 - val_mae: 158.1912 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 897us/step - loss: 101291.8672 - mae: 150.7560 - val_loss: 114975.7891 - val_mae: 155.4315 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 902us/step - loss: 101299.7969 - mae: 151.1497 - val_loss: 119082.9062 - val_mae: 156.6593 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 904us/step - loss: 101275.9453 - mae: 151.3351 - val_loss: 115332.2266 - val_mae: 156.4989 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 905us/step - loss: 101178.2031 - mae: 151.2211 - val_loss: 114780.4922 - val_mae: 155.6889 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 901us/step - loss: 100871.6328 - mae: 150.7164 - val_loss: 114836.1953 - val_mae: 157.2383 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 100387.0078 - mae: 150.1417 - val_loss: 117502.0234 - val_mae: 158.4888 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 913us/step - loss: 100394.7500 - mae: 149.2567 - val_loss: 113284.2344 - val_mae: 153.7067 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 100764.0000 - mae: 150.3008 - val_loss: 129651.9375 - val_mae: 170.0388 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 911us/step - loss: 100658.0938 - mae: 149.9996 - val_loss: 113309.3203 - val_mae: 154.4070 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 913us/step - loss: 100477.8125 - mae: 149.5364 - val_loss: 118543.3203 - val_mae: 155.2141 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 913us/step - loss: 100225.7812 - mae: 149.8452 - val_loss: 119690.6250 - val_mae: 155.9697 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 908us/step - loss: 100340.3750 - mae: 149.4511 - val_loss: 114659.6562 - val_mae: 153.6217 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 913us/step - loss: 100326.5078 - mae: 149.5427 - val_loss: 118708.8438 - val_mae: 153.7087 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 100042.6484 - mae: 148.9153 - val_loss: 114152.2500 - val_mae: 153.8533 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 100129.8672 - mae: 149.5502 - val_loss: 114798.9141 - val_mae: 152.6230 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 17:53:45,570]\u001b[0m Trial 18 finished with value: 114798.90598177456 and parameters: {'feature_dim': 32, 'output_dim': 9, 'num_decision_steps': 1}. Best is trial 16 with value: 112047.12673578341.\u001b[0m\n",
      "[TabNet]: 47 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 4s 2ms/step - loss: 1649789.1250 - mae: 742.2621 - val_loss: 1270489.0000 - val_mae: 679.8244 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1396807.2500 - mae: 780.0688 - val_loss: 1094593.7500 - val_mae: 758.8281 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1249097.1250 - mae: 842.9901 - val_loss: 1069942.5000 - val_mae: 833.7023 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1220000.3750 - mae: 881.3278 - val_loss: 1080520.3750 - val_mae: 862.3466 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217986.3750 - mae: 893.1508 - val_loss: 1081139.8750 - val_mae: 863.6466 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217872.7500 - mae: 894.2894 - val_loss: 1082754.8750 - val_mae: 866.7047 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217767.1250 - mae: 894.3871 - val_loss: 1084597.7500 - val_mae: 869.9175 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217807.2500 - mae: 896.0778 - val_loss: 1082246.1250 - val_mae: 865.9607 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217704.2500 - mae: 894.5305 - val_loss: 1084419.7500 - val_mae: 869.7415 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217691.3750 - mae: 896.4462 - val_loss: 1079615.3750 - val_mae: 861.2463 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217605.3750 - mae: 895.9086 - val_loss: 1076452.6250 - val_mae: 854.7798 - lr: 0.0010\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217709.2500 - mae: 893.9589 - val_loss: 1081141.5000 - val_mae: 864.2305 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217529.1250 - mae: 894.4131 - val_loss: 1084289.8750 - val_mae: 869.7514 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217538.5000 - mae: 897.8223 - val_loss: 1083500.0000 - val_mae: 868.4379 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217494.1250 - mae: 896.8188 - val_loss: 1082658.3750 - val_mae: 867.0068 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217468.7500 - mae: 895.9620 - val_loss: 1082281.2500 - val_mae: 866.3617 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217448.7500 - mae: 895.6909 - val_loss: 1081729.2500 - val_mae: 865.3975 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217436.0000 - mae: 895.1476 - val_loss: 1081492.8750 - val_mae: 864.9829 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217427.0000 - mae: 895.2152 - val_loss: 1081222.2500 - val_mae: 864.5051 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217420.3750 - mae: 894.9093 - val_loss: 1081027.2500 - val_mae: 864.1588 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217415.5000 - mae: 894.9042 - val_loss: 1081009.5000 - val_mae: 864.1345 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217399.5000 - mae: 894.8685 - val_loss: 1080815.3750 - val_mae: 863.7870 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1217399.6250 - mae: 894.4646 - val_loss: 1081084.8750 - val_mae: 864.2894 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 17:54:34,795]\u001b[0m Trial 19 finished with value: 1081084.9962715483 and parameters: {'feature_dim': 58, 'output_dim': 11, 'num_decision_steps': 2}. Best is trial 16 with value: 112047.12673578341.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1720946.2500 - mae: 731.5669 - val_loss: 1395443.3750 - val_mae: 621.2024 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1561435.3750 - mae: 677.5925 - val_loss: 1218134.8750 - val_mae: 562.5323 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1333142.8750 - mae: 607.2236 - val_loss: 1007618.8750 - val_mae: 493.5836 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1086090.2500 - mae: 531.9801 - val_loss: 796698.7500 - val_mae: 428.4438 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 850320.5625 - mae: 459.5175 - val_loss: 609940.8125 - val_mae: 371.0553 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 643269.0625 - mae: 392.7195 - val_loss: 460058.5000 - val_mae: 318.6697 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 473042.2500 - mae: 334.9936 - val_loss: 341863.0625 - val_mae: 284.0979 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 345223.5312 - mae: 288.9530 - val_loss: 258523.5000 - val_mae: 249.1252 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 253360.6875 - mae: 252.0486 - val_loss: 199761.5781 - val_mae: 230.3322 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 193225.6250 - mae: 224.8712 - val_loss: 171937.9844 - val_mae: 207.7206 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 155086.5312 - mae: 203.7748 - val_loss: 146775.7969 - val_mae: 193.4070 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 133694.5156 - mae: 189.6855 - val_loss: 145065.5469 - val_mae: 194.8040 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 121177.8125 - mae: 180.3611 - val_loss: 128904.1328 - val_mae: 175.8732 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 114412.4922 - mae: 173.6423 - val_loss: 137330.3281 - val_mae: 180.4893 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110009.0078 - mae: 168.1991 - val_loss: 121025.3281 - val_mae: 173.1137 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107617.5703 - mae: 164.9359 - val_loss: 130235.8984 - val_mae: 179.2003 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106211.0391 - mae: 162.6862 - val_loss: 124907.3594 - val_mae: 169.5056 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105679.8750 - mae: 161.3373 - val_loss: 122214.8672 - val_mae: 167.8093 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105262.1484 - mae: 160.0779 - val_loss: 122516.8594 - val_mae: 169.8737 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103662.8438 - mae: 158.0804 - val_loss: 122100.2969 - val_mae: 166.2755 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103368.7578 - mae: 157.5433 - val_loss: 123200.4453 - val_mae: 168.1833 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103776.8594 - mae: 157.0181 - val_loss: 119349.1016 - val_mae: 161.4810 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102688.1172 - mae: 155.8239 - val_loss: 128366.7891 - val_mae: 169.4877 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102091.5469 - mae: 154.8068 - val_loss: 119475.0703 - val_mae: 163.1535 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102537.4766 - mae: 154.6929 - val_loss: 121221.3359 - val_mae: 163.7543 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101733.2812 - mae: 153.9907 - val_loss: 113588.5312 - val_mae: 158.1362 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101550.1094 - mae: 153.4934 - val_loss: 115816.6719 - val_mae: 158.4421 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101371.8516 - mae: 153.1404 - val_loss: 124558.7969 - val_mae: 166.6856 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101335.7812 - mae: 152.9900 - val_loss: 124585.9297 - val_mae: 167.1929 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100832.6094 - mae: 151.9887 - val_loss: 121441.9219 - val_mae: 162.6878 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101182.0703 - mae: 152.3611 - val_loss: 118307.5391 - val_mae: 157.3427 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100633.4375 - mae: 151.7392 - val_loss: 120597.2344 - val_mae: 161.0666 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100691.6484 - mae: 152.2211 - val_loss: 114683.8359 - val_mae: 153.5558 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100370.1641 - mae: 150.9045 - val_loss: 116574.5000 - val_mae: 155.6876 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100244.3594 - mae: 150.5639 - val_loss: 112386.2656 - val_mae: 152.5340 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100189.0156 - mae: 150.3453 - val_loss: 114354.6328 - val_mae: 155.9820 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100199.4453 - mae: 150.3947 - val_loss: 116327.0938 - val_mae: 157.3277 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100237.4062 - mae: 150.6282 - val_loss: 114819.6875 - val_mae: 156.5778 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99879.3672 - mae: 150.0148 - val_loss: 114981.2031 - val_mae: 154.9219 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99472.8672 - mae: 149.1813 - val_loss: 112761.3203 - val_mae: 153.5210 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99056.0938 - mae: 148.6117 - val_loss: 114749.5391 - val_mae: 152.7710 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99382.1406 - mae: 148.7515 - val_loss: 112271.8438 - val_mae: 152.0751 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99677.1172 - mae: 148.8791 - val_loss: 122386.6953 - val_mae: 167.3725 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99372.3203 - mae: 148.7345 - val_loss: 111630.6328 - val_mae: 151.8711 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99320.2578 - mae: 147.9626 - val_loss: 114672.4609 - val_mae: 151.7098 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98594.0078 - mae: 148.1612 - val_loss: 117092.6797 - val_mae: 153.6168 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98962.4297 - mae: 148.2872 - val_loss: 112379.6016 - val_mae: 152.4091 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98768.1250 - mae: 148.2166 - val_loss: 117061.9297 - val_mae: 153.3101 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98897.9062 - mae: 147.6786 - val_loss: 111286.8047 - val_mae: 149.9451 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98739.6719 - mae: 147.7243 - val_loss: 112457.5625 - val_mae: 151.3968 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 17:55:32,457]\u001b[0m Trial 20 finished with value: 112457.5479893303 and parameters: {'feature_dim': 47, 'output_dim': 9, 'num_decision_steps': 1}. Best is trial 16 with value: 112047.12673578341.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1692482.0000 - mae: 724.8838 - val_loss: 1344989.3750 - val_mae: 606.1127 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1467251.8750 - mae: 648.7697 - val_loss: 1104456.7500 - val_mae: 527.4138 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1168890.5000 - mae: 556.4673 - val_loss: 840983.5625 - val_mae: 438.3757 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 874711.3750 - mae: 464.6517 - val_loss: 608925.1250 - val_mae: 367.7645 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 623299.6875 - mae: 382.5267 - val_loss: 425549.6875 - val_mae: 306.3335 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 429775.7500 - mae: 314.7259 - val_loss: 304550.0000 - val_mae: 260.8781 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 296323.2188 - mae: 265.0490 - val_loss: 221213.0625 - val_mae: 231.3937 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 212392.8594 - mae: 229.4289 - val_loss: 173441.8594 - val_mae: 204.3233 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 161965.0625 - mae: 202.9062 - val_loss: 148405.4688 - val_mae: 189.6812 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 137249.0156 - mae: 187.1012 - val_loss: 142776.7812 - val_mae: 179.2528 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 123005.2344 - mae: 176.2071 - val_loss: 135046.5156 - val_mae: 175.3213 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 115567.9688 - mae: 169.1108 - val_loss: 130494.5469 - val_mae: 167.2018 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110261.2266 - mae: 163.6821 - val_loss: 125414.8594 - val_mae: 162.9311 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107790.6484 - mae: 160.0600 - val_loss: 136070.1875 - val_mae: 170.3920 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106501.0469 - mae: 158.3341 - val_loss: 119630.3281 - val_mae: 161.2928 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105865.2031 - mae: 157.2771 - val_loss: 126027.3047 - val_mae: 162.8241 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104926.3594 - mae: 155.9807 - val_loss: 125791.9297 - val_mae: 161.6402 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105049.9766 - mae: 155.7840 - val_loss: 123732.7578 - val_mae: 166.8713 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104453.2188 - mae: 155.0203 - val_loss: 122517.5000 - val_mae: 160.8648 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103499.8125 - mae: 153.7961 - val_loss: 119103.6094 - val_mae: 158.8145 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103264.5312 - mae: 153.4181 - val_loss: 120693.2891 - val_mae: 159.3771 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103566.8281 - mae: 153.1814 - val_loss: 121774.1719 - val_mae: 158.9733 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102499.5859 - mae: 152.4235 - val_loss: 126904.6250 - val_mae: 162.9654 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102196.0859 - mae: 151.8172 - val_loss: 120919.4297 - val_mae: 161.1782 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102349.1406 - mae: 151.6636 - val_loss: 123150.8984 - val_mae: 162.0652 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101998.0625 - mae: 151.6083 - val_loss: 114487.6406 - val_mae: 156.3601 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101567.1953 - mae: 151.2669 - val_loss: 118645.5000 - val_mae: 155.2440 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101447.2031 - mae: 150.9647 - val_loss: 126712.0625 - val_mae: 165.4348 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101214.0547 - mae: 150.7282 - val_loss: 123940.6562 - val_mae: 163.0963 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100930.2812 - mae: 150.1231 - val_loss: 122293.7500 - val_mae: 160.4802 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100996.7891 - mae: 150.2882 - val_loss: 118876.7734 - val_mae: 155.2065 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100513.8750 - mae: 149.9400 - val_loss: 121780.4141 - val_mae: 157.9450 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100545.5469 - mae: 150.2682 - val_loss: 115617.4766 - val_mae: 152.6341 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100341.3203 - mae: 149.2200 - val_loss: 118993.1172 - val_mae: 155.3911 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100122.0469 - mae: 149.0484 - val_loss: 113772.0859 - val_mae: 151.8817 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100111.6016 - mae: 148.6786 - val_loss: 115398.1953 - val_mae: 153.3374 - lr: 0.0010\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100075.2031 - mae: 148.9683 - val_loss: 117261.7031 - val_mae: 155.2942 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99887.2266 - mae: 148.9094 - val_loss: 115901.6797 - val_mae: 154.8853 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99573.9609 - mae: 148.7343 - val_loss: 118228.9219 - val_mae: 155.4999 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99103.9297 - mae: 147.9269 - val_loss: 113662.9609 - val_mae: 154.0818 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99074.0781 - mae: 147.9976 - val_loss: 119863.5781 - val_mae: 157.9961 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99251.9141 - mae: 147.7753 - val_loss: 114129.3438 - val_mae: 152.4846 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99402.9141 - mae: 147.9928 - val_loss: 122369.3359 - val_mae: 164.4568 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98955.4453 - mae: 147.9776 - val_loss: 113513.7422 - val_mae: 150.8022 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98896.0703 - mae: 147.2072 - val_loss: 118398.4062 - val_mae: 154.4423 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98454.0469 - mae: 147.6271 - val_loss: 120980.7578 - val_mae: 155.9678 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98441.1953 - mae: 147.3701 - val_loss: 116629.3828 - val_mae: 156.9322 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98592.2500 - mae: 147.6660 - val_loss: 115700.8672 - val_mae: 150.2060 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98350.8750 - mae: 147.0312 - val_loss: 114410.0781 - val_mae: 151.9609 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98322.4375 - mae: 147.2975 - val_loss: 116474.7891 - val_mae: 150.6938 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 17:56:29,211]\u001b[0m Trial 21 finished with value: 116474.74379487293 and parameters: {'feature_dim': 47, 'output_dim': 9, 'num_decision_steps': 1}. Best is trial 16 with value: 112047.12673578341.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1670968.3750 - mae: 719.3814 - val_loss: 1308909.0000 - val_mae: 592.9608 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1405806.1250 - mae: 630.1029 - val_loss: 1035757.7500 - val_mae: 508.8503 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1074350.0000 - mae: 528.2520 - val_loss: 751859.1875 - val_mae: 413.8775 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 765976.8750 - mae: 431.4643 - val_loss: 520001.9688 - val_mae: 342.7463 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 521145.9375 - mae: 351.9312 - val_loss: 355008.4062 - val_mae: 285.7625 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 349167.4062 - mae: 290.1599 - val_loss: 252211.8281 - val_mae: 243.4076 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 239497.3594 - mae: 246.2916 - val_loss: 195487.2812 - val_mae: 232.8633 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 177125.0469 - mae: 216.9344 - val_loss: 166587.8281 - val_mae: 204.8391 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 143987.5938 - mae: 196.8808 - val_loss: 149299.9844 - val_mae: 196.9662 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 130005.0547 - mae: 186.5176 - val_loss: 139702.8594 - val_mae: 181.8967 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 120876.1250 - mae: 176.9928 - val_loss: 132786.2812 - val_mae: 179.6308 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 115803.3828 - mae: 170.6855 - val_loss: 132708.6250 - val_mae: 174.6680 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111823.7812 - mae: 166.3709 - val_loss: 124363.1250 - val_mae: 170.2446 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110169.0625 - mae: 163.7648 - val_loss: 131340.2969 - val_mae: 168.0141 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108388.5000 - mae: 161.4642 - val_loss: 122590.3594 - val_mae: 169.1273 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107946.4609 - mae: 161.1308 - val_loss: 128122.1328 - val_mae: 168.6453 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 107030.8984 - mae: 160.6557 - val_loss: 131470.7188 - val_mae: 169.2640 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106961.5469 - mae: 159.9413 - val_loss: 123064.0391 - val_mae: 165.4259 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106897.5000 - mae: 160.1139 - val_loss: 126516.3125 - val_mae: 163.9285 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105374.5547 - mae: 158.5372 - val_loss: 125101.1250 - val_mae: 165.5726 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 105696.6719 - mae: 158.7419 - val_loss: 124035.3750 - val_mae: 164.6440 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105723.8047 - mae: 158.9681 - val_loss: 123126.7500 - val_mae: 164.8674 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104584.5000 - mae: 157.7585 - val_loss: 131905.8281 - val_mae: 171.3450 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104365.3828 - mae: 157.4700 - val_loss: 119434.8828 - val_mae: 167.2903 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104525.5781 - mae: 157.3443 - val_loss: 122118.0938 - val_mae: 165.6487 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103684.9219 - mae: 156.6140 - val_loss: 118715.9844 - val_mae: 162.1171 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103405.7812 - mae: 155.9879 - val_loss: 120148.5234 - val_mae: 160.3956 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102988.3750 - mae: 155.4842 - val_loss: 124287.3750 - val_mae: 166.8039 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102966.3203 - mae: 155.6874 - val_loss: 130149.3047 - val_mae: 169.8528 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 102571.0078 - mae: 154.5840 - val_loss: 124655.5703 - val_mae: 166.0447 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102655.0781 - mae: 154.4506 - val_loss: 123747.4766 - val_mae: 164.4735 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102207.6719 - mae: 153.9737 - val_loss: 125558.7969 - val_mae: 165.7927 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102123.1094 - mae: 154.0321 - val_loss: 119848.0781 - val_mae: 160.5036 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101936.8281 - mae: 153.2775 - val_loss: 120965.9609 - val_mae: 162.9409 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101685.4922 - mae: 153.1926 - val_loss: 116024.3594 - val_mae: 157.6583 - lr: 0.0010\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101433.0391 - mae: 152.3298 - val_loss: 117025.9062 - val_mae: 159.2204 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101267.3281 - mae: 152.3675 - val_loss: 118991.8828 - val_mae: 158.7045 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101213.5391 - mae: 152.2667 - val_loss: 115372.0781 - val_mae: 157.2551 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100955.3984 - mae: 152.0790 - val_loss: 118113.9922 - val_mae: 159.6731 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100813.1016 - mae: 151.5969 - val_loss: 115750.1484 - val_mae: 156.8466 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100299.7812 - mae: 151.3380 - val_loss: 121513.3906 - val_mae: 161.1407 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100386.8203 - mae: 150.7031 - val_loss: 114377.4531 - val_mae: 154.8908 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100794.7578 - mae: 151.3276 - val_loss: 127277.3359 - val_mae: 169.7120 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100372.7188 - mae: 151.1311 - val_loss: 113768.0391 - val_mae: 155.4207 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100309.3672 - mae: 150.5097 - val_loss: 120394.7188 - val_mae: 159.6102 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100027.8984 - mae: 150.8405 - val_loss: 120712.1172 - val_mae: 159.4907 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99988.2109 - mae: 150.4968 - val_loss: 116882.7734 - val_mae: 159.2340 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99946.7656 - mae: 150.2070 - val_loss: 115652.2188 - val_mae: 155.0258 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99869.8047 - mae: 149.7800 - val_loss: 114158.8516 - val_mae: 154.6782 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99843.9922 - mae: 150.3250 - val_loss: 115158.9688 - val_mae: 155.1651 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 17:57:24,893]\u001b[0m Trial 22 finished with value: 115158.95991479528 and parameters: {'feature_dim': 41, 'output_dim': 7, 'num_decision_steps': 1}. Best is trial 16 with value: 112047.12673578341.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1703983.8750 - mae: 732.8405 - val_loss: 1363503.5000 - val_mae: 609.4086 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 1499702.6250 - mae: 658.6201 - val_loss: 1142073.8750 - val_mae: 537.0061 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 1221770.6250 - mae: 573.2405 - val_loss: 892730.1250 - val_mae: 456.7838 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 939039.5625 - mae: 485.1167 - val_loss: 664963.3125 - val_mae: 386.8167 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 689660.2500 - mae: 405.6464 - val_loss: 479768.5938 - val_mae: 322.9423 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 489686.4062 - mae: 338.6826 - val_loss: 344132.7188 - val_mae: 275.1284 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 343025.8750 - mae: 285.3483 - val_loss: 254431.9688 - val_mae: 242.0470 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 245970.8594 - mae: 245.9778 - val_loss: 201175.5156 - val_mae: 216.1830 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 184818.0938 - mae: 216.3703 - val_loss: 161092.5312 - val_mae: 200.3715 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 150225.4531 - mae: 196.2254 - val_loss: 152698.9062 - val_mae: 185.7050 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 131469.0781 - mae: 182.7889 - val_loss: 138434.4219 - val_mae: 175.0167 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 122637.7266 - mae: 175.2123 - val_loss: 141747.0000 - val_mae: 174.9091 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 116635.3359 - mae: 169.9177 - val_loss: 127342.0000 - val_mae: 165.7388 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 112985.6641 - mae: 165.4355 - val_loss: 140097.1875 - val_mae: 173.8048 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 110412.1250 - mae: 162.4011 - val_loss: 119852.3047 - val_mae: 160.6997 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 109087.1641 - mae: 160.8869 - val_loss: 125601.6875 - val_mae: 162.1207 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 945us/step - loss: 107684.5859 - mae: 159.0218 - val_loss: 124988.1797 - val_mae: 162.0937 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 107719.8906 - mae: 158.8056 - val_loss: 120476.2188 - val_mae: 158.8636 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 106531.7031 - mae: 157.5076 - val_loss: 122338.5000 - val_mae: 158.8165 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 105556.1094 - mae: 156.5158 - val_loss: 121161.6953 - val_mae: 159.6451 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 105067.2500 - mae: 155.8901 - val_loss: 121477.2500 - val_mae: 159.6819 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 105134.8281 - mae: 155.6671 - val_loss: 119939.0391 - val_mae: 157.9920 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 104193.1875 - mae: 154.9802 - val_loss: 128505.4375 - val_mae: 163.0336 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 103282.2891 - mae: 153.9620 - val_loss: 115870.0781 - val_mae: 155.8991 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 103516.4062 - mae: 153.6515 - val_loss: 117255.7109 - val_mae: 157.0853 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 102968.1484 - mae: 152.9074 - val_loss: 113028.0703 - val_mae: 156.1464 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 102608.8906 - mae: 152.6088 - val_loss: 115951.6484 - val_mae: 153.9824 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 102393.3750 - mae: 152.2727 - val_loss: 123733.3594 - val_mae: 162.9508 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 102111.6172 - mae: 152.0689 - val_loss: 123608.6406 - val_mae: 161.2602 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 101969.5703 - mae: 151.5723 - val_loss: 119689.4922 - val_mae: 156.6863 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 101930.7500 - mae: 151.3084 - val_loss: 121780.2266 - val_mae: 157.4696 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 101552.0469 - mae: 151.1325 - val_loss: 119171.5234 - val_mae: 155.4577 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 101346.9922 - mae: 151.2787 - val_loss: 116763.7656 - val_mae: 153.3396 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 101352.0234 - mae: 150.3399 - val_loss: 115882.2422 - val_mae: 154.0818 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 101185.6016 - mae: 150.0638 - val_loss: 112999.9297 - val_mae: 152.0654 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 100752.1641 - mae: 149.5011 - val_loss: 114860.1875 - val_mae: 154.5527 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 945us/step - loss: 100734.2344 - mae: 149.6710 - val_loss: 114749.4297 - val_mae: 151.8598 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 100759.8984 - mae: 149.7766 - val_loss: 114332.6641 - val_mae: 154.0071 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 100507.5625 - mae: 148.9697 - val_loss: 114104.6172 - val_mae: 153.0715 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 100304.6328 - mae: 148.9118 - val_loss: 112323.5859 - val_mae: 151.8150 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 99947.0078 - mae: 148.5268 - val_loss: 117227.2031 - val_mae: 154.6689 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 99991.3203 - mae: 148.3451 - val_loss: 110578.5859 - val_mae: 149.5489 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 945us/step - loss: 100340.4922 - mae: 148.2973 - val_loss: 119453.7891 - val_mae: 160.8331 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 99827.9609 - mae: 148.3569 - val_loss: 109939.7266 - val_mae: 150.4803 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 99616.3672 - mae: 147.5464 - val_loss: 116537.7344 - val_mae: 151.7336 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 99698.3281 - mae: 148.2076 - val_loss: 116253.7031 - val_mae: 152.5386 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 99637.3594 - mae: 148.1679 - val_loss: 111387.2031 - val_mae: 150.3697 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 99738.6484 - mae: 148.0374 - val_loss: 113563.1094 - val_mae: 149.2946 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 99598.3594 - mae: 147.3679 - val_loss: 112010.9531 - val_mae: 151.0826 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 99577.6094 - mae: 147.8192 - val_loss: 111655.8594 - val_mae: 150.1151 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 17:58:17,871]\u001b[0m Trial 23 finished with value: 111655.84303198793 and parameters: {'feature_dim': 36, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 23 with value: 111655.84303198793.\u001b[0m\n",
      "[TabNet]: 24 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1678492.5000 - mae: 739.6476 - val_loss: 1320332.6250 - val_mae: 665.0688 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1444358.7500 - mae: 764.8474 - val_loss: 1114280.7500 - val_mae: 720.3751 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1257929.7500 - mae: 817.0866 - val_loss: 1027352.0625 - val_mae: 779.9781 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1189558.3750 - mae: 845.6755 - val_loss: 981519.7500 - val_mae: 787.9730 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1164674.1250 - mae: 853.5621 - val_loss: 955983.6250 - val_mae: 776.1478 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1155422.6250 - mae: 854.2723 - val_loss: 984796.2500 - val_mae: 824.1542 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1149176.6250 - mae: 851.5644 - val_loss: 954464.8125 - val_mae: 793.6708 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1144333.5000 - mae: 849.3845 - val_loss: 946276.5625 - val_mae: 783.6907 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1139132.7500 - mae: 846.2863 - val_loss: 967350.8125 - val_mae: 809.9984 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1138555.3750 - mae: 846.1396 - val_loss: 945669.6875 - val_mae: 783.3612 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1136643.7500 - mae: 847.4388 - val_loss: 932954.8750 - val_mae: 732.0508 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1135045.8750 - mae: 846.0391 - val_loss: 927465.8125 - val_mae: 750.4952 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1137032.6250 - mae: 846.6955 - val_loss: 966153.3750 - val_mae: 811.4509 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1136948.0000 - mae: 849.4651 - val_loss: 938211.3750 - val_mae: 763.7225 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1135496.7500 - mae: 847.6008 - val_loss: 940677.0000 - val_mae: 775.9254 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1137980.0000 - mae: 849.8038 - val_loss: 932570.3750 - val_mae: 747.0140 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1138799.2500 - mae: 850.2513 - val_loss: 932838.9375 - val_mae: 735.4846 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1136814.2500 - mae: 845.1914 - val_loss: 942577.3125 - val_mae: 774.3326 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1133980.3750 - mae: 847.7521 - val_loss: 935009.6875 - val_mae: 751.1075 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1134641.3750 - mae: 847.4795 - val_loss: 965832.3125 - val_mae: 807.8615 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1139385.7500 - mae: 851.2240 - val_loss: 943770.1875 - val_mae: 778.4534 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1135108.7500 - mae: 849.4733 - val_loss: 941723.9375 - val_mae: 773.1592 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1121231.3750 - mae: 849.4167 - val_loss: 964994.1250 - val_mae: 803.8726 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1111518.1250 - mae: 834.4158 - val_loss: 920754.5625 - val_mae: 733.5932 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1108752.5000 - mae: 826.5023 - val_loss: 916742.0000 - val_mae: 728.2433 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1107061.3750 - mae: 826.6115 - val_loss: 928962.3125 - val_mae: 746.3043 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1108093.8750 - mae: 827.0696 - val_loss: 919923.6250 - val_mae: 729.7548 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1107108.3750 - mae: 824.5726 - val_loss: 923876.1250 - val_mae: 740.9902 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1107576.2500 - mae: 828.0265 - val_loss: 926344.6875 - val_mae: 740.5538 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1108365.1250 - mae: 826.7437 - val_loss: 935293.6875 - val_mae: 758.6735 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1108047.5000 - mae: 826.9568 - val_loss: 941314.7500 - val_mae: 769.7875 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1105444.8750 - mae: 825.0280 - val_loss: 935967.1875 - val_mae: 755.6746 - lr: 1.0000e-04\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1107078.3750 - mae: 826.0688 - val_loss: 927731.3125 - val_mae: 743.5640 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1106308.5000 - mae: 825.8970 - val_loss: 927623.6875 - val_mae: 738.1479 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1107739.5000 - mae: 826.3130 - val_loss: 947726.3125 - val_mae: 779.9624 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1102757.1250 - mae: 826.8908 - val_loss: 929386.8750 - val_mae: 747.1895 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1102043.0000 - mae: 824.6899 - val_loss: 930581.3125 - val_mae: 747.1289 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1101833.6250 - mae: 823.5510 - val_loss: 923796.5625 - val_mae: 730.9249 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1101624.2500 - mae: 822.9908 - val_loss: 927404.6875 - val_mae: 737.2271 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1101608.0000 - mae: 821.9418 - val_loss: 933531.9375 - val_mae: 751.4191 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1101433.3750 - mae: 822.6060 - val_loss: 925095.3125 - val_mae: 730.8900 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1101581.0000 - mae: 822.2345 - val_loss: 926002.7500 - val_mae: 733.2332 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1101391.1250 - mae: 822.0947 - val_loss: 924842.8750 - val_mae: 730.3239 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1101568.7500 - mae: 821.8144 - val_loss: 932510.5000 - val_mae: 747.2294 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1101471.2500 - mae: 821.8564 - val_loss: 931609.1875 - val_mae: 745.8622 - lr: 1.0000e-05\n",
      "\u001b[32m[I 2022-07-28 17:59:35,544]\u001b[0m Trial 24 finished with value: 931608.9774443209 and parameters: {'feature_dim': 35, 'output_dim': 11, 'num_decision_steps': 2}. Best is trial 23 with value: 111655.84303198793.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1648958.2500 - mae: 716.4181 - val_loss: 1251928.8750 - val_mae: 576.6741 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 1289884.8750 - mae: 595.5718 - val_loss: 895870.1250 - val_mae: 459.8493 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 884172.4375 - mae: 469.3955 - val_loss: 578996.8125 - val_mae: 360.6491 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 559934.4375 - mae: 364.4542 - val_loss: 363553.0000 - val_mae: 288.3729 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 345432.5938 - mae: 287.6333 - val_loss: 243553.2344 - val_mae: 242.0635 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 222503.4688 - mae: 236.2293 - val_loss: 182095.2500 - val_mae: 209.7654 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 161087.2344 - mae: 203.7077 - val_loss: 165155.4062 - val_mae: 207.2020 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 133842.0938 - mae: 185.4796 - val_loss: 144496.0000 - val_mae: 187.7171 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 120337.9844 - mae: 174.6386 - val_loss: 132838.3750 - val_mae: 178.2394 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 114351.3828 - mae: 167.9563 - val_loss: 136828.9375 - val_mae: 176.6238 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 110400.0469 - mae: 163.1739 - val_loss: 132045.1719 - val_mae: 175.6429 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 109256.8203 - mae: 161.1831 - val_loss: 130358.9297 - val_mae: 165.4653 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 106960.6172 - mae: 158.6095 - val_loss: 124434.3125 - val_mae: 170.3770 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 106122.5703 - mae: 156.8257 - val_loss: 136273.4844 - val_mae: 169.6566 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 105036.6328 - mae: 155.5590 - val_loss: 118931.5625 - val_mae: 159.8502 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 104615.7734 - mae: 155.5069 - val_loss: 125282.5938 - val_mae: 160.3204 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 103832.6719 - mae: 154.0005 - val_loss: 122897.0078 - val_mae: 159.8120 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 103516.1328 - mae: 153.9801 - val_loss: 118306.0703 - val_mae: 158.3603 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 103817.6719 - mae: 153.7069 - val_loss: 117349.9531 - val_mae: 154.4426 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 102573.2500 - mae: 152.3906 - val_loss: 120997.5156 - val_mae: 160.1315 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 102555.1328 - mae: 152.4759 - val_loss: 116074.7500 - val_mae: 157.5178 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 102722.5078 - mae: 152.4835 - val_loss: 116188.3125 - val_mae: 154.1058 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 101523.3594 - mae: 151.2836 - val_loss: 123969.3047 - val_mae: 161.4471 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 101177.1719 - mae: 150.5230 - val_loss: 115442.2031 - val_mae: 157.3439 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 101823.1953 - mae: 151.0491 - val_loss: 113855.3516 - val_mae: 153.7393 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 101043.4062 - mae: 150.2449 - val_loss: 111342.6172 - val_mae: 152.3920 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 101049.9453 - mae: 150.3034 - val_loss: 113766.6797 - val_mae: 151.0216 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 100685.0703 - mae: 149.6450 - val_loss: 117883.6016 - val_mae: 158.8438 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 100726.4375 - mae: 149.8018 - val_loss: 120743.0391 - val_mae: 161.3561 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 100307.1797 - mae: 149.1179 - val_loss: 119185.7891 - val_mae: 160.4441 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 100674.0703 - mae: 149.2233 - val_loss: 115949.5156 - val_mae: 152.7990 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 100482.3359 - mae: 149.3418 - val_loss: 117806.5391 - val_mae: 157.4935 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 100068.1172 - mae: 149.1703 - val_loss: 114963.7969 - val_mae: 153.3303 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 100228.7422 - mae: 148.5072 - val_loss: 113425.2500 - val_mae: 153.2998 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 99995.1797 - mae: 148.5588 - val_loss: 110499.3828 - val_mae: 150.7604 - lr: 0.0010\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 971us/step - loss: 99574.0156 - mae: 148.1359 - val_loss: 112689.0469 - val_mae: 154.1034 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 99833.5547 - mae: 148.4279 - val_loss: 115194.0625 - val_mae: 155.8364 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 99941.9609 - mae: 148.7403 - val_loss: 111928.6250 - val_mae: 154.0350 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 99588.5469 - mae: 148.2821 - val_loss: 112591.4688 - val_mae: 151.0292 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 99183.6562 - mae: 147.6817 - val_loss: 112317.2031 - val_mae: 152.8147 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 98895.7188 - mae: 147.4483 - val_loss: 116424.1953 - val_mae: 156.1017 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 99203.8281 - mae: 147.2578 - val_loss: 110607.5391 - val_mae: 151.0561 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 99119.7969 - mae: 147.5062 - val_loss: 122852.3203 - val_mae: 167.2613 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 99177.7812 - mae: 147.6931 - val_loss: 109429.9141 - val_mae: 150.5001 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 98889.0469 - mae: 147.1127 - val_loss: 116210.4531 - val_mae: 153.3329 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 98718.0938 - mae: 147.3779 - val_loss: 116296.6016 - val_mae: 154.5558 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 98658.9609 - mae: 146.8181 - val_loss: 112362.4922 - val_mae: 153.3645 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 98800.2344 - mae: 147.1784 - val_loss: 113016.1016 - val_mae: 149.9571 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 98531.5547 - mae: 146.7064 - val_loss: 111801.5469 - val_mae: 151.0307 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 98700.8594 - mae: 147.2099 - val_loss: 110640.7891 - val_mae: 149.2987 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:00:29,192]\u001b[0m Trial 25 finished with value: 110640.79483212534 and parameters: {'feature_dim': 39, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1659351.6250 - mae: 718.3839 - val_loss: 1286111.1250 - val_mae: 586.8401 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 1358172.7500 - mae: 616.1499 - val_loss: 976771.5625 - val_mae: 490.2133 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 990422.7500 - mae: 502.3347 - val_loss: 672361.3750 - val_mae: 388.3078 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 669157.1250 - mae: 399.5901 - val_loss: 443683.4062 - val_mae: 314.0914 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 433288.3750 - mae: 319.6738 - val_loss: 294647.0000 - val_mae: 260.6767 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 279879.9688 - mae: 259.8972 - val_loss: 212442.7188 - val_mae: 221.3614 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 192663.0781 - mae: 220.0163 - val_loss: 164013.9844 - val_mae: 199.5786 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 149026.1094 - mae: 195.1556 - val_loss: 141516.4219 - val_mae: 180.6119 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 128696.3750 - mae: 180.4780 - val_loss: 132468.0156 - val_mae: 179.0797 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 119832.4453 - mae: 172.4824 - val_loss: 135172.3750 - val_mae: 170.4608 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 114558.3281 - mae: 166.2258 - val_loss: 130334.3281 - val_mae: 171.9837 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 112581.1016 - mae: 163.4258 - val_loss: 131084.0781 - val_mae: 167.7718 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 109797.6641 - mae: 160.4978 - val_loss: 125461.7500 - val_mae: 168.8284 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 108282.9844 - mae: 158.4079 - val_loss: 132503.7656 - val_mae: 166.2264 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 106494.1016 - mae: 156.3363 - val_loss: 120900.2109 - val_mae: 165.7710 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 106241.0000 - mae: 156.1419 - val_loss: 123673.7031 - val_mae: 160.2973 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 104808.3672 - mae: 153.8770 - val_loss: 123006.8750 - val_mae: 162.9047 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 104521.2500 - mae: 154.0793 - val_loss: 119906.0469 - val_mae: 161.6409 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 104120.4688 - mae: 153.3698 - val_loss: 117493.1875 - val_mae: 157.4284 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 103183.1406 - mae: 152.4394 - val_loss: 121628.5234 - val_mae: 160.4301 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 102813.8359 - mae: 152.1697 - val_loss: 119284.3594 - val_mae: 159.9538 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 103241.9219 - mae: 152.1788 - val_loss: 119191.6797 - val_mae: 160.5202 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 101852.8516 - mae: 150.8802 - val_loss: 121693.8047 - val_mae: 159.9662 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 101767.4453 - mae: 150.7100 - val_loss: 118134.6406 - val_mae: 161.0246 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 101841.4141 - mae: 150.5584 - val_loss: 117662.9766 - val_mae: 159.2324 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 101119.2344 - mae: 149.9051 - val_loss: 113536.9453 - val_mae: 157.7937 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 100960.8281 - mae: 149.5212 - val_loss: 116007.1016 - val_mae: 152.7081 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 100750.0547 - mae: 149.1984 - val_loss: 121004.1016 - val_mae: 162.0638 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 100646.9453 - mae: 149.3612 - val_loss: 122084.4219 - val_mae: 162.0110 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 100142.6641 - mae: 148.4300 - val_loss: 122190.2656 - val_mae: 161.3193 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 100183.6562 - mae: 148.4704 - val_loss: 117313.2578 - val_mae: 155.8457 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 99978.3594 - mae: 148.4238 - val_loss: 118113.1406 - val_mae: 155.0478 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 99732.5625 - mae: 148.6355 - val_loss: 116015.4531 - val_mae: 152.4111 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 99549.6953 - mae: 147.4764 - val_loss: 115404.5000 - val_mae: 153.6844 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 99567.2578 - mae: 147.9147 - val_loss: 112323.6016 - val_mae: 152.3150 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 99100.3438 - mae: 147.0929 - val_loss: 117071.6641 - val_mae: 156.0922 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 99402.1719 - mae: 147.3105 - val_loss: 118309.3594 - val_mae: 156.1876 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 99359.3438 - mae: 147.7322 - val_loss: 114726.5859 - val_mae: 153.5368 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 99073.3516 - mae: 147.4022 - val_loss: 113705.3672 - val_mae: 153.4079 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 98619.5000 - mae: 146.8556 - val_loss: 113752.4062 - val_mae: 152.9259 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 98303.1641 - mae: 146.4024 - val_loss: 114684.6797 - val_mae: 155.5200 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 98306.9609 - mae: 146.4364 - val_loss: 114346.9062 - val_mae: 153.0856 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 98750.6016 - mae: 146.8018 - val_loss: 123486.3594 - val_mae: 164.6101 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 98083.6641 - mae: 146.4871 - val_loss: 114270.4141 - val_mae: 152.3191 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 98079.5938 - mae: 146.0940 - val_loss: 118329.0234 - val_mae: 154.4324 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 95286.5547 - mae: 142.5093 - val_loss: 114328.1953 - val_mae: 151.8901 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 94933.3516 - mae: 142.1239 - val_loss: 114482.8594 - val_mae: 152.3367 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 94869.5469 - mae: 142.1156 - val_loss: 115212.8125 - val_mae: 153.0281 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 94743.8672 - mae: 141.9023 - val_loss: 114033.5078 - val_mae: 151.2223 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 94706.8750 - mae: 141.7850 - val_loss: 114614.4297 - val_mae: 151.6191 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:01:22,439]\u001b[0m Trial 26 finished with value: 114614.47654830497 and parameters: {'feature_dim': 42, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "[TabNet]: 26 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1682960.8750 - mae: 715.4188 - val_loss: 1296142.0000 - val_mae: 602.0800 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1360552.2500 - mae: 631.5460 - val_loss: 987267.8125 - val_mae: 529.0536 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1006123.0000 - mae: 543.0040 - val_loss: 742903.0000 - val_mae: 477.0989 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 760920.9375 - mae: 486.1937 - val_loss: 630432.6250 - val_mae: 468.7918 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 628408.5625 - mae: 456.6531 - val_loss: 627203.6250 - val_mae: 483.7086 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 576096.1250 - mae: 447.0955 - val_loss: 572829.5000 - val_mae: 461.7742 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 540305.3750 - mae: 435.8759 - val_loss: 586398.4375 - val_mae: 469.0000 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 515568.3750 - mae: 426.9232 - val_loss: 531113.6250 - val_mae: 431.0448 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 512885.3125 - mae: 426.9644 - val_loss: 542950.8125 - val_mae: 452.4318 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 501320.2812 - mae: 422.2319 - val_loss: 567730.8125 - val_mae: 466.7519 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 495936.8125 - mae: 420.3454 - val_loss: 589554.4375 - val_mae: 472.9401 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 492232.1562 - mae: 419.0413 - val_loss: 547498.7500 - val_mae: 453.4570 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 491105.8750 - mae: 418.1108 - val_loss: 535368.1250 - val_mae: 448.4599 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 488199.9688 - mae: 416.9186 - val_loss: 547647.0000 - val_mae: 456.3567 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 483316.7188 - mae: 414.9034 - val_loss: 587412.8750 - val_mae: 474.9134 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 482796.0312 - mae: 414.9137 - val_loss: 526377.1250 - val_mae: 433.4388 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 483170.3438 - mae: 415.0357 - val_loss: 565077.5000 - val_mae: 462.2486 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 481455.5938 - mae: 414.4764 - val_loss: 563570.3750 - val_mae: 463.5464 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 477815.9375 - mae: 413.0390 - val_loss: 595146.2500 - val_mae: 480.1278 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 479772.3125 - mae: 413.3336 - val_loss: 534287.5625 - val_mae: 445.3849 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 479579.0000 - mae: 413.9440 - val_loss: 593437.4375 - val_mae: 477.2125 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 477170.2500 - mae: 412.8129 - val_loss: 567299.9375 - val_mae: 465.3896 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 475078.5938 - mae: 411.6421 - val_loss: 525183.1875 - val_mae: 436.7582 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 475677.6250 - mae: 411.8556 - val_loss: 571915.6875 - val_mae: 468.9553 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 476268.3438 - mae: 412.5132 - val_loss: 547832.0625 - val_mae: 453.1827 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 474274.0312 - mae: 411.4129 - val_loss: 564672.1875 - val_mae: 464.8507 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 473521.8125 - mae: 411.3234 - val_loss: 544902.2500 - val_mae: 452.2699 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 474095.5938 - mae: 411.7896 - val_loss: 528632.2500 - val_mae: 436.7477 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 473796.7500 - mae: 411.4702 - val_loss: 558982.0625 - val_mae: 466.5341 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 473333.3750 - mae: 412.0673 - val_loss: 547603.5625 - val_mae: 456.6824 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 473273.9062 - mae: 411.4951 - val_loss: 545361.1250 - val_mae: 458.0929 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 472860.0625 - mae: 411.8910 - val_loss: 555461.2500 - val_mae: 457.5059 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 473219.6875 - mae: 411.5141 - val_loss: 570771.0000 - val_mae: 473.0822 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 469913.6250 - mae: 411.6967 - val_loss: 546316.1250 - val_mae: 455.5229 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 469265.4688 - mae: 410.2086 - val_loss: 547914.4375 - val_mae: 455.9696 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 469314.9062 - mae: 409.6774 - val_loss: 553918.0625 - val_mae: 460.2627 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 469152.0625 - mae: 409.5510 - val_loss: 547666.4375 - val_mae: 456.8165 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 469146.7812 - mae: 409.8708 - val_loss: 554297.0000 - val_mae: 460.0438 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 469181.9688 - mae: 409.5981 - val_loss: 559130.8750 - val_mae: 463.1083 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 468971.8438 - mae: 409.4841 - val_loss: 560088.0625 - val_mae: 463.5211 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 469021.9375 - mae: 409.5997 - val_loss: 550761.1250 - val_mae: 457.9628 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 468885.0312 - mae: 409.5440 - val_loss: 556093.1875 - val_mae: 461.1771 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 469104.6250 - mae: 409.5315 - val_loss: 555314.8750 - val_mae: 460.7325 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:02:35,666]\u001b[0m Trial 27 finished with value: 555314.6206860025 and parameters: {'feature_dim': 36, 'output_dim': 10, 'num_decision_steps': 2}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1676974.1250 - mae: 723.2311 - val_loss: 1306860.7500 - val_mae: 594.8164 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 1384180.3750 - mae: 623.9563 - val_loss: 999778.3750 - val_mae: 494.5159 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 1016969.3125 - mae: 510.5021 - val_loss: 693443.1875 - val_mae: 394.8602 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 692141.0625 - mae: 407.0984 - val_loss: 458971.0625 - val_mae: 318.0328 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 451638.3750 - mae: 326.7697 - val_loss: 305710.4375 - val_mae: 262.7318 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 293077.7188 - mae: 266.1274 - val_loss: 221712.2344 - val_mae: 229.5935 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 200551.5000 - mae: 224.9746 - val_loss: 167220.9531 - val_mae: 207.7250 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 153435.3125 - mae: 198.7437 - val_loss: 143367.6094 - val_mae: 185.6602 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 130000.9531 - mae: 182.5235 - val_loss: 130074.3984 - val_mae: 176.4752 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 118872.5703 - mae: 171.9181 - val_loss: 135255.7344 - val_mae: 174.2341 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 112432.9453 - mae: 165.6613 - val_loss: 132798.8125 - val_mae: 173.3709 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 110209.5469 - mae: 162.7437 - val_loss: 127962.5625 - val_mae: 165.9785 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 107615.3906 - mae: 159.4798 - val_loss: 122626.9531 - val_mae: 166.2952 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 106766.7578 - mae: 157.9652 - val_loss: 135274.5000 - val_mae: 172.8659 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 105595.4531 - mae: 156.5049 - val_loss: 117420.0859 - val_mae: 160.7465 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 105217.4766 - mae: 156.4057 - val_loss: 124404.6094 - val_mae: 161.9296 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 104371.4375 - mae: 154.9254 - val_loss: 121119.8203 - val_mae: 159.5891 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 104801.8359 - mae: 155.4950 - val_loss: 121852.5938 - val_mae: 163.6555 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 104552.7344 - mae: 155.2181 - val_loss: 120885.0391 - val_mae: 160.5567 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 103357.8125 - mae: 153.9617 - val_loss: 119727.7891 - val_mae: 158.3887 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 103243.3828 - mae: 153.5407 - val_loss: 118186.5547 - val_mae: 158.7954 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 103449.7266 - mae: 153.5477 - val_loss: 118725.5625 - val_mae: 159.0025 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 102433.1719 - mae: 152.6131 - val_loss: 123149.6172 - val_mae: 162.5072 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 101801.3359 - mae: 151.8430 - val_loss: 117870.0781 - val_mae: 162.0421 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 945us/step - loss: 101999.4297 - mae: 151.4788 - val_loss: 118163.6797 - val_mae: 162.6677 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 98502.3828 - mae: 147.3729 - val_loss: 115727.1484 - val_mae: 156.4910 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 98263.8047 - mae: 146.8782 - val_loss: 115722.2578 - val_mae: 156.7608 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 98236.4922 - mae: 146.5943 - val_loss: 116372.0234 - val_mae: 157.3802 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 98200.8047 - mae: 146.6292 - val_loss: 115473.5781 - val_mae: 156.9775 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 98012.2812 - mae: 146.5737 - val_loss: 116644.0078 - val_mae: 157.5590 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 98005.6250 - mae: 146.3154 - val_loss: 117676.2109 - val_mae: 158.2186 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 97982.7578 - mae: 146.3350 - val_loss: 118302.3594 - val_mae: 158.5613 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 97953.1250 - mae: 146.3308 - val_loss: 116100.0547 - val_mae: 155.9662 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 97872.2109 - mae: 146.1128 - val_loss: 116491.0391 - val_mae: 156.7141 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 97811.9141 - mae: 146.2006 - val_loss: 116041.9844 - val_mae: 156.7141 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 97786.0234 - mae: 146.0777 - val_loss: 116032.2500 - val_mae: 156.9823 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 97713.0859 - mae: 146.1567 - val_loss: 114581.2109 - val_mae: 156.0340 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 97690.9375 - mae: 146.1837 - val_loss: 115121.8984 - val_mae: 156.2873 - lr: 1.0000e-04\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 974us/step - loss: 97665.9531 - mae: 146.0718 - val_loss: 115835.3516 - val_mae: 156.4466 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 97527.1250 - mae: 146.0494 - val_loss: 114924.7266 - val_mae: 155.4901 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 97522.3125 - mae: 145.8505 - val_loss: 117129.8594 - val_mae: 157.3612 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 97524.1797 - mae: 145.6307 - val_loss: 115103.6328 - val_mae: 156.4313 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 97531.6797 - mae: 145.9332 - val_loss: 115010.4219 - val_mae: 155.9550 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 97415.7656 - mae: 145.8818 - val_loss: 114264.2422 - val_mae: 154.7461 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 97408.3047 - mae: 145.6998 - val_loss: 115149.9375 - val_mae: 156.2042 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 97434.7500 - mae: 146.0152 - val_loss: 115812.1562 - val_mae: 156.2091 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 97410.9453 - mae: 145.6221 - val_loss: 115076.7578 - val_mae: 156.4375 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 97427.8125 - mae: 145.9007 - val_loss: 116886.4922 - val_mae: 157.7869 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 97269.6875 - mae: 145.7097 - val_loss: 115343.3359 - val_mae: 156.3289 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 97339.0547 - mae: 145.7615 - val_loss: 114317.9297 - val_mae: 155.8027 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:03:28,911]\u001b[0m Trial 28 finished with value: 114317.95166450397 and parameters: {'feature_dim': 40, 'output_dim': 12, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1654351.6250 - mae: 717.8456 - val_loss: 1276723.3750 - val_mae: 584.5635 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 1344777.0000 - mae: 613.1868 - val_loss: 963840.9375 - val_mae: 486.6588 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 974959.5000 - mae: 498.6579 - val_loss: 659645.0000 - val_mae: 387.3839 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 654683.4375 - mae: 395.8319 - val_loss: 433249.4375 - val_mae: 314.8675 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 422345.6875 - mae: 317.3740 - val_loss: 286205.4375 - val_mae: 258.1646 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 272667.5625 - mae: 259.2663 - val_loss: 209333.2344 - val_mae: 226.3823 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 189035.9062 - mae: 222.5677 - val_loss: 161125.9375 - val_mae: 210.3737 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 147568.0156 - mae: 198.2211 - val_loss: 141377.6094 - val_mae: 184.2327 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 127880.7109 - mae: 183.1230 - val_loss: 133718.9531 - val_mae: 186.4113 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 120126.3125 - mae: 175.7261 - val_loss: 135204.5156 - val_mae: 173.4594 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 115141.6094 - mae: 170.2477 - val_loss: 130046.5312 - val_mae: 176.7910 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 113415.5547 - mae: 168.2028 - val_loss: 132896.2500 - val_mae: 174.2264 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 111267.2109 - mae: 165.4863 - val_loss: 127323.9375 - val_mae: 172.5012 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 110207.9375 - mae: 162.7424 - val_loss: 138621.2031 - val_mae: 175.0222 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 108963.0156 - mae: 160.4538 - val_loss: 126081.8984 - val_mae: 170.8330 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 108308.0938 - mae: 159.3027 - val_loss: 130362.6797 - val_mae: 166.2565 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 106736.8125 - mae: 156.8490 - val_loss: 130014.2500 - val_mae: 168.6862 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 106423.6406 - mae: 156.8209 - val_loss: 126465.5078 - val_mae: 166.3241 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 105607.4844 - mae: 155.8676 - val_loss: 121074.7734 - val_mae: 157.9826 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 104127.2812 - mae: 154.3567 - val_loss: 122354.5469 - val_mae: 160.2325 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 103889.6875 - mae: 154.1007 - val_loss: 122306.2422 - val_mae: 160.2295 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 104392.6797 - mae: 154.4523 - val_loss: 121526.6641 - val_mae: 159.6510 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 103123.8516 - mae: 153.3118 - val_loss: 129857.2891 - val_mae: 164.5813 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 102754.5156 - mae: 152.6739 - val_loss: 118935.7578 - val_mae: 160.5568 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 103278.0703 - mae: 152.8161 - val_loss: 121992.0078 - val_mae: 160.3761 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 102583.2266 - mae: 152.1249 - val_loss: 115831.8359 - val_mae: 156.2948 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 102286.6641 - mae: 151.8320 - val_loss: 117566.6094 - val_mae: 155.6472 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 102237.3047 - mae: 151.8064 - val_loss: 126842.6250 - val_mae: 165.8932 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 101958.1875 - mae: 151.6424 - val_loss: 129755.0078 - val_mae: 168.2369 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 101681.4297 - mae: 151.0687 - val_loss: 124882.3672 - val_mae: 162.9774 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 101994.5469 - mae: 151.2435 - val_loss: 123865.0625 - val_mae: 159.4861 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 101291.7500 - mae: 150.7734 - val_loss: 124869.0078 - val_mae: 160.3311 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 101371.8438 - mae: 151.2866 - val_loss: 119751.5469 - val_mae: 157.2973 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 101184.1250 - mae: 150.4912 - val_loss: 118909.2266 - val_mae: 157.0525 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 100975.3984 - mae: 150.0679 - val_loss: 114697.1016 - val_mae: 154.2913 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 100729.6641 - mae: 149.6019 - val_loss: 119769.3828 - val_mae: 158.6661 - lr: 0.0010\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 972us/step - loss: 100625.9922 - mae: 149.8036 - val_loss: 118969.6094 - val_mae: 157.3592 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 100656.5938 - mae: 149.9923 - val_loss: 117577.0547 - val_mae: 158.0624 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 100277.3438 - mae: 149.5281 - val_loss: 117535.9375 - val_mae: 155.5242 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 99924.9141 - mae: 148.9171 - val_loss: 114073.2812 - val_mae: 154.6970 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 99656.9375 - mae: 148.7751 - val_loss: 118843.6484 - val_mae: 156.2168 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 99804.6797 - mae: 148.6442 - val_loss: 115379.0000 - val_mae: 154.7991 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 100118.6016 - mae: 149.3373 - val_loss: 129190.7891 - val_mae: 171.5025 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 99694.5547 - mae: 148.9160 - val_loss: 113164.3281 - val_mae: 153.4910 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 99559.5938 - mae: 148.3318 - val_loss: 121558.8359 - val_mae: 157.7534 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 99301.9766 - mae: 148.7103 - val_loss: 121118.3594 - val_mae: 158.8700 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 99219.6016 - mae: 148.4178 - val_loss: 115392.7891 - val_mae: 156.2939 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 99340.2734 - mae: 148.7062 - val_loss: 115755.2344 - val_mae: 152.8205 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 98900.8672 - mae: 147.8075 - val_loss: 113748.8750 - val_mae: 152.9337 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 98925.2344 - mae: 147.9907 - val_loss: 115216.1484 - val_mae: 153.0953 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:04:22,281]\u001b[0m Trial 29 finished with value: 115216.161497212 and parameters: {'feature_dim': 44, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1685811.2500 - mae: 724.5549 - val_loss: 1336104.8750 - val_mae: 602.6838 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1454340.0000 - mae: 644.8685 - val_loss: 1091135.2500 - val_mae: 520.7155 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1152518.3750 - mae: 553.3173 - val_loss: 826847.4375 - val_mae: 441.8315 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 856978.4375 - mae: 462.0883 - val_loss: 595403.2500 - val_mae: 371.4028 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 608486.2500 - mae: 382.9276 - val_loss: 417457.4688 - val_mae: 308.5242 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 416099.9375 - mae: 315.4685 - val_loss: 288257.9688 - val_mae: 259.6458 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 274607.8438 - mae: 261.3751 - val_loss: 215928.2656 - val_mae: 234.0813 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 194701.4844 - mae: 225.5863 - val_loss: 171790.5938 - val_mae: 207.6093 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 153104.8594 - mae: 202.1420 - val_loss: 153453.6719 - val_mae: 203.6570 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 134633.2500 - mae: 189.5445 - val_loss: 148648.2344 - val_mae: 189.7797 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 124584.5547 - mae: 181.4877 - val_loss: 142467.8281 - val_mae: 189.4106 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 120449.7578 - mae: 176.6030 - val_loss: 145984.9844 - val_mae: 186.0373 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 116586.1406 - mae: 172.4685 - val_loss: 134584.5625 - val_mae: 184.4056 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 115022.1250 - mae: 170.5253 - val_loss: 141784.7031 - val_mae: 182.3557 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 113628.9297 - mae: 168.6202 - val_loss: 132678.3594 - val_mae: 181.7638 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 113203.1484 - mae: 167.4883 - val_loss: 136665.0781 - val_mae: 177.0640 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111589.9453 - mae: 165.2889 - val_loss: 136122.2500 - val_mae: 176.2110 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110677.5469 - mae: 163.8104 - val_loss: 125486.5781 - val_mae: 164.5753 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108600.9531 - mae: 161.2610 - val_loss: 126236.0000 - val_mae: 164.0463 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106421.2500 - mae: 158.7305 - val_loss: 124094.0078 - val_mae: 163.2952 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106100.1406 - mae: 158.2201 - val_loss: 118212.7812 - val_mae: 159.1661 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106057.8281 - mae: 157.4318 - val_loss: 118678.3984 - val_mae: 158.5069 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104700.6953 - mae: 156.2990 - val_loss: 128916.8906 - val_mae: 164.4394 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103608.5547 - mae: 154.7608 - val_loss: 115326.1484 - val_mae: 161.3068 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103797.4844 - mae: 154.3777 - val_loss: 118378.1016 - val_mae: 157.9891 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102946.1875 - mae: 153.5538 - val_loss: 113285.8750 - val_mae: 157.4292 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102582.2891 - mae: 153.0110 - val_loss: 115708.0703 - val_mae: 153.9684 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102512.4609 - mae: 152.6643 - val_loss: 127713.2891 - val_mae: 167.8969 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102309.8438 - mae: 152.8030 - val_loss: 127173.4062 - val_mae: 166.0086 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101867.4531 - mae: 151.8908 - val_loss: 124608.4141 - val_mae: 163.7769 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102032.4375 - mae: 151.8793 - val_loss: 119447.5156 - val_mae: 156.4035 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101680.5078 - mae: 151.7029 - val_loss: 121202.6328 - val_mae: 158.0836 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101367.8594 - mae: 151.4148 - val_loss: 116783.5000 - val_mae: 155.8539 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100899.5781 - mae: 150.5097 - val_loss: 117713.5859 - val_mae: 156.5596 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101090.3516 - mae: 150.9136 - val_loss: 114701.5000 - val_mae: 154.1342 - lr: 0.0010\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100396.7188 - mae: 149.7649 - val_loss: 115534.2109 - val_mae: 155.1588 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97689.8750 - mae: 146.5679 - val_loss: 112457.7891 - val_mae: 152.0216 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97445.6016 - mae: 145.8316 - val_loss: 113782.2422 - val_mae: 153.5797 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97397.6719 - mae: 145.7556 - val_loss: 114122.0391 - val_mae: 153.0073 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97210.7109 - mae: 145.7017 - val_loss: 113396.4297 - val_mae: 152.3378 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97300.5625 - mae: 145.3867 - val_loss: 115433.3594 - val_mae: 153.8390 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97212.7969 - mae: 145.1893 - val_loss: 113292.3516 - val_mae: 153.3166 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97254.8359 - mae: 145.4909 - val_loss: 113258.9766 - val_mae: 152.0729 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97139.5625 - mae: 145.2949 - val_loss: 112905.0703 - val_mae: 151.6255 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97130.1562 - mae: 145.1919 - val_loss: 113160.2188 - val_mae: 152.3956 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97163.8828 - mae: 145.4396 - val_loss: 114311.8438 - val_mae: 153.8139 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97116.0859 - mae: 145.2391 - val_loss: 113382.3203 - val_mae: 152.8384 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96759.0391 - mae: 145.2086 - val_loss: 114248.3828 - val_mae: 153.4603 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96732.4844 - mae: 144.8430 - val_loss: 113637.7031 - val_mae: 152.6835 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96716.8125 - mae: 144.7156 - val_loss: 113775.2656 - val_mae: 152.7393 - lr: 1.0000e-05\n",
      "\u001b[32m[I 2022-07-28 18:05:19,915]\u001b[0m Trial 30 finished with value: 113775.25972817118 and parameters: {'feature_dim': 49, 'output_dim': 12, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1663290.2500 - mae: 717.3345 - val_loss: 1277790.2500 - val_mae: 583.7537 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 1334830.1250 - mae: 608.7034 - val_loss: 945756.7500 - val_mae: 475.0799 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 948207.5625 - mae: 488.7041 - val_loss: 633494.6250 - val_mae: 376.4942 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 622645.4375 - mae: 385.3297 - val_loss: 408373.6250 - val_mae: 304.3048 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 392974.3750 - mae: 304.9648 - val_loss: 267516.9062 - val_mae: 248.3115 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 982us/step - loss: 251157.4844 - mae: 246.9556 - val_loss: 194669.8594 - val_mae: 213.0802 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 175293.2656 - mae: 210.5142 - val_loss: 156393.9375 - val_mae: 198.3919 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 139369.9375 - mae: 188.7481 - val_loss: 136665.4844 - val_mae: 177.3866 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 122468.5938 - mae: 175.8082 - val_loss: 127388.1953 - val_mae: 174.7068 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 115388.8047 - mae: 168.8038 - val_loss: 132327.1719 - val_mae: 171.0121 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 110677.0938 - mae: 163.8155 - val_loss: 131691.4375 - val_mae: 174.8693 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 108485.5234 - mae: 160.7778 - val_loss: 129146.6406 - val_mae: 168.2238 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 106276.3203 - mae: 158.2386 - val_loss: 123274.1641 - val_mae: 169.9379 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 105151.0938 - mae: 156.2459 - val_loss: 136359.2344 - val_mae: 173.5401 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 982us/step - loss: 104317.3750 - mae: 155.0929 - val_loss: 117803.2891 - val_mae: 161.8877 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 104319.7266 - mae: 154.9529 - val_loss: 122079.8984 - val_mae: 161.9792 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 103551.8828 - mae: 153.2977 - val_loss: 122902.2344 - val_mae: 161.4282 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 104026.2812 - mae: 154.2609 - val_loss: 122750.6172 - val_mae: 165.7681 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 103904.4922 - mae: 153.9045 - val_loss: 120573.9141 - val_mae: 161.6903 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 102828.3828 - mae: 152.6212 - val_loss: 123645.1094 - val_mae: 162.8837 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 102599.2109 - mae: 152.4077 - val_loss: 118567.7344 - val_mae: 160.2253 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 103035.9922 - mae: 152.4870 - val_loss: 120499.8516 - val_mae: 160.8804 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 102200.0391 - mae: 151.8909 - val_loss: 123577.7188 - val_mae: 162.8041 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 101605.8281 - mae: 150.9111 - val_loss: 118053.7422 - val_mae: 163.2953 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 981us/step - loss: 102225.8984 - mae: 151.2594 - val_loss: 117881.7266 - val_mae: 159.0866 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 98435.6016 - mae: 145.9983 - val_loss: 115049.8047 - val_mae: 155.3776 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 98225.5625 - mae: 145.5922 - val_loss: 115456.3047 - val_mae: 155.9596 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 98239.6484 - mae: 145.6268 - val_loss: 116256.9062 - val_mae: 156.5332 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 98192.1719 - mae: 145.6235 - val_loss: 115125.2109 - val_mae: 156.1677 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 97987.3594 - mae: 145.6399 - val_loss: 116946.4922 - val_mae: 157.2333 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 97985.1719 - mae: 145.4222 - val_loss: 117389.7188 - val_mae: 157.8245 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 97950.8828 - mae: 145.4336 - val_loss: 118200.5469 - val_mae: 158.0705 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 97921.0703 - mae: 145.3164 - val_loss: 115958.2031 - val_mae: 155.7392 - lr: 1.0000e-04\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 984us/step - loss: 97851.0156 - mae: 145.2517 - val_loss: 116204.9531 - val_mae: 156.2887 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 97789.8516 - mae: 145.3384 - val_loss: 116554.5547 - val_mae: 156.1682 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 97761.6875 - mae: 145.1639 - val_loss: 115494.0312 - val_mae: 156.2949 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 97328.8438 - mae: 145.0782 - val_loss: 115492.5781 - val_mae: 155.8992 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 97312.2109 - mae: 144.6797 - val_loss: 115786.3828 - val_mae: 156.1995 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 97311.3125 - mae: 144.7349 - val_loss: 115630.6641 - val_mae: 156.0267 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 97284.9531 - mae: 144.7734 - val_loss: 115571.0703 - val_mae: 155.8982 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 97283.6328 - mae: 144.6431 - val_loss: 116200.2422 - val_mae: 156.4965 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 97279.8516 - mae: 144.5950 - val_loss: 115838.4688 - val_mae: 156.2302 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 97285.1094 - mae: 144.7628 - val_loss: 115664.8516 - val_mae: 156.0283 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 97272.6953 - mae: 144.6520 - val_loss: 115751.7578 - val_mae: 156.1001 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 97252.4609 - mae: 144.6858 - val_loss: 115641.8984 - val_mae: 155.9789 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 97268.8672 - mae: 144.6267 - val_loss: 115648.2578 - val_mae: 156.0085 - lr: 1.0000e-05\n",
      "\u001b[32m[I 2022-07-28 18:06:10,083]\u001b[0m Trial 31 finished with value: 115648.301160527 and parameters: {'feature_dim': 39, 'output_dim': 10, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1681784.5000 - mae: 724.9792 - val_loss: 1324820.7500 - val_mae: 598.6487 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 1429861.3750 - mae: 637.0033 - val_loss: 1059847.5000 - val_mae: 512.0512 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 1106897.8750 - mae: 537.8722 - val_loss: 781315.5000 - val_mae: 422.4652 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 800510.5000 - mae: 441.5172 - val_loss: 547124.0000 - val_mae: 349.8733 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 551854.6250 - mae: 361.4127 - val_loss: 376429.0625 - val_mae: 290.4980 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 370915.0000 - mae: 296.2823 - val_loss: 267763.0938 - val_mae: 248.1464 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 251384.9844 - mae: 246.8227 - val_loss: 195758.9531 - val_mae: 216.8082 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 182511.5312 - mae: 214.5048 - val_loss: 157284.9375 - val_mae: 192.1816 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 144519.3281 - mae: 191.8187 - val_loss: 138055.2656 - val_mae: 178.0168 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 127106.2734 - mae: 179.0560 - val_loss: 137925.6719 - val_mae: 173.7551 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 117320.4062 - mae: 170.4237 - val_loss: 132960.9531 - val_mae: 172.4592 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 113006.9609 - mae: 165.7286 - val_loss: 130093.6328 - val_mae: 165.2413 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 109275.5703 - mae: 161.4237 - val_loss: 121868.1562 - val_mae: 160.6563 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 107509.3516 - mae: 158.8565 - val_loss: 132577.9844 - val_mae: 167.6955 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 933us/step - loss: 106305.8594 - mae: 157.5301 - val_loss: 117378.0547 - val_mae: 156.6411 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 105586.2344 - mae: 156.5554 - val_loss: 122576.7188 - val_mae: 157.3956 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 104818.4141 - mae: 155.5274 - val_loss: 120519.9297 - val_mae: 157.1899 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 105062.2734 - mae: 155.8327 - val_loss: 118176.2656 - val_mae: 156.7806 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 104627.1406 - mae: 155.2096 - val_loss: 117708.9375 - val_mae: 156.7939 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 933us/step - loss: 103938.6094 - mae: 154.4933 - val_loss: 118999.9688 - val_mae: 157.3416 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 103632.6562 - mae: 154.2296 - val_loss: 119130.5000 - val_mae: 157.5724 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 103943.5391 - mae: 154.0488 - val_loss: 118052.2578 - val_mae: 155.9246 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 102787.2578 - mae: 153.0557 - val_loss: 126238.9922 - val_mae: 163.0221 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 102505.7344 - mae: 152.7658 - val_loss: 118311.3359 - val_mae: 159.4077 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 102765.9688 - mae: 152.6436 - val_loss: 116695.9297 - val_mae: 156.1577 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 102077.6016 - mae: 151.9158 - val_loss: 114641.3984 - val_mae: 159.4769 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 101795.4062 - mae: 151.3813 - val_loss: 113864.2109 - val_mae: 153.7280 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 101699.4297 - mae: 151.3781 - val_loss: 121203.2812 - val_mae: 161.5226 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 101527.4922 - mae: 151.1111 - val_loss: 121197.1875 - val_mae: 160.0187 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 101082.6719 - mae: 150.8646 - val_loss: 121160.6484 - val_mae: 161.6807 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 101458.5547 - mae: 150.6761 - val_loss: 117919.4922 - val_mae: 156.1849 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 100894.7969 - mae: 150.2794 - val_loss: 120501.4766 - val_mae: 156.8650 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 100795.2812 - mae: 150.4490 - val_loss: 115436.0000 - val_mae: 153.7238 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 100778.6953 - mae: 149.7499 - val_loss: 116134.3594 - val_mae: 156.3922 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 933us/step - loss: 100524.4062 - mae: 149.4930 - val_loss: 112727.8516 - val_mae: 152.3670 - lr: 0.0010\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 938us/step - loss: 100456.0156 - mae: 149.3388 - val_loss: 116282.8281 - val_mae: 155.2341 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 933us/step - loss: 100289.4219 - mae: 149.4087 - val_loss: 117243.3281 - val_mae: 155.7083 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 100332.0859 - mae: 149.6920 - val_loss: 116063.9453 - val_mae: 154.4379 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 100133.6250 - mae: 149.3868 - val_loss: 116700.0391 - val_mae: 157.6507 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 933us/step - loss: 99792.2734 - mae: 148.6016 - val_loss: 113167.3906 - val_mae: 152.8382 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 933us/step - loss: 99441.3281 - mae: 148.4448 - val_loss: 115898.2656 - val_mae: 155.3315 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 99637.7344 - mae: 148.0476 - val_loss: 113295.0703 - val_mae: 153.1303 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 99993.9531 - mae: 148.6386 - val_loss: 119956.3281 - val_mae: 157.7088 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 930us/step - loss: 99670.1328 - mae: 148.8476 - val_loss: 111707.3438 - val_mae: 151.2518 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 99341.6719 - mae: 147.7611 - val_loss: 117453.5938 - val_mae: 154.7989 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 923us/step - loss: 99311.6094 - mae: 148.2543 - val_loss: 118104.1484 - val_mae: 155.4083 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 99252.1797 - mae: 148.2006 - val_loss: 114865.1250 - val_mae: 154.8327 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 931us/step - loss: 99270.8594 - mae: 148.0206 - val_loss: 115554.8516 - val_mae: 152.4550 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 99067.2969 - mae: 147.4695 - val_loss: 112485.9297 - val_mae: 152.0027 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 99108.3594 - mae: 147.9763 - val_loss: 113474.7266 - val_mae: 151.3091 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:07:02,150]\u001b[0m Trial 32 finished with value: 113474.74577550632 and parameters: {'feature_dim': 36, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1654856.6250 - mae: 717.3802 - val_loss: 1268271.2500 - val_mae: 580.5519 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 921us/step - loss: 1312557.5000 - mae: 601.8220 - val_loss: 918047.8750 - val_mae: 467.9032 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 922us/step - loss: 911508.1875 - mae: 477.1389 - val_loss: 601869.8125 - val_mae: 367.2190 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 586477.8750 - mae: 372.2015 - val_loss: 383522.1250 - val_mae: 294.5298 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 366131.2812 - mae: 295.1230 - val_loss: 253099.7656 - val_mae: 243.4949 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 235828.8594 - mae: 241.7568 - val_loss: 187036.7969 - val_mae: 210.7849 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 167885.2031 - mae: 207.3278 - val_loss: 155824.9844 - val_mae: 199.6897 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 926us/step - loss: 137490.0312 - mae: 187.9072 - val_loss: 141693.9531 - val_mae: 183.2123 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 922us/step - loss: 123470.6172 - mae: 176.3610 - val_loss: 135189.0781 - val_mae: 183.4399 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 926us/step - loss: 117797.5547 - mae: 170.3321 - val_loss: 140100.8750 - val_mae: 173.3853 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 114274.8906 - mae: 166.1827 - val_loss: 134190.5938 - val_mae: 174.8991 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 926us/step - loss: 113359.4609 - mae: 164.3778 - val_loss: 136224.7812 - val_mae: 170.6466 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 931us/step - loss: 110749.3438 - mae: 162.3139 - val_loss: 125581.3359 - val_mae: 170.1206 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 925us/step - loss: 109302.1016 - mae: 160.3486 - val_loss: 139970.6406 - val_mae: 172.1456 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 107562.0938 - mae: 158.5788 - val_loss: 120301.1562 - val_mae: 161.8705 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 923us/step - loss: 106768.3672 - mae: 157.8117 - val_loss: 125862.8750 - val_mae: 162.9330 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 105508.5547 - mae: 156.2262 - val_loss: 127008.2500 - val_mae: 163.9137 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 923us/step - loss: 105453.9141 - mae: 156.2267 - val_loss: 121318.9453 - val_mae: 161.6846 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 105101.0703 - mae: 156.0234 - val_loss: 120872.4297 - val_mae: 159.3499 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 103861.3516 - mae: 154.5658 - val_loss: 122008.4453 - val_mae: 160.0713 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 913us/step - loss: 103662.6172 - mae: 154.0871 - val_loss: 121403.0156 - val_mae: 161.1031 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 912us/step - loss: 103917.7266 - mae: 154.2129 - val_loss: 118839.5078 - val_mae: 158.0106 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 913us/step - loss: 102526.0234 - mae: 152.7276 - val_loss: 127672.2188 - val_mae: 163.8676 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 912us/step - loss: 102432.0625 - mae: 152.2812 - val_loss: 116675.9062 - val_mae: 161.5228 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 912us/step - loss: 102685.8438 - mae: 152.3835 - val_loss: 118468.1172 - val_mae: 157.4184 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 914us/step - loss: 102113.0156 - mae: 151.5804 - val_loss: 112571.8281 - val_mae: 154.0659 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 913us/step - loss: 101683.3125 - mae: 151.2101 - val_loss: 114857.7344 - val_mae: 152.6380 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 909us/step - loss: 101411.1875 - mae: 150.6799 - val_loss: 120233.4219 - val_mae: 161.0634 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 101384.9688 - mae: 150.7266 - val_loss: 124604.9219 - val_mae: 162.9910 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 101092.7578 - mae: 150.3257 - val_loss: 120146.0391 - val_mae: 158.1644 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 101067.4453 - mae: 150.1137 - val_loss: 117348.9062 - val_mae: 154.6896 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 100664.3516 - mae: 149.7472 - val_loss: 118312.5859 - val_mae: 155.3345 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 100501.5547 - mae: 149.7886 - val_loss: 116287.4141 - val_mae: 154.4376 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 100444.5078 - mae: 148.7813 - val_loss: 114906.6094 - val_mae: 153.3086 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 100247.5703 - mae: 148.9206 - val_loss: 110073.6406 - val_mae: 149.4135 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 914us/step - loss: 99832.8047 - mae: 148.1241 - val_loss: 112169.0234 - val_mae: 150.0962 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 99936.7734 - mae: 148.5483 - val_loss: 116345.4609 - val_mae: 155.0944 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 915us/step - loss: 99734.8438 - mae: 148.6230 - val_loss: 115759.7891 - val_mae: 154.8908 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 921us/step - loss: 99642.5625 - mae: 148.3130 - val_loss: 111607.3359 - val_mae: 150.4669 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 919us/step - loss: 99193.0234 - mae: 147.5298 - val_loss: 112975.3281 - val_mae: 151.3847 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 916us/step - loss: 98917.2344 - mae: 147.2891 - val_loss: 117227.9062 - val_mae: 154.2929 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 909us/step - loss: 98779.2969 - mae: 146.6581 - val_loss: 109268.2266 - val_mae: 147.3975 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 914us/step - loss: 99278.8984 - mae: 147.3018 - val_loss: 122637.9609 - val_mae: 164.6422 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 916us/step - loss: 98809.1250 - mae: 147.3695 - val_loss: 111093.2344 - val_mae: 150.1787 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 920us/step - loss: 98467.3125 - mae: 146.3323 - val_loss: 117563.9062 - val_mae: 153.0325 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 98331.6641 - mae: 146.8437 - val_loss: 115903.7031 - val_mae: 152.2656 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 913us/step - loss: 98426.9453 - mae: 146.9590 - val_loss: 111911.0078 - val_mae: 150.2095 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 914us/step - loss: 98402.7578 - mae: 146.7834 - val_loss: 113342.2266 - val_mae: 148.9833 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 98118.3438 - mae: 146.1876 - val_loss: 111323.1953 - val_mae: 148.6389 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 916us/step - loss: 98235.4609 - mae: 146.6243 - val_loss: 112769.2500 - val_mae: 150.2761 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:07:53,237]\u001b[0m Trial 33 finished with value: 112769.29276505788 and parameters: {'feature_dim': 34, 'output_dim': 10, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1698255.1250 - mae: 729.1431 - val_loss: 1345305.1250 - val_mae: 605.1812 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 1458669.1250 - mae: 646.7261 - val_loss: 1088962.3750 - val_mae: 519.1387 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 900us/step - loss: 1144396.1250 - mae: 549.6711 - val_loss: 815378.3750 - val_mae: 431.2480 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 905us/step - loss: 840303.7500 - mae: 452.3247 - val_loss: 580028.4375 - val_mae: 355.6667 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 588681.7500 - mae: 369.7407 - val_loss: 402342.7812 - val_mae: 298.3918 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 909us/step - loss: 403471.0000 - mae: 305.6478 - val_loss: 285565.3750 - val_mae: 251.1303 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 908us/step - loss: 279377.6875 - mae: 258.7932 - val_loss: 209002.8281 - val_mae: 227.0278 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 904us/step - loss: 201899.3906 - mae: 224.6533 - val_loss: 168372.4375 - val_mae: 201.0603 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 156740.2344 - mae: 199.9101 - val_loss: 149128.5312 - val_mae: 191.2412 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 905us/step - loss: 134969.9688 - mae: 185.9938 - val_loss: 141774.6094 - val_mae: 178.7876 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 904us/step - loss: 122060.6953 - mae: 175.7947 - val_loss: 136894.2812 - val_mae: 178.7875 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 899us/step - loss: 116426.8516 - mae: 170.4886 - val_loss: 133617.1094 - val_mae: 170.9065 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 909us/step - loss: 112336.5547 - mae: 165.9596 - val_loss: 128941.7188 - val_mae: 170.6671 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 899us/step - loss: 109805.5234 - mae: 162.5555 - val_loss: 139092.3438 - val_mae: 174.7349 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 905us/step - loss: 107688.5469 - mae: 159.8601 - val_loss: 122819.0938 - val_mae: 165.4364 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 901us/step - loss: 106835.2812 - mae: 158.7917 - val_loss: 127112.1641 - val_mae: 163.3395 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 907us/step - loss: 105731.8438 - mae: 157.0108 - val_loss: 122153.5625 - val_mae: 160.7785 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 105571.5781 - mae: 156.6765 - val_loss: 124978.7734 - val_mae: 164.6560 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 903us/step - loss: 105391.2109 - mae: 156.0910 - val_loss: 121843.0703 - val_mae: 162.9773 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 906us/step - loss: 104452.9297 - mae: 155.0241 - val_loss: 122652.5625 - val_mae: 162.1110 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 902us/step - loss: 104245.7500 - mae: 154.6496 - val_loss: 122318.3047 - val_mae: 163.6121 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 905us/step - loss: 104359.7422 - mae: 154.5479 - val_loss: 120712.2578 - val_mae: 159.8972 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 899us/step - loss: 103225.3750 - mae: 153.3884 - val_loss: 126817.7812 - val_mae: 164.9278 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 102672.1094 - mae: 152.6964 - val_loss: 119867.6406 - val_mae: 164.8668 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 103289.4141 - mae: 152.9960 - val_loss: 117346.3828 - val_mae: 159.8568 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 909us/step - loss: 102500.6094 - mae: 152.1489 - val_loss: 116065.8828 - val_mae: 162.4485 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 102280.5156 - mae: 151.9784 - val_loss: 115459.6328 - val_mae: 154.9173 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 915us/step - loss: 102327.7109 - mae: 151.8094 - val_loss: 121456.2109 - val_mae: 162.5314 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 914us/step - loss: 102079.6797 - mae: 151.8541 - val_loss: 125312.7969 - val_mae: 163.5116 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 918us/step - loss: 101733.1016 - mae: 151.4835 - val_loss: 123080.6875 - val_mae: 164.1390 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 908us/step - loss: 102118.4609 - mae: 151.3872 - val_loss: 121664.8750 - val_mae: 158.3160 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 917us/step - loss: 101498.9609 - mae: 150.9549 - val_loss: 121940.5547 - val_mae: 158.8844 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 909us/step - loss: 101549.0156 - mae: 151.1713 - val_loss: 116958.5078 - val_mae: 155.1149 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 912us/step - loss: 101200.9453 - mae: 150.3702 - val_loss: 117481.9531 - val_mae: 156.6266 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 928us/step - loss: 101138.3984 - mae: 150.1009 - val_loss: 114230.3984 - val_mae: 154.0178 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 912us/step - loss: 100905.2422 - mae: 149.9630 - val_loss: 115669.3906 - val_mae: 155.6428 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 910us/step - loss: 100792.8203 - mae: 150.2159 - val_loss: 116746.8359 - val_mae: 155.2688 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 926us/step - loss: 100789.1953 - mae: 150.4227 - val_loss: 116903.5078 - val_mae: 157.0753 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 100470.0938 - mae: 150.3605 - val_loss: 115318.2500 - val_mae: 156.6589 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 100277.6562 - mae: 149.6688 - val_loss: 114974.8516 - val_mae: 155.8817 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 909us/step - loss: 99891.6094 - mae: 149.3496 - val_loss: 116846.4375 - val_mae: 157.4026 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 916us/step - loss: 99963.1719 - mae: 149.0958 - val_loss: 111388.6172 - val_mae: 152.9513 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 100321.4688 - mae: 149.4721 - val_loss: 127709.1406 - val_mae: 169.3955 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 908us/step - loss: 99956.5312 - mae: 149.3449 - val_loss: 112262.1953 - val_mae: 154.5755 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 910us/step - loss: 99584.2891 - mae: 148.6458 - val_loss: 117556.8125 - val_mae: 155.9130 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 928us/step - loss: 99576.5078 - mae: 149.2657 - val_loss: 119390.9297 - val_mae: 155.8098 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 921us/step - loss: 99343.3125 - mae: 148.9050 - val_loss: 114536.2578 - val_mae: 156.6793 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 99389.2266 - mae: 148.9816 - val_loss: 115468.7891 - val_mae: 153.6450 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 908us/step - loss: 99377.6094 - mae: 148.5955 - val_loss: 113363.0078 - val_mae: 155.7622 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 915us/step - loss: 99272.4609 - mae: 148.9114 - val_loss: 112367.2188 - val_mae: 153.3325 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:08:43,934]\u001b[0m Trial 34 finished with value: 112367.22845278976 and parameters: {'feature_dim': 32, 'output_dim': 12, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "[TabNet]: 30 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1698545.6250 - mae: 717.6028 - val_loss: 1355475.6250 - val_mae: 604.5151 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1487242.8750 - mae: 652.2903 - val_loss: 1128895.0000 - val_mae: 531.8851 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1204955.8750 - mae: 567.7350 - val_loss: 879261.5000 - val_mae: 452.1310 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 927046.1875 - mae: 483.7811 - val_loss: 656569.0000 - val_mae: 382.5157 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 703801.0000 - mae: 420.3764 - val_loss: 543757.6250 - val_mae: 377.4171 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 539615.2500 - mae: 373.1138 - val_loss: 389752.7500 - val_mae: 297.8883 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 440226.0625 - mae: 345.6275 - val_loss: 306128.8438 - val_mae: 273.2950 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 361946.7188 - mae: 317.0421 - val_loss: 274418.2812 - val_mae: 264.3514 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 329846.4062 - mae: 306.0091 - val_loss: 231942.8750 - val_mae: 238.5248 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 285049.5625 - mae: 283.4347 - val_loss: 486103.8438 - val_mae: 331.2421 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 288901.9688 - mae: 287.2604 - val_loss: 271107.8438 - val_mae: 267.3412 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 262714.0312 - mae: 272.6725 - val_loss: 212966.1094 - val_mae: 233.1159 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 264342.4062 - mae: 273.0230 - val_loss: 230548.1719 - val_mae: 242.8639 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 250276.0781 - mae: 265.1096 - val_loss: 201067.2812 - val_mae: 226.4407 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 245735.4375 - mae: 262.5674 - val_loss: 195534.9531 - val_mae: 220.1407 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 227681.6719 - mae: 252.8273 - val_loss: 185520.7656 - val_mae: 215.1456 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 233160.0938 - mae: 255.0001 - val_loss: 194823.1562 - val_mae: 220.5717 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 244026.4844 - mae: 260.5615 - val_loss: 189841.5781 - val_mae: 217.1118 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 238871.2812 - mae: 258.5716 - val_loss: 184400.2812 - val_mae: 213.5350 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 242383.6719 - mae: 259.2365 - val_loss: 214595.7500 - val_mae: 232.6053 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 219965.2812 - mae: 248.0898 - val_loss: 407238.1250 - val_mae: 318.5104 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 233123.9219 - mae: 254.7509 - val_loss: 239328.1406 - val_mae: 243.4253 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 219825.8438 - mae: 246.8101 - val_loss: 217612.2969 - val_mae: 230.5630 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 219759.9219 - mae: 247.4232 - val_loss: 218430.9062 - val_mae: 234.7903 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 220045.5469 - mae: 248.0237 - val_loss: 207257.9219 - val_mae: 225.8477 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 210126.5781 - mae: 242.3540 - val_loss: 193063.4062 - val_mae: 218.4875 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 205974.7188 - mae: 239.2410 - val_loss: 171735.4688 - val_mae: 205.7568 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 221347.9844 - mae: 247.1623 - val_loss: 174800.8750 - val_mae: 210.5621 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 204917.4375 - mae: 238.3711 - val_loss: 263961.5938 - val_mae: 252.2830 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 202266.1562 - mae: 237.8956 - val_loss: 205797.1406 - val_mae: 223.1416 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 195032.7031 - mae: 231.7656 - val_loss: 211669.0312 - val_mae: 225.2779 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 198760.8906 - mae: 234.5692 - val_loss: 179949.4844 - val_mae: 207.5252 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 199467.0469 - mae: 234.7145 - val_loss: 178313.6719 - val_mae: 206.7034 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 189415.5000 - mae: 228.7679 - val_loss: 170915.5312 - val_mae: 203.3021 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 197454.6094 - mae: 233.5516 - val_loss: 170506.6562 - val_mae: 202.9053 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 191230.7188 - mae: 229.5311 - val_loss: 174946.8125 - val_mae: 204.3455 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 183642.8125 - mae: 224.7577 - val_loss: 197616.0625 - val_mae: 213.9541 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 185108.6094 - mae: 225.4349 - val_loss: 172951.7812 - val_mae: 205.6298 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 185923.1250 - mae: 225.5267 - val_loss: 168272.2344 - val_mae: 200.8338 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 187885.2656 - mae: 226.7678 - val_loss: 168036.8906 - val_mae: 206.3618 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 186071.7344 - mae: 226.4232 - val_loss: 169700.9062 - val_mae: 201.1801 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 181143.8125 - mae: 222.9221 - val_loss: 179010.1562 - val_mae: 205.5378 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 186601.9219 - mae: 226.2549 - val_loss: 177051.1250 - val_mae: 204.2875 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 185547.7812 - mae: 225.4461 - val_loss: 163905.6250 - val_mae: 199.0188 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 182732.6406 - mae: 224.1814 - val_loss: 208793.4688 - val_mae: 219.2060 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 178856.6406 - mae: 220.7509 - val_loss: 195481.7812 - val_mae: 213.6849 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 180635.5469 - mae: 222.2487 - val_loss: 183486.9688 - val_mae: 211.0843 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 177571.1406 - mae: 219.9549 - val_loss: 172684.5156 - val_mae: 200.6278 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 177345.2188 - mae: 220.4963 - val_loss: 195415.1562 - val_mae: 219.1550 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 176501.8594 - mae: 219.4213 - val_loss: 169267.5469 - val_mae: 202.7419 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:10:14,935]\u001b[0m Trial 35 finished with value: 169267.55466485868 and parameters: {'feature_dim': 39, 'output_dim': 9, 'num_decision_steps': 2}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1762663.2500 - mae: 737.2357 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.7500 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.0000 - mae: 737.2339 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.2500 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.1250 - mae: 737.2339 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.2500 - mae: 737.2347 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.8750 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.5000 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2333 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.5000 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.7500 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.6250 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2337 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.1250 - mae: 737.2337 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762658.8750 - mae: 737.2338 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.3750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.2500 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.7500 - mae: 737.2346 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.6250 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:10:39,141]\u001b[0m Trial 36 finished with value: 1487783.123857698 and parameters: {'feature_dim': 44, 'output_dim': 7, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "[TabNet]: 26 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 1600466.1250 - mae: 690.4922 - val_loss: 1143559.2500 - val_mae: 544.5813 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1068841.1250 - mae: 537.9423 - val_loss: 667858.3125 - val_mae: 412.0887 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 648538.0625 - mae: 424.5031 - val_loss: 413106.3438 - val_mae: 333.9002 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 439455.6875 - mae: 363.0341 - val_loss: 308875.2812 - val_mae: 316.1817 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 337684.3125 - mae: 328.6988 - val_loss: 253071.4062 - val_mae: 278.0801 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 301558.3750 - mae: 313.0440 - val_loss: 235656.1094 - val_mae: 277.6998 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 279672.6250 - mae: 299.9129 - val_loss: 213063.0938 - val_mae: 260.1425 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 258374.9688 - mae: 288.4363 - val_loss: 220030.5938 - val_mae: 255.5005 - lr: 0.0010\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 2ms/step - loss: 258550.9531 - mae: 285.2028 - val_loss: 180748.0312 - val_mae: 233.7355 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 240587.7500 - mae: 276.9235 - val_loss: 187958.0312 - val_mae: 235.3131 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 231788.4375 - mae: 270.8213 - val_loss: 173508.1562 - val_mae: 224.0207 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 232850.0781 - mae: 268.5864 - val_loss: 178456.8906 - val_mae: 221.0361 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 228102.4062 - mae: 264.3728 - val_loss: 220274.4062 - val_mae: 242.1436 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 226753.3125 - mae: 262.2986 - val_loss: 178100.0312 - val_mae: 217.6344 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 221609.6719 - mae: 259.7589 - val_loss: 184975.2812 - val_mae: 221.5824 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 219126.4688 - mae: 257.8987 - val_loss: 196485.9375 - val_mae: 226.2027 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 221800.8750 - mae: 258.6770 - val_loss: 161792.7500 - val_mae: 205.3282 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 216482.8750 - mae: 254.2095 - val_loss: 162603.3438 - val_mae: 203.6640 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 215233.5000 - mae: 253.8720 - val_loss: 234901.6875 - val_mae: 243.4398 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 215647.7344 - mae: 252.6120 - val_loss: 161636.6094 - val_mae: 201.0140 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 209821.1406 - mae: 249.8909 - val_loss: 184279.7656 - val_mae: 214.2294 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 209651.8438 - mae: 248.8939 - val_loss: 169999.9688 - val_mae: 207.6551 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 208225.6406 - mae: 248.0395 - val_loss: 186658.1250 - val_mae: 213.0617 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 204712.8594 - mae: 245.7363 - val_loss: 233923.2500 - val_mae: 238.8965 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 205242.3281 - mae: 245.8011 - val_loss: 201135.8281 - val_mae: 221.2555 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 206704.4375 - mae: 246.5018 - val_loss: 192932.4062 - val_mae: 218.4671 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 204853.9219 - mae: 245.2325 - val_loss: 212302.4375 - val_mae: 229.0968 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 201725.1719 - mae: 243.2430 - val_loss: 178262.1875 - val_mae: 210.1083 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 204522.6875 - mae: 243.9209 - val_loss: 220274.0156 - val_mae: 232.2563 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 201451.0625 - mae: 242.7242 - val_loss: 178737.9531 - val_mae: 211.7980 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 190082.4844 - mae: 236.0855 - val_loss: 188522.8125 - val_mae: 214.4326 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 189755.6094 - mae: 235.7807 - val_loss: 194666.5000 - val_mae: 217.7355 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 189617.3750 - mae: 235.6842 - val_loss: 185507.5625 - val_mae: 213.1026 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 189476.8906 - mae: 235.7466 - val_loss: 183268.3594 - val_mae: 211.5506 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 189691.5000 - mae: 235.8703 - val_loss: 187910.4219 - val_mae: 214.4979 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 189677.7031 - mae: 235.6981 - val_loss: 192655.3906 - val_mae: 217.5648 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 189082.1562 - mae: 235.3443 - val_loss: 186201.7500 - val_mae: 213.5471 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 189310.8906 - mae: 235.4826 - val_loss: 184069.7344 - val_mae: 212.3889 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 189143.7969 - mae: 235.2074 - val_loss: 186883.6406 - val_mae: 214.3277 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 188640.1719 - mae: 234.8281 - val_loss: 190377.0469 - val_mae: 216.4380 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:12:12,728]\u001b[0m Trial 37 finished with value: 190377.01273994645 and parameters: {'feature_dim': 36, 'output_dim': 10, 'num_decision_steps': 3}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "[TabNet]: 24 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1674747.0000 - mae: 710.5092 - val_loss: 1309436.6250 - val_mae: 589.4621 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1398449.5000 - mae: 625.4473 - val_loss: 1021803.3750 - val_mae: 498.0811 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1057401.7500 - mae: 524.1602 - val_loss: 738088.4375 - val_mae: 411.4433 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 760944.3125 - mae: 436.6700 - val_loss: 530404.3125 - val_mae: 356.1505 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 566751.1250 - mae: 386.5645 - val_loss: 380401.0625 - val_mae: 298.2675 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 430234.7500 - mae: 340.7198 - val_loss: 296400.5625 - val_mae: 268.1061 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 354722.0312 - mae: 314.2810 - val_loss: 272209.8438 - val_mae: 263.7412 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 328182.4062 - mae: 308.5471 - val_loss: 228922.1406 - val_mae: 240.7214 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 269924.7812 - mae: 277.6069 - val_loss: 243522.0156 - val_mae: 254.2636 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 265870.5625 - mae: 275.4104 - val_loss: 198183.2812 - val_mae: 223.9014 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 238640.7500 - mae: 259.7221 - val_loss: 219799.1562 - val_mae: 238.6354 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 238006.8125 - mae: 258.5555 - val_loss: 191959.7188 - val_mae: 219.3591 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 224806.8438 - mae: 250.9961 - val_loss: 184195.0000 - val_mae: 212.6793 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 220000.1875 - mae: 248.4864 - val_loss: 195832.1094 - val_mae: 220.0964 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 214725.2969 - mae: 244.7010 - val_loss: 219787.6875 - val_mae: 230.6197 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 211991.2344 - mae: 243.6138 - val_loss: 200050.3438 - val_mae: 225.4360 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 211191.3906 - mae: 242.5410 - val_loss: 177513.7031 - val_mae: 207.5757 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 207906.6406 - mae: 240.0124 - val_loss: 193794.6875 - val_mae: 215.1231 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 199352.0312 - mae: 235.7733 - val_loss: 175387.2812 - val_mae: 205.3207 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 203819.1250 - mae: 236.3708 - val_loss: 217277.5000 - val_mae: 235.7438 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 197583.9844 - mae: 233.4894 - val_loss: 174205.7969 - val_mae: 204.4204 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 200660.2812 - mae: 235.2291 - val_loss: 174882.3438 - val_mae: 204.2431 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 190803.5938 - mae: 229.3766 - val_loss: 184242.0938 - val_mae: 207.7606 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 192162.4844 - mae: 230.2944 - val_loss: 229637.2969 - val_mae: 230.2946 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 192356.8281 - mae: 230.5493 - val_loss: 185020.8906 - val_mae: 208.7147 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 192608.4844 - mae: 230.2582 - val_loss: 165909.5781 - val_mae: 204.6496 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 184055.5000 - mae: 224.8400 - val_loss: 166448.8125 - val_mae: 200.4394 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 187778.8438 - mae: 227.4633 - val_loss: 174788.0000 - val_mae: 206.6120 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 186548.0312 - mae: 226.4052 - val_loss: 191494.9844 - val_mae: 217.9734 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 181489.3594 - mae: 223.5543 - val_loss: 182805.8281 - val_mae: 207.3148 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 181114.6094 - mae: 222.5847 - val_loss: 215336.5312 - val_mae: 227.1086 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 182110.7031 - mae: 223.3454 - val_loss: 170436.0625 - val_mae: 201.9329 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 181490.0469 - mae: 223.3536 - val_loss: 175103.5156 - val_mae: 203.3541 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 181279.9062 - mae: 223.2233 - val_loss: 172551.8281 - val_mae: 202.0665 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 181533.5156 - mae: 222.7648 - val_loss: 166217.9688 - val_mae: 199.4660 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 178581.7812 - mae: 220.8891 - val_loss: 213266.0938 - val_mae: 227.6335 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 162700.1719 - mae: 211.2155 - val_loss: 165643.7188 - val_mae: 198.2071 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 161390.9688 - mae: 210.2333 - val_loss: 164397.2031 - val_mae: 197.5182 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 160569.8281 - mae: 209.4016 - val_loss: 165317.1875 - val_mae: 197.7244 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 160153.0938 - mae: 208.9686 - val_loss: 163160.3594 - val_mae: 197.3913 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 160007.0312 - mae: 208.7885 - val_loss: 168368.2656 - val_mae: 198.6853 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 160943.0312 - mae: 209.0117 - val_loss: 163502.1562 - val_mae: 197.0698 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 160256.8125 - mae: 208.5013 - val_loss: 164978.2344 - val_mae: 198.3696 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 159561.6406 - mae: 208.2922 - val_loss: 166197.9375 - val_mae: 197.8087 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 158997.8281 - mae: 207.7114 - val_loss: 164889.2812 - val_mae: 197.3812 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 159260.0938 - mae: 207.8985 - val_loss: 163822.4219 - val_mae: 197.0120 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 159501.7031 - mae: 208.1664 - val_loss: 163667.7656 - val_mae: 196.8872 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 159197.0156 - mae: 207.6885 - val_loss: 165803.4844 - val_mae: 197.5930 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 158777.8906 - mae: 207.3261 - val_loss: 164081.3281 - val_mae: 197.2834 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 158563.5938 - mae: 207.3750 - val_loss: 163847.3438 - val_mae: 197.0580 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:13:35,885]\u001b[0m Trial 38 finished with value: 163847.4214096173 and parameters: {'feature_dim': 32, 'output_dim': 8, 'num_decision_steps': 2}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1675723.6250 - mae: 717.5002 - val_loss: 1323670.2500 - val_mae: 598.1088 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1437133.0000 - mae: 639.6292 - val_loss: 1074136.6250 - val_mae: 516.2520 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1131458.7500 - mae: 545.8712 - val_loss: 807714.5000 - val_mae: 430.3370 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 835265.9375 - mae: 453.1037 - val_loss: 577998.1875 - val_mae: 362.0698 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 588362.0625 - mae: 373.9246 - val_loss: 403008.9062 - val_mae: 301.2094 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 403647.8438 - mae: 310.2762 - val_loss: 288911.2188 - val_mae: 260.7031 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 279251.9375 - mae: 262.9670 - val_loss: 218237.6719 - val_mae: 239.3486 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 202848.5938 - mae: 229.5179 - val_loss: 176117.2500 - val_mae: 208.3282 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 158642.6719 - mae: 203.6175 - val_loss: 156781.2812 - val_mae: 203.0184 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 137132.8281 - mae: 187.8229 - val_loss: 147562.1250 - val_mae: 179.9622 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 124799.2656 - mae: 177.4609 - val_loss: 136727.1094 - val_mae: 176.2354 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 118364.0078 - mae: 171.1588 - val_loss: 136503.1406 - val_mae: 171.2373 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 113789.0625 - mae: 166.6913 - val_loss: 125165.8672 - val_mae: 168.8121 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110505.6953 - mae: 162.7770 - val_loss: 135263.7500 - val_mae: 170.0430 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107872.3750 - mae: 159.7048 - val_loss: 120713.6641 - val_mae: 162.2106 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106670.6562 - mae: 158.3672 - val_loss: 128395.6562 - val_mae: 165.2505 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105579.3594 - mae: 156.6274 - val_loss: 128794.8594 - val_mae: 165.0900 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105947.5234 - mae: 156.9361 - val_loss: 121523.5391 - val_mae: 162.1415 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105953.9297 - mae: 156.4593 - val_loss: 121928.3281 - val_mae: 158.3574 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104278.6484 - mae: 154.5587 - val_loss: 125950.2344 - val_mae: 163.2496 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104496.3047 - mae: 154.8400 - val_loss: 119043.3906 - val_mae: 157.4776 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104964.6484 - mae: 154.7251 - val_loss: 120075.2812 - val_mae: 158.5146 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103700.7969 - mae: 153.5645 - val_loss: 131830.4688 - val_mae: 166.1271 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103241.4922 - mae: 152.7470 - val_loss: 117999.5234 - val_mae: 159.7705 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103846.8359 - mae: 152.9507 - val_loss: 121471.6250 - val_mae: 159.3489 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103179.5781 - mae: 152.3238 - val_loss: 115031.8672 - val_mae: 156.1139 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103048.9688 - mae: 152.2675 - val_loss: 119502.6484 - val_mae: 157.9592 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102691.5547 - mae: 151.7017 - val_loss: 127060.3281 - val_mae: 167.1124 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102534.5391 - mae: 151.7519 - val_loss: 126605.7812 - val_mae: 164.4855 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102303.9375 - mae: 151.0771 - val_loss: 125712.7891 - val_mae: 163.9530 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102498.8516 - mae: 151.3744 - val_loss: 124204.7109 - val_mae: 159.7329 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101908.6562 - mae: 150.8484 - val_loss: 126354.3828 - val_mae: 161.6561 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101648.2734 - mae: 150.7059 - val_loss: 118519.3047 - val_mae: 156.0013 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101734.5312 - mae: 150.4029 - val_loss: 117684.0000 - val_mae: 155.1609 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101368.5000 - mae: 149.7783 - val_loss: 114290.0000 - val_mae: 153.1301 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100988.0469 - mae: 149.2584 - val_loss: 115617.7656 - val_mae: 154.7144 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101026.8203 - mae: 149.4973 - val_loss: 119383.4453 - val_mae: 159.1859 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100891.3750 - mae: 149.6633 - val_loss: 117651.0391 - val_mae: 159.1188 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100481.0078 - mae: 149.0999 - val_loss: 114347.9141 - val_mae: 152.3546 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100054.0938 - mae: 148.5119 - val_loss: 114098.0625 - val_mae: 154.3678 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99894.2344 - mae: 148.1164 - val_loss: 117104.1953 - val_mae: 154.7588 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100078.6562 - mae: 148.2686 - val_loss: 113217.1406 - val_mae: 151.5414 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100212.0000 - mae: 148.3322 - val_loss: 126260.2812 - val_mae: 168.8908 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99638.0781 - mae: 147.8049 - val_loss: 110016.8906 - val_mae: 149.9884 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99615.1875 - mae: 147.4404 - val_loss: 117953.4531 - val_mae: 154.3908 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99237.1250 - mae: 147.9598 - val_loss: 118837.6797 - val_mae: 155.7301 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99303.9609 - mae: 147.8231 - val_loss: 114015.1875 - val_mae: 152.8527 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99216.0703 - mae: 147.5038 - val_loss: 115379.8438 - val_mae: 151.3940 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99101.7188 - mae: 147.3201 - val_loss: 111738.5078 - val_mae: 151.1423 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99036.7422 - mae: 147.7821 - val_loss: 114047.1406 - val_mae: 149.7608 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:14:35,863]\u001b[0m Trial 39 finished with value: 114047.11011386865 and parameters: {'feature_dim': 52, 'output_dim': 5, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1682862.2500 - mae: 725.2756 - val_loss: 1323235.5000 - val_mae: 601.1804 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1420745.1250 - mae: 634.9954 - val_loss: 1046187.5000 - val_mae: 509.6178 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1084711.1250 - mae: 531.2322 - val_loss: 759277.6250 - val_mae: 418.1955 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 771431.6250 - mae: 432.4941 - val_loss: 522153.1250 - val_mae: 339.5658 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 522315.4688 - mae: 350.6752 - val_loss: 351271.9375 - val_mae: 279.3967 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 347029.7188 - mae: 287.1991 - val_loss: 249531.5781 - val_mae: 238.1539 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 235748.3906 - mae: 241.8582 - val_loss: 185529.8594 - val_mae: 218.9468 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 173850.3594 - mae: 211.9183 - val_loss: 151946.7969 - val_mae: 187.6800 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 140512.7969 - mae: 191.4399 - val_loss: 136757.0938 - val_mae: 177.8724 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 125861.2734 - mae: 179.6994 - val_loss: 136285.4844 - val_mae: 174.0461 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 116351.9141 - mae: 170.6797 - val_loss: 131148.3438 - val_mae: 171.4580 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111789.3672 - mae: 165.3279 - val_loss: 127822.3281 - val_mae: 164.4427 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 108960.3750 - mae: 161.4563 - val_loss: 123851.7578 - val_mae: 165.4417 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 107721.8438 - mae: 159.1408 - val_loss: 136887.0469 - val_mae: 171.0648 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 106519.3672 - mae: 157.6645 - val_loss: 121616.5078 - val_mae: 163.4878 - lr: 0.0010\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105977.8047 - mae: 157.4198 - val_loss: 128266.9766 - val_mae: 166.0543 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105188.2656 - mae: 156.0803 - val_loss: 122315.1953 - val_mae: 161.4456 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105693.2656 - mae: 156.0896 - val_loss: 124565.4375 - val_mae: 164.9932 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105453.3516 - mae: 155.9098 - val_loss: 122145.0781 - val_mae: 162.9196 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104283.0547 - mae: 154.8083 - val_loss: 121941.5078 - val_mae: 162.7922 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103857.6719 - mae: 154.0567 - val_loss: 123436.3672 - val_mae: 164.1568 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104390.9766 - mae: 154.1132 - val_loss: 122889.1641 - val_mae: 162.5594 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102860.8750 - mae: 152.7600 - val_loss: 127734.3438 - val_mae: 165.4485 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102466.2344 - mae: 152.5863 - val_loss: 120981.5625 - val_mae: 163.4700 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102722.8125 - mae: 152.4166 - val_loss: 120652.9297 - val_mae: 161.4120 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101872.0781 - mae: 151.5312 - val_loss: 116676.2031 - val_mae: 159.8461 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101604.6172 - mae: 151.3842 - val_loss: 119609.8672 - val_mae: 158.9636 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101571.4844 - mae: 150.9526 - val_loss: 129516.6406 - val_mae: 168.4772 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101442.6562 - mae: 151.3025 - val_loss: 128590.8594 - val_mae: 165.9481 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100904.8359 - mae: 150.4699 - val_loss: 126227.5234 - val_mae: 164.8060 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101424.0625 - mae: 150.8106 - val_loss: 123080.2734 - val_mae: 160.6338 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100669.4844 - mae: 149.8847 - val_loss: 124604.8750 - val_mae: 159.9049 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100469.5938 - mae: 149.9102 - val_loss: 118116.8125 - val_mae: 155.0661 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 100495.9375 - mae: 149.3817 - val_loss: 117837.7266 - val_mae: 156.0216 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 100408.9453 - mae: 149.1242 - val_loss: 117347.3750 - val_mae: 157.4914 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 100058.7656 - mae: 148.9176 - val_loss: 118643.5859 - val_mae: 155.8556 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97247.0234 - mae: 145.7777 - val_loss: 115655.5547 - val_mae: 154.1181 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97001.9766 - mae: 145.1441 - val_loss: 116360.6562 - val_mae: 154.9736 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 96963.3281 - mae: 145.0511 - val_loss: 117467.0703 - val_mae: 155.4281 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 96781.2109 - mae: 144.9663 - val_loss: 116469.7734 - val_mae: 154.3208 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 96836.7109 - mae: 144.7222 - val_loss: 118843.0312 - val_mae: 155.8442 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 96789.5703 - mae: 144.6244 - val_loss: 116536.0547 - val_mae: 154.7917 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 96842.1484 - mae: 144.8048 - val_loss: 116437.4609 - val_mae: 154.4288 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 96705.5859 - mae: 144.6729 - val_loss: 115437.0859 - val_mae: 153.4181 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 96723.1797 - mae: 144.6547 - val_loss: 116983.4844 - val_mae: 155.3583 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 96761.9219 - mae: 144.7688 - val_loss: 117670.6953 - val_mae: 155.7509 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 96758.0859 - mae: 144.6179 - val_loss: 116467.6875 - val_mae: 155.2896 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 96770.2344 - mae: 144.7951 - val_loss: 118648.8906 - val_mae: 156.2509 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 96644.4141 - mae: 144.5340 - val_loss: 116877.5000 - val_mae: 154.7639 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 96690.7578 - mae: 144.6089 - val_loss: 116176.7344 - val_mae: 153.9585 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:15:31,561]\u001b[0m Trial 40 finished with value: 116176.7490466563 and parameters: {'feature_dim': 43, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1667773.8750 - mae: 724.5375 - val_loss: 1294067.3750 - val_mae: 588.6948 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 1364982.2500 - mae: 618.1514 - val_loss: 980364.9375 - val_mae: 490.2573 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 992512.8125 - mae: 503.0139 - val_loss: 672726.3125 - val_mae: 388.6548 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 668639.6875 - mae: 399.5430 - val_loss: 441507.5625 - val_mae: 314.3871 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 933us/step - loss: 433018.7812 - mae: 321.4356 - val_loss: 293153.3438 - val_mae: 263.0291 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 280573.6562 - mae: 262.8600 - val_loss: 212790.2812 - val_mae: 226.6550 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 193633.5156 - mae: 223.3988 - val_loss: 163065.5625 - val_mae: 207.5125 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 150261.8906 - mae: 198.5934 - val_loss: 145585.2344 - val_mae: 184.5307 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 129741.4453 - mae: 183.5293 - val_loss: 135042.0781 - val_mae: 183.8168 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 121015.6797 - mae: 175.1430 - val_loss: 138499.0938 - val_mae: 173.4717 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 115587.3047 - mae: 169.1453 - val_loss: 130476.3672 - val_mae: 171.8981 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 113537.0078 - mae: 165.9492 - val_loss: 134372.6250 - val_mae: 171.0792 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 111356.7500 - mae: 163.6055 - val_loss: 127381.8359 - val_mae: 171.4581 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 931us/step - loss: 110112.8672 - mae: 161.8062 - val_loss: 144614.5469 - val_mae: 177.5417 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 108964.2969 - mae: 160.4090 - val_loss: 125225.6172 - val_mae: 169.5840 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 108614.7344 - mae: 160.0820 - val_loss: 132580.2031 - val_mae: 169.1901 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 930us/step - loss: 107286.1094 - mae: 158.1992 - val_loss: 128620.6953 - val_mae: 167.2121 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 107031.9688 - mae: 157.9433 - val_loss: 126687.5234 - val_mae: 166.3320 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 106252.8203 - mae: 156.9661 - val_loss: 126280.2500 - val_mae: 163.1419 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 104804.5938 - mae: 155.5233 - val_loss: 125649.3906 - val_mae: 163.6194 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 104751.1094 - mae: 155.3743 - val_loss: 126582.2188 - val_mae: 164.6901 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 105109.6406 - mae: 155.7278 - val_loss: 124496.5156 - val_mae: 162.8722 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 103777.3750 - mae: 154.3031 - val_loss: 133510.0938 - val_mae: 168.5807 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 103240.5078 - mae: 153.9291 - val_loss: 121386.2031 - val_mae: 163.7307 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 103742.6484 - mae: 153.6750 - val_loss: 122791.0703 - val_mae: 161.7476 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 103003.6797 - mae: 153.1129 - val_loss: 118369.4219 - val_mae: 160.5778 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 928us/step - loss: 103038.9844 - mae: 153.1231 - val_loss: 121009.3594 - val_mae: 159.1091 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 102582.3203 - mae: 152.5936 - val_loss: 128686.0312 - val_mae: 169.5899 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 102855.4688 - mae: 153.0733 - val_loss: 129171.5234 - val_mae: 168.3351 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 102291.8750 - mae: 152.2484 - val_loss: 127397.9141 - val_mae: 166.1825 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 102500.0938 - mae: 152.2024 - val_loss: 125541.1406 - val_mae: 161.9592 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 102118.2422 - mae: 152.3466 - val_loss: 127173.4688 - val_mae: 162.7460 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 931us/step - loss: 102041.8359 - mae: 152.3850 - val_loss: 122642.3984 - val_mae: 159.0659 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 930us/step - loss: 101907.7500 - mae: 151.7454 - val_loss: 121598.8125 - val_mae: 159.3784 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 101702.8828 - mae: 151.2710 - val_loss: 117650.7578 - val_mae: 157.3467 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 101399.7422 - mae: 150.7885 - val_loss: 119660.0625 - val_mae: 159.1704 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 101418.0547 - mae: 151.1483 - val_loss: 122908.8359 - val_mae: 160.4637 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 101280.4297 - mae: 150.9132 - val_loss: 119720.3828 - val_mae: 159.6323 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 101049.0625 - mae: 150.9238 - val_loss: 120528.5859 - val_mae: 157.8103 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 930us/step - loss: 100779.4375 - mae: 150.1782 - val_loss: 116539.3594 - val_mae: 155.7714 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 100454.1406 - mae: 150.0264 - val_loss: 120672.8047 - val_mae: 157.4183 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 100617.9141 - mae: 149.3736 - val_loss: 115700.6562 - val_mae: 154.6906 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 100790.5234 - mae: 149.9181 - val_loss: 132189.1875 - val_mae: 173.7833 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 100451.3828 - mae: 149.8651 - val_loss: 113233.3828 - val_mae: 153.1810 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 100239.6562 - mae: 149.2483 - val_loss: 119659.1328 - val_mae: 156.2631 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 99957.2500 - mae: 149.5134 - val_loss: 121412.5000 - val_mae: 158.5246 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 933us/step - loss: 100029.1641 - mae: 149.3734 - val_loss: 117076.6562 - val_mae: 158.2366 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 100017.6484 - mae: 149.4919 - val_loss: 118878.7969 - val_mae: 155.8181 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 99713.8281 - mae: 148.8227 - val_loss: 114306.7188 - val_mae: 154.1801 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 99672.1719 - mae: 149.2377 - val_loss: 116254.3750 - val_mae: 154.2481 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:16:23,848]\u001b[0m Trial 41 finished with value: 116254.38372549451 and parameters: {'feature_dim': 32, 'output_dim': 12, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1682110.5000 - mae: 727.3613 - val_loss: 1318737.8750 - val_mae: 597.1944 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 1406992.5000 - mae: 630.6986 - val_loss: 1026745.5000 - val_mae: 504.1632 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 1054689.6250 - mae: 522.2861 - val_loss: 728631.6250 - val_mae: 406.8613 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 734080.5625 - mae: 420.9259 - val_loss: 492011.7812 - val_mae: 333.8435 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 488090.9062 - mae: 339.5117 - val_loss: 330895.8438 - val_mae: 273.5642 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 321048.3125 - mae: 277.9589 - val_loss: 237928.1094 - val_mae: 235.7001 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 219574.2500 - mae: 235.3334 - val_loss: 182170.1719 - val_mae: 219.5519 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 165030.3750 - mae: 207.5801 - val_loss: 155720.9531 - val_mae: 190.6420 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 137356.7969 - mae: 189.0612 - val_loss: 142932.2500 - val_mae: 186.9411 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 125350.6719 - mae: 179.0256 - val_loss: 140871.0469 - val_mae: 175.2689 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 118888.9609 - mae: 171.7163 - val_loss: 133059.6094 - val_mae: 176.4780 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 115928.6094 - mae: 168.0157 - val_loss: 139540.0938 - val_mae: 173.6310 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 113754.3750 - mae: 165.3490 - val_loss: 127657.9141 - val_mae: 172.8194 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 112562.3984 - mae: 163.4634 - val_loss: 140642.3906 - val_mae: 174.4450 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 111246.6172 - mae: 161.6821 - val_loss: 125764.5156 - val_mae: 167.8589 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 110800.8047 - mae: 161.3319 - val_loss: 138350.0000 - val_mae: 172.5645 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 109957.3750 - mae: 159.9679 - val_loss: 133913.5000 - val_mae: 172.2282 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 109454.1875 - mae: 159.6121 - val_loss: 127527.0234 - val_mae: 168.8818 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 108729.7656 - mae: 159.0370 - val_loss: 130380.1328 - val_mae: 169.2129 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 107046.0938 - mae: 157.5612 - val_loss: 129152.6250 - val_mae: 166.3921 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 106459.1562 - mae: 156.9051 - val_loss: 126849.7891 - val_mae: 165.1561 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 106096.9609 - mae: 156.4755 - val_loss: 126230.4922 - val_mae: 166.4471 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 104855.9219 - mae: 155.2311 - val_loss: 130315.4375 - val_mae: 166.1855 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 104163.8828 - mae: 154.3164 - val_loss: 122080.1016 - val_mae: 167.8710 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 104492.2500 - mae: 154.3304 - val_loss: 124170.0234 - val_mae: 165.5125 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 103234.6797 - mae: 152.9199 - val_loss: 118241.2891 - val_mae: 164.6008 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 103148.3672 - mae: 152.9025 - val_loss: 122415.8828 - val_mae: 166.9918 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 102941.3906 - mae: 152.5794 - val_loss: 127622.0703 - val_mae: 170.4805 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 102882.9766 - mae: 152.5460 - val_loss: 128520.2344 - val_mae: 168.7039 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 102295.6406 - mae: 151.7979 - val_loss: 127908.2656 - val_mae: 167.0523 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 102435.8906 - mae: 151.4952 - val_loss: 123773.7344 - val_mae: 163.5578 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 102250.6562 - mae: 151.5013 - val_loss: 127636.9766 - val_mae: 163.7093 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 102042.4688 - mae: 151.6813 - val_loss: 120617.7578 - val_mae: 158.9939 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 101797.3203 - mae: 150.6234 - val_loss: 121905.1016 - val_mae: 161.2683 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 101604.8125 - mae: 150.4829 - val_loss: 115506.1016 - val_mae: 156.7971 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 101233.5156 - mae: 149.9611 - val_loss: 117664.8750 - val_mae: 156.8216 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 101264.9219 - mae: 150.2820 - val_loss: 120894.5391 - val_mae: 159.2507 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 101366.0547 - mae: 150.5005 - val_loss: 117793.7031 - val_mae: 158.8294 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 101133.8203 - mae: 150.1934 - val_loss: 118175.0234 - val_mae: 158.9247 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 100690.6406 - mae: 149.5594 - val_loss: 116078.7031 - val_mae: 157.4613 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 100292.3828 - mae: 149.1015 - val_loss: 119636.7500 - val_mae: 159.3015 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 100424.6406 - mae: 148.8073 - val_loss: 114964.2891 - val_mae: 156.5524 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 100754.2734 - mae: 149.1995 - val_loss: 133395.1094 - val_mae: 174.6878 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 100238.7969 - mae: 149.0541 - val_loss: 114972.9219 - val_mae: 156.6233 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 100262.9297 - mae: 148.6010 - val_loss: 120077.6016 - val_mae: 158.1449 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 99787.2500 - mae: 148.5621 - val_loss: 122381.5000 - val_mae: 159.7878 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 99886.8047 - mae: 148.4057 - val_loss: 116589.1016 - val_mae: 156.4484 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 99842.6875 - mae: 148.3447 - val_loss: 118170.5625 - val_mae: 154.4278 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 99649.2266 - mae: 147.8472 - val_loss: 114519.6797 - val_mae: 154.8279 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 99529.5234 - mae: 148.1453 - val_loss: 116900.2344 - val_mae: 155.8026 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:17:17,084]\u001b[0m Trial 42 finished with value: 116900.25626711985 and parameters: {'feature_dim': 34, 'output_dim': 12, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1667701.2500 - mae: 718.7022 - val_loss: 1286938.2500 - val_mae: 587.5233 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 1345527.0000 - mae: 613.6288 - val_loss: 953813.0000 - val_mae: 484.0072 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 953617.9375 - mae: 491.0782 - val_loss: 635705.8750 - val_mae: 378.0688 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 623439.5625 - mae: 385.0709 - val_loss: 406984.3750 - val_mae: 305.2650 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 389639.4688 - mae: 305.4972 - val_loss: 264768.3125 - val_mae: 250.4648 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 246484.2031 - mae: 247.4694 - val_loss: 193387.0156 - val_mae: 214.6857 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 173320.9219 - mae: 212.8017 - val_loss: 159423.0000 - val_mae: 207.2021 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 140285.6250 - mae: 192.8668 - val_loss: 141461.7500 - val_mae: 185.3267 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 124381.0625 - mae: 178.8748 - val_loss: 131679.1406 - val_mae: 178.0086 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 118067.3047 - mae: 171.9291 - val_loss: 136127.5469 - val_mae: 172.8856 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 113519.2188 - mae: 166.4020 - val_loss: 131936.1562 - val_mae: 173.4508 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 111386.6172 - mae: 163.5703 - val_loss: 132410.1719 - val_mae: 171.7692 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 109124.3203 - mae: 161.3102 - val_loss: 124571.5859 - val_mae: 167.4369 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 982us/step - loss: 107680.0156 - mae: 159.3712 - val_loss: 135894.0312 - val_mae: 173.5697 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 106392.3125 - mae: 158.2697 - val_loss: 118681.3750 - val_mae: 164.6398 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 106180.0469 - mae: 158.1370 - val_loss: 127905.5078 - val_mae: 166.7229 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 104867.4531 - mae: 156.3564 - val_loss: 122721.3516 - val_mae: 163.9487 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 104849.5938 - mae: 156.3642 - val_loss: 119058.7969 - val_mae: 162.4782 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 981us/step - loss: 104631.8203 - mae: 156.1464 - val_loss: 120528.7109 - val_mae: 162.4142 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 103530.1016 - mae: 154.6793 - val_loss: 120975.2188 - val_mae: 160.7721 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 102880.5469 - mae: 154.0955 - val_loss: 117923.3828 - val_mae: 160.4477 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 103418.8828 - mae: 154.3065 - val_loss: 120636.0391 - val_mae: 159.8254 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 102268.7656 - mae: 153.1956 - val_loss: 131665.8906 - val_mae: 168.6105 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 101721.1562 - mae: 152.3399 - val_loss: 115627.7734 - val_mae: 160.0119 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 102015.6172 - mae: 152.6167 - val_loss: 117041.7969 - val_mae: 163.0885 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 101348.9375 - mae: 152.0556 - val_loss: 113691.5469 - val_mae: 157.6144 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 101332.7344 - mae: 151.7047 - val_loss: 114401.7344 - val_mae: 155.2033 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 100937.0703 - mae: 151.3035 - val_loss: 124620.3125 - val_mae: 168.3011 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 100932.6172 - mae: 151.2775 - val_loss: 124033.8594 - val_mae: 164.6859 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 100551.4141 - mae: 150.6370 - val_loss: 124458.6797 - val_mae: 166.0591 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 100821.3359 - mae: 150.8360 - val_loss: 118792.6406 - val_mae: 158.2831 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 100530.4609 - mae: 150.5736 - val_loss: 121032.4375 - val_mae: 160.0975 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 100095.2812 - mae: 150.4688 - val_loss: 117079.2422 - val_mae: 154.8348 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 100036.0625 - mae: 149.3954 - val_loss: 115215.0547 - val_mae: 155.1161 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 100071.5156 - mae: 149.8558 - val_loss: 111244.1875 - val_mae: 153.8754 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 99636.7031 - mae: 148.8724 - val_loss: 114392.0000 - val_mae: 154.6151 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 99905.1094 - mae: 149.4557 - val_loss: 114993.9297 - val_mae: 155.4561 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 99692.8125 - mae: 149.6082 - val_loss: 112571.7422 - val_mae: 153.2040 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 99490.1719 - mae: 149.2490 - val_loss: 114427.2969 - val_mae: 154.3367 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 98955.3672 - mae: 148.2681 - val_loss: 115086.9141 - val_mae: 156.1897 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 98757.4375 - mae: 148.3028 - val_loss: 114245.7969 - val_mae: 154.0992 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 99004.0000 - mae: 148.1955 - val_loss: 110735.1016 - val_mae: 150.6369 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 99251.0000 - mae: 148.2507 - val_loss: 126812.7266 - val_mae: 169.6517 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 99008.0625 - mae: 148.3279 - val_loss: 112742.9297 - val_mae: 151.5903 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 98930.8438 - mae: 148.0152 - val_loss: 115708.6719 - val_mae: 153.7549 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 981us/step - loss: 98497.0391 - mae: 147.9887 - val_loss: 117171.0078 - val_mae: 155.3642 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 98602.8203 - mae: 147.9700 - val_loss: 112817.0312 - val_mae: 153.9234 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 98699.3906 - mae: 147.9733 - val_loss: 114156.9297 - val_mae: 152.9593 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 98320.9375 - mae: 147.0106 - val_loss: 113804.9922 - val_mae: 152.8844 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 98577.8906 - mae: 147.7279 - val_loss: 113058.7656 - val_mae: 152.3067 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:18:11,439]\u001b[0m Trial 43 finished with value: 113058.79650859063 and parameters: {'feature_dim': 40, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "[TabNet]: 25 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 6s 4ms/step - loss: 1495486.0000 - mae: 662.6555 - val_loss: 959601.8125 - val_mae: 480.7110 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 876628.8750 - mae: 511.7337 - val_loss: 489789.1250 - val_mae: 358.4229 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 452584.0625 - mae: 354.1067 - val_loss: 298937.0625 - val_mae: 298.6349 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 288895.9375 - mae: 292.6854 - val_loss: 219998.8750 - val_mae: 248.9715 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 233385.5781 - mae: 265.5577 - val_loss: 204680.3594 - val_mae: 245.1262 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 202163.4062 - mae: 247.6231 - val_loss: 213493.5781 - val_mae: 243.3323 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 190672.6562 - mae: 237.1986 - val_loss: 175079.8438 - val_mae: 213.3220 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 177241.6562 - mae: 224.9591 - val_loss: 172129.0469 - val_mae: 205.9807 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 172124.5469 - mae: 220.1442 - val_loss: 176752.9062 - val_mae: 210.4108 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 165832.7969 - mae: 213.9245 - val_loss: 155978.0469 - val_mae: 193.1771 - lr: 0.0010\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 3s 3ms/step - loss: 160800.4062 - mae: 209.9053 - val_loss: 160317.8594 - val_mae: 195.1093 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 160388.8750 - mae: 208.8467 - val_loss: 160582.7344 - val_mae: 192.3350 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 157012.3750 - mae: 206.0845 - val_loss: 170740.7344 - val_mae: 199.6673 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 156752.5938 - mae: 206.1855 - val_loss: 165140.9219 - val_mae: 192.1489 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 152028.0312 - mae: 201.9709 - val_loss: 152307.1562 - val_mae: 189.0841 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 151298.9219 - mae: 201.4394 - val_loss: 166535.7188 - val_mae: 194.6704 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 143586.3281 - mae: 198.8112 - val_loss: 138508.7031 - val_mae: 182.7218 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 131965.1719 - mae: 188.2191 - val_loss: 146746.5781 - val_mae: 182.1819 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 126167.5391 - mae: 180.8771 - val_loss: 139537.8281 - val_mae: 175.1815 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 123135.1406 - mae: 177.7742 - val_loss: 147763.0781 - val_mae: 183.8071 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 123059.4219 - mae: 177.4918 - val_loss: 138088.9062 - val_mae: 174.7215 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 122303.6172 - mae: 176.1470 - val_loss: 143032.3438 - val_mae: 181.4926 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 119351.5312 - mae: 172.6481 - val_loss: 149099.8594 - val_mae: 178.5063 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 117525.5625 - mae: 170.7751 - val_loss: 133758.2031 - val_mae: 174.2209 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 117988.2891 - mae: 171.2256 - val_loss: 142685.5312 - val_mae: 174.6798 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 116066.5156 - mae: 169.4142 - val_loss: 129567.8047 - val_mae: 165.7022 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 114110.0938 - mae: 167.2801 - val_loss: 124338.0312 - val_mae: 163.7722 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 112517.7266 - mae: 164.9654 - val_loss: 140107.6562 - val_mae: 177.6689 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 112335.9375 - mae: 164.5421 - val_loss: 157759.7031 - val_mae: 189.9254 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 111289.5156 - mae: 163.4855 - val_loss: 130502.1797 - val_mae: 164.8911 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 111423.4297 - mae: 163.5689 - val_loss: 135361.5000 - val_mae: 168.5403 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 111320.9297 - mae: 162.6110 - val_loss: 134789.6562 - val_mae: 169.1136 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 111090.4219 - mae: 163.3462 - val_loss: 130279.6328 - val_mae: 168.3422 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 110321.8281 - mae: 161.2301 - val_loss: 128854.2109 - val_mae: 167.2851 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 109821.1328 - mae: 161.3169 - val_loss: 128207.5078 - val_mae: 161.8820 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 109831.0391 - mae: 160.3458 - val_loss: 128791.1250 - val_mae: 163.9081 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 109711.8750 - mae: 161.0596 - val_loss: 138478.1250 - val_mae: 175.2678 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 106653.6484 - mae: 154.6140 - val_loss: 129631.7812 - val_mae: 161.8461 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 105957.6406 - mae: 153.6281 - val_loss: 130520.4609 - val_mae: 162.6459 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 105696.9844 - mae: 153.5319 - val_loss: 127872.2656 - val_mae: 160.7200 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 105774.2188 - mae: 153.6297 - val_loss: 132266.8438 - val_mae: 163.5025 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 105659.4453 - mae: 152.9742 - val_loss: 128135.0938 - val_mae: 161.5255 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 105625.7266 - mae: 153.0866 - val_loss: 127913.9844 - val_mae: 161.1951 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 105591.8359 - mae: 152.9208 - val_loss: 129152.3984 - val_mae: 162.5218 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 105531.5938 - mae: 153.0072 - val_loss: 128518.0312 - val_mae: 161.1614 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 105523.5078 - mae: 153.0306 - val_loss: 128781.1406 - val_mae: 162.2506 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 3s 3ms/step - loss: 105388.0234 - mae: 152.9881 - val_loss: 129844.2656 - val_mae: 162.3521 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:20:37,764]\u001b[0m Trial 44 finished with value: 129844.27710242853 and parameters: {'feature_dim': 37, 'output_dim': 12, 'num_decision_steps': 4}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1700811.7500 - mae: 732.4429 - val_loss: 1363461.1250 - val_mae: 612.1454 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 925us/step - loss: 1505044.2500 - mae: 659.5536 - val_loss: 1151541.7500 - val_mae: 540.5840 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 1238818.5000 - mae: 577.6931 - val_loss: 912187.6250 - val_mae: 465.8190 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 928us/step - loss: 965439.1875 - mae: 492.9109 - val_loss: 689610.8750 - val_mae: 398.1249 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 720605.0000 - mae: 416.1806 - val_loss: 506992.5312 - val_mae: 335.8613 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 933us/step - loss: 521488.5000 - mae: 351.3719 - val_loss: 368831.9688 - val_mae: 289.1576 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 923us/step - loss: 371637.3438 - mae: 297.5474 - val_loss: 273110.6250 - val_mae: 253.0229 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 268659.3438 - mae: 257.3392 - val_loss: 213065.9531 - val_mae: 229.3454 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 201093.5156 - mae: 226.6477 - val_loss: 177021.1406 - val_mae: 222.2903 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 931us/step - loss: 160992.4219 - mae: 204.4273 - val_loss: 160780.2031 - val_mae: 192.8681 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 138693.9531 - mae: 190.1092 - val_loss: 146135.3438 - val_mae: 185.0421 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 127858.3359 - mae: 180.7836 - val_loss: 145499.2500 - val_mae: 178.4954 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 120742.8984 - mae: 174.5336 - val_loss: 136218.8906 - val_mae: 182.7429 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 929us/step - loss: 116816.5547 - mae: 169.5978 - val_loss: 140861.1875 - val_mae: 173.8152 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 114362.3281 - mae: 166.2506 - val_loss: 132083.0781 - val_mae: 173.3333 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 113024.8281 - mae: 164.9120 - val_loss: 135303.1875 - val_mae: 170.7217 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 111360.7578 - mae: 162.6289 - val_loss: 140442.6406 - val_mae: 175.5153 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 111409.6641 - mae: 162.6447 - val_loss: 128200.5625 - val_mae: 167.0621 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 109934.7734 - mae: 161.0898 - val_loss: 134302.2969 - val_mae: 168.0701 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 108791.0781 - mae: 159.8242 - val_loss: 130639.5859 - val_mae: 168.1425 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 108462.0156 - mae: 159.6421 - val_loss: 131962.6719 - val_mae: 168.4714 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 108297.9375 - mae: 158.8627 - val_loss: 127160.3125 - val_mae: 164.8532 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 930us/step - loss: 106689.2891 - mae: 157.5347 - val_loss: 135974.1406 - val_mae: 170.8249 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 926us/step - loss: 106003.7422 - mae: 156.9123 - val_loss: 120907.5391 - val_mae: 162.7118 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 925us/step - loss: 105990.5547 - mae: 156.7025 - val_loss: 126209.9844 - val_mae: 162.7275 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 928us/step - loss: 104717.0859 - mae: 155.2076 - val_loss: 119641.2422 - val_mae: 161.0311 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 104253.9141 - mae: 154.7638 - val_loss: 121716.3594 - val_mae: 159.6478 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 927us/step - loss: 103971.9062 - mae: 154.6819 - val_loss: 123015.3438 - val_mae: 163.6634 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 103427.7891 - mae: 154.0053 - val_loss: 128252.7578 - val_mae: 165.8839 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 103118.5078 - mae: 153.1863 - val_loss: 124012.9219 - val_mae: 162.7256 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 103121.9141 - mae: 153.1996 - val_loss: 122136.9922 - val_mae: 158.0677 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 102698.0469 - mae: 152.6736 - val_loss: 127217.3906 - val_mae: 162.4640 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 102647.8281 - mae: 153.2552 - val_loss: 119325.1484 - val_mae: 156.2366 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 102321.7422 - mae: 152.4782 - val_loss: 118097.9141 - val_mae: 156.4189 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 102088.3125 - mae: 151.7415 - val_loss: 116091.4609 - val_mae: 155.3108 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 102043.1797 - mae: 151.8255 - val_loss: 118256.7344 - val_mae: 157.9208 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 101833.1562 - mae: 151.6603 - val_loss: 119679.4062 - val_mae: 157.8645 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 101684.0781 - mae: 151.7564 - val_loss: 117852.4297 - val_mae: 158.6169 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 101410.1719 - mae: 151.3850 - val_loss: 117548.5234 - val_mae: 156.0434 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 101075.3203 - mae: 150.8698 - val_loss: 115600.6016 - val_mae: 154.9242 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 100673.3672 - mae: 150.4378 - val_loss: 121403.2891 - val_mae: 158.0940 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 100913.6250 - mae: 150.3791 - val_loss: 114145.5078 - val_mae: 154.4990 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 101064.1094 - mae: 150.5400 - val_loss: 128904.1016 - val_mae: 169.5448 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 100750.9219 - mae: 150.4851 - val_loss: 112966.6016 - val_mae: 152.1661 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 100577.5391 - mae: 149.7887 - val_loss: 118968.2109 - val_mae: 156.8441 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 100299.2344 - mae: 149.9771 - val_loss: 120771.8828 - val_mae: 156.8489 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 100438.3438 - mae: 149.9786 - val_loss: 116227.4297 - val_mae: 155.8040 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 100518.1250 - mae: 150.0340 - val_loss: 116950.6562 - val_mae: 152.3881 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 100390.8672 - mae: 149.5815 - val_loss: 113467.8125 - val_mae: 152.0255 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 100157.5000 - mae: 149.6651 - val_loss: 114411.8438 - val_mae: 152.5984 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:21:29,796]\u001b[0m Trial 45 finished with value: 114411.85454144639 and parameters: {'feature_dim': 32, 'output_dim': 12, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1685677.5000 - mae: 721.5212 - val_loss: 1341251.3750 - val_mae: 604.8870 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1467980.7500 - mae: 649.0996 - val_loss: 1109239.2500 - val_mae: 530.0415 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1178856.8750 - mae: 560.0180 - val_loss: 853230.5000 - val_mae: 442.8607 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 891104.8750 - mae: 469.9623 - val_loss: 624577.7500 - val_mae: 374.5605 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 642906.2500 - mae: 390.1618 - val_loss: 443151.0938 - val_mae: 312.6898 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 448479.8750 - mae: 323.6688 - val_loss: 314290.0312 - val_mae: 264.6147 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 307939.9062 - mae: 271.7786 - val_loss: 229527.7031 - val_mae: 237.0233 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 217066.4688 - mae: 232.4294 - val_loss: 175527.7188 - val_mae: 206.0049 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 163081.9531 - mae: 204.1557 - val_loss: 149266.8125 - val_mae: 191.8652 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 136372.8906 - mae: 187.2142 - val_loss: 142346.6250 - val_mae: 180.0874 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 121729.8281 - mae: 175.9746 - val_loss: 135253.6562 - val_mae: 179.2882 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 114294.5078 - mae: 168.8815 - val_loss: 129247.5703 - val_mae: 169.8773 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109497.9375 - mae: 163.7334 - val_loss: 125600.2109 - val_mae: 169.2739 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107192.6328 - mae: 160.2844 - val_loss: 133643.2812 - val_mae: 171.6930 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105742.0000 - mae: 158.2352 - val_loss: 117661.4141 - val_mae: 160.7719 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 104936.6875 - mae: 157.1476 - val_loss: 122244.8203 - val_mae: 161.7302 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104346.0938 - mae: 156.1057 - val_loss: 119152.4766 - val_mae: 158.8065 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104287.1719 - mae: 155.5233 - val_loss: 121807.0312 - val_mae: 165.8090 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103987.4531 - mae: 155.2691 - val_loss: 117973.6953 - val_mae: 158.8560 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102673.3828 - mae: 153.8847 - val_loss: 119959.8281 - val_mae: 158.2875 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 102586.6719 - mae: 153.1658 - val_loss: 118870.7578 - val_mae: 160.2514 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 102704.3438 - mae: 153.0586 - val_loss: 117330.7891 - val_mae: 158.4172 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 101644.0938 - mae: 152.1579 - val_loss: 121176.0703 - val_mae: 159.4748 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101158.7891 - mae: 151.3559 - val_loss: 118565.4219 - val_mae: 162.5423 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101511.0781 - mae: 151.0109 - val_loss: 116103.3594 - val_mae: 155.8723 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 100437.1250 - mae: 150.1338 - val_loss: 112134.7969 - val_mae: 155.9880 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100570.9688 - mae: 150.0833 - val_loss: 111922.0703 - val_mae: 152.6546 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100373.8906 - mae: 149.7079 - val_loss: 118762.7031 - val_mae: 159.4361 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100205.8438 - mae: 149.4140 - val_loss: 124499.2266 - val_mae: 164.8729 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99784.9219 - mae: 149.0447 - val_loss: 118332.6797 - val_mae: 158.6266 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100110.0156 - mae: 149.0215 - val_loss: 116044.2812 - val_mae: 156.0043 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99628.2109 - mae: 148.2615 - val_loss: 116573.3047 - val_mae: 155.8178 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99588.0391 - mae: 148.9680 - val_loss: 113197.3516 - val_mae: 152.2514 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99236.1719 - mae: 147.6820 - val_loss: 114150.4453 - val_mae: 154.1801 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99430.9453 - mae: 148.1252 - val_loss: 113065.4766 - val_mae: 154.3133 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99032.2344 - mae: 147.4643 - val_loss: 112531.7812 - val_mae: 152.6493 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98963.2188 - mae: 147.4469 - val_loss: 115102.1797 - val_mae: 156.0542 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96270.5391 - mae: 143.4174 - val_loss: 111567.0625 - val_mae: 151.6517 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95918.7734 - mae: 143.2536 - val_loss: 112027.1562 - val_mae: 151.5738 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95675.9141 - mae: 143.2370 - val_loss: 111437.6797 - val_mae: 150.2921 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95696.4297 - mae: 142.9476 - val_loss: 113162.4062 - val_mae: 152.3751 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95645.5078 - mae: 142.6868 - val_loss: 111659.5859 - val_mae: 152.0874 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95655.4297 - mae: 143.0540 - val_loss: 111598.5312 - val_mae: 151.3227 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95596.5000 - mae: 143.0309 - val_loss: 111429.2891 - val_mae: 150.9923 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95540.3203 - mae: 142.7223 - val_loss: 111840.8672 - val_mae: 151.6923 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95548.5781 - mae: 143.0008 - val_loss: 112149.8359 - val_mae: 151.9513 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95559.4297 - mae: 142.8600 - val_loss: 111832.0234 - val_mae: 151.8341 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95539.2422 - mae: 142.8704 - val_loss: 113297.4688 - val_mae: 153.3197 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95443.1953 - mae: 142.8714 - val_loss: 111653.9609 - val_mae: 151.4073 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95470.3672 - mae: 142.7889 - val_loss: 111760.6406 - val_mae: 151.5166 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:22:25,809]\u001b[0m Trial 46 finished with value: 111760.60746934019 and parameters: {'feature_dim': 42, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "[TabNet]: 35 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1641308.3750 - mae: 704.0164 - val_loss: 1245645.5000 - val_mae: 586.2399 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1282761.2500 - mae: 611.7930 - val_loss: 914934.6250 - val_mae: 512.9524 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 923237.5000 - mae: 529.2930 - val_loss: 700816.9375 - val_mae: 482.8302 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 724712.9375 - mae: 492.8354 - val_loss: 622709.5625 - val_mae: 478.8162 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 642218.0000 - mae: 473.8671 - val_loss: 587279.4375 - val_mae: 463.3617 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 598915.5000 - mae: 459.2209 - val_loss: 660074.4375 - val_mae: 504.9267 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 587612.0000 - mae: 457.5646 - val_loss: 639012.2500 - val_mae: 491.8479 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 545676.8750 - mae: 439.5520 - val_loss: 547936.3125 - val_mae: 451.6935 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 534085.6875 - mae: 435.9545 - val_loss: 595565.1250 - val_mae: 476.3998 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 516090.7188 - mae: 428.0740 - val_loss: 638859.4375 - val_mae: 496.4947 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 509939.1875 - mae: 425.7799 - val_loss: 563460.7500 - val_mae: 458.3730 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 503673.0000 - mae: 423.2261 - val_loss: 595770.4375 - val_mae: 476.1217 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 502275.5938 - mae: 422.5526 - val_loss: 541703.6875 - val_mae: 453.3091 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 493675.6562 - mae: 418.8747 - val_loss: 555093.4375 - val_mae: 459.4846 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 495326.9062 - mae: 419.6274 - val_loss: 647228.0625 - val_mae: 496.4539 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 491333.6875 - mae: 418.9461 - val_loss: 573247.4375 - val_mae: 461.5570 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 489765.0938 - mae: 417.5658 - val_loss: 557258.9375 - val_mae: 458.9260 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 489075.3750 - mae: 417.4491 - val_loss: 569860.7500 - val_mae: 467.0893 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 485964.7812 - mae: 416.6615 - val_loss: 582044.1875 - val_mae: 476.8736 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 484159.7500 - mae: 415.1280 - val_loss: 568663.6875 - val_mae: 465.8670 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 484525.7812 - mae: 416.2224 - val_loss: 651006.5000 - val_mae: 498.0936 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 485057.7812 - mae: 416.1318 - val_loss: 562767.9375 - val_mae: 463.1253 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 484401.0000 - mae: 415.9498 - val_loss: 529187.0000 - val_mae: 441.5667 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 483615.0000 - mae: 415.4187 - val_loss: 581366.6250 - val_mae: 472.1554 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 482996.8125 - mae: 415.4514 - val_loss: 565262.0000 - val_mae: 461.9125 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 479873.0938 - mae: 413.6695 - val_loss: 586514.0000 - val_mae: 473.6321 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 480652.7812 - mae: 414.6514 - val_loss: 553941.2500 - val_mae: 456.4238 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 480030.8125 - mae: 414.2249 - val_loss: 557800.0000 - val_mae: 458.9677 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 480625.3750 - mae: 413.9929 - val_loss: 548859.9375 - val_mae: 459.6945 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 478878.8125 - mae: 413.7944 - val_loss: 545272.1875 - val_mae: 454.4655 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 479761.7500 - mae: 413.8740 - val_loss: 582730.8750 - val_mae: 476.7861 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 478356.9062 - mae: 413.4507 - val_loss: 552536.1875 - val_mae: 455.2107 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 478586.8125 - mae: 412.9746 - val_loss: 631784.5625 - val_mae: 495.5185 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 473127.6250 - mae: 411.9526 - val_loss: 551506.0000 - val_mae: 458.4121 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 470708.0938 - mae: 410.3187 - val_loss: 552575.8750 - val_mae: 458.5154 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 470681.4062 - mae: 410.0220 - val_loss: 553754.6250 - val_mae: 459.9581 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 470393.7812 - mae: 409.8534 - val_loss: 557168.6250 - val_mae: 462.0277 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 470232.2188 - mae: 410.2162 - val_loss: 560831.6250 - val_mae: 463.4944 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 470209.8750 - mae: 409.9478 - val_loss: 569164.8125 - val_mae: 467.9351 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 470147.5625 - mae: 409.9796 - val_loss: 558034.6875 - val_mae: 462.0678 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 470038.0312 - mae: 410.0145 - val_loss: 550045.6875 - val_mae: 457.6128 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 469764.6875 - mae: 409.7694 - val_loss: 560795.0625 - val_mae: 463.7667 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 470089.8125 - mae: 409.9714 - val_loss: 551992.5625 - val_mae: 458.8228 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:23:49,060]\u001b[0m Trial 47 finished with value: 551992.7034557706 and parameters: {'feature_dim': 45, 'output_dim': 10, 'num_decision_steps': 2}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1644527.6250 - mae: 713.3152 - val_loss: 1251423.3750 - val_mae: 575.3660 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1292729.2500 - mae: 595.8463 - val_loss: 899933.2500 - val_mae: 462.7916 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 889175.1875 - mae: 469.9687 - val_loss: 583049.6875 - val_mae: 361.2370 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 563664.1250 - mae: 363.9554 - val_loss: 366032.2812 - val_mae: 287.4447 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 346371.0938 - mae: 285.8019 - val_loss: 238883.5938 - val_mae: 237.6061 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 221480.7344 - mae: 233.3558 - val_loss: 181214.5312 - val_mae: 206.3186 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 159780.7969 - mae: 201.6301 - val_loss: 149870.3438 - val_mae: 193.7392 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 132293.6094 - mae: 183.7113 - val_loss: 136773.5781 - val_mae: 174.8661 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 118901.8516 - mae: 172.3204 - val_loss: 127448.3672 - val_mae: 168.8374 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 113381.3828 - mae: 165.7149 - val_loss: 132553.0469 - val_mae: 169.4522 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109042.6016 - mae: 161.0163 - val_loss: 127143.1719 - val_mae: 167.0807 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107771.7578 - mae: 159.5949 - val_loss: 134298.1875 - val_mae: 168.7490 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105805.1016 - mae: 157.2484 - val_loss: 120504.3594 - val_mae: 162.2753 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105284.6406 - mae: 156.0640 - val_loss: 134469.5312 - val_mae: 168.2683 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104403.3516 - mae: 155.0692 - val_loss: 119158.0078 - val_mae: 157.1573 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104363.7422 - mae: 155.0826 - val_loss: 123782.2891 - val_mae: 160.9250 - lr: 0.0010\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103607.6797 - mae: 153.9552 - val_loss: 120973.9453 - val_mae: 157.5539 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103774.4922 - mae: 154.2501 - val_loss: 120666.3750 - val_mae: 159.4394 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104107.0781 - mae: 154.0006 - val_loss: 119568.7812 - val_mae: 155.6236 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103000.5234 - mae: 153.2453 - val_loss: 119115.6406 - val_mae: 157.1707 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103072.7422 - mae: 153.1555 - val_loss: 119427.1328 - val_mae: 158.4760 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103397.0000 - mae: 153.2114 - val_loss: 118814.7578 - val_mae: 153.8911 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102283.5469 - mae: 152.3508 - val_loss: 127886.0859 - val_mae: 162.8310 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102148.2656 - mae: 151.8821 - val_loss: 115931.8438 - val_mae: 160.6085 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102442.4141 - mae: 151.7507 - val_loss: 120208.7344 - val_mae: 156.4827 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101707.5234 - mae: 151.2794 - val_loss: 113419.9531 - val_mae: 153.0732 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101711.7891 - mae: 151.0009 - val_loss: 115887.9531 - val_mae: 152.5733 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101643.2734 - mae: 150.6854 - val_loss: 124873.8516 - val_mae: 164.5961 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101732.5703 - mae: 150.9405 - val_loss: 123484.4453 - val_mae: 162.4094 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101229.7344 - mae: 150.2299 - val_loss: 123129.5703 - val_mae: 160.8255 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101128.7969 - mae: 149.9566 - val_loss: 118410.9297 - val_mae: 154.5393 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100896.8047 - mae: 149.7718 - val_loss: 123075.6484 - val_mae: 158.7186 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100868.8516 - mae: 149.9407 - val_loss: 116651.6172 - val_mae: 152.9136 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100765.8984 - mae: 149.3933 - val_loss: 115736.7109 - val_mae: 151.3591 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100853.6172 - mae: 149.3494 - val_loss: 112444.4609 - val_mae: 150.5955 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100519.3281 - mae: 148.8632 - val_loss: 115630.1172 - val_mae: 153.6871 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100523.1172 - mae: 149.0006 - val_loss: 117072.9219 - val_mae: 154.5447 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100468.5625 - mae: 149.3090 - val_loss: 114681.7812 - val_mae: 153.5976 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100329.3750 - mae: 148.9376 - val_loss: 114118.3438 - val_mae: 153.0202 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99860.5625 - mae: 148.1298 - val_loss: 114359.6953 - val_mae: 153.3099 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99645.1641 - mae: 148.1603 - val_loss: 116554.5781 - val_mae: 155.6790 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99846.3125 - mae: 147.6733 - val_loss: 111201.2109 - val_mae: 151.1454 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100162.1641 - mae: 148.3628 - val_loss: 128489.1250 - val_mae: 169.2242 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99804.8359 - mae: 148.0459 - val_loss: 109078.9453 - val_mae: 149.0599 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99525.4609 - mae: 147.2428 - val_loss: 114802.1875 - val_mae: 150.0299 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99393.4297 - mae: 147.8812 - val_loss: 116616.4531 - val_mae: 153.4097 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99318.0312 - mae: 147.6130 - val_loss: 112692.8359 - val_mae: 152.3580 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99332.1953 - mae: 147.6193 - val_loss: 114768.5625 - val_mae: 150.0608 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99111.3906 - mae: 146.9516 - val_loss: 112481.6328 - val_mae: 151.7073 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99221.8594 - mae: 147.6540 - val_loss: 112237.0703 - val_mae: 149.6124 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:24:48,733]\u001b[0m Trial 48 finished with value: 112237.09582387916 and parameters: {'feature_dim': 50, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "[TabNet]: 32 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 5s 3ms/step - loss: 1573831.7500 - mae: 720.9010 - val_loss: 1116358.1250 - val_mae: 603.2034 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1054675.5000 - mae: 626.5493 - val_loss: 694996.6875 - val_mae: 510.9849 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 665187.7500 - mae: 530.1101 - val_loss: 443380.8438 - val_mae: 417.7404 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 439622.3750 - mae: 429.3986 - val_loss: 290595.9375 - val_mae: 323.4550 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 325905.8438 - mae: 357.9190 - val_loss: 244951.5781 - val_mae: 282.6940 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 270232.9688 - mae: 311.1175 - val_loss: 202746.1406 - val_mae: 265.8616 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 239582.1406 - mae: 288.6673 - val_loss: 181948.5469 - val_mae: 254.7996 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 221356.4219 - mae: 283.6458 - val_loss: 167278.7812 - val_mae: 246.8781 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 217132.6875 - mae: 282.1926 - val_loss: 163650.7031 - val_mae: 239.0074 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 208102.1250 - mae: 277.7217 - val_loss: 161432.4062 - val_mae: 235.4683 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 204311.7188 - mae: 279.6221 - val_loss: 193912.6250 - val_mae: 255.9471 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 202878.3594 - mae: 280.9504 - val_loss: 166503.3750 - val_mae: 239.1692 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 199656.7656 - mae: 280.0594 - val_loss: 209227.0000 - val_mae: 269.9538 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 199751.7812 - mae: 280.9125 - val_loss: 177304.2031 - val_mae: 248.3199 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 193811.5625 - mae: 278.3789 - val_loss: 158320.3906 - val_mae: 239.7625 - lr: 0.0010\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 2ms/step - loss: 192547.7656 - mae: 278.1891 - val_loss: 175472.3906 - val_mae: 248.3577 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 190907.0625 - mae: 277.9833 - val_loss: 173409.0625 - val_mae: 252.2736 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 192795.4219 - mae: 278.0976 - val_loss: 164399.8750 - val_mae: 244.2186 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 189452.7812 - mae: 276.5698 - val_loss: 186934.6094 - val_mae: 268.8514 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 188040.2344 - mae: 276.6301 - val_loss: 159291.7344 - val_mae: 236.8167 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 187127.7969 - mae: 276.3281 - val_loss: 170398.4531 - val_mae: 244.5169 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 186622.7656 - mae: 275.1988 - val_loss: 161558.8438 - val_mae: 237.4202 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 188551.0156 - mae: 276.8784 - val_loss: 196421.0469 - val_mae: 261.8975 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 184535.1719 - mae: 274.2340 - val_loss: 196348.9062 - val_mae: 260.1045 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 184926.8906 - mae: 275.2379 - val_loss: 200001.6094 - val_mae: 261.0705 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 178684.0000 - mae: 270.6104 - val_loss: 172916.8594 - val_mae: 250.0906 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 178414.3750 - mae: 271.4686 - val_loss: 172705.6406 - val_mae: 249.0795 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 178257.4375 - mae: 271.4596 - val_loss: 179051.5000 - val_mae: 254.4709 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 178522.4688 - mae: 271.9063 - val_loss: 182411.7500 - val_mae: 258.5280 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 178079.1562 - mae: 271.5665 - val_loss: 178752.7500 - val_mae: 254.7127 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 178281.3438 - mae: 272.1907 - val_loss: 176408.3906 - val_mae: 252.0250 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 177966.2969 - mae: 271.5842 - val_loss: 178578.1250 - val_mae: 252.8887 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 178069.3125 - mae: 271.5703 - val_loss: 172129.2812 - val_mae: 249.2982 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 178025.9688 - mae: 272.3578 - val_loss: 172126.6875 - val_mae: 249.5093 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 178070.0000 - mae: 271.7198 - val_loss: 173124.7188 - val_mae: 250.0048 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:26:17,746]\u001b[0m Trial 49 finished with value: 173124.66835741155 and parameters: {'feature_dim': 42, 'output_dim': 10, 'num_decision_steps': 3}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1668133.6250 - mae: 723.5226 - val_loss: 1297098.0000 - val_mae: 591.1258 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 1376235.0000 - mae: 622.1305 - val_loss: 997404.3125 - val_mae: 499.1845 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 1017358.6875 - mae: 510.3445 - val_loss: 696420.0000 - val_mae: 395.1823 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 697617.0625 - mae: 408.4892 - val_loss: 464745.5625 - val_mae: 323.7328 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 458830.0938 - mae: 330.0234 - val_loss: 312157.3750 - val_mae: 268.9120 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 300773.9062 - mae: 271.5670 - val_loss: 226455.2812 - val_mae: 233.7827 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 207020.0000 - mae: 232.0802 - val_loss: 175447.6250 - val_mae: 217.5887 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 158644.8750 - mae: 205.6382 - val_loss: 152008.6094 - val_mae: 192.0529 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 134258.0156 - mae: 186.5545 - val_loss: 139344.6406 - val_mae: 183.3609 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 123668.3516 - mae: 176.1769 - val_loss: 140034.5469 - val_mae: 175.6648 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 117639.2422 - mae: 169.5520 - val_loss: 135320.7500 - val_mae: 177.0012 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 115516.3047 - mae: 166.3700 - val_loss: 135299.7812 - val_mae: 170.9162 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 113434.6719 - mae: 164.0373 - val_loss: 128357.9688 - val_mae: 171.8735 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 111970.1328 - mae: 162.3309 - val_loss: 142829.9219 - val_mae: 174.3495 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 110986.1484 - mae: 160.7291 - val_loss: 125857.4375 - val_mae: 168.3878 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 110591.6953 - mae: 160.6436 - val_loss: 136025.0156 - val_mae: 170.3338 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 109448.4453 - mae: 159.0762 - val_loss: 129093.7500 - val_mae: 167.8566 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 108858.7734 - mae: 158.8201 - val_loss: 124599.4062 - val_mae: 167.1662 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 107477.1797 - mae: 157.7309 - val_loss: 124599.3906 - val_mae: 163.4866 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 105491.6406 - mae: 155.9620 - val_loss: 124404.7266 - val_mae: 163.5325 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 105294.4609 - mae: 155.6738 - val_loss: 121915.4766 - val_mae: 161.8506 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 105057.1719 - mae: 155.1244 - val_loss: 121530.7891 - val_mae: 163.0017 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 104005.2344 - mae: 154.0644 - val_loss: 127897.8828 - val_mae: 165.7715 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 103585.8594 - mae: 153.8439 - val_loss: 118761.4297 - val_mae: 164.5448 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 103896.1484 - mae: 153.6168 - val_loss: 121840.6719 - val_mae: 163.1989 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 103171.4141 - mae: 153.0921 - val_loss: 116348.2344 - val_mae: 161.1344 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 102935.4844 - mae: 152.6309 - val_loss: 118950.6016 - val_mae: 158.1301 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 102639.0391 - mae: 151.9867 - val_loss: 125672.2656 - val_mae: 166.7734 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 102519.7656 - mae: 152.0859 - val_loss: 126000.8594 - val_mae: 166.6182 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 101992.9297 - mae: 151.3788 - val_loss: 124977.3359 - val_mae: 166.8135 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 101832.4297 - mae: 150.7209 - val_loss: 121351.4688 - val_mae: 162.1932 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 101885.4062 - mae: 150.9234 - val_loss: 121631.7891 - val_mae: 159.5833 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 101627.6094 - mae: 150.9373 - val_loss: 121065.8750 - val_mae: 158.5350 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 101342.8125 - mae: 150.1992 - val_loss: 119891.2891 - val_mae: 158.5165 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 101184.3438 - mae: 149.8039 - val_loss: 114589.3594 - val_mae: 158.7330 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 100706.3438 - mae: 149.3674 - val_loss: 116694.6719 - val_mae: 156.7449 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 100664.8047 - mae: 149.5193 - val_loss: 117591.7031 - val_mae: 157.5300 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 100877.0000 - mae: 150.0766 - val_loss: 114682.0938 - val_mae: 156.0217 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 100397.3359 - mae: 149.5658 - val_loss: 115747.5938 - val_mae: 158.2562 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 100087.3047 - mae: 149.0042 - val_loss: 115417.8125 - val_mae: 157.6663 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 99733.7734 - mae: 148.7602 - val_loss: 117608.8125 - val_mae: 159.7847 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 99739.0625 - mae: 147.9141 - val_loss: 112872.7891 - val_mae: 153.9325 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 100189.7500 - mae: 148.4840 - val_loss: 129019.1406 - val_mae: 170.8367 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 99829.8281 - mae: 148.6139 - val_loss: 113585.2578 - val_mae: 155.8338 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 99551.4922 - mae: 147.9081 - val_loss: 119495.5469 - val_mae: 156.3931 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 99207.7188 - mae: 147.7124 - val_loss: 122172.9531 - val_mae: 159.3035 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 99318.3438 - mae: 147.8923 - val_loss: 114290.6484 - val_mae: 154.4886 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 99332.5000 - mae: 147.6614 - val_loss: 115791.3281 - val_mae: 152.5242 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 99362.2734 - mae: 147.4062 - val_loss: 114300.7344 - val_mae: 154.6005 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 99193.2266 - mae: 147.6809 - val_loss: 114077.5391 - val_mae: 152.8252 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:27:10,723]\u001b[0m Trial 50 finished with value: 114077.55335500317 and parameters: {'feature_dim': 38, 'output_dim': 9, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1647126.6250 - mae: 711.3411 - val_loss: 1264015.7500 - val_mae: 578.5932 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1320207.3750 - mae: 604.0209 - val_loss: 933399.5000 - val_mae: 471.8790 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 934273.2500 - mae: 484.2262 - val_loss: 622494.0625 - val_mae: 372.2513 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 610751.0000 - mae: 380.3725 - val_loss: 399892.2500 - val_mae: 302.1383 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 384605.0312 - mae: 303.2166 - val_loss: 262067.2031 - val_mae: 250.0838 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 246010.8906 - mae: 247.9615 - val_loss: 193370.1719 - val_mae: 217.3353 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 172481.0781 - mae: 211.9888 - val_loss: 155499.8750 - val_mae: 200.8923 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 138122.5000 - mae: 190.5739 - val_loss: 135510.7344 - val_mae: 176.4660 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 122584.1484 - mae: 178.5005 - val_loss: 126268.7422 - val_mae: 175.3607 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 116127.5938 - mae: 171.6085 - val_loss: 131688.8594 - val_mae: 169.1954 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111787.3438 - mae: 166.6311 - val_loss: 128720.4297 - val_mae: 169.6131 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110147.8828 - mae: 163.6939 - val_loss: 131245.2656 - val_mae: 166.3969 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107674.7109 - mae: 160.6242 - val_loss: 122881.4531 - val_mae: 163.3174 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106603.4688 - mae: 158.5785 - val_loss: 133574.4531 - val_mae: 169.2473 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105444.8203 - mae: 156.9024 - val_loss: 118598.8750 - val_mae: 160.0314 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104834.9688 - mae: 156.0296 - val_loss: 124760.2109 - val_mae: 162.9750 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104290.2188 - mae: 154.9796 - val_loss: 121729.3906 - val_mae: 158.9726 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104362.8203 - mae: 155.0125 - val_loss: 124263.1484 - val_mae: 165.1621 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104122.9141 - mae: 154.5855 - val_loss: 120537.2656 - val_mae: 159.7121 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103042.9141 - mae: 153.2041 - val_loss: 121946.4141 - val_mae: 159.3581 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102862.0859 - mae: 152.9594 - val_loss: 120838.8984 - val_mae: 159.1198 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103328.3047 - mae: 153.1180 - val_loss: 121618.3906 - val_mae: 157.7396 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102236.8438 - mae: 152.0610 - val_loss: 127259.1719 - val_mae: 163.0222 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101611.8750 - mae: 151.0892 - val_loss: 115781.0625 - val_mae: 156.0274 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102243.6797 - mae: 151.4124 - val_loss: 118570.5391 - val_mae: 155.1235 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101515.8047 - mae: 150.5970 - val_loss: 112721.5078 - val_mae: 153.8791 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101206.9297 - mae: 150.2967 - val_loss: 114073.3594 - val_mae: 150.3697 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101079.6875 - mae: 150.1929 - val_loss: 126236.4609 - val_mae: 163.8385 - lr: 0.0010\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100940.9766 - mae: 149.9574 - val_loss: 123365.9297 - val_mae: 160.0202 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100719.7578 - mae: 149.3414 - val_loss: 121483.6406 - val_mae: 158.3000 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100761.6406 - mae: 149.1967 - val_loss: 119214.7891 - val_mae: 153.8994 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100402.5312 - mae: 148.7561 - val_loss: 122307.7656 - val_mae: 157.2800 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100323.4922 - mae: 149.4080 - val_loss: 114958.3906 - val_mae: 151.1615 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100036.9375 - mae: 148.2807 - val_loss: 117645.1875 - val_mae: 152.5582 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100029.1250 - mae: 148.1024 - val_loss: 112433.1641 - val_mae: 152.5161 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99643.3203 - mae: 147.7424 - val_loss: 113037.5391 - val_mae: 149.7313 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99641.2656 - mae: 147.9718 - val_loss: 116822.7891 - val_mae: 153.9999 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99690.6094 - mae: 148.3823 - val_loss: 113250.0703 - val_mae: 152.1015 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99382.9922 - mae: 147.8082 - val_loss: 114783.3281 - val_mae: 152.1403 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98848.0234 - mae: 147.3501 - val_loss: 112312.6641 - val_mae: 151.0105 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98628.9297 - mae: 146.8602 - val_loss: 115957.3984 - val_mae: 150.7173 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98748.3438 - mae: 146.6852 - val_loss: 111378.6406 - val_mae: 149.9062 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99113.0547 - mae: 147.2710 - val_loss: 126344.3125 - val_mae: 168.1596 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98728.3203 - mae: 146.9185 - val_loss: 108260.3984 - val_mae: 146.1959 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98507.2344 - mae: 146.2464 - val_loss: 115524.3047 - val_mae: 150.4955 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98205.7188 - mae: 146.8026 - val_loss: 120814.5234 - val_mae: 154.0869 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98402.9297 - mae: 146.7079 - val_loss: 113874.5469 - val_mae: 153.8592 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98336.8359 - mae: 146.6672 - val_loss: 111891.3047 - val_mae: 145.7842 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98140.7422 - mae: 146.0209 - val_loss: 109964.9062 - val_mae: 147.8728 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98025.2578 - mae: 146.2545 - val_loss: 112691.5703 - val_mae: 148.3975 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:28:13,483]\u001b[0m Trial 51 finished with value: 112691.54467625536 and parameters: {'feature_dim': 54, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1642238.7500 - mae: 713.7582 - val_loss: 1240149.7500 - val_mae: 574.2062 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1262239.1250 - mae: 585.8574 - val_loss: 860815.6250 - val_mae: 448.4362 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 836206.5000 - mae: 452.6531 - val_loss: 536468.5000 - val_mae: 344.6705 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 510184.0312 - mae: 345.6493 - val_loss: 329045.3750 - val_mae: 273.8141 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 306664.0938 - mae: 271.4986 - val_loss: 221010.6094 - val_mae: 234.6779 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 197751.6562 - mae: 223.4395 - val_loss: 167648.0000 - val_mae: 198.9788 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 147393.5469 - mae: 194.5302 - val_loss: 148828.7656 - val_mae: 193.8247 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 127299.0000 - mae: 179.5036 - val_loss: 135242.6094 - val_mae: 174.0999 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 117987.0312 - mae: 171.2924 - val_loss: 131525.3125 - val_mae: 176.2228 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 114447.0703 - mae: 166.5706 - val_loss: 133147.4531 - val_mae: 167.6573 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111447.0391 - mae: 162.6598 - val_loss: 129521.6562 - val_mae: 168.6290 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110163.8203 - mae: 160.8971 - val_loss: 129397.8828 - val_mae: 164.8197 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108133.6250 - mae: 158.6790 - val_loss: 123256.8984 - val_mae: 166.2377 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106949.5234 - mae: 156.6980 - val_loss: 134956.7500 - val_mae: 168.1002 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105569.5859 - mae: 155.4097 - val_loss: 118575.6328 - val_mae: 161.3561 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104940.8750 - mae: 154.8332 - val_loss: 123628.6719 - val_mae: 159.2862 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104069.6094 - mae: 153.4309 - val_loss: 122841.0781 - val_mae: 160.7879 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104388.6484 - mae: 154.2436 - val_loss: 122215.5312 - val_mae: 162.4363 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104163.6094 - mae: 153.9209 - val_loss: 121001.2109 - val_mae: 157.8545 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103157.0781 - mae: 152.6362 - val_loss: 121337.0938 - val_mae: 159.0543 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103022.5000 - mae: 152.6585 - val_loss: 120983.7891 - val_mae: 158.7004 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103294.3906 - mae: 152.7645 - val_loss: 119855.3125 - val_mae: 158.1091 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102113.2734 - mae: 151.4773 - val_loss: 125665.2422 - val_mae: 162.2633 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102006.0859 - mae: 151.2387 - val_loss: 117985.2812 - val_mae: 162.5040 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102413.9375 - mae: 151.1943 - val_loss: 118788.6328 - val_mae: 157.6257 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101751.3906 - mae: 150.6257 - val_loss: 113748.4531 - val_mae: 155.7664 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101339.9531 - mae: 150.1319 - val_loss: 114678.6719 - val_mae: 152.7696 - lr: 0.0010\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101342.9922 - mae: 150.0818 - val_loss: 122855.4531 - val_mae: 162.7710 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101254.4531 - mae: 150.1416 - val_loss: 125035.1562 - val_mae: 164.3100 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100798.1875 - mae: 149.7264 - val_loss: 122640.3750 - val_mae: 160.0811 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100989.3672 - mae: 149.5210 - val_loss: 117758.7969 - val_mae: 155.3176 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100436.5547 - mae: 149.0993 - val_loss: 123968.5000 - val_mae: 157.3358 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100509.3516 - mae: 149.5484 - val_loss: 115854.2891 - val_mae: 151.2158 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100203.3203 - mae: 148.1588 - val_loss: 117578.8906 - val_mae: 153.7370 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100269.9219 - mae: 148.4866 - val_loss: 113222.7344 - val_mae: 151.0843 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99833.3906 - mae: 147.8535 - val_loss: 117374.0625 - val_mae: 154.0282 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99725.6172 - mae: 147.9480 - val_loss: 118189.7344 - val_mae: 154.3747 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99741.5547 - mae: 148.4268 - val_loss: 116418.6875 - val_mae: 153.9191 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99647.9766 - mae: 148.2096 - val_loss: 115480.0469 - val_mae: 153.0896 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99096.8672 - mae: 147.2428 - val_loss: 114173.0938 - val_mae: 152.3963 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98950.1875 - mae: 147.0564 - val_loss: 117269.5469 - val_mae: 153.8459 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99127.1094 - mae: 146.8097 - val_loss: 114366.6797 - val_mae: 152.8315 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99341.9453 - mae: 147.3345 - val_loss: 128279.4375 - val_mae: 168.5121 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99056.3906 - mae: 147.2914 - val_loss: 112247.5391 - val_mae: 150.1867 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98820.4141 - mae: 146.6381 - val_loss: 116995.9297 - val_mae: 152.3912 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98649.6094 - mae: 147.0097 - val_loss: 117874.9922 - val_mae: 153.5415 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98836.0625 - mae: 147.0322 - val_loss: 115053.0234 - val_mae: 152.5065 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98716.6250 - mae: 146.8379 - val_loss: 115918.1641 - val_mae: 150.7153 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98603.5547 - mae: 146.4159 - val_loss: 111939.2422 - val_mae: 150.0381 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98490.0547 - mae: 146.8703 - val_loss: 115347.8281 - val_mae: 152.0327 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:29:11,620]\u001b[0m Trial 52 finished with value: 115347.85869634601 and parameters: {'feature_dim': 50, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1653360.2500 - mae: 715.3441 - val_loss: 1264434.3750 - val_mae: 578.9365 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1315490.0000 - mae: 602.6685 - val_loss: 925940.9375 - val_mae: 469.1541 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 922226.1875 - mae: 481.2675 - val_loss: 610921.1250 - val_mae: 371.2578 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 584282.7500 - mae: 371.8414 - val_loss: 369613.1250 - val_mae: 291.9187 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 343567.0938 - mae: 287.7291 - val_loss: 235172.9062 - val_mae: 237.9332 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 214648.0469 - mae: 232.0585 - val_loss: 177276.4219 - val_mae: 203.7413 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 154572.6719 - mae: 199.5314 - val_loss: 152795.8438 - val_mae: 202.1055 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 129444.6016 - mae: 182.2360 - val_loss: 133931.4219 - val_mae: 173.9366 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 118185.4688 - mae: 172.2230 - val_loss: 126445.2891 - val_mae: 169.9805 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 113717.5547 - mae: 166.4776 - val_loss: 132154.9062 - val_mae: 170.0477 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110016.1562 - mae: 162.3118 - val_loss: 127732.7969 - val_mae: 167.9355 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109002.6641 - mae: 160.6615 - val_loss: 125786.0703 - val_mae: 160.4027 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106860.6328 - mae: 158.0429 - val_loss: 119575.1562 - val_mae: 162.4549 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106079.2344 - mae: 156.5697 - val_loss: 135929.0312 - val_mae: 170.6943 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105108.2734 - mae: 155.7015 - val_loss: 117017.6406 - val_mae: 158.1446 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105268.1094 - mae: 155.6388 - val_loss: 121975.9609 - val_mae: 156.7902 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104423.1797 - mae: 154.5961 - val_loss: 120368.9375 - val_mae: 157.0621 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104712.6797 - mae: 155.0114 - val_loss: 120566.9062 - val_mae: 161.3749 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104507.8125 - mae: 154.6886 - val_loss: 119010.1094 - val_mae: 157.1402 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103528.9141 - mae: 153.5515 - val_loss: 118622.2578 - val_mae: 156.7059 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103444.7109 - mae: 153.6815 - val_loss: 118593.0703 - val_mae: 157.2910 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103730.0938 - mae: 153.4256 - val_loss: 118416.7656 - val_mae: 158.1967 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102835.6250 - mae: 152.8283 - val_loss: 125924.0703 - val_mae: 163.1471 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102388.4922 - mae: 152.1965 - val_loss: 117259.5312 - val_mae: 160.5942 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103064.1094 - mae: 152.3242 - val_loss: 119220.2344 - val_mae: 160.6109 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99469.5391 - mae: 148.0454 - val_loss: 115937.0156 - val_mae: 156.3885 - lr: 1.0000e-04\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99302.2266 - mae: 147.7898 - val_loss: 115963.3750 - val_mae: 155.4688 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99299.0234 - mae: 147.6276 - val_loss: 117124.2031 - val_mae: 156.7207 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99310.2734 - mae: 147.6036 - val_loss: 115329.9453 - val_mae: 155.7333 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99100.3750 - mae: 147.5060 - val_loss: 117370.3281 - val_mae: 156.7815 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99198.6016 - mae: 147.3984 - val_loss: 118397.9766 - val_mae: 157.8909 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99181.9922 - mae: 147.5862 - val_loss: 118825.7812 - val_mae: 157.4688 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99131.9844 - mae: 147.3898 - val_loss: 116598.8828 - val_mae: 155.3474 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99100.0938 - mae: 147.3564 - val_loss: 117174.3672 - val_mae: 156.5490 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99091.9141 - mae: 147.3642 - val_loss: 116689.6953 - val_mae: 155.9530 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99054.1328 - mae: 147.2606 - val_loss: 115746.1406 - val_mae: 155.3058 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99022.9219 - mae: 147.3960 - val_loss: 114796.3594 - val_mae: 155.0983 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99013.7969 - mae: 147.3573 - val_loss: 115838.8516 - val_mae: 155.7789 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98976.5625 - mae: 147.3370 - val_loss: 116533.0234 - val_mae: 155.4463 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98859.9766 - mae: 147.2394 - val_loss: 115562.2109 - val_mae: 154.6610 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98831.4062 - mae: 146.9843 - val_loss: 117933.6797 - val_mae: 156.2477 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98816.2266 - mae: 146.9247 - val_loss: 115373.5391 - val_mae: 155.1712 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98888.4766 - mae: 147.0648 - val_loss: 115472.6250 - val_mae: 154.6265 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98747.7656 - mae: 146.9439 - val_loss: 114442.7344 - val_mae: 153.7910 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98754.6094 - mae: 146.9218 - val_loss: 116260.1406 - val_mae: 156.2826 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98769.3125 - mae: 147.1940 - val_loss: 116234.1875 - val_mae: 155.9005 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98765.8750 - mae: 146.9530 - val_loss: 115488.2031 - val_mae: 155.9713 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98764.1797 - mae: 147.0777 - val_loss: 116478.4297 - val_mae: 155.5468 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98676.2969 - mae: 146.8145 - val_loss: 115756.9453 - val_mae: 155.1989 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98697.8125 - mae: 146.9376 - val_loss: 115068.9062 - val_mae: 154.5537 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:30:13,975]\u001b[0m Trial 53 finished with value: 115068.90449615783 and parameters: {'feature_dim': 58, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1631035.0000 - mae: 707.6449 - val_loss: 1238833.2500 - val_mae: 568.4631 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1280611.3750 - mae: 591.4567 - val_loss: 891800.3125 - val_mae: 459.9018 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 882503.2500 - mae: 467.7842 - val_loss: 579800.0625 - val_mae: 363.1813 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 561290.5000 - mae: 363.9168 - val_loss: 364927.1562 - val_mae: 286.9822 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 346253.9062 - mae: 288.7345 - val_loss: 239035.9688 - val_mae: 237.7976 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 221467.6562 - mae: 234.7079 - val_loss: 180174.5938 - val_mae: 205.4624 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 159403.4219 - mae: 201.5132 - val_loss: 146598.9688 - val_mae: 192.0257 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 130989.8125 - mae: 182.7738 - val_loss: 132342.5312 - val_mae: 171.1521 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 117611.1172 - mae: 171.7634 - val_loss: 125479.9141 - val_mae: 168.7630 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 112365.1484 - mae: 165.5463 - val_loss: 128735.8203 - val_mae: 169.6337 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107965.7656 - mae: 160.5300 - val_loss: 128849.5547 - val_mae: 170.8617 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106880.4219 - mae: 158.6697 - val_loss: 125513.2266 - val_mae: 163.0016 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105008.4141 - mae: 156.5850 - val_loss: 121063.4688 - val_mae: 163.5086 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104457.9531 - mae: 155.2077 - val_loss: 132320.8750 - val_mae: 168.7912 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103649.3047 - mae: 154.1189 - val_loss: 114061.2891 - val_mae: 157.3408 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103329.5391 - mae: 153.9564 - val_loss: 120063.4609 - val_mae: 157.2350 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102503.8750 - mae: 152.0882 - val_loss: 117593.6484 - val_mae: 155.0205 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102836.1094 - mae: 152.7174 - val_loss: 116907.1719 - val_mae: 158.0998 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102990.4453 - mae: 153.0587 - val_loss: 118554.3828 - val_mae: 158.5673 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101808.4609 - mae: 151.4157 - val_loss: 118770.4375 - val_mae: 155.7267 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101708.4297 - mae: 151.1725 - val_loss: 119779.8203 - val_mae: 158.7120 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102118.2344 - mae: 151.4347 - val_loss: 117946.6406 - val_mae: 156.4648 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101168.7969 - mae: 150.6806 - val_loss: 125007.1562 - val_mae: 158.8930 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100516.9766 - mae: 149.5972 - val_loss: 117062.7422 - val_mae: 156.4326 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100907.9531 - mae: 149.7727 - val_loss: 114911.9922 - val_mae: 153.0760 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97420.4609 - mae: 145.4164 - val_loss: 113831.2891 - val_mae: 151.7728 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97234.4922 - mae: 145.1665 - val_loss: 114456.5391 - val_mae: 151.9185 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97147.6328 - mae: 144.8226 - val_loss: 114807.3359 - val_mae: 152.7681 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97155.2812 - mae: 144.8136 - val_loss: 113293.3594 - val_mae: 151.8885 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96960.3750 - mae: 144.7872 - val_loss: 115747.5312 - val_mae: 153.7914 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96995.8672 - mae: 144.5880 - val_loss: 116474.5312 - val_mae: 154.0533 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96936.9844 - mae: 144.6450 - val_loss: 117200.6797 - val_mae: 154.9055 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96912.8906 - mae: 144.5608 - val_loss: 114344.1406 - val_mae: 151.6236 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96901.6016 - mae: 144.4820 - val_loss: 115214.8359 - val_mae: 152.9036 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96824.3984 - mae: 144.4306 - val_loss: 114268.9141 - val_mae: 152.0055 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96790.8594 - mae: 144.3783 - val_loss: 114103.6406 - val_mae: 152.4138 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96759.7031 - mae: 144.4169 - val_loss: 112710.2109 - val_mae: 151.5947 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96717.1094 - mae: 144.3559 - val_loss: 113836.6953 - val_mae: 152.5227 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96710.2188 - mae: 144.3852 - val_loss: 114851.1172 - val_mae: 152.4991 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96487.7891 - mae: 144.2939 - val_loss: 113802.8438 - val_mae: 151.9238 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96538.4297 - mae: 144.0630 - val_loss: 115345.7344 - val_mae: 152.2269 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96490.6719 - mae: 143.8367 - val_loss: 113627.6094 - val_mae: 152.8789 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96521.9609 - mae: 144.0758 - val_loss: 113300.1328 - val_mae: 151.9184 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96435.8203 - mae: 143.9930 - val_loss: 112617.7109 - val_mae: 150.8066 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96378.7188 - mae: 143.8500 - val_loss: 114039.3125 - val_mae: 152.1112 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96407.3203 - mae: 144.0284 - val_loss: 114958.2422 - val_mae: 153.2654 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96406.9766 - mae: 143.9184 - val_loss: 114041.1719 - val_mae: 153.0732 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96393.5469 - mae: 144.0749 - val_loss: 115206.6172 - val_mae: 153.6338 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96263.0312 - mae: 143.7754 - val_loss: 113277.1641 - val_mae: 151.4247 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96291.9453 - mae: 143.8352 - val_loss: 112879.9766 - val_mae: 150.8499 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:31:23,314]\u001b[0m Trial 54 finished with value: 112880.0010557163 and parameters: {'feature_dim': 65, 'output_dim': 10, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1660470.0000 - mae: 715.9850 - val_loss: 1286334.8750 - val_mae: 585.9129 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1357971.7500 - mae: 615.7361 - val_loss: 976106.5000 - val_mae: 486.2083 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 990066.9375 - mae: 501.8403 - val_loss: 672556.7500 - val_mae: 386.4986 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 668910.0000 - mae: 398.9074 - val_loss: 443212.4688 - val_mae: 314.8026 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 433630.9688 - mae: 320.4001 - val_loss: 295422.2188 - val_mae: 264.0636 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 281143.4375 - mae: 262.6233 - val_loss: 215451.5000 - val_mae: 227.9743 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 194359.0781 - mae: 224.5752 - val_loss: 168410.5781 - val_mae: 209.2354 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 151510.7500 - mae: 201.0711 - val_loss: 148516.1719 - val_mae: 191.3994 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 130251.8125 - mae: 186.6186 - val_loss: 135369.9688 - val_mae: 185.7859 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 119571.3828 - mae: 176.6628 - val_loss: 136476.8594 - val_mae: 175.4707 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 113617.6641 - mae: 170.0950 - val_loss: 127388.3828 - val_mae: 175.1758 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110959.6875 - mae: 166.6085 - val_loss: 131193.8906 - val_mae: 172.1759 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108572.6641 - mae: 163.7279 - val_loss: 123595.1328 - val_mae: 168.4397 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107896.6250 - mae: 162.3784 - val_loss: 135093.3594 - val_mae: 174.6157 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106849.2188 - mae: 161.1635 - val_loss: 118986.9141 - val_mae: 167.6847 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106183.8750 - mae: 160.9896 - val_loss: 126971.0078 - val_mae: 169.2289 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105216.7734 - mae: 159.0875 - val_loss: 127020.5469 - val_mae: 168.8526 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105171.2891 - mae: 158.5106 - val_loss: 120453.4922 - val_mae: 164.6512 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105218.6250 - mae: 157.2680 - val_loss: 121933.1719 - val_mae: 163.3465 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103756.8672 - mae: 155.2761 - val_loss: 121424.7500 - val_mae: 163.3772 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103659.8516 - mae: 154.6307 - val_loss: 118676.4297 - val_mae: 158.7545 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103581.2188 - mae: 154.2038 - val_loss: 120181.0625 - val_mae: 163.3346 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102584.7500 - mae: 153.3792 - val_loss: 121385.7344 - val_mae: 160.2740 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 102138.7422 - mae: 152.3475 - val_loss: 116929.3828 - val_mae: 160.2542 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 102661.3281 - mae: 152.6068 - val_loss: 119384.5469 - val_mae: 161.1953 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101889.6641 - mae: 151.5322 - val_loss: 112694.4922 - val_mae: 156.3011 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101555.6094 - mae: 151.3873 - val_loss: 115829.5781 - val_mae: 158.8038 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 101295.3594 - mae: 150.7652 - val_loss: 122060.9688 - val_mae: 164.3026 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 101359.1484 - mae: 150.7398 - val_loss: 125114.5156 - val_mae: 164.1745 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100809.8281 - mae: 149.7464 - val_loss: 120599.8750 - val_mae: 160.0499 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101011.7188 - mae: 149.8887 - val_loss: 115940.4609 - val_mae: 154.6784 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 100688.6797 - mae: 149.4017 - val_loss: 118683.2344 - val_mae: 156.2802 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100355.9922 - mae: 149.7383 - val_loss: 114775.0234 - val_mae: 152.6308 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100048.8438 - mae: 148.3111 - val_loss: 115310.3047 - val_mae: 155.2009 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100117.5938 - mae: 148.1781 - val_loss: 112337.3750 - val_mae: 151.9606 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99564.3828 - mae: 147.8171 - val_loss: 113589.6641 - val_mae: 152.5818 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99771.2578 - mae: 148.1710 - val_loss: 115189.0000 - val_mae: 153.7803 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99614.5859 - mae: 148.5235 - val_loss: 114641.3281 - val_mae: 152.9297 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99591.9609 - mae: 148.2945 - val_loss: 113934.7109 - val_mae: 152.4215 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98972.3750 - mae: 147.1809 - val_loss: 112153.0312 - val_mae: 152.5426 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98834.2188 - mae: 147.0784 - val_loss: 115804.0312 - val_mae: 154.1437 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98892.4297 - mae: 146.8769 - val_loss: 111344.7969 - val_mae: 149.6021 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99352.6875 - mae: 147.2232 - val_loss: 123045.6406 - val_mae: 163.9924 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98954.3359 - mae: 147.3103 - val_loss: 110746.7812 - val_mae: 149.6377 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98739.1875 - mae: 146.7179 - val_loss: 116650.5312 - val_mae: 152.9606 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98460.4922 - mae: 147.0231 - val_loss: 118104.9922 - val_mae: 155.5083 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98500.5859 - mae: 146.8279 - val_loss: 112506.8828 - val_mae: 151.5757 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98515.3438 - mae: 146.9545 - val_loss: 111715.6953 - val_mae: 148.1674 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98191.1094 - mae: 146.1100 - val_loss: 113067.3359 - val_mae: 151.1331 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98202.3125 - mae: 146.5977 - val_loss: 111788.0938 - val_mae: 149.7040 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:32:19,327]\u001b[0m Trial 55 finished with value: 111788.08038616559 and parameters: {'feature_dim': 42, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1669552.6250 - mae: 717.6548 - val_loss: 1308894.0000 - val_mae: 594.4459 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1405474.6250 - mae: 629.8434 - val_loss: 1033647.3125 - val_mae: 503.2273 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 1072436.1250 - mae: 526.4196 - val_loss: 749749.7500 - val_mae: 410.9303 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 763061.8750 - mae: 428.5092 - val_loss: 516068.4375 - val_mae: 334.8123 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 517027.9062 - mae: 346.5714 - val_loss: 349445.1562 - val_mae: 277.2603 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 343784.2812 - mae: 283.6409 - val_loss: 248586.1406 - val_mae: 236.2724 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 233854.2656 - mae: 238.6534 - val_loss: 182699.2344 - val_mae: 209.9964 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 172326.4219 - mae: 208.8378 - val_loss: 150440.6719 - val_mae: 188.9730 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 139074.7812 - mae: 188.3583 - val_loss: 140688.7969 - val_mae: 179.7435 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 124661.2734 - mae: 176.7592 - val_loss: 135132.7500 - val_mae: 172.9291 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 114974.9766 - mae: 167.8452 - val_loss: 131999.3750 - val_mae: 172.7578 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 110814.1250 - mae: 162.9827 - val_loss: 131023.3516 - val_mae: 167.7568 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 107283.3672 - mae: 158.8374 - val_loss: 126168.2344 - val_mae: 164.7805 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106125.8125 - mae: 156.7918 - val_loss: 132028.8125 - val_mae: 167.2523 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105171.1094 - mae: 155.5268 - val_loss: 119922.7891 - val_mae: 160.2482 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104789.6875 - mae: 154.8578 - val_loss: 125010.3672 - val_mae: 160.6600 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 103959.8125 - mae: 153.5447 - val_loss: 123850.8047 - val_mae: 158.7900 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 103993.8047 - mae: 153.4046 - val_loss: 122614.8906 - val_mae: 161.9808 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103671.0000 - mae: 153.0975 - val_loss: 118768.3281 - val_mae: 156.7556 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 102654.7109 - mae: 151.9519 - val_loss: 119809.4375 - val_mae: 157.3855 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102632.9922 - mae: 151.9021 - val_loss: 122987.8203 - val_mae: 159.1756 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 102824.4531 - mae: 151.6599 - val_loss: 120698.2578 - val_mae: 156.4765 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101666.8672 - mae: 150.8758 - val_loss: 126328.5156 - val_mae: 161.1754 - lr: 0.0010\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 999us/step - loss: 101274.8672 - mae: 150.1272 - val_loss: 119424.6328 - val_mae: 158.0896 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 101666.6250 - mae: 150.1566 - val_loss: 117733.6094 - val_mae: 155.0371 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101136.0625 - mae: 149.7204 - val_loss: 113846.0547 - val_mae: 154.0650 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 100859.5859 - mae: 149.3631 - val_loss: 115427.5391 - val_mae: 151.6094 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 100729.6094 - mae: 149.0876 - val_loss: 124438.9062 - val_mae: 162.4655 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 100694.8906 - mae: 149.0297 - val_loss: 122857.6406 - val_mae: 161.0571 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100296.9922 - mae: 148.3050 - val_loss: 122597.9844 - val_mae: 159.2238 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100571.7188 - mae: 148.6783 - val_loss: 119024.5938 - val_mae: 154.1488 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 100158.2422 - mae: 148.2110 - val_loss: 121250.6406 - val_mae: 156.1854 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100151.6562 - mae: 148.7250 - val_loss: 116015.3906 - val_mae: 151.5224 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 99976.3594 - mae: 147.7970 - val_loss: 115390.1875 - val_mae: 150.5906 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 99791.1562 - mae: 147.4896 - val_loss: 113149.5078 - val_mae: 150.3169 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 99677.6094 - mae: 147.3550 - val_loss: 115661.3594 - val_mae: 152.3374 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 99567.6953 - mae: 147.3937 - val_loss: 117394.4531 - val_mae: 155.0535 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 99662.7031 - mae: 147.7016 - val_loss: 114702.9375 - val_mae: 153.3761 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 99272.8516 - mae: 147.3395 - val_loss: 117061.1406 - val_mae: 152.9239 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99058.7266 - mae: 146.8739 - val_loss: 113018.4453 - val_mae: 151.1738 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 98752.6406 - mae: 146.5238 - val_loss: 115675.0781 - val_mae: 151.1516 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 98965.0156 - mae: 146.5215 - val_loss: 112702.0234 - val_mae: 150.2493 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 99148.0547 - mae: 146.8646 - val_loss: 121014.2422 - val_mae: 162.2738 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98715.1328 - mae: 146.6280 - val_loss: 111552.9766 - val_mae: 147.7405 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 98593.7500 - mae: 145.9721 - val_loss: 118761.1953 - val_mae: 152.7484 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 98304.6953 - mae: 146.3633 - val_loss: 119900.1641 - val_mae: 153.6916 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 98604.4766 - mae: 146.5446 - val_loss: 113394.6406 - val_mae: 152.9109 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 98519.4531 - mae: 146.4638 - val_loss: 116423.7188 - val_mae: 150.1536 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 98352.4141 - mae: 145.8989 - val_loss: 111371.9531 - val_mae: 148.3110 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98213.4766 - mae: 146.0294 - val_loss: 113823.6562 - val_mae: 149.2215 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:33:15,064]\u001b[0m Trial 56 finished with value: 113823.67669568729 and parameters: {'feature_dim': 41, 'output_dim': 10, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "[TabNet]: 41 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1723664.3750 - mae: 739.4052 - val_loss: 1382413.1250 - val_mae: 661.8513 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1558018.1250 - mae: 753.0932 - val_loss: 1250287.3750 - val_mae: 693.9208 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1411094.0000 - mae: 782.3782 - val_loss: 1152883.0000 - val_mae: 738.7907 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1309147.3750 - mae: 816.6305 - val_loss: 1091136.1250 - val_mae: 770.7838 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1239361.3750 - mae: 826.9659 - val_loss: 1020803.3125 - val_mae: 768.7050 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1182290.6250 - mae: 825.4387 - val_loss: 982318.7500 - val_mae: 787.3545 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1146183.5000 - mae: 831.4130 - val_loss: 927300.6250 - val_mae: 703.0639 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1131354.2500 - mae: 834.7877 - val_loss: 961404.8750 - val_mae: 798.3074 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1127469.1250 - mae: 838.3356 - val_loss: 973896.5625 - val_mae: 818.0854 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1126599.8750 - mae: 840.9329 - val_loss: 916095.3750 - val_mae: 723.7702 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1124428.8750 - mae: 838.9736 - val_loss: 927133.4375 - val_mae: 745.3414 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1122690.8750 - mae: 838.0859 - val_loss: 919871.3750 - val_mae: 741.8035 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1124647.8750 - mae: 839.2869 - val_loss: 926327.1250 - val_mae: 756.2770 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1124193.7500 - mae: 838.6483 - val_loss: 925747.0000 - val_mae: 726.7017 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1128308.1250 - mae: 841.0637 - val_loss: 931807.5625 - val_mae: 759.4973 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1125379.7500 - mae: 841.0936 - val_loss: 922077.0625 - val_mae: 740.2511 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1124161.7500 - mae: 840.4774 - val_loss: 921161.5625 - val_mae: 719.8192 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1123542.0000 - mae: 839.0851 - val_loss: 953858.4375 - val_mae: 792.2737 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1125870.6250 - mae: 841.5920 - val_loss: 926621.1250 - val_mae: 752.7003 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1123138.0000 - mae: 840.1008 - val_loss: 928043.8750 - val_mae: 755.8144 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1111088.5000 - mae: 837.1503 - val_loss: 926485.6875 - val_mae: 743.1747 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1106220.3750 - mae: 828.3140 - val_loss: 922380.1875 - val_mae: 732.4830 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1105369.6250 - mae: 825.6150 - val_loss: 933958.3750 - val_mae: 750.2767 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1104764.8750 - mae: 824.1199 - val_loss: 928304.4375 - val_mae: 738.2138 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1105192.3750 - mae: 822.9054 - val_loss: 946774.1250 - val_mae: 775.9106 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1104044.3750 - mae: 823.3979 - val_loss: 929059.1875 - val_mae: 739.4830 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1104734.3750 - mae: 823.0255 - val_loss: 920807.2500 - val_mae: 724.9603 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1103959.2500 - mae: 821.9485 - val_loss: 927213.8125 - val_mae: 741.5120 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1103936.7500 - mae: 823.9621 - val_loss: 930324.1250 - val_mae: 742.7831 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1104226.0000 - mae: 822.5018 - val_loss: 933414.0000 - val_mae: 748.6416 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:34:12,429]\u001b[0m Trial 57 finished with value: 933413.8080535504 and parameters: {'feature_dim': 46, 'output_dim': 5, 'num_decision_steps': 2}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1679111.6250 - mae: 722.7441 - val_loss: 1319175.2500 - val_mae: 597.7914 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 1419514.0000 - mae: 634.4749 - val_loss: 1048390.3125 - val_mae: 512.0858 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1090437.1250 - mae: 532.4995 - val_loss: 765972.6875 - val_mae: 417.7837 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 781836.3125 - mae: 434.8084 - val_loss: 532502.2500 - val_mae: 345.9688 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 534483.3125 - mae: 354.1784 - val_loss: 364410.2188 - val_mae: 284.3940 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 358857.6875 - mae: 292.3958 - val_loss: 259032.9219 - val_mae: 245.2334 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 245540.6719 - mae: 247.1051 - val_loss: 197598.0781 - val_mae: 230.6565 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 180673.4219 - mae: 216.2223 - val_loss: 165168.1875 - val_mae: 200.4536 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 145659.4688 - mae: 194.5966 - val_loss: 153729.5781 - val_mae: 200.4111 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 130844.1484 - mae: 183.0980 - val_loss: 144784.9219 - val_mae: 179.3819 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 121551.9922 - mae: 174.2976 - val_loss: 139400.3594 - val_mae: 179.1945 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 117571.4141 - mae: 169.2975 - val_loss: 138552.2969 - val_mae: 171.7494 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 113427.6328 - mae: 164.9696 - val_loss: 129401.9844 - val_mae: 171.3088 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 110467.2188 - mae: 161.5814 - val_loss: 138811.2031 - val_mae: 171.3958 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 107877.4141 - mae: 158.7795 - val_loss: 119265.8047 - val_mae: 160.7076 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 106693.0781 - mae: 157.5093 - val_loss: 126515.5078 - val_mae: 162.1652 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105634.7344 - mae: 156.0235 - val_loss: 123823.3125 - val_mae: 160.2676 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105753.1719 - mae: 156.1417 - val_loss: 120645.1797 - val_mae: 159.6100 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105122.4609 - mae: 155.1334 - val_loss: 121946.0234 - val_mae: 158.9956 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 982us/step - loss: 104260.3125 - mae: 154.2334 - val_loss: 121459.6641 - val_mae: 158.8932 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 104220.6953 - mae: 154.0368 - val_loss: 121233.7109 - val_mae: 158.7510 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 104327.1250 - mae: 153.9119 - val_loss: 119918.8828 - val_mae: 158.0876 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 103182.2500 - mae: 152.7875 - val_loss: 127190.5312 - val_mae: 163.8230 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 102922.8594 - mae: 152.4270 - val_loss: 117866.6953 - val_mae: 158.0710 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103272.4062 - mae: 152.5213 - val_loss: 119451.8516 - val_mae: 157.8103 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 102670.8672 - mae: 151.8123 - val_loss: 115819.2422 - val_mae: 156.3319 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102458.1797 - mae: 151.6422 - val_loss: 117621.8516 - val_mae: 155.4838 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 102277.6016 - mae: 151.2267 - val_loss: 125340.4453 - val_mae: 164.7359 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 102104.8984 - mae: 151.0881 - val_loss: 125746.2812 - val_mae: 164.3649 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 101907.3594 - mae: 150.8203 - val_loss: 124270.2969 - val_mae: 162.3281 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 101906.1641 - mae: 150.4192 - val_loss: 119284.7656 - val_mae: 156.0250 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 101777.3125 - mae: 150.5753 - val_loss: 124588.0859 - val_mae: 159.2841 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101367.8281 - mae: 150.5192 - val_loss: 116879.1016 - val_mae: 152.9505 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 101500.5625 - mae: 149.8094 - val_loss: 117328.5938 - val_mae: 154.5775 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 101223.2734 - mae: 149.4524 - val_loss: 114253.7969 - val_mae: 152.6524 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 101054.8906 - mae: 149.5332 - val_loss: 114979.8438 - val_mae: 153.1317 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 101066.8984 - mae: 149.6660 - val_loss: 117152.5391 - val_mae: 154.5888 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 100911.5859 - mae: 149.7148 - val_loss: 115829.9141 - val_mae: 154.6124 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 100700.3359 - mae: 149.3382 - val_loss: 114843.5391 - val_mae: 153.7360 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 100527.2344 - mae: 149.1021 - val_loss: 114229.3281 - val_mae: 152.8535 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 100085.8828 - mae: 148.6284 - val_loss: 116557.5859 - val_mae: 154.1106 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 100259.1953 - mae: 148.5054 - val_loss: 111799.4766 - val_mae: 151.6361 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 100543.0859 - mae: 148.7080 - val_loss: 127306.2969 - val_mae: 168.4333 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 100252.6016 - mae: 148.7614 - val_loss: 113820.2266 - val_mae: 153.1515 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 100076.1250 - mae: 148.3054 - val_loss: 118673.8125 - val_mae: 154.8530 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 99837.6250 - mae: 148.5285 - val_loss: 117305.8750 - val_mae: 153.4495 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 99972.8984 - mae: 148.3507 - val_loss: 114687.8047 - val_mae: 153.0757 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 99983.7969 - mae: 148.3224 - val_loss: 116031.7109 - val_mae: 151.1111 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 99848.1250 - mae: 147.7358 - val_loss: 111764.5000 - val_mae: 151.4362 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 99647.2500 - mae: 147.9988 - val_loss: 114475.6328 - val_mae: 152.2112 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:35:07,669]\u001b[0m Trial 58 finished with value: 114475.65163331071 and parameters: {'feature_dim': 39, 'output_dim': 9, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1687904.2500 - mae: 724.6066 - val_loss: 1342790.7500 - val_mae: 604.4045 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1468678.3750 - mae: 649.3101 - val_loss: 1108956.6250 - val_mae: 527.9849 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1177734.8750 - mae: 558.7308 - val_loss: 851216.3750 - val_mae: 440.3016 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 884334.5000 - mae: 467.6287 - val_loss: 610419.8125 - val_mae: 367.3368 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 614742.1875 - mae: 380.1046 - val_loss: 410733.7500 - val_mae: 297.6044 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 408392.3125 - mae: 307.3384 - val_loss: 291148.9688 - val_mae: 255.3232 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 273968.8438 - mae: 255.7916 - val_loss: 204212.5000 - val_mae: 221.1025 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 195032.0312 - mae: 220.8497 - val_loss: 162349.0781 - val_mae: 193.0818 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 150645.1250 - mae: 195.8834 - val_loss: 146117.4531 - val_mae: 183.3936 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 130495.8125 - mae: 182.4175 - val_loss: 138940.2656 - val_mae: 176.6397 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 118829.1016 - mae: 172.6321 - val_loss: 130554.7969 - val_mae: 171.5174 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 112716.7734 - mae: 167.0590 - val_loss: 127906.0859 - val_mae: 166.2175 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108733.2500 - mae: 162.7203 - val_loss: 125710.0000 - val_mae: 166.7377 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106897.7812 - mae: 159.3177 - val_loss: 132999.7031 - val_mae: 170.0920 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105463.6016 - mae: 157.7360 - val_loss: 119060.5000 - val_mae: 160.2769 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105054.6250 - mae: 156.8299 - val_loss: 122970.9844 - val_mae: 160.1013 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103988.2188 - mae: 154.9725 - val_loss: 124270.1016 - val_mae: 160.7316 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104361.8281 - mae: 155.1371 - val_loss: 124135.3281 - val_mae: 163.6059 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103771.0312 - mae: 154.0631 - val_loss: 118535.0625 - val_mae: 158.2852 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102918.6797 - mae: 153.1409 - val_loss: 121118.6016 - val_mae: 157.7000 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102643.0078 - mae: 152.8026 - val_loss: 119196.9688 - val_mae: 159.3270 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102780.7188 - mae: 152.1338 - val_loss: 118000.5781 - val_mae: 155.7593 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 101822.5391 - mae: 151.3602 - val_loss: 124642.9297 - val_mae: 161.0534 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101209.3828 - mae: 150.4054 - val_loss: 118033.5234 - val_mae: 159.8522 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 101801.7734 - mae: 150.6406 - val_loss: 117506.8828 - val_mae: 156.0576 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101117.0625 - mae: 149.8702 - val_loss: 113578.9688 - val_mae: 156.0752 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 101004.0547 - mae: 150.0567 - val_loss: 116802.3203 - val_mae: 154.4557 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100755.5078 - mae: 149.4946 - val_loss: 123808.2812 - val_mae: 162.7451 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 100628.2188 - mae: 149.4817 - val_loss: 126097.1562 - val_mae: 164.6289 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 100238.3203 - mae: 149.0516 - val_loss: 121105.7266 - val_mae: 160.8820 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 100672.5391 - mae: 149.0168 - val_loss: 119213.0781 - val_mae: 155.1147 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 100025.5078 - mae: 148.6012 - val_loss: 122407.4375 - val_mae: 159.7108 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 99870.2031 - mae: 148.8864 - val_loss: 116575.7656 - val_mae: 154.5871 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 99714.6875 - mae: 147.8504 - val_loss: 117170.7422 - val_mae: 154.1956 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 99484.2891 - mae: 147.8045 - val_loss: 113921.3203 - val_mae: 153.0672 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 99092.1250 - mae: 147.2724 - val_loss: 115869.2656 - val_mae: 154.1428 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 96446.9531 - mae: 143.8660 - val_loss: 113642.6406 - val_mae: 151.2688 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 96187.8438 - mae: 143.2151 - val_loss: 114450.3594 - val_mae: 152.4175 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 96156.3594 - mae: 143.1898 - val_loss: 114936.5156 - val_mae: 152.2357 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 95979.7500 - mae: 143.2748 - val_loss: 114498.6328 - val_mae: 151.4520 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 96044.0859 - mae: 142.9081 - val_loss: 116185.2812 - val_mae: 153.0650 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 95921.7812 - mae: 142.6463 - val_loss: 114382.8672 - val_mae: 152.4422 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 95940.9375 - mae: 142.9353 - val_loss: 114627.8516 - val_mae: 151.7432 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 95896.4297 - mae: 142.8543 - val_loss: 114394.8359 - val_mae: 150.9870 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 95863.1797 - mae: 142.7075 - val_loss: 114291.8516 - val_mae: 151.3589 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 95838.2266 - mae: 142.8812 - val_loss: 114757.4766 - val_mae: 152.2931 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:35:59,214]\u001b[0m Trial 59 finished with value: 114757.48895734428 and parameters: {'feature_dim': 43, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "[TabNet]: 27 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 3s 2ms/step - loss: 1692170.3750 - mae: 717.4044 - val_loss: 1340824.8750 - val_mae: 609.2709 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1453239.6250 - mae: 653.0688 - val_loss: 1093681.5000 - val_mae: 551.0913 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1153018.7500 - mae: 580.0927 - val_loss: 857744.0625 - val_mae: 501.1943 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 894535.3750 - mae: 516.3251 - val_loss: 701653.7500 - val_mae: 477.1047 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 729468.0625 - mae: 485.4595 - val_loss: 629276.0625 - val_mae: 475.5168 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 646937.3750 - mae: 472.0783 - val_loss: 616782.4375 - val_mae: 480.2502 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 616670.1875 - mae: 468.0387 - val_loss: 648213.1875 - val_mae: 495.9787 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 628187.5625 - mae: 476.8567 - val_loss: 575998.4375 - val_mae: 467.5016 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 591021.0000 - mae: 461.2278 - val_loss: 653370.5625 - val_mae: 500.8810 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 582033.8125 - mae: 457.0001 - val_loss: 563710.3125 - val_mae: 460.1821 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 590252.6250 - mae: 462.4133 - val_loss: 624625.5625 - val_mae: 484.9595 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 585127.5000 - mae: 460.5887 - val_loss: 655077.0625 - val_mae: 505.2424 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 615381.5000 - mae: 475.3618 - val_loss: 645343.3750 - val_mae: 501.7052 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 384192.5938 - mae: 355.3947 - val_loss: 228851.6562 - val_mae: 262.0335 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 211239.7500 - mae: 261.4166 - val_loss: 184359.4844 - val_mae: 225.5964 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 168888.9375 - mae: 226.4558 - val_loss: 166731.2031 - val_mae: 208.3567 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 151292.0938 - mae: 210.5886 - val_loss: 150408.0938 - val_mae: 193.8538 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 139758.8594 - mae: 202.1737 - val_loss: 143296.3125 - val_mae: 192.2384 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 130706.7500 - mae: 192.9034 - val_loss: 167847.2656 - val_mae: 200.3479 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 128231.0234 - mae: 189.5515 - val_loss: 145154.8125 - val_mae: 185.2241 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 124261.8906 - mae: 184.0581 - val_loss: 140424.0781 - val_mae: 183.2005 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 123430.9922 - mae: 182.6596 - val_loss: 136741.5938 - val_mae: 194.5534 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 121992.2031 - mae: 180.4660 - val_loss: 144283.5938 - val_mae: 180.0014 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 118358.1250 - mae: 175.8757 - val_loss: 130464.7578 - val_mae: 179.3625 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 117402.8594 - mae: 173.6818 - val_loss: 161682.2500 - val_mae: 199.9397 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 116966.2188 - mae: 173.3297 - val_loss: 123606.1484 - val_mae: 171.9888 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 116215.3516 - mae: 172.1259 - val_loss: 130006.9766 - val_mae: 170.2388 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 114149.2812 - mae: 168.8851 - val_loss: 131807.8906 - val_mae: 181.2781 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 115225.6641 - mae: 170.6095 - val_loss: 124994.3594 - val_mae: 166.6428 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 113828.2422 - mae: 168.3273 - val_loss: 129854.9062 - val_mae: 173.9008 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 115115.6172 - mae: 169.3501 - val_loss: 126512.9297 - val_mae: 167.2791 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 113272.5547 - mae: 167.6530 - val_loss: 131407.0938 - val_mae: 170.2045 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 112066.4766 - mae: 166.9593 - val_loss: 125266.7578 - val_mae: 171.5426 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 111958.0391 - mae: 165.5168 - val_loss: 132031.7500 - val_mae: 173.6572 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 111315.6406 - mae: 165.0269 - val_loss: 131715.1406 - val_mae: 169.9937 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 111613.8438 - mae: 165.0861 - val_loss: 131776.2969 - val_mae: 169.6403 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 104929.7031 - mae: 156.7477 - val_loss: 122907.9141 - val_mae: 162.9560 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 104433.5156 - mae: 156.0050 - val_loss: 121104.8750 - val_mae: 163.1922 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 104255.7422 - mae: 156.0340 - val_loss: 125799.4531 - val_mae: 165.8263 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 103993.4141 - mae: 155.7611 - val_loss: 122815.4062 - val_mae: 162.9107 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 103956.8594 - mae: 155.5566 - val_loss: 126531.2578 - val_mae: 165.7328 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 104092.7422 - mae: 155.2831 - val_loss: 122865.9219 - val_mae: 163.2892 - lr: 1.0000e-04\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 2ms/step - loss: 103821.4375 - mae: 155.3692 - val_loss: 122491.9219 - val_mae: 162.2115 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 103833.7422 - mae: 155.3623 - val_loss: 120660.0938 - val_mae: 162.6869 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 103791.5469 - mae: 155.0371 - val_loss: 122032.0703 - val_mae: 163.5847 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 103655.2344 - mae: 155.3341 - val_loss: 127323.1562 - val_mae: 166.5673 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 103608.7734 - mae: 155.1221 - val_loss: 121494.5312 - val_mae: 164.2272 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 103715.6641 - mae: 154.9347 - val_loss: 121043.1875 - val_mae: 162.8247 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 103536.7344 - mae: 154.8257 - val_loss: 123095.9922 - val_mae: 163.8213 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 103478.6719 - mae: 155.0655 - val_loss: 121690.1641 - val_mae: 162.2909 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:37:23,590]\u001b[0m Trial 60 finished with value: 121690.17556304626 and parameters: {'feature_dim': 35, 'output_dim': 8, 'num_decision_steps': 2}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1704384.6250 - mae: 729.0869 - val_loss: 1362901.2500 - val_mae: 610.2213 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 1498188.6250 - mae: 658.3300 - val_loss: 1139774.0000 - val_mae: 537.7443 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 1218525.0000 - mae: 572.5826 - val_loss: 889522.8750 - val_mae: 457.3703 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 934824.7500 - mae: 485.4258 - val_loss: 661974.1875 - val_mae: 393.5566 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 685889.1875 - mae: 406.8196 - val_loss: 477642.9062 - val_mae: 326.0192 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 487312.5000 - mae: 341.1302 - val_loss: 344920.2812 - val_mae: 280.3167 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 342474.4688 - mae: 288.5673 - val_loss: 257139.7969 - val_mae: 247.7374 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 247829.7969 - mae: 249.3852 - val_loss: 202915.0000 - val_mae: 222.9419 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 186831.0781 - mae: 219.5552 - val_loss: 168112.3594 - val_mae: 211.7759 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 153453.4062 - mae: 200.3931 - val_loss: 153267.2969 - val_mae: 189.2117 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 134339.3281 - mae: 186.7197 - val_loss: 145595.2812 - val_mae: 183.9086 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 982us/step - loss: 126315.6250 - mae: 180.3660 - val_loss: 144891.7031 - val_mae: 180.2649 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 121150.3828 - mae: 175.4969 - val_loss: 141914.5000 - val_mae: 185.4200 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 118479.9844 - mae: 171.8252 - val_loss: 149764.0781 - val_mae: 180.4398 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 115492.1562 - mae: 168.1653 - val_loss: 138172.5000 - val_mae: 180.7032 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 113549.1484 - mae: 165.7275 - val_loss: 137890.5312 - val_mae: 171.9078 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 110895.2031 - mae: 162.3372 - val_loss: 133310.1406 - val_mae: 172.1590 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 109841.7266 - mae: 160.6614 - val_loss: 127292.4453 - val_mae: 167.8888 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 108643.5156 - mae: 159.5981 - val_loss: 130172.5469 - val_mae: 165.6311 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 106897.4609 - mae: 157.4913 - val_loss: 126957.1250 - val_mae: 166.6555 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 106422.9766 - mae: 156.9504 - val_loss: 124830.1797 - val_mae: 162.3826 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 106480.4922 - mae: 156.3489 - val_loss: 123536.1250 - val_mae: 163.6477 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 105208.7031 - mae: 155.6283 - val_loss: 133512.9219 - val_mae: 168.6928 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 104670.8125 - mae: 154.7649 - val_loss: 119560.0078 - val_mae: 161.5288 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 104893.3047 - mae: 154.8796 - val_loss: 124991.4844 - val_mae: 162.5936 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 104056.6797 - mae: 153.9097 - val_loss: 119187.3750 - val_mae: 160.6285 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 982us/step - loss: 103629.5312 - mae: 153.3227 - val_loss: 120460.5938 - val_mae: 159.5955 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 103205.7812 - mae: 152.9713 - val_loss: 127023.0391 - val_mae: 167.1916 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 103018.5391 - mae: 152.7713 - val_loss: 126855.3594 - val_mae: 166.5670 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 102529.2578 - mae: 152.0862 - val_loss: 127146.4766 - val_mae: 165.2264 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 102643.1875 - mae: 151.9748 - val_loss: 122412.5312 - val_mae: 160.4671 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 102016.9688 - mae: 151.4174 - val_loss: 124765.8984 - val_mae: 161.1352 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 101729.4609 - mae: 151.4287 - val_loss: 122282.6953 - val_mae: 158.7232 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 101710.6719 - mae: 150.8716 - val_loss: 119721.0156 - val_mae: 159.3339 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 101406.6328 - mae: 150.3036 - val_loss: 116859.4688 - val_mae: 155.7975 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 101036.6562 - mae: 149.7735 - val_loss: 116739.7031 - val_mae: 155.6902 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 101098.7656 - mae: 150.1557 - val_loss: 119789.0312 - val_mae: 157.3718 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 101057.4609 - mae: 150.3435 - val_loss: 117277.6250 - val_mae: 156.8450 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 100571.2500 - mae: 149.7393 - val_loss: 117780.2656 - val_mae: 157.1981 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 100346.4531 - mae: 149.1919 - val_loss: 117032.5000 - val_mae: 156.4338 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 100067.7891 - mae: 149.0170 - val_loss: 118958.7891 - val_mae: 157.1934 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 100263.4219 - mae: 149.0342 - val_loss: 116137.4844 - val_mae: 155.0348 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 100330.8672 - mae: 149.0483 - val_loss: 127355.5234 - val_mae: 167.3824 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 99814.4297 - mae: 148.5715 - val_loss: 114123.9453 - val_mae: 154.6143 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 99874.6641 - mae: 148.4036 - val_loss: 119303.7500 - val_mae: 156.4538 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 99469.5938 - mae: 148.7124 - val_loss: 120204.2422 - val_mae: 157.3373 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 99561.0781 - mae: 148.3884 - val_loss: 115833.1797 - val_mae: 155.3129 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 99629.3125 - mae: 148.4328 - val_loss: 117606.7266 - val_mae: 152.8341 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 99499.3828 - mae: 147.9267 - val_loss: 113462.6875 - val_mae: 152.8910 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 99342.1172 - mae: 148.1101 - val_loss: 116150.6094 - val_mae: 154.7048 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:38:17,478]\u001b[0m Trial 61 finished with value: 116150.58398514116 and parameters: {'feature_dim': 37, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1655672.2500 - mae: 714.5001 - val_loss: 1272268.6250 - val_mae: 582.3433 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 1327918.7500 - mae: 606.2654 - val_loss: 938370.7500 - val_mae: 470.3320 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 937849.0000 - mae: 484.2989 - val_loss: 624241.0000 - val_mae: 371.7430 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 610912.3750 - mae: 378.6247 - val_loss: 398704.2188 - val_mae: 297.8759 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 381931.7500 - mae: 297.3719 - val_loss: 261875.5625 - val_mae: 246.2265 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 243748.2188 - mae: 242.3837 - val_loss: 188314.6719 - val_mae: 210.1083 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 170017.0469 - mae: 206.7399 - val_loss: 150835.7656 - val_mae: 193.2983 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 987us/step - loss: 136347.4219 - mae: 186.3498 - val_loss: 134720.2969 - val_mae: 175.8034 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 120322.3672 - mae: 174.3452 - val_loss: 125938.2109 - val_mae: 172.2800 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 113501.8125 - mae: 166.9353 - val_loss: 131933.4062 - val_mae: 170.4228 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 109112.8906 - mae: 161.9353 - val_loss: 129157.7891 - val_mae: 169.3229 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 108038.7031 - mae: 159.8479 - val_loss: 127893.6016 - val_mae: 164.0361 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 105612.7656 - mae: 157.8169 - val_loss: 123476.8906 - val_mae: 165.9983 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 104519.3906 - mae: 155.8112 - val_loss: 135083.1719 - val_mae: 170.6270 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 987us/step - loss: 103622.0078 - mae: 154.4751 - val_loss: 117297.0312 - val_mae: 158.3651 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 103423.8203 - mae: 154.2780 - val_loss: 123121.2734 - val_mae: 159.1657 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 102849.3047 - mae: 152.8982 - val_loss: 120967.1250 - val_mae: 157.7086 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 987us/step - loss: 103045.1328 - mae: 153.0319 - val_loss: 122749.0625 - val_mae: 161.9846 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 102865.9844 - mae: 152.8075 - val_loss: 122305.4531 - val_mae: 160.7330 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102324.1250 - mae: 152.1194 - val_loss: 120698.6797 - val_mae: 158.8184 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 102171.7109 - mae: 151.8124 - val_loss: 121059.0859 - val_mae: 160.6160 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 102301.1797 - mae: 151.5829 - val_loss: 118812.2422 - val_mae: 156.6597 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 982us/step - loss: 101699.0703 - mae: 151.1855 - val_loss: 123683.0703 - val_mae: 160.0766 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 101222.0547 - mae: 150.6269 - val_loss: 120476.0703 - val_mae: 161.7318 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 101533.5938 - mae: 150.2513 - val_loss: 119530.2734 - val_mae: 156.6819 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 98134.4688 - mae: 146.4334 - val_loss: 115997.4141 - val_mae: 153.9787 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 97859.8828 - mae: 145.9106 - val_loss: 115956.8828 - val_mae: 153.9994 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 97841.4141 - mae: 145.6977 - val_loss: 116355.8203 - val_mae: 153.8916 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 97845.2734 - mae: 145.6910 - val_loss: 115259.5000 - val_mae: 153.3010 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 97674.3828 - mae: 145.6498 - val_loss: 116582.2578 - val_mae: 154.3343 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 97732.9609 - mae: 145.4622 - val_loss: 116844.5391 - val_mae: 154.6489 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 97681.7891 - mae: 145.5737 - val_loss: 117907.5938 - val_mae: 154.8989 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 987us/step - loss: 97616.8203 - mae: 145.4695 - val_loss: 116411.2188 - val_mae: 153.1030 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 97611.9062 - mae: 145.2513 - val_loss: 116202.5000 - val_mae: 153.4825 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 97583.4766 - mae: 145.3543 - val_loss: 115871.9141 - val_mae: 153.0520 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 97561.7578 - mae: 145.3285 - val_loss: 115951.4219 - val_mae: 152.7025 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 981us/step - loss: 97464.2266 - mae: 145.2031 - val_loss: 114274.7031 - val_mae: 152.3300 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97488.1797 - mae: 145.1466 - val_loss: 115177.3438 - val_mae: 153.3256 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 97468.7500 - mae: 145.1862 - val_loss: 115523.9844 - val_mae: 152.6677 - lr: 1.0000e-04\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 995us/step - loss: 97356.2422 - mae: 145.2317 - val_loss: 114978.6406 - val_mae: 152.1374 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 97369.9844 - mae: 144.9298 - val_loss: 116967.4531 - val_mae: 153.6619 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 97282.4844 - mae: 144.7278 - val_loss: 114893.7031 - val_mae: 152.7518 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 97353.2891 - mae: 145.0142 - val_loss: 114971.2812 - val_mae: 152.0102 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 97263.7422 - mae: 144.8642 - val_loss: 114497.9297 - val_mae: 151.4385 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 97239.8984 - mae: 144.7751 - val_loss: 115008.8594 - val_mae: 152.5132 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 97230.7344 - mae: 144.9136 - val_loss: 115286.8750 - val_mae: 152.5204 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 97219.2500 - mae: 144.7239 - val_loss: 114684.4844 - val_mae: 152.8505 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 96839.9609 - mae: 144.6161 - val_loss: 115329.5547 - val_mae: 152.9336 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96791.6719 - mae: 144.3526 - val_loss: 115000.4531 - val_mae: 152.4300 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 96777.9062 - mae: 144.3210 - val_loss: 115065.5156 - val_mae: 152.3301 - lr: 1.0000e-05\n",
      "\u001b[32m[I 2022-07-28 18:39:12,353]\u001b[0m Trial 62 finished with value: 115065.49500455157 and parameters: {'feature_dim': 40, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1637378.6250 - mae: 712.5918 - val_loss: 1228875.2500 - val_mae: 566.2539 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1247454.1250 - mae: 581.1667 - val_loss: 847234.6875 - val_mae: 444.2188 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 820701.1875 - mae: 447.9644 - val_loss: 524546.6250 - val_mae: 341.8347 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 498585.9062 - mae: 342.9546 - val_loss: 322309.3438 - val_mae: 272.4633 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 298244.7188 - mae: 269.8115 - val_loss: 212405.4844 - val_mae: 231.2147 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 190449.8125 - mae: 221.7795 - val_loss: 164755.1875 - val_mae: 199.7203 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 143327.0156 - mae: 194.2081 - val_loss: 142404.5938 - val_mae: 193.1758 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 125163.5078 - mae: 180.4213 - val_loss: 134274.8594 - val_mae: 177.1647 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 116626.7344 - mae: 172.5168 - val_loss: 129008.0625 - val_mae: 179.0489 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 113528.0234 - mae: 168.1261 - val_loss: 130259.5859 - val_mae: 168.1277 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110578.8672 - mae: 164.5036 - val_loss: 127760.2188 - val_mae: 172.7456 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109335.5547 - mae: 163.0642 - val_loss: 128996.2109 - val_mae: 165.8496 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107391.8047 - mae: 161.0009 - val_loss: 121535.5781 - val_mae: 168.7039 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106670.6406 - mae: 159.3297 - val_loss: 133694.1406 - val_mae: 170.6669 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105282.4062 - mae: 157.8134 - val_loss: 120125.6328 - val_mae: 164.3745 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105040.6953 - mae: 157.1102 - val_loss: 123617.9766 - val_mae: 162.2233 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104303.7812 - mae: 155.7558 - val_loss: 126357.6719 - val_mae: 165.0378 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 104440.4297 - mae: 155.5836 - val_loss: 120656.9141 - val_mae: 163.7565 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104042.7891 - mae: 154.9693 - val_loss: 117308.7891 - val_mae: 157.9205 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102846.7344 - mae: 153.3257 - val_loss: 119870.1094 - val_mae: 159.7901 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102883.7656 - mae: 153.0939 - val_loss: 117856.5234 - val_mae: 157.9233 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 103136.5078 - mae: 153.1600 - val_loss: 117433.1094 - val_mae: 158.7859 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 101983.6016 - mae: 152.0392 - val_loss: 125189.5703 - val_mae: 161.8925 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101687.9297 - mae: 151.3200 - val_loss: 117941.4297 - val_mae: 164.9415 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101938.2031 - mae: 151.3009 - val_loss: 116966.6562 - val_mae: 157.3290 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 101503.2109 - mae: 150.9470 - val_loss: 113205.0547 - val_mae: 154.8301 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 101322.4062 - mae: 150.4824 - val_loss: 114568.9297 - val_mae: 151.8853 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 101156.1484 - mae: 150.1334 - val_loss: 122252.1875 - val_mae: 164.8710 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 101120.1797 - mae: 150.3333 - val_loss: 125032.3281 - val_mae: 164.0953 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 100714.0547 - mae: 149.6178 - val_loss: 122306.5000 - val_mae: 160.8495 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 100815.8438 - mae: 149.2789 - val_loss: 116754.8047 - val_mae: 154.9043 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 100539.8750 - mae: 149.2692 - val_loss: 119919.1797 - val_mae: 156.5437 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 100370.7344 - mae: 149.4397 - val_loss: 114270.9062 - val_mae: 151.9974 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 100278.4062 - mae: 148.4440 - val_loss: 114505.8359 - val_mae: 152.5459 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 100219.0859 - mae: 148.4258 - val_loss: 111970.7266 - val_mae: 151.4473 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 99728.6797 - mae: 147.8460 - val_loss: 112854.1406 - val_mae: 151.7109 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 99973.5000 - mae: 148.3446 - val_loss: 117087.6641 - val_mae: 156.1738 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 99912.8984 - mae: 148.5235 - val_loss: 113390.6406 - val_mae: 153.1197 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 99699.6172 - mae: 148.0966 - val_loss: 113911.9297 - val_mae: 153.4316 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 981us/step - loss: 99296.7734 - mae: 147.6813 - val_loss: 111703.0703 - val_mae: 152.3513 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 99080.8438 - mae: 147.3282 - val_loss: 114588.2891 - val_mae: 153.5543 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 99258.4688 - mae: 146.8667 - val_loss: 111046.4688 - val_mae: 150.2944 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 99415.0625 - mae: 147.3366 - val_loss: 127816.1016 - val_mae: 168.6115 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 99237.7500 - mae: 147.3507 - val_loss: 111339.5547 - val_mae: 149.4692 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 99093.5000 - mae: 146.7446 - val_loss: 117551.9688 - val_mae: 152.2190 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 98859.7734 - mae: 147.2899 - val_loss: 117706.3516 - val_mae: 154.6581 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 98997.8438 - mae: 147.2792 - val_loss: 113279.2578 - val_mae: 151.3776 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 98736.9688 - mae: 146.8227 - val_loss: 114463.0938 - val_mae: 149.5798 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 98755.8984 - mae: 146.5902 - val_loss: 112006.6172 - val_mae: 149.3433 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 98832.7109 - mae: 146.9722 - val_loss: 113104.4688 - val_mae: 150.1787 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:40:08,276]\u001b[0m Trial 63 finished with value: 113104.50575466307 and parameters: {'feature_dim': 42, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1659988.7500 - mae: 716.0879 - val_loss: 1279973.5000 - val_mae: 582.7973 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1341609.6250 - mae: 610.1152 - val_loss: 954198.3750 - val_mae: 480.0263 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 958872.2500 - mae: 491.9528 - val_loss: 642691.5000 - val_mae: 379.6041 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 633639.5625 - mae: 388.3386 - val_loss: 415930.6562 - val_mae: 307.3879 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 402856.5938 - mae: 309.0571 - val_loss: 274951.7188 - val_mae: 253.0122 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 259016.2344 - mae: 252.1655 - val_loss: 199046.5156 - val_mae: 216.3496 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 180531.6562 - mae: 215.0603 - val_loss: 159377.8750 - val_mae: 208.8046 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 143663.2188 - mae: 193.1666 - val_loss: 138200.2344 - val_mae: 179.9464 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 126074.0312 - mae: 179.3856 - val_loss: 130401.9297 - val_mae: 178.2122 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 119068.6641 - mae: 172.5107 - val_loss: 135813.5781 - val_mae: 170.8032 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 114822.4922 - mae: 167.4508 - val_loss: 130859.7188 - val_mae: 172.0844 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 112957.5391 - mae: 164.9283 - val_loss: 133683.9375 - val_mae: 169.3413 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111151.9844 - mae: 163.1117 - val_loss: 126329.2422 - val_mae: 171.2541 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109963.2578 - mae: 161.3441 - val_loss: 137846.6562 - val_mae: 173.7437 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107781.9531 - mae: 158.8525 - val_loss: 121577.5391 - val_mae: 164.0447 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106902.5703 - mae: 158.0438 - val_loss: 125966.3594 - val_mae: 164.1745 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105617.1328 - mae: 156.6121 - val_loss: 125842.8281 - val_mae: 164.5812 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105661.9688 - mae: 156.7198 - val_loss: 125040.5000 - val_mae: 169.1064 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105486.3594 - mae: 156.4038 - val_loss: 120726.7578 - val_mae: 161.8692 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104083.6094 - mae: 154.7464 - val_loss: 122621.2500 - val_mae: 162.4947 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104068.2500 - mae: 154.9251 - val_loss: 122288.9375 - val_mae: 162.0699 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104377.3359 - mae: 154.9069 - val_loss: 122089.5859 - val_mae: 163.4163 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103397.4062 - mae: 153.8924 - val_loss: 126463.5000 - val_mae: 164.6477 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102675.8906 - mae: 152.7559 - val_loss: 118369.3984 - val_mae: 163.8528 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103263.8125 - mae: 153.2834 - val_loss: 121911.1875 - val_mae: 162.3652 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102618.2188 - mae: 152.4414 - val_loss: 115360.2422 - val_mae: 161.3473 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102355.6484 - mae: 152.0758 - val_loss: 116046.5156 - val_mae: 155.0996 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102265.8125 - mae: 151.8511 - val_loss: 124692.9297 - val_mae: 166.5018 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102049.9219 - mae: 151.7305 - val_loss: 127404.8281 - val_mae: 166.0438 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101658.5781 - mae: 150.9634 - val_loss: 123552.0703 - val_mae: 162.8591 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101878.6953 - mae: 150.9212 - val_loss: 121234.8359 - val_mae: 159.5911 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101249.5469 - mae: 150.3019 - val_loss: 124131.1562 - val_mae: 159.7863 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101047.1953 - mae: 150.7700 - val_loss: 118460.4688 - val_mae: 156.2711 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101103.6172 - mae: 150.0626 - val_loss: 118650.7266 - val_mae: 155.9475 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100804.7422 - mae: 149.5660 - val_loss: 113478.1797 - val_mae: 152.7174 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100553.0703 - mae: 149.0843 - val_loss: 114984.5547 - val_mae: 151.9259 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100333.2109 - mae: 149.1745 - val_loss: 117749.8516 - val_mae: 155.5858 - lr: 0.0010\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100499.7266 - mae: 149.8368 - val_loss: 114788.2578 - val_mae: 153.2265 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100150.3125 - mae: 149.1970 - val_loss: 116046.9375 - val_mae: 156.5329 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99761.1797 - mae: 148.5811 - val_loss: 113984.7344 - val_mae: 154.2623 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99483.8672 - mae: 148.0655 - val_loss: 117976.9844 - val_mae: 155.0725 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99599.3672 - mae: 147.8407 - val_loss: 112433.9766 - val_mae: 149.9245 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100129.7422 - mae: 148.7173 - val_loss: 130992.7734 - val_mae: 171.2402 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99391.4297 - mae: 147.9942 - val_loss: 111174.6719 - val_mae: 149.6385 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99509.0703 - mae: 147.5857 - val_loss: 116370.0000 - val_mae: 151.7706 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99202.9375 - mae: 148.0698 - val_loss: 121745.2578 - val_mae: 157.0984 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99319.0078 - mae: 147.9396 - val_loss: 112916.4609 - val_mae: 151.9893 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99092.0547 - mae: 147.8100 - val_loss: 116476.4062 - val_mae: 151.4325 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99176.1016 - mae: 147.7583 - val_loss: 111507.8047 - val_mae: 150.8488 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98947.1953 - mae: 147.7141 - val_loss: 113065.8672 - val_mae: 150.1437 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:41:07,802]\u001b[0m Trial 64 finished with value: 113065.8464081839 and parameters: {'feature_dim': 50, 'output_dim': 12, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1685333.2500 - mae: 728.8158 - val_loss: 1342309.6250 - val_mae: 604.0236 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 1474567.1250 - mae: 651.7068 - val_loss: 1120568.1250 - val_mae: 530.5966 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 945us/step - loss: 1199210.1250 - mae: 567.2522 - val_loss: 875613.0000 - val_mae: 453.5080 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 921713.1875 - mae: 480.3120 - val_loss: 652917.4375 - val_mae: 385.9598 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 677323.1875 - mae: 402.1935 - val_loss: 471925.3750 - val_mae: 321.1766 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 481895.8750 - mae: 336.5315 - val_loss: 340980.4375 - val_mae: 275.3719 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 338771.4062 - mae: 284.6118 - val_loss: 251936.3281 - val_mae: 243.0296 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 243634.0781 - mae: 245.9692 - val_loss: 197943.4375 - val_mae: 216.0849 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 183423.7500 - mae: 216.4698 - val_loss: 163448.6250 - val_mae: 205.5351 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 149864.7812 - mae: 196.6708 - val_loss: 150960.6719 - val_mae: 184.2425 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 131073.7656 - mae: 182.9864 - val_loss: 137420.6875 - val_mae: 176.3277 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 122411.6562 - mae: 174.8706 - val_loss: 145963.7031 - val_mae: 176.0075 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 116300.8516 - mae: 169.6374 - val_loss: 127494.8125 - val_mae: 172.8517 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 113247.6562 - mae: 166.0874 - val_loss: 140818.1406 - val_mae: 174.4090 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 110567.0234 - mae: 162.8586 - val_loss: 121846.9062 - val_mae: 167.1725 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 109601.7266 - mae: 161.6205 - val_loss: 128621.8672 - val_mae: 163.6660 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 107851.4297 - mae: 159.6310 - val_loss: 125141.5078 - val_mae: 167.4101 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 107834.4688 - mae: 159.1933 - val_loss: 120452.1719 - val_mae: 164.3937 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 106545.3047 - mae: 157.6893 - val_loss: 119710.8047 - val_mae: 159.2511 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 105495.1875 - mae: 156.4242 - val_loss: 119303.3047 - val_mae: 158.3183 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 105363.9453 - mae: 156.3065 - val_loss: 119807.6328 - val_mae: 159.2180 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 105422.2031 - mae: 155.4567 - val_loss: 120580.3125 - val_mae: 158.9494 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 103989.6406 - mae: 154.3002 - val_loss: 127574.1484 - val_mae: 163.3042 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 103745.5938 - mae: 153.9371 - val_loss: 119305.1172 - val_mae: 162.6125 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 103789.9531 - mae: 153.6002 - val_loss: 120277.1797 - val_mae: 158.9103 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 103363.7734 - mae: 153.2585 - val_loss: 116214.8125 - val_mae: 161.2089 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 945us/step - loss: 103136.2734 - mae: 153.2280 - val_loss: 118757.3516 - val_mae: 156.5001 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 103063.6797 - mae: 152.6807 - val_loss: 124935.8047 - val_mae: 165.9201 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 102697.7109 - mae: 152.1712 - val_loss: 124424.8594 - val_mae: 163.2392 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 102487.0234 - mae: 151.9372 - val_loss: 127073.9141 - val_mae: 165.5135 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 102642.4766 - mae: 151.9300 - val_loss: 120617.5938 - val_mae: 157.8248 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 102302.8594 - mae: 151.6342 - val_loss: 124056.3047 - val_mae: 159.1602 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 101845.4375 - mae: 151.5093 - val_loss: 117576.7891 - val_mae: 154.4655 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 101997.3125 - mae: 151.2268 - val_loss: 119021.6719 - val_mae: 158.0423 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 101605.9766 - mae: 150.6767 - val_loss: 115908.2031 - val_mae: 155.8554 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 101548.8906 - mae: 150.5791 - val_loss: 116661.5000 - val_mae: 156.0787 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 101459.0781 - mae: 150.9018 - val_loss: 117953.1562 - val_mae: 154.9291 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 101348.6406 - mae: 150.8221 - val_loss: 116067.2109 - val_mae: 154.8847 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 101052.5000 - mae: 150.4831 - val_loss: 118615.8125 - val_mae: 159.3545 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 100827.3047 - mae: 150.1024 - val_loss: 114934.2891 - val_mae: 155.8033 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 100419.4531 - mae: 149.5753 - val_loss: 118134.7344 - val_mae: 156.1399 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 100591.8125 - mae: 149.4954 - val_loss: 113695.4062 - val_mae: 153.6389 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 100916.0938 - mae: 149.9936 - val_loss: 123953.6328 - val_mae: 163.2243 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 945us/step - loss: 100442.1875 - mae: 149.6162 - val_loss: 113419.1719 - val_mae: 154.5689 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 100319.9922 - mae: 149.0582 - val_loss: 120220.9297 - val_mae: 157.7881 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 100196.3359 - mae: 149.5024 - val_loss: 121106.9062 - val_mae: 157.5589 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 100151.4844 - mae: 149.5040 - val_loss: 116955.8594 - val_mae: 158.8142 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 100125.9766 - mae: 149.4542 - val_loss: 118613.3438 - val_mae: 154.8456 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 100150.5625 - mae: 149.0294 - val_loss: 113565.5547 - val_mae: 155.9487 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 100018.3984 - mae: 149.4658 - val_loss: 115126.2266 - val_mae: 153.9476 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:42:00,345]\u001b[0m Trial 65 finished with value: 115126.22318663068 and parameters: {'feature_dim': 35, 'output_dim': 6, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1666510.2500 - mae: 718.5289 - val_loss: 1293937.1250 - val_mae: 588.4102 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 1372240.6250 - mae: 619.8478 - val_loss: 992715.2500 - val_mae: 489.7574 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 1013165.5000 - mae: 509.1041 - val_loss: 693239.9375 - val_mae: 394.5852 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 694165.9375 - mae: 408.2009 - val_loss: 462598.7812 - val_mae: 324.5692 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 456200.0938 - mae: 329.4853 - val_loss: 310194.2188 - val_mae: 267.7598 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 298209.6562 - mae: 270.5306 - val_loss: 221720.8125 - val_mae: 231.6534 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 205218.8594 - mae: 231.3743 - val_loss: 172911.3906 - val_mae: 216.8622 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 156628.3906 - mae: 205.4677 - val_loss: 149163.6719 - val_mae: 192.8375 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 132968.1562 - mae: 188.6521 - val_loss: 137442.5469 - val_mae: 189.8921 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 122710.4922 - mae: 179.6859 - val_loss: 139697.1875 - val_mae: 179.5895 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 117224.7109 - mae: 173.2864 - val_loss: 132121.7031 - val_mae: 177.9331 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 114990.6250 - mae: 169.9925 - val_loss: 136608.1875 - val_mae: 176.9281 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 112769.8984 - mae: 167.7956 - val_loss: 127150.5625 - val_mae: 173.4244 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 111244.4062 - mae: 165.7268 - val_loss: 140807.3750 - val_mae: 177.8918 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 109840.5547 - mae: 163.7408 - val_loss: 123442.2266 - val_mae: 170.4814 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 109040.7578 - mae: 163.3563 - val_loss: 130024.1016 - val_mae: 170.1362 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 107392.4609 - mae: 161.3300 - val_loss: 130410.2500 - val_mae: 171.4658 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 107062.4531 - mae: 161.0139 - val_loss: 121945.0859 - val_mae: 166.1517 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 106278.2266 - mae: 160.1965 - val_loss: 122231.8594 - val_mae: 163.3503 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 104716.7734 - mae: 158.2662 - val_loss: 124513.9141 - val_mae: 165.8410 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 104389.5625 - mae: 157.5252 - val_loss: 121208.0000 - val_mae: 163.0191 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 104493.2656 - mae: 157.2023 - val_loss: 120927.6719 - val_mae: 163.0122 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 103483.9609 - mae: 155.5126 - val_loss: 126437.5078 - val_mae: 164.5783 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 102906.5312 - mae: 154.6376 - val_loss: 118132.3594 - val_mae: 162.8352 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 103435.1016 - mae: 154.4359 - val_loss: 120196.6641 - val_mae: 161.8663 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 102855.3203 - mae: 153.4469 - val_loss: 115532.3281 - val_mae: 159.8223 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 102533.9688 - mae: 152.8125 - val_loss: 118787.1797 - val_mae: 158.2200 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 102329.2031 - mae: 152.3730 - val_loss: 123678.2344 - val_mae: 165.9067 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 102261.2344 - mae: 152.2171 - val_loss: 124452.9297 - val_mae: 165.6344 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 101927.0781 - mae: 151.7724 - val_loss: 124580.1484 - val_mae: 163.9905 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 102010.3828 - mae: 151.7364 - val_loss: 121520.8828 - val_mae: 160.7154 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 101625.6484 - mae: 151.3017 - val_loss: 124660.2109 - val_mae: 160.5786 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 101568.1875 - mae: 151.7210 - val_loss: 118167.0781 - val_mae: 154.9792 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 101547.9844 - mae: 150.5627 - val_loss: 118649.9688 - val_mae: 158.2282 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 101395.0547 - mae: 150.5013 - val_loss: 115162.9531 - val_mae: 156.5377 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 955us/step - loss: 101093.1016 - mae: 150.1767 - val_loss: 116232.0547 - val_mae: 156.0717 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 101071.0078 - mae: 150.3038 - val_loss: 119202.8359 - val_mae: 157.4928 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 101043.2422 - mae: 150.4168 - val_loss: 118000.3203 - val_mae: 158.2023 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 100768.4688 - mae: 150.1757 - val_loss: 115497.7031 - val_mae: 158.3486 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 100559.2891 - mae: 149.7956 - val_loss: 115694.0703 - val_mae: 156.3213 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 100283.2891 - mae: 149.4524 - val_loss: 117944.4141 - val_mae: 157.0697 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 100332.5312 - mae: 149.0248 - val_loss: 114139.5547 - val_mae: 154.0118 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 100682.2031 - mae: 149.4613 - val_loss: 129718.8438 - val_mae: 171.0986 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 100304.1875 - mae: 149.2374 - val_loss: 113393.8984 - val_mae: 154.1003 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 100076.9609 - mae: 148.6495 - val_loss: 119309.9297 - val_mae: 155.0736 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 100113.9062 - mae: 149.2562 - val_loss: 120423.3438 - val_mae: 156.2881 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 99965.8594 - mae: 148.8781 - val_loss: 115925.7734 - val_mae: 154.3881 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 100050.2031 - mae: 148.9972 - val_loss: 117650.2188 - val_mae: 153.3472 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 99845.2266 - mae: 148.3716 - val_loss: 112941.4297 - val_mae: 151.9048 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 99786.0078 - mae: 148.6460 - val_loss: 114321.6094 - val_mae: 152.2935 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:42:53,634]\u001b[0m Trial 66 finished with value: 114321.57776631568 and parameters: {'feature_dim': 38, 'output_dim': 10, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1657428.1250 - mae: 719.7587 - val_loss: 1266820.5000 - val_mae: 579.6535 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1314060.0000 - mae: 602.5612 - val_loss: 920399.3750 - val_mae: 467.0818 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 913190.1875 - mae: 477.8236 - val_loss: 602096.9375 - val_mae: 367.3120 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 585337.9375 - mae: 372.5297 - val_loss: 380696.9062 - val_mae: 294.8746 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 363393.2500 - mae: 294.7989 - val_loss: 251441.4531 - val_mae: 243.5611 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 232322.1250 - mae: 241.7753 - val_loss: 184101.3125 - val_mae: 210.7118 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 164734.1094 - mae: 207.4761 - val_loss: 154724.1719 - val_mae: 199.8486 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 135161.9688 - mae: 187.7001 - val_loss: 138862.9531 - val_mae: 178.5793 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 121052.0859 - mae: 175.5509 - val_loss: 129695.8828 - val_mae: 178.6060 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 115075.3828 - mae: 169.3643 - val_loss: 131095.7500 - val_mae: 169.0081 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111141.6484 - mae: 164.5831 - val_loss: 131014.0625 - val_mae: 172.3968 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109778.3828 - mae: 162.3072 - val_loss: 132689.8594 - val_mae: 168.3275 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107611.5000 - mae: 159.8009 - val_loss: 121764.5000 - val_mae: 165.4940 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106824.7422 - mae: 158.1234 - val_loss: 137490.1094 - val_mae: 172.7738 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105691.7266 - mae: 156.7773 - val_loss: 120646.5078 - val_mae: 160.8114 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105303.3438 - mae: 156.4976 - val_loss: 125597.0938 - val_mae: 161.3577 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104468.3438 - mae: 155.0921 - val_loss: 122404.2031 - val_mae: 159.8575 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104621.1875 - mae: 155.2361 - val_loss: 121640.8203 - val_mae: 163.4861 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104355.1328 - mae: 154.9505 - val_loss: 123095.8203 - val_mae: 161.1527 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103547.9062 - mae: 154.0554 - val_loss: 122246.4375 - val_mae: 159.5655 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103609.2109 - mae: 153.9748 - val_loss: 125731.7344 - val_mae: 165.2434 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 103884.6328 - mae: 153.5653 - val_loss: 120406.2734 - val_mae: 158.6482 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102900.7422 - mae: 153.0633 - val_loss: 133125.0156 - val_mae: 167.9352 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102593.9141 - mae: 152.5600 - val_loss: 118446.4141 - val_mae: 160.5478 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 102959.2188 - mae: 152.6011 - val_loss: 121590.2109 - val_mae: 161.3150 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 102363.0547 - mae: 151.9712 - val_loss: 114707.2109 - val_mae: 158.1539 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102173.7422 - mae: 151.7441 - val_loss: 118634.0469 - val_mae: 155.2658 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 101963.6328 - mae: 151.2254 - val_loss: 125580.2500 - val_mae: 164.3705 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 102056.3516 - mae: 151.4972 - val_loss: 125873.0703 - val_mae: 163.6216 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 101576.0625 - mae: 150.4730 - val_loss: 122471.3984 - val_mae: 161.7838 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101570.6953 - mae: 150.6453 - val_loss: 119783.6953 - val_mae: 156.6989 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101167.6328 - mae: 150.1510 - val_loss: 122640.7031 - val_mae: 158.8582 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100967.9688 - mae: 150.2442 - val_loss: 117069.9453 - val_mae: 153.6646 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 100781.2656 - mae: 149.1124 - val_loss: 116580.6875 - val_mae: 154.0260 - lr: 0.0010\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 997us/step - loss: 100722.2422 - mae: 149.0413 - val_loss: 113853.9219 - val_mae: 153.7382 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 100340.7656 - mae: 148.8353 - val_loss: 116240.3594 - val_mae: 155.0305 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 100241.7500 - mae: 148.5875 - val_loss: 117175.0156 - val_mae: 155.8645 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 100260.5469 - mae: 148.8434 - val_loss: 114276.9688 - val_mae: 154.0234 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 100049.5859 - mae: 148.5123 - val_loss: 114135.7969 - val_mae: 153.2780 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 99788.4766 - mae: 147.9751 - val_loss: 113920.6719 - val_mae: 153.4013 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 99553.2969 - mae: 147.7892 - val_loss: 115731.9453 - val_mae: 154.2215 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 99564.9453 - mae: 147.4110 - val_loss: 112402.1328 - val_mae: 150.0457 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 99805.4766 - mae: 147.8048 - val_loss: 128032.7891 - val_mae: 169.3349 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 99500.1641 - mae: 147.7691 - val_loss: 109728.4062 - val_mae: 150.0959 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 99466.5938 - mae: 147.1848 - val_loss: 115755.2344 - val_mae: 151.1837 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 99333.6328 - mae: 147.5986 - val_loss: 118093.0859 - val_mae: 154.5260 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99074.4688 - mae: 147.3203 - val_loss: 114016.9609 - val_mae: 153.0936 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98999.1953 - mae: 147.0583 - val_loss: 113782.5625 - val_mae: 149.3396 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98944.9844 - mae: 146.8426 - val_loss: 112459.8125 - val_mae: 150.4934 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 99010.5781 - mae: 147.4500 - val_loss: 112596.6172 - val_mae: 149.4743 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:43:49,706]\u001b[0m Trial 67 finished with value: 112596.61054788591 and parameters: {'feature_dim': 46, 'output_dim': 12, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1651278.0000 - mae: 715.3510 - val_loss: 1256313.7500 - val_mae: 577.4444 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 1294167.2500 - mae: 596.1659 - val_loss: 897642.2500 - val_mae: 458.5515 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 883774.5000 - mae: 468.5512 - val_loss: 577239.0000 - val_mae: 355.2726 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 556601.8750 - mae: 361.7710 - val_loss: 359819.7500 - val_mae: 284.8873 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 341412.3125 - mae: 285.1979 - val_loss: 235929.9844 - val_mae: 239.2603 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 218961.5938 - mae: 232.9952 - val_loss: 179752.3125 - val_mae: 206.5933 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 158782.3125 - mae: 201.6387 - val_loss: 151011.5625 - val_mae: 202.5462 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 132134.6875 - mae: 184.1077 - val_loss: 136734.4844 - val_mae: 178.1756 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 119675.8359 - mae: 173.9420 - val_loss: 130456.7578 - val_mae: 178.2775 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 114932.0156 - mae: 168.8561 - val_loss: 131582.1719 - val_mae: 168.3356 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 111313.6328 - mae: 164.4226 - val_loss: 129534.1328 - val_mae: 173.2254 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 109361.1484 - mae: 162.2841 - val_loss: 127791.3594 - val_mae: 164.6654 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 107300.3359 - mae: 159.5436 - val_loss: 121830.3906 - val_mae: 164.4248 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 106372.2734 - mae: 157.8197 - val_loss: 137273.1719 - val_mae: 170.0740 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105391.5938 - mae: 156.4118 - val_loss: 121539.8672 - val_mae: 164.3828 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 105162.6719 - mae: 156.3691 - val_loss: 125841.8984 - val_mae: 161.3574 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 104449.4141 - mae: 154.7873 - val_loss: 125743.0391 - val_mae: 163.0567 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 104897.6875 - mae: 155.6097 - val_loss: 125867.8359 - val_mae: 165.1899 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 104832.5938 - mae: 155.0615 - val_loss: 122446.0703 - val_mae: 158.4261 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 103691.2188 - mae: 153.6097 - val_loss: 121704.3750 - val_mae: 160.2722 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 103811.7109 - mae: 153.7080 - val_loss: 121541.8906 - val_mae: 158.5235 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 104080.3438 - mae: 153.9576 - val_loss: 121349.3359 - val_mae: 158.6807 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 987us/step - loss: 103083.9375 - mae: 152.7075 - val_loss: 126899.1562 - val_mae: 161.2478 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 102788.7891 - mae: 152.7037 - val_loss: 120822.4609 - val_mae: 162.2551 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 987us/step - loss: 103374.7578 - mae: 152.4147 - val_loss: 121475.1953 - val_mae: 157.9959 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 102801.6641 - mae: 151.9492 - val_loss: 115324.7500 - val_mae: 155.6424 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 987us/step - loss: 102546.1719 - mae: 151.5433 - val_loss: 117257.7656 - val_mae: 153.4183 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 102436.1250 - mae: 151.3005 - val_loss: 123916.1953 - val_mae: 162.8873 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 987us/step - loss: 102476.8984 - mae: 151.5461 - val_loss: 124677.3203 - val_mae: 163.9357 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 101949.9297 - mae: 150.8095 - val_loss: 124487.4375 - val_mae: 162.1611 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 102123.5703 - mae: 150.9237 - val_loss: 121302.0312 - val_mae: 157.4348 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 101779.5781 - mae: 150.4860 - val_loss: 123220.8047 - val_mae: 157.3218 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 101677.1719 - mae: 150.6995 - val_loss: 119156.8516 - val_mae: 154.9229 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 101358.5312 - mae: 149.9436 - val_loss: 117509.8203 - val_mae: 154.7512 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 101469.9766 - mae: 150.0524 - val_loss: 114174.8203 - val_mae: 153.1194 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 101065.0078 - mae: 149.3189 - val_loss: 117245.9219 - val_mae: 153.8256 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 100990.5078 - mae: 149.7297 - val_loss: 120035.5938 - val_mae: 156.6782 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 101025.1094 - mae: 150.0273 - val_loss: 116812.7656 - val_mae: 154.9692 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 100842.7734 - mae: 149.7645 - val_loss: 116597.7500 - val_mae: 155.3645 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100461.0156 - mae: 148.9835 - val_loss: 115040.2109 - val_mae: 154.5173 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 100273.3359 - mae: 148.7380 - val_loss: 118623.5234 - val_mae: 156.8331 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100385.2891 - mae: 148.3202 - val_loss: 114800.1953 - val_mae: 153.6924 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 100545.2109 - mae: 149.1512 - val_loss: 134521.4219 - val_mae: 174.7999 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 100346.0391 - mae: 149.0551 - val_loss: 112776.8281 - val_mae: 151.0464 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 100167.3438 - mae: 148.4171 - val_loss: 118475.0625 - val_mae: 153.8204 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 99892.1875 - mae: 148.5818 - val_loss: 118508.7812 - val_mae: 154.2584 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 100031.2891 - mae: 148.5865 - val_loss: 116496.6953 - val_mae: 155.1117 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 99966.3906 - mae: 148.4621 - val_loss: 116825.7422 - val_mae: 151.6888 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 99823.8594 - mae: 148.1060 - val_loss: 113990.6562 - val_mae: 151.6631 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 99725.9297 - mae: 148.3535 - val_loss: 114639.9062 - val_mae: 151.0518 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:44:45,148]\u001b[0m Trial 68 finished with value: 114639.93844066966 and parameters: {'feature_dim': 41, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1646548.2500 - mae: 711.5749 - val_loss: 1246381.6250 - val_mae: 572.5641 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1278125.2500 - mae: 591.1371 - val_loss: 880914.0625 - val_mae: 456.2641 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 862645.3750 - mae: 462.4351 - val_loss: 559206.4375 - val_mae: 353.1416 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 536608.0000 - mae: 356.5878 - val_loss: 346706.6562 - val_mae: 282.3495 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 326558.5938 - mae: 280.2246 - val_loss: 229816.1875 - val_mae: 232.7640 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 209111.7188 - mae: 228.4754 - val_loss: 174904.0938 - val_mae: 202.5647 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 152465.8750 - mae: 197.2031 - val_loss: 151984.1094 - val_mae: 195.7738 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 126923.4766 - mae: 179.4808 - val_loss: 130401.4062 - val_mae: 172.6545 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 114910.4609 - mae: 169.4621 - val_loss: 122844.8516 - val_mae: 166.7720 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110548.9375 - mae: 163.4319 - val_loss: 131041.0234 - val_mae: 170.5006 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106903.8125 - mae: 159.2818 - val_loss: 125587.0547 - val_mae: 166.8713 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106261.3359 - mae: 157.6875 - val_loss: 127648.7734 - val_mae: 164.5430 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104347.3438 - mae: 155.5519 - val_loss: 119966.6250 - val_mae: 164.6160 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103682.8906 - mae: 154.3099 - val_loss: 133846.2656 - val_mae: 169.0678 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102648.2188 - mae: 152.8674 - val_loss: 115475.5625 - val_mae: 157.7937 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102518.3359 - mae: 152.9645 - val_loss: 122894.0156 - val_mae: 159.6873 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101896.1406 - mae: 151.7356 - val_loss: 119106.2266 - val_mae: 156.2486 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102403.7422 - mae: 152.1858 - val_loss: 120065.3750 - val_mae: 158.1924 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102346.7031 - mae: 152.0307 - val_loss: 118223.4141 - val_mae: 155.8665 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101407.2500 - mae: 151.1860 - val_loss: 117907.8047 - val_mae: 155.2086 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101178.0391 - mae: 150.6682 - val_loss: 116668.2031 - val_mae: 155.1014 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101772.0156 - mae: 150.9380 - val_loss: 117153.8594 - val_mae: 153.7664 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100828.9219 - mae: 150.2064 - val_loss: 122826.3047 - val_mae: 159.4289 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100539.4219 - mae: 149.8684 - val_loss: 118098.0547 - val_mae: 162.1198 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101082.5234 - mae: 150.0542 - val_loss: 115906.1172 - val_mae: 154.2633 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97632.2578 - mae: 145.7108 - val_loss: 113677.2188 - val_mae: 152.1882 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97103.1797 - mae: 145.0511 - val_loss: 114326.3125 - val_mae: 152.7673 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97085.6328 - mae: 144.8078 - val_loss: 114972.3125 - val_mae: 153.0073 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97073.4844 - mae: 144.8473 - val_loss: 113372.2578 - val_mae: 152.1610 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96924.0938 - mae: 144.7794 - val_loss: 115761.9688 - val_mae: 153.8917 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96927.7266 - mae: 144.6362 - val_loss: 115789.1719 - val_mae: 154.2336 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96886.7109 - mae: 144.7361 - val_loss: 116816.1953 - val_mae: 154.6576 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96863.1484 - mae: 144.6444 - val_loss: 114499.4453 - val_mae: 152.2432 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96819.6094 - mae: 144.3606 - val_loss: 115226.7266 - val_mae: 153.6192 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96795.9531 - mae: 144.5381 - val_loss: 114664.8125 - val_mae: 152.8713 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96778.7500 - mae: 144.4566 - val_loss: 114308.1484 - val_mae: 152.8797 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96733.4375 - mae: 144.4469 - val_loss: 113494.2969 - val_mae: 152.3125 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96687.4219 - mae: 144.4546 - val_loss: 114431.3828 - val_mae: 152.9141 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96698.4453 - mae: 144.4036 - val_loss: 115064.9062 - val_mae: 153.1442 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96239.1953 - mae: 143.9399 - val_loss: 114319.2266 - val_mae: 152.5605 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96206.2109 - mae: 143.7895 - val_loss: 114942.6719 - val_mae: 153.1864 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96198.9375 - mae: 143.7383 - val_loss: 114413.6562 - val_mae: 152.8174 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96197.5078 - mae: 143.8887 - val_loss: 114379.8672 - val_mae: 152.7640 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96194.9609 - mae: 143.7694 - val_loss: 114426.6406 - val_mae: 152.8302 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96181.0938 - mae: 143.7984 - val_loss: 114358.9531 - val_mae: 152.7516 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96191.1641 - mae: 143.7482 - val_loss: 114350.8516 - val_mae: 152.8031 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96178.0156 - mae: 143.7416 - val_loss: 114407.8047 - val_mae: 152.8481 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96162.4922 - mae: 143.7249 - val_loss: 114986.6016 - val_mae: 153.4510 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96182.1562 - mae: 143.8047 - val_loss: 114433.1484 - val_mae: 152.9138 - lr: 1.0000e-05\n",
      "\u001b[32m[I 2022-07-28 18:45:40,278]\u001b[0m Trial 69 finished with value: 114433.17344714898 and parameters: {'feature_dim': 44, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1669138.3750 - mae: 716.8640 - val_loss: 1310242.3750 - val_mae: 594.5795 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1416540.8750 - mae: 633.0085 - val_loss: 1054191.7500 - val_mae: 509.3348 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1105216.6250 - mae: 536.9217 - val_loss: 786611.8750 - val_mae: 419.9869 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 808235.8125 - mae: 442.2049 - val_loss: 559518.0625 - val_mae: 347.9407 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 563617.0000 - mae: 361.4877 - val_loss: 383797.5000 - val_mae: 287.8258 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 383398.8750 - mae: 298.4865 - val_loss: 275041.3750 - val_mae: 249.9640 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 263605.7500 - mae: 252.0609 - val_loss: 202305.2656 - val_mae: 218.2010 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 191475.2969 - mae: 219.3788 - val_loss: 164094.1094 - val_mae: 196.2137 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 149743.7188 - mae: 195.2230 - val_loss: 145425.0000 - val_mae: 187.9066 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 131099.6094 - mae: 182.1697 - val_loss: 143223.1562 - val_mae: 177.2932 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 119973.7891 - mae: 172.7947 - val_loss: 139688.2188 - val_mae: 177.2360 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 114829.0000 - mae: 167.4164 - val_loss: 132020.2188 - val_mae: 166.7931 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110706.1094 - mae: 163.3017 - val_loss: 125893.4844 - val_mae: 164.9145 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107645.7109 - mae: 159.2212 - val_loss: 139649.0000 - val_mae: 175.8438 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106003.7266 - mae: 157.3654 - val_loss: 121410.7266 - val_mae: 160.8886 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105308.9062 - mae: 156.2428 - val_loss: 127479.8984 - val_mae: 164.5858 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104725.6797 - mae: 155.4080 - val_loss: 123249.1875 - val_mae: 160.6770 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104971.7266 - mae: 155.6013 - val_loss: 126569.3906 - val_mae: 168.5269 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104568.2266 - mae: 154.8165 - val_loss: 123182.8281 - val_mae: 163.6472 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103454.5938 - mae: 153.8644 - val_loss: 122640.0312 - val_mae: 161.0680 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103311.8828 - mae: 153.4608 - val_loss: 122359.3906 - val_mae: 162.7582 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103702.9688 - mae: 153.3738 - val_loss: 123644.2344 - val_mae: 163.6219 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102452.0625 - mae: 152.4210 - val_loss: 130636.4297 - val_mae: 168.1331 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102013.4688 - mae: 151.7929 - val_loss: 121182.5625 - val_mae: 165.5834 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102273.0781 - mae: 151.5556 - val_loss: 119721.9453 - val_mae: 158.2392 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101880.5312 - mae: 151.4667 - val_loss: 115212.0469 - val_mae: 158.8202 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101583.8125 - mae: 150.9805 - val_loss: 116998.6484 - val_mae: 155.3720 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101421.6797 - mae: 150.6963 - val_loss: 125887.0781 - val_mae: 166.4727 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101276.0547 - mae: 150.8568 - val_loss: 124727.6562 - val_mae: 164.2308 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100976.2109 - mae: 150.3629 - val_loss: 123154.6797 - val_mae: 162.6659 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101131.6641 - mae: 150.2143 - val_loss: 119364.9375 - val_mae: 157.2611 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100681.0469 - mae: 149.9928 - val_loss: 122727.7188 - val_mae: 159.6727 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100539.1406 - mae: 150.1501 - val_loss: 117088.7500 - val_mae: 153.5517 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100528.4297 - mae: 149.6162 - val_loss: 117311.1250 - val_mae: 154.5043 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100367.0859 - mae: 149.2622 - val_loss: 114242.7969 - val_mae: 153.7669 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100064.6406 - mae: 148.9317 - val_loss: 117105.8359 - val_mae: 154.6312 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100018.4219 - mae: 149.2696 - val_loss: 117514.6406 - val_mae: 154.5248 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99958.0234 - mae: 149.4281 - val_loss: 115454.2578 - val_mae: 155.2699 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99660.9453 - mae: 149.1194 - val_loss: 118003.0781 - val_mae: 156.8973 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99522.6484 - mae: 148.7274 - val_loss: 114603.6562 - val_mae: 155.1358 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99004.3047 - mae: 148.4022 - val_loss: 116525.8906 - val_mae: 155.7213 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99224.5000 - mae: 148.1516 - val_loss: 111847.6875 - val_mae: 151.0637 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99568.6562 - mae: 148.8280 - val_loss: 124794.3438 - val_mae: 163.7158 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99101.2734 - mae: 148.4266 - val_loss: 111022.0000 - val_mae: 152.1058 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99034.6016 - mae: 147.7255 - val_loss: 117143.7891 - val_mae: 154.1309 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98717.1406 - mae: 148.2095 - val_loss: 117981.1641 - val_mae: 153.8750 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98707.2422 - mae: 148.1163 - val_loss: 115482.4844 - val_mae: 156.8314 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98761.2031 - mae: 148.1432 - val_loss: 116760.8359 - val_mae: 152.6776 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98593.6562 - mae: 147.6589 - val_loss: 111351.8125 - val_mae: 151.8010 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98537.5391 - mae: 147.8346 - val_loss: 112255.3281 - val_mae: 151.4707 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:46:43,717]\u001b[0m Trial 70 finished with value: 112255.32846479275 and parameters: {'feature_dim': 56, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1664929.8750 - mae: 717.7367 - val_loss: 1304079.2500 - val_mae: 596.8844 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1407323.8750 - mae: 633.0842 - val_loss: 1043939.8125 - val_mae: 508.0356 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1093542.3750 - mae: 533.8585 - val_loss: 774990.0000 - val_mae: 420.6790 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 796513.5625 - mae: 439.6125 - val_loss: 547557.1875 - val_mae: 350.3515 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 553747.3750 - mae: 361.0479 - val_loss: 379673.4062 - val_mae: 290.0860 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 376200.6562 - mae: 299.1980 - val_loss: 273534.9062 - val_mae: 251.2413 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 258870.9219 - mae: 252.6294 - val_loss: 206033.1875 - val_mae: 229.3686 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 189187.1094 - mae: 220.3795 - val_loss: 170153.6094 - val_mae: 202.5966 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 149745.8750 - mae: 196.4138 - val_loss: 148582.1875 - val_mae: 191.6749 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 131286.2031 - mae: 182.6136 - val_loss: 143544.9844 - val_mae: 178.3016 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 120306.5859 - mae: 172.6205 - val_loss: 134662.4531 - val_mae: 177.9514 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 115217.9297 - mae: 167.5699 - val_loss: 134197.6875 - val_mae: 170.8195 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111482.1562 - mae: 163.7305 - val_loss: 124673.8203 - val_mae: 171.5567 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109745.3906 - mae: 161.1339 - val_loss: 140402.6719 - val_mae: 178.1803 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107989.1719 - mae: 159.2810 - val_loss: 121176.1484 - val_mae: 165.8387 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106802.5391 - mae: 158.1052 - val_loss: 128508.7891 - val_mae: 164.1689 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105746.5234 - mae: 156.3977 - val_loss: 131013.8516 - val_mae: 166.8790 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106146.5234 - mae: 156.9595 - val_loss: 121661.9844 - val_mae: 162.8447 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105417.6172 - mae: 156.0733 - val_loss: 122369.6562 - val_mae: 160.3971 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104261.7812 - mae: 154.5495 - val_loss: 122150.0234 - val_mae: 159.6869 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104206.0156 - mae: 154.7325 - val_loss: 119881.4609 - val_mae: 158.8042 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104492.4922 - mae: 154.5675 - val_loss: 121917.7891 - val_mae: 158.3272 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103243.0547 - mae: 153.4912 - val_loss: 131492.0000 - val_mae: 165.9124 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102928.5859 - mae: 153.0707 - val_loss: 119804.1641 - val_mae: 164.9303 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103285.5234 - mae: 153.0350 - val_loss: 119641.2031 - val_mae: 157.4742 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102642.9766 - mae: 152.4011 - val_loss: 116919.3125 - val_mae: 161.4094 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102170.5703 - mae: 151.9118 - val_loss: 119107.8984 - val_mae: 156.4766 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102007.4609 - mae: 151.3264 - val_loss: 124123.2891 - val_mae: 164.6446 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102112.3750 - mae: 151.5415 - val_loss: 126429.2266 - val_mae: 163.9245 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101615.4062 - mae: 150.8271 - val_loss: 124901.0781 - val_mae: 162.2127 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102013.3125 - mae: 151.0247 - val_loss: 121435.4844 - val_mae: 156.6278 - lr: 0.0010\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101411.4453 - mae: 150.6090 - val_loss: 124341.8359 - val_mae: 159.1895 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101291.2188 - mae: 150.3775 - val_loss: 118761.0156 - val_mae: 152.8188 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101248.2969 - mae: 149.6832 - val_loss: 120984.0547 - val_mae: 157.4354 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101084.2344 - mae: 149.7415 - val_loss: 116085.9297 - val_mae: 155.3644 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100807.1641 - mae: 149.3174 - val_loss: 119539.5547 - val_mae: 157.3131 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100798.8906 - mae: 149.3572 - val_loss: 121155.5234 - val_mae: 157.5089 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100800.3906 - mae: 149.6095 - val_loss: 119431.7891 - val_mae: 156.5760 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100472.9922 - mae: 149.3134 - val_loss: 118085.4922 - val_mae: 158.1377 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100147.4609 - mae: 148.6553 - val_loss: 117749.9844 - val_mae: 155.8496 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99913.5938 - mae: 148.6874 - val_loss: 120267.2500 - val_mae: 156.5995 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99809.2266 - mae: 148.1392 - val_loss: 115694.1406 - val_mae: 152.2489 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100503.1641 - mae: 148.8785 - val_loss: 129107.0391 - val_mae: 166.9214 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99846.9688 - mae: 148.3255 - val_loss: 112862.8047 - val_mae: 150.7345 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99518.5859 - mae: 147.4346 - val_loss: 118629.3047 - val_mae: 154.1464 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99497.3438 - mae: 148.0551 - val_loss: 119223.3750 - val_mae: 153.9968 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99692.3047 - mae: 148.2942 - val_loss: 117024.7891 - val_mae: 155.1500 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99516.3672 - mae: 148.0596 - val_loss: 117245.6797 - val_mae: 151.5752 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99364.9219 - mae: 147.3513 - val_loss: 114666.2656 - val_mae: 152.1803 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99370.9844 - mae: 147.9500 - val_loss: 115444.2344 - val_mae: 152.6192 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:47:46,563]\u001b[0m Trial 71 finished with value: 115444.1925474082 and parameters: {'feature_dim': 56, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1762660.8750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.7500 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.0000 - mae: 737.2339 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.2500 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.1250 - mae: 737.2339 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.2500 - mae: 737.2347 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.8750 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.5000 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2333 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.5000 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.7500 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.6250 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2337 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.1250 - mae: 737.2337 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762658.8750 - mae: 737.2338 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.3750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.2500 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.7500 - mae: 737.2346 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.6250 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:48:15,310]\u001b[0m Trial 72 finished with value: 1487783.123857698 and parameters: {'feature_dim': 60, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1655179.1250 - mae: 713.6522 - val_loss: 1296502.7500 - val_mae: 590.9843 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1395871.8750 - mae: 627.0658 - val_loss: 1030728.3125 - val_mae: 502.4936 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1074368.0000 - mae: 527.7190 - val_loss: 755388.0000 - val_mae: 413.1046 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 773459.3125 - mae: 432.7739 - val_loss: 528180.1875 - val_mae: 341.7849 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 531023.6875 - mae: 353.6878 - val_loss: 362649.4688 - val_mae: 286.8325 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 355248.2188 - mae: 289.8913 - val_loss: 257310.2188 - val_mae: 244.0122 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 242098.3281 - mae: 244.1719 - val_loss: 188226.8125 - val_mae: 214.7005 - lr: 0.0010\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 177413.7031 - mae: 213.7310 - val_loss: 153651.9375 - val_mae: 193.6051 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 141822.2812 - mae: 192.4867 - val_loss: 142116.3906 - val_mae: 188.0842 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 126746.9766 - mae: 181.6121 - val_loss: 138480.1250 - val_mae: 175.7145 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 117015.3750 - mae: 172.8874 - val_loss: 131020.0156 - val_mae: 173.5653 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 112649.0625 - mae: 168.0353 - val_loss: 129564.0625 - val_mae: 169.5324 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109186.7109 - mae: 164.3898 - val_loss: 126416.1172 - val_mae: 169.8855 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106664.1172 - mae: 161.0504 - val_loss: 131756.8594 - val_mae: 170.7995 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105459.8672 - mae: 159.7870 - val_loss: 119322.1484 - val_mae: 165.3710 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105064.1641 - mae: 159.1299 - val_loss: 123118.1016 - val_mae: 163.5997 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103923.4531 - mae: 157.6953 - val_loss: 123432.6719 - val_mae: 163.7893 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104230.6094 - mae: 157.8170 - val_loss: 122678.7344 - val_mae: 166.4588 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103856.1406 - mae: 157.3116 - val_loss: 120672.4297 - val_mae: 162.0260 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102656.7266 - mae: 155.7433 - val_loss: 122944.4922 - val_mae: 166.1742 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102665.1328 - mae: 155.5123 - val_loss: 122279.4141 - val_mae: 165.7918 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102745.6641 - mae: 154.9822 - val_loss: 119773.3750 - val_mae: 161.1023 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101495.4062 - mae: 153.3746 - val_loss: 126056.1016 - val_mae: 164.3586 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101055.5703 - mae: 152.5306 - val_loss: 117330.7812 - val_mae: 160.1277 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101430.6172 - mae: 152.2756 - val_loss: 116239.9453 - val_mae: 158.3728 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100855.2500 - mae: 151.5056 - val_loss: 114226.4766 - val_mae: 158.7157 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100571.7188 - mae: 150.9208 - val_loss: 114375.2109 - val_mae: 154.9492 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100360.1953 - mae: 150.4669 - val_loss: 121646.0000 - val_mae: 162.2989 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100317.1094 - mae: 150.2427 - val_loss: 124659.1250 - val_mae: 163.1858 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100077.3672 - mae: 149.6493 - val_loss: 119342.4609 - val_mae: 157.6862 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100183.9531 - mae: 149.5739 - val_loss: 116086.7812 - val_mae: 153.3037 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99792.6875 - mae: 149.0308 - val_loss: 116721.7266 - val_mae: 156.7023 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99649.8750 - mae: 149.3001 - val_loss: 115430.6797 - val_mae: 152.8298 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99340.9453 - mae: 148.1464 - val_loss: 114661.6172 - val_mae: 153.3021 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99422.3359 - mae: 148.6777 - val_loss: 113148.1016 - val_mae: 153.6399 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99068.0000 - mae: 148.1000 - val_loss: 112990.6797 - val_mae: 153.4448 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99148.9141 - mae: 148.4568 - val_loss: 113285.3203 - val_mae: 154.8995 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99014.5234 - mae: 148.2608 - val_loss: 113723.2344 - val_mae: 155.9037 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98706.9688 - mae: 147.9082 - val_loss: 111380.7500 - val_mae: 150.4475 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98346.8906 - mae: 147.3623 - val_loss: 112436.8828 - val_mae: 153.7323 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98127.0547 - mae: 147.1313 - val_loss: 115243.1562 - val_mae: 151.9160 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98422.5312 - mae: 146.9414 - val_loss: 110524.2031 - val_mae: 149.3817 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98656.6797 - mae: 147.1643 - val_loss: 120641.4531 - val_mae: 162.8757 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98071.4219 - mae: 147.0086 - val_loss: 109831.7188 - val_mae: 150.2587 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98098.8828 - mae: 146.4434 - val_loss: 115399.9844 - val_mae: 152.7507 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97683.5938 - mae: 146.8785 - val_loss: 114434.3281 - val_mae: 151.4803 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97788.1328 - mae: 146.5665 - val_loss: 110638.8125 - val_mae: 151.0129 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98042.0000 - mae: 146.8197 - val_loss: 110929.1953 - val_mae: 148.4720 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97629.7266 - mae: 146.1281 - val_loss: 109895.2344 - val_mae: 148.8322 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97854.6094 - mae: 146.7576 - val_loss: 111064.3906 - val_mae: 149.9833 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:49:21,373]\u001b[0m Trial 73 finished with value: 111064.339620084 and parameters: {'feature_dim': 62, 'output_dim': 5, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1659430.5000 - mae: 713.7072 - val_loss: 1297411.7500 - val_mae: 588.6058 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1391483.6250 - mae: 624.9911 - val_loss: 1021799.3750 - val_mae: 500.8762 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1057523.3750 - mae: 522.1241 - val_loss: 737330.8125 - val_mae: 407.4912 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 748833.6250 - mae: 425.7138 - val_loss: 506225.7188 - val_mae: 334.3743 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 505558.0312 - mae: 346.1381 - val_loss: 342486.7500 - val_mae: 281.4168 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 335083.3438 - mae: 285.4497 - val_loss: 243472.9531 - val_mae: 242.7250 - lr: 0.0010\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 1ms/step - loss: 227343.2031 - mae: 239.9913 - val_loss: 178801.0469 - val_mae: 212.9540 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 168541.0156 - mae: 211.6964 - val_loss: 150767.1875 - val_mae: 192.1639 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 137655.8438 - mae: 192.1075 - val_loss: 136665.6250 - val_mae: 182.7414 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 123469.1328 - mae: 181.5468 - val_loss: 137785.9375 - val_mae: 179.0139 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 115060.0781 - mae: 172.5993 - val_loss: 131848.0781 - val_mae: 178.3423 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 110950.9609 - mae: 168.8366 - val_loss: 132811.2656 - val_mae: 172.6638 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 107662.4219 - mae: 164.3716 - val_loss: 125019.8672 - val_mae: 174.4195 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 106399.6562 - mae: 161.6925 - val_loss: 133948.8906 - val_mae: 171.9948 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 105299.0469 - mae: 159.8763 - val_loss: 119622.1484 - val_mae: 165.4808 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 104771.9297 - mae: 159.0842 - val_loss: 124792.5312 - val_mae: 166.1728 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 103989.9453 - mae: 157.7445 - val_loss: 122750.4688 - val_mae: 165.0196 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 104476.4141 - mae: 157.7494 - val_loss: 121277.0703 - val_mae: 165.4120 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 104130.7812 - mae: 156.8879 - val_loss: 120066.7891 - val_mae: 163.3415 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 103111.7734 - mae: 156.0888 - val_loss: 118215.0156 - val_mae: 163.1256 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 102732.5391 - mae: 155.4096 - val_loss: 118450.1562 - val_mae: 163.8060 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103356.8281 - mae: 155.5289 - val_loss: 119555.5859 - val_mae: 162.0659 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 101974.8516 - mae: 154.2292 - val_loss: 123385.3438 - val_mae: 162.6732 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 101714.7500 - mae: 153.8544 - val_loss: 117097.4844 - val_mae: 164.3685 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102160.3125 - mae: 153.7805 - val_loss: 119152.5312 - val_mae: 159.0842 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 101377.7266 - mae: 152.8506 - val_loss: 112737.7969 - val_mae: 156.5117 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101321.7422 - mae: 153.2524 - val_loss: 116884.3359 - val_mae: 158.9423 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100845.2500 - mae: 152.0993 - val_loss: 120545.3984 - val_mae: 164.5763 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100814.8906 - mae: 152.1254 - val_loss: 118864.5781 - val_mae: 164.2435 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 100609.2578 - mae: 151.8299 - val_loss: 121478.2812 - val_mae: 163.7878 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 100754.2891 - mae: 151.7353 - val_loss: 118019.0859 - val_mae: 159.0617 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 100225.9688 - mae: 150.7933 - val_loss: 117611.4375 - val_mae: 158.0323 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 99985.0938 - mae: 150.9030 - val_loss: 115167.7344 - val_mae: 154.9991 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 99862.1797 - mae: 150.4355 - val_loss: 116053.3203 - val_mae: 156.6676 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 100060.8984 - mae: 150.5345 - val_loss: 114043.3516 - val_mae: 156.9856 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 99610.5625 - mae: 150.1639 - val_loss: 116003.1953 - val_mae: 154.5982 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 96663.2031 - mae: 146.1050 - val_loss: 112046.2266 - val_mae: 153.2408 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96263.3281 - mae: 145.2329 - val_loss: 112831.0234 - val_mae: 154.4837 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 96189.0781 - mae: 145.2104 - val_loss: 112671.7344 - val_mae: 153.8502 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95938.7578 - mae: 145.1256 - val_loss: 112597.0391 - val_mae: 153.6224 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96008.3359 - mae: 144.9836 - val_loss: 113717.8594 - val_mae: 154.2102 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95897.8594 - mae: 144.7358 - val_loss: 112756.8906 - val_mae: 154.7078 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95972.1406 - mae: 145.0588 - val_loss: 112176.3047 - val_mae: 153.3972 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95833.9766 - mae: 144.7973 - val_loss: 111443.9609 - val_mae: 153.1761 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95849.5625 - mae: 144.7275 - val_loss: 112560.3125 - val_mae: 153.8436 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95743.7734 - mae: 144.9210 - val_loss: 113171.3516 - val_mae: 154.6803 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 95788.7500 - mae: 144.7781 - val_loss: 112476.1953 - val_mae: 154.4996 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95794.8828 - mae: 144.7589 - val_loss: 113296.7891 - val_mae: 154.3677 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95613.4297 - mae: 144.6400 - val_loss: 112401.5078 - val_mae: 153.6730 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95714.6719 - mae: 144.6768 - val_loss: 112374.7812 - val_mae: 153.1486 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:50:37,660]\u001b[0m Trial 74 finished with value: 112374.76326700348 and parameters: {'feature_dim': 72, 'output_dim': 5, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1700455.2500 - mae: 725.6457 - val_loss: 1366700.5000 - val_mae: 611.4005 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1516703.2500 - mae: 663.8652 - val_loss: 1168949.1250 - val_mae: 544.6512 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1265733.8750 - mae: 586.7523 - val_loss: 940022.0000 - val_mae: 472.0753 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1002967.6875 - mae: 507.0262 - val_loss: 723188.6875 - val_mae: 406.2364 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 761141.1250 - mae: 431.7719 - val_loss: 537106.4375 - val_mae: 347.3914 - lr: 0.0010\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 557449.1250 - mae: 365.1301 - val_loss: 398901.2812 - val_mae: 299.7490 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 399207.3125 - mae: 310.3702 - val_loss: 291351.0000 - val_mae: 266.3307 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 287258.4688 - mae: 268.3886 - val_loss: 223445.4375 - val_mae: 234.4545 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 210785.4062 - mae: 234.1982 - val_loss: 175826.1250 - val_mae: 212.3396 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 165366.3906 - mae: 211.2755 - val_loss: 153929.3594 - val_mae: 196.0291 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 138006.0000 - mae: 192.5906 - val_loss: 136840.8594 - val_mae: 180.6195 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 123098.4062 - mae: 180.9195 - val_loss: 133557.4375 - val_mae: 178.9693 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 114129.7188 - mae: 172.8863 - val_loss: 124280.8125 - val_mae: 169.3702 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109623.6250 - mae: 167.3918 - val_loss: 133744.7188 - val_mae: 178.1132 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106726.5000 - mae: 163.6678 - val_loss: 117153.9844 - val_mae: 164.1602 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105072.7188 - mae: 160.6916 - val_loss: 122295.2812 - val_mae: 164.7127 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104183.3047 - mae: 159.3976 - val_loss: 124467.9375 - val_mae: 166.8195 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104225.2891 - mae: 158.5392 - val_loss: 119118.5234 - val_mae: 163.8120 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104207.5938 - mae: 158.5030 - val_loss: 121264.8203 - val_mae: 165.2910 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102941.4766 - mae: 156.3651 - val_loss: 119252.3203 - val_mae: 163.9153 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102684.5391 - mae: 156.5594 - val_loss: 122424.8359 - val_mae: 165.2272 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103120.7500 - mae: 155.9309 - val_loss: 118069.3516 - val_mae: 159.1610 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102134.8594 - mae: 155.1520 - val_loss: 126541.5703 - val_mae: 165.2852 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101823.6953 - mae: 154.4086 - val_loss: 118683.7031 - val_mae: 164.2226 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102048.3594 - mae: 154.6202 - val_loss: 122639.5938 - val_mae: 168.1670 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98472.5156 - mae: 149.3805 - val_loss: 114188.6094 - val_mae: 155.3959 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98058.6406 - mae: 148.4743 - val_loss: 114598.9922 - val_mae: 156.4721 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97965.9297 - mae: 148.3343 - val_loss: 114986.9219 - val_mae: 156.7194 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97938.8906 - mae: 148.3720 - val_loss: 113739.7422 - val_mae: 155.9267 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97685.8281 - mae: 148.3040 - val_loss: 115255.0859 - val_mae: 157.5488 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97717.8203 - mae: 148.0717 - val_loss: 115984.8047 - val_mae: 158.0001 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97647.2109 - mae: 148.0361 - val_loss: 116290.8359 - val_mae: 158.2339 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97618.3672 - mae: 147.9996 - val_loss: 114694.0312 - val_mae: 156.3884 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97560.7578 - mae: 147.8574 - val_loss: 114834.2266 - val_mae: 157.0482 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97500.1953 - mae: 147.9534 - val_loss: 114744.4141 - val_mae: 156.2311 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97485.9766 - mae: 147.6926 - val_loss: 113878.9609 - val_mae: 155.6575 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97448.3828 - mae: 147.6839 - val_loss: 113006.0703 - val_mae: 155.3901 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97393.1562 - mae: 147.8775 - val_loss: 113994.1172 - val_mae: 156.2861 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97371.7109 - mae: 147.7292 - val_loss: 114347.1562 - val_mae: 155.7689 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97169.3672 - mae: 147.6469 - val_loss: 113661.5078 - val_mae: 155.0019 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97190.8203 - mae: 147.4386 - val_loss: 114933.0703 - val_mae: 156.0964 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97153.7500 - mae: 147.2458 - val_loss: 113674.5000 - val_mae: 156.5535 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97205.8672 - mae: 147.6749 - val_loss: 113261.7891 - val_mae: 155.0085 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97155.5859 - mae: 147.4419 - val_loss: 112666.5781 - val_mae: 154.1024 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97094.3359 - mae: 147.2039 - val_loss: 114004.5078 - val_mae: 156.1970 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97101.1094 - mae: 147.5579 - val_loss: 113626.9609 - val_mae: 155.4936 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97098.7188 - mae: 147.2749 - val_loss: 112986.9219 - val_mae: 155.2433 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97111.2031 - mae: 147.3855 - val_loss: 114563.4141 - val_mae: 156.3251 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96974.0547 - mae: 147.2430 - val_loss: 113426.8828 - val_mae: 154.9685 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96994.3594 - mae: 147.2318 - val_loss: 112818.3750 - val_mae: 154.0329 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:51:42,414]\u001b[0m Trial 75 finished with value: 112818.34440751545 and parameters: {'feature_dim': 63, 'output_dim': 5, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1624162.1250 - mae: 704.4196 - val_loss: 1215495.7500 - val_mae: 566.8781 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1230406.5000 - mae: 576.0166 - val_loss: 832105.4375 - val_mae: 437.8985 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 804125.0625 - mae: 441.9340 - val_loss: 510277.0312 - val_mae: 333.5463 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 483197.2812 - mae: 333.6759 - val_loss: 312585.3125 - val_mae: 268.2109 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 287858.5000 - mae: 260.9490 - val_loss: 206406.1562 - val_mae: 220.6089 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 186983.1094 - mae: 216.3268 - val_loss: 161523.0625 - val_mae: 193.0013 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 141638.2188 - mae: 189.6862 - val_loss: 141321.3281 - val_mae: 184.0059 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 122685.4062 - mae: 175.4301 - val_loss: 127334.4141 - val_mae: 167.2979 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 112902.6328 - mae: 166.4871 - val_loss: 122928.9922 - val_mae: 163.9248 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109474.9844 - mae: 161.3022 - val_loss: 129435.7188 - val_mae: 169.3509 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106177.6094 - mae: 157.6489 - val_loss: 129671.5859 - val_mae: 169.4041 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105647.9844 - mae: 156.6498 - val_loss: 124228.7422 - val_mae: 162.0246 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104425.2344 - mae: 155.5802 - val_loss: 120509.8828 - val_mae: 163.3588 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103587.4375 - mae: 154.1593 - val_loss: 128626.0469 - val_mae: 165.6829 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103111.3203 - mae: 153.4014 - val_loss: 115224.6406 - val_mae: 157.4761 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102751.0000 - mae: 153.2305 - val_loss: 117116.3203 - val_mae: 155.7180 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102401.5547 - mae: 152.2630 - val_loss: 119077.2422 - val_mae: 156.9066 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102714.8906 - mae: 153.1032 - val_loss: 117570.6797 - val_mae: 158.1188 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102565.7422 - mae: 152.4317 - val_loss: 115416.1953 - val_mae: 155.4333 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101425.2344 - mae: 151.3914 - val_loss: 119185.6016 - val_mae: 156.6935 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101682.6875 - mae: 151.5710 - val_loss: 116328.1562 - val_mae: 156.5843 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101829.1406 - mae: 151.4786 - val_loss: 119310.7422 - val_mae: 158.0128 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100751.1016 - mae: 150.7336 - val_loss: 121284.6719 - val_mae: 158.1900 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100442.6641 - mae: 150.0611 - val_loss: 120418.7500 - val_mae: 162.5016 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100996.5938 - mae: 150.4627 - val_loss: 114235.2422 - val_mae: 153.0098 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100255.6172 - mae: 149.6384 - val_loss: 113322.6953 - val_mae: 156.1249 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100200.2578 - mae: 149.5415 - val_loss: 117055.2734 - val_mae: 154.5841 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100062.6719 - mae: 149.2606 - val_loss: 121475.1328 - val_mae: 162.3415 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100064.5312 - mae: 149.4352 - val_loss: 126291.7812 - val_mae: 165.8814 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99747.5156 - mae: 148.8843 - val_loss: 122227.1641 - val_mae: 162.4053 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100038.9219 - mae: 148.8287 - val_loss: 121805.2500 - val_mae: 157.5432 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99496.1484 - mae: 148.5900 - val_loss: 119558.5703 - val_mae: 156.7890 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99457.6172 - mae: 148.5577 - val_loss: 116678.1875 - val_mae: 156.3244 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99094.1641 - mae: 147.6527 - val_loss: 114630.5859 - val_mae: 152.9978 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99202.8203 - mae: 147.8552 - val_loss: 114192.2500 - val_mae: 153.6688 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99102.2812 - mae: 147.6333 - val_loss: 116145.6875 - val_mae: 155.3038 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96277.7734 - mae: 144.0255 - val_loss: 112537.1562 - val_mae: 151.2173 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95915.3516 - mae: 143.3468 - val_loss: 113255.2969 - val_mae: 151.8596 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95904.0547 - mae: 143.2809 - val_loss: 113399.8125 - val_mae: 151.6759 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95676.7891 - mae: 143.3024 - val_loss: 113777.7812 - val_mae: 151.8271 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95784.3516 - mae: 143.0860 - val_loss: 114763.0703 - val_mae: 152.3703 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95712.2734 - mae: 142.8766 - val_loss: 113271.1172 - val_mae: 152.5345 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95721.2891 - mae: 143.1231 - val_loss: 112668.1484 - val_mae: 151.0420 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95635.8750 - mae: 143.0111 - val_loss: 112492.1562 - val_mae: 150.7655 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95624.5391 - mae: 142.9816 - val_loss: 112920.1250 - val_mae: 151.3098 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95640.6562 - mae: 143.1183 - val_loss: 113676.1250 - val_mae: 152.0784 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95592.8203 - mae: 142.9139 - val_loss: 113121.6406 - val_mae: 151.9841 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95624.7109 - mae: 142.9803 - val_loss: 114320.5078 - val_mae: 152.6308 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95503.7812 - mae: 142.8931 - val_loss: 113007.5703 - val_mae: 151.4338 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95593.0078 - mae: 142.9098 - val_loss: 113088.3594 - val_mae: 151.2339 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:52:55,686]\u001b[0m Trial 76 finished with value: 113088.40639852942 and parameters: {'feature_dim': 70, 'output_dim': 10, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1659885.5000 - mae: 719.1103 - val_loss: 1279122.6250 - val_mae: 584.6791 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 1340522.0000 - mae: 610.5206 - val_loss: 953412.4375 - val_mae: 478.8409 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 958104.1875 - mae: 492.2721 - val_loss: 642179.5625 - val_mae: 379.4449 - lr: 0.0010\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 984us/step - loss: 633376.8125 - mae: 388.3086 - val_loss: 416234.5625 - val_mae: 306.4892 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 402999.5938 - mae: 308.9081 - val_loss: 272960.8438 - val_mae: 253.0429 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 258223.0781 - mae: 250.9652 - val_loss: 198486.5000 - val_mae: 217.6703 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 179899.1562 - mae: 214.1529 - val_loss: 158042.6719 - val_mae: 203.8497 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 142877.6094 - mae: 191.9141 - val_loss: 137970.7188 - val_mae: 177.8183 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 125219.5234 - mae: 177.7968 - val_loss: 129699.3516 - val_mae: 172.6220 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 117956.3516 - mae: 170.5238 - val_loss: 134523.7188 - val_mae: 168.5419 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 113067.8984 - mae: 165.0784 - val_loss: 131265.4531 - val_mae: 170.6665 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 111325.3281 - mae: 162.6198 - val_loss: 132281.8438 - val_mae: 167.7751 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 108661.4375 - mae: 160.1929 - val_loss: 124399.8516 - val_mae: 167.6544 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 107406.7109 - mae: 158.3268 - val_loss: 133280.9219 - val_mae: 168.1506 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 105861.5859 - mae: 156.6090 - val_loss: 121816.1328 - val_mae: 164.5131 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 105618.7656 - mae: 156.2619 - val_loss: 126711.8828 - val_mae: 163.8288 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 104863.6484 - mae: 155.1270 - val_loss: 125251.3516 - val_mae: 163.8374 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 105150.8750 - mae: 155.4618 - val_loss: 122653.3594 - val_mae: 166.0336 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 104813.9844 - mae: 154.9828 - val_loss: 121972.2656 - val_mae: 163.2378 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 103900.8125 - mae: 154.0392 - val_loss: 125080.7266 - val_mae: 162.2626 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 103829.9453 - mae: 153.8809 - val_loss: 124389.3750 - val_mae: 163.0078 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 981us/step - loss: 104137.2266 - mae: 153.9675 - val_loss: 123706.8750 - val_mae: 163.0154 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 102958.3672 - mae: 152.8367 - val_loss: 126168.3594 - val_mae: 163.1770 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 102640.8828 - mae: 152.1232 - val_loss: 119598.8125 - val_mae: 161.2084 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 103056.9922 - mae: 152.5209 - val_loss: 121742.4609 - val_mae: 162.0249 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 102389.7266 - mae: 151.7600 - val_loss: 117815.9922 - val_mae: 159.6796 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 981us/step - loss: 102253.3750 - mae: 151.5976 - val_loss: 121066.4375 - val_mae: 158.5265 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 102120.0000 - mae: 151.3029 - val_loss: 127823.6016 - val_mae: 167.6214 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 101966.6094 - mae: 151.6464 - val_loss: 126603.7891 - val_mae: 164.1136 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 101577.2656 - mae: 150.7688 - val_loss: 126187.0547 - val_mae: 163.6107 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 101603.4844 - mae: 150.4991 - val_loss: 123265.9062 - val_mae: 160.5303 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 101137.0781 - mae: 150.1304 - val_loss: 122231.9766 - val_mae: 158.4028 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 100982.9688 - mae: 150.5270 - val_loss: 119993.9766 - val_mae: 154.8556 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 100825.1484 - mae: 149.5672 - val_loss: 119622.5781 - val_mae: 156.8442 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 100678.7734 - mae: 149.4057 - val_loss: 116488.5625 - val_mae: 156.9704 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 100292.9297 - mae: 148.9083 - val_loss: 116585.3984 - val_mae: 154.4128 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 100331.3906 - mae: 149.1423 - val_loss: 120284.7656 - val_mae: 156.9428 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 100322.2500 - mae: 149.4857 - val_loss: 115567.8359 - val_mae: 153.9148 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 99876.3047 - mae: 149.0577 - val_loss: 119135.3828 - val_mae: 157.5022 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 99756.7188 - mae: 148.2698 - val_loss: 114716.2500 - val_mae: 153.5850 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 99450.2891 - mae: 148.1525 - val_loss: 119256.7344 - val_mae: 157.7779 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 99472.7422 - mae: 147.7091 - val_loss: 115121.1719 - val_mae: 153.3168 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 99906.3438 - mae: 148.3335 - val_loss: 128920.0156 - val_mae: 168.2525 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 99532.1562 - mae: 147.9707 - val_loss: 112393.8281 - val_mae: 152.0047 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 99441.8438 - mae: 147.4381 - val_loss: 119945.9453 - val_mae: 155.1772 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 99132.3984 - mae: 147.9783 - val_loss: 122045.9219 - val_mae: 156.3256 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 99196.5469 - mae: 147.8275 - val_loss: 115336.4609 - val_mae: 154.7813 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 99086.1719 - mae: 147.6107 - val_loss: 117170.9922 - val_mae: 152.9565 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 98917.0234 - mae: 147.2763 - val_loss: 113505.2734 - val_mae: 153.4227 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 98903.5156 - mae: 147.4260 - val_loss: 114986.6016 - val_mae: 151.6195 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:53:50,104]\u001b[0m Trial 77 finished with value: 114986.60870185326 and parameters: {'feature_dim': 37, 'output_dim': 12, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1677707.8750 - mae: 721.8513 - val_loss: 1309284.2500 - val_mae: 593.3658 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 1391510.6250 - mae: 625.4332 - val_loss: 1012415.8750 - val_mae: 498.8824 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 949us/step - loss: 1039580.1250 - mae: 516.2371 - val_loss: 717414.3750 - val_mae: 400.7932 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 722473.8750 - mae: 415.1961 - val_loss: 483911.4688 - val_mae: 327.0683 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 479657.9375 - mae: 335.1976 - val_loss: 325860.5938 - val_mae: 271.1933 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 315085.2500 - mae: 275.2755 - val_loss: 234130.6406 - val_mae: 233.2061 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 215649.8125 - mae: 233.6861 - val_loss: 181131.6250 - val_mae: 215.2752 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 162714.8281 - mae: 206.0705 - val_loss: 154089.7500 - val_mae: 190.8096 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 136411.2500 - mae: 187.7608 - val_loss: 143537.9844 - val_mae: 187.7520 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 125058.4375 - mae: 177.5982 - val_loss: 140525.1719 - val_mae: 175.5400 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 118652.2812 - mae: 170.9949 - val_loss: 134664.9375 - val_mae: 175.4172 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 115751.5859 - mae: 167.4414 - val_loss: 136182.0625 - val_mae: 172.1661 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 113282.2422 - mae: 164.7139 - val_loss: 126213.0938 - val_mae: 170.7332 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 111553.6406 - mae: 162.4541 - val_loss: 139423.4531 - val_mae: 173.6607 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 109613.1953 - mae: 160.4153 - val_loss: 122135.1094 - val_mae: 163.3137 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 108835.9297 - mae: 160.0273 - val_loss: 129805.7344 - val_mae: 166.4081 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 107315.1172 - mae: 158.1196 - val_loss: 126196.5469 - val_mae: 163.6278 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 107020.9375 - mae: 158.1226 - val_loss: 120751.2109 - val_mae: 158.5107 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 106261.0547 - mae: 157.1077 - val_loss: 119495.5156 - val_mae: 157.4863 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 105022.5703 - mae: 155.9886 - val_loss: 121680.7891 - val_mae: 160.1656 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 104576.6797 - mae: 155.3707 - val_loss: 120296.3828 - val_mae: 160.5722 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 104793.1719 - mae: 155.6053 - val_loss: 120106.7812 - val_mae: 159.9617 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 103663.6562 - mae: 154.1289 - val_loss: 126386.6250 - val_mae: 164.7664 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 103101.6641 - mae: 153.5058 - val_loss: 118177.5000 - val_mae: 161.1516 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 103758.8203 - mae: 153.6609 - val_loss: 119468.8828 - val_mae: 158.9747 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 102989.0625 - mae: 152.8071 - val_loss: 114836.3594 - val_mae: 158.6321 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 102917.7734 - mae: 152.7828 - val_loss: 117841.3438 - val_mae: 156.3497 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 102713.2188 - mae: 152.5496 - val_loss: 123413.9297 - val_mae: 164.7694 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 102596.4062 - mae: 152.2414 - val_loss: 124703.6016 - val_mae: 165.6287 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 102261.0312 - mae: 151.7661 - val_loss: 122104.8203 - val_mae: 162.5208 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 102338.0312 - mae: 151.7343 - val_loss: 118420.5781 - val_mae: 156.6838 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 101982.3047 - mae: 151.3803 - val_loss: 123774.2578 - val_mae: 160.3328 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 101901.9375 - mae: 151.5189 - val_loss: 116665.9609 - val_mae: 154.4305 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 101814.0156 - mae: 150.8622 - val_loss: 116499.4609 - val_mae: 155.0975 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 101674.0938 - mae: 150.7296 - val_loss: 114853.2656 - val_mae: 153.5684 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 101436.8203 - mae: 150.2443 - val_loss: 115575.7812 - val_mae: 154.0217 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 99081.6562 - mae: 147.1383 - val_loss: 113894.5156 - val_mae: 153.3266 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 98912.9688 - mae: 146.8197 - val_loss: 114972.6406 - val_mae: 154.1295 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 98872.9688 - mae: 146.7195 - val_loss: 115657.2812 - val_mae: 154.4219 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 98710.0000 - mae: 146.6486 - val_loss: 114942.8125 - val_mae: 153.5945 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 98748.0625 - mae: 146.4855 - val_loss: 116880.3047 - val_mae: 155.5450 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 98734.8281 - mae: 146.3648 - val_loss: 114874.6016 - val_mae: 154.2616 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 98733.5625 - mae: 146.5710 - val_loss: 114983.1484 - val_mae: 153.7327 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 98690.5469 - mae: 146.3900 - val_loss: 114206.7031 - val_mae: 153.2637 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 98620.4141 - mae: 146.3317 - val_loss: 114890.3047 - val_mae: 154.2627 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 98661.7422 - mae: 146.5595 - val_loss: 115255.3516 - val_mae: 154.5113 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 98631.1797 - mae: 146.2672 - val_loss: 114450.5312 - val_mae: 154.1360 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 98359.0078 - mae: 146.4799 - val_loss: 115376.0859 - val_mae: 154.6221 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 98325.1797 - mae: 146.0056 - val_loss: 114855.2422 - val_mae: 154.0308 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 98305.9922 - mae: 146.0541 - val_loss: 114939.2031 - val_mae: 154.0095 - lr: 1.0000e-05\n",
      "\u001b[32m[I 2022-07-28 18:54:42,719]\u001b[0m Trial 78 finished with value: 114939.22457907465 and parameters: {'feature_dim': 34, 'output_dim': 7, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1674451.1250 - mae: 720.9879 - val_loss: 1314386.2500 - val_mae: 595.1361 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 1412500.7500 - mae: 632.0049 - val_loss: 1039760.2500 - val_mae: 509.3587 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 1050894.5000 - mae: 521.2574 - val_loss: 711483.5000 - val_mae: 401.5695 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 707786.2500 - mae: 412.7296 - val_loss: 469582.5312 - val_mae: 328.9876 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 461862.1250 - mae: 332.1057 - val_loss: 313787.7812 - val_mae: 268.8267 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 301773.6875 - mae: 271.9010 - val_loss: 227968.7031 - val_mae: 233.7833 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 207819.2188 - mae: 231.1653 - val_loss: 179050.3125 - val_mae: 224.4801 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 159019.1562 - mae: 204.8323 - val_loss: 154842.6406 - val_mae: 193.4542 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 135457.9062 - mae: 188.4770 - val_loss: 150979.4844 - val_mae: 197.4917 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 125207.2109 - mae: 179.2933 - val_loss: 142607.2188 - val_mae: 176.8917 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 118958.6641 - mae: 172.0871 - val_loss: 138816.7031 - val_mae: 180.9611 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 115948.8672 - mae: 167.6638 - val_loss: 139796.4375 - val_mae: 173.1236 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 113331.1016 - mae: 164.4176 - val_loss: 128752.0156 - val_mae: 169.7944 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 111490.5938 - mae: 162.0408 - val_loss: 142300.0000 - val_mae: 172.9493 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 109172.7812 - mae: 159.3141 - val_loss: 123706.7344 - val_mae: 165.4403 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 107621.0469 - mae: 158.3674 - val_loss: 129654.5312 - val_mae: 165.2818 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 106628.6094 - mae: 157.1243 - val_loss: 129089.6016 - val_mae: 165.2591 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 106613.3047 - mae: 156.9669 - val_loss: 122696.8672 - val_mae: 162.4516 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 106124.7266 - mae: 156.6661 - val_loss: 125615.8984 - val_mae: 161.6913 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 104477.7969 - mae: 155.0201 - val_loss: 122176.5391 - val_mae: 160.4138 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 104707.1406 - mae: 155.1623 - val_loss: 123064.7422 - val_mae: 162.2318 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 104603.7188 - mae: 154.9816 - val_loss: 120353.2656 - val_mae: 158.8718 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 103421.4922 - mae: 153.6702 - val_loss: 128292.3594 - val_mae: 164.6701 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 102851.6328 - mae: 153.2366 - val_loss: 117851.4688 - val_mae: 158.7023 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 103376.6172 - mae: 153.2563 - val_loss: 120302.0547 - val_mae: 160.1647 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 102726.5703 - mae: 152.7382 - val_loss: 115395.0234 - val_mae: 157.0916 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 102529.9844 - mae: 152.3396 - val_loss: 117651.1172 - val_mae: 157.0335 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 102164.0234 - mae: 151.9561 - val_loss: 124592.9219 - val_mae: 164.1782 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 102223.9219 - mae: 152.0697 - val_loss: 123064.0469 - val_mae: 162.1491 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 101527.4609 - mae: 151.0767 - val_loss: 121697.0859 - val_mae: 160.0740 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 101681.5000 - mae: 151.1309 - val_loss: 119388.9297 - val_mae: 156.9905 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 101443.1250 - mae: 150.8266 - val_loss: 119413.1328 - val_mae: 156.5567 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 101174.3359 - mae: 150.9833 - val_loss: 115822.0938 - val_mae: 153.1469 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 100904.3125 - mae: 149.3969 - val_loss: 115371.4062 - val_mae: 153.3819 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 100945.0312 - mae: 149.4989 - val_loss: 113150.6016 - val_mae: 153.4323 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 100414.9531 - mae: 149.0751 - val_loss: 113938.6172 - val_mae: 153.8284 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 100322.2500 - mae: 149.0327 - val_loss: 116549.8828 - val_mae: 155.2842 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 100433.3125 - mae: 149.4771 - val_loss: 113673.8516 - val_mae: 153.6217 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 100177.4844 - mae: 148.8208 - val_loss: 114965.6797 - val_mae: 153.3728 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 99505.9531 - mae: 148.0111 - val_loss: 114218.2656 - val_mae: 153.6276 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 99344.6875 - mae: 148.0415 - val_loss: 116942.0469 - val_mae: 155.6134 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 99385.0547 - mae: 147.5158 - val_loss: 112432.6094 - val_mae: 151.9131 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 99932.3359 - mae: 148.0673 - val_loss: 121765.2891 - val_mae: 163.1738 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 99319.1953 - mae: 147.4879 - val_loss: 110033.1406 - val_mae: 149.3156 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 99031.1250 - mae: 146.9566 - val_loss: 117196.1719 - val_mae: 153.6395 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 98862.3906 - mae: 147.4746 - val_loss: 116537.5625 - val_mae: 154.4145 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 99135.2812 - mae: 147.2989 - val_loss: 114399.0000 - val_mae: 155.4097 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 98795.1406 - mae: 147.1771 - val_loss: 113416.3984 - val_mae: 149.9027 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 98881.0938 - mae: 146.8664 - val_loss: 111870.3359 - val_mae: 149.9119 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 98694.1797 - mae: 147.0325 - val_loss: 113623.8203 - val_mae: 151.5469 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:55:36,131]\u001b[0m Trial 79 finished with value: 113623.80977838532 and parameters: {'feature_dim': 40, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1680502.0000 - mae: 725.1262 - val_loss: 1331132.5000 - val_mae: 603.1575 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1449062.3750 - mae: 643.9376 - val_loss: 1086976.7500 - val_mae: 520.4070 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1148472.8750 - mae: 549.8667 - val_loss: 823174.4375 - val_mae: 432.1790 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 854464.8750 - mae: 456.6248 - val_loss: 592034.8750 - val_mae: 357.4642 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 604658.8750 - mae: 374.2303 - val_loss: 413669.2188 - val_mae: 300.4163 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 416644.2188 - mae: 309.8956 - val_loss: 299267.6250 - val_mae: 258.7432 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 287790.2812 - mae: 261.8582 - val_loss: 214365.0469 - val_mae: 226.6508 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 207931.7344 - mae: 227.8000 - val_loss: 170118.9688 - val_mae: 203.0648 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 159887.0625 - mae: 201.9171 - val_loss: 150220.2500 - val_mae: 192.2212 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 135519.3750 - mae: 185.8032 - val_loss: 142777.8594 - val_mae: 177.1873 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 122477.7734 - mae: 174.8229 - val_loss: 134142.7656 - val_mae: 173.3222 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 115638.8438 - mae: 168.2202 - val_loss: 132731.1250 - val_mae: 169.5653 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111290.4375 - mae: 163.7339 - val_loss: 127285.7812 - val_mae: 165.1444 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108214.2891 - mae: 159.5282 - val_loss: 135769.8438 - val_mae: 170.1712 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106339.7656 - mae: 157.3600 - val_loss: 121035.7734 - val_mae: 161.0289 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105607.1797 - mae: 155.9962 - val_loss: 124825.2266 - val_mae: 161.9022 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104535.9609 - mae: 154.6552 - val_loss: 122276.1172 - val_mae: 159.0811 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104846.3828 - mae: 154.7186 - val_loss: 123953.8906 - val_mae: 163.2655 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104204.6250 - mae: 153.7824 - val_loss: 122267.1719 - val_mae: 159.7246 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103531.3828 - mae: 153.1154 - val_loss: 121188.8359 - val_mae: 159.3766 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103247.1172 - mae: 152.9787 - val_loss: 122398.7109 - val_mae: 160.9621 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103469.0547 - mae: 152.5266 - val_loss: 119618.1484 - val_mae: 156.0171 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102408.1875 - mae: 151.9090 - val_loss: 124631.9297 - val_mae: 161.0175 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101832.7422 - mae: 150.9728 - val_loss: 121759.3516 - val_mae: 161.0780 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102311.0156 - mae: 151.0427 - val_loss: 119856.8594 - val_mae: 157.8779 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101616.4844 - mae: 150.4282 - val_loss: 114252.8828 - val_mae: 155.0825 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101357.2734 - mae: 150.4149 - val_loss: 117884.0156 - val_mae: 154.7178 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101298.1953 - mae: 150.1105 - val_loss: 122852.1016 - val_mae: 161.0178 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100998.1016 - mae: 150.0126 - val_loss: 125132.4922 - val_mae: 163.1909 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100791.9609 - mae: 149.3281 - val_loss: 123892.0391 - val_mae: 161.9866 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101171.7500 - mae: 149.5337 - val_loss: 122086.8281 - val_mae: 157.9329 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100615.1016 - mae: 149.0381 - val_loss: 119630.8906 - val_mae: 155.9736 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100532.6719 - mae: 149.3374 - val_loss: 118158.8906 - val_mae: 153.7958 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100384.1875 - mae: 148.6422 - val_loss: 117330.8125 - val_mae: 154.5509 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100211.7031 - mae: 148.3482 - val_loss: 113442.9219 - val_mae: 151.8949 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99997.1641 - mae: 148.0497 - val_loss: 116455.2891 - val_mae: 153.0003 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99777.4141 - mae: 148.1380 - val_loss: 119052.6953 - val_mae: 159.0332 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99983.0781 - mae: 148.6004 - val_loss: 117719.9219 - val_mae: 156.5977 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99514.6250 - mae: 148.2609 - val_loss: 116823.2344 - val_mae: 153.5796 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99375.1328 - mae: 147.5774 - val_loss: 113412.9062 - val_mae: 152.8928 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98977.9922 - mae: 147.2372 - val_loss: 117666.3203 - val_mae: 153.2928 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99289.3984 - mae: 147.1819 - val_loss: 114495.8984 - val_mae: 150.9753 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99436.8125 - mae: 147.5117 - val_loss: 119958.2266 - val_mae: 159.4900 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99094.3125 - mae: 147.3936 - val_loss: 112185.4922 - val_mae: 149.9159 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99037.9688 - mae: 147.0381 - val_loss: 118936.1094 - val_mae: 153.7884 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98686.4688 - mae: 147.4956 - val_loss: 123743.4297 - val_mae: 156.9689 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98756.3828 - mae: 147.3532 - val_loss: 114596.8047 - val_mae: 154.1469 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98845.8047 - mae: 147.2613 - val_loss: 118023.5469 - val_mae: 151.9842 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98536.4297 - mae: 146.8353 - val_loss: 113172.7656 - val_mae: 151.0413 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98686.0547 - mae: 147.1296 - val_loss: 114431.9297 - val_mae: 150.5753 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 18:56:34,967]\u001b[0m Trial 80 finished with value: 114431.96347416381 and parameters: {'feature_dim': 48, 'output_dim': 6, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1688130.7500 - mae: 723.7482 - val_loss: 1334475.0000 - val_mae: 608.8683 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1442885.7500 - mae: 642.5753 - val_loss: 1072978.1250 - val_mae: 518.5604 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1122063.6250 - mae: 543.2622 - val_loss: 794014.0000 - val_mae: 427.8928 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 813935.6875 - mae: 445.6964 - val_loss: 556621.3750 - val_mae: 350.1711 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 561210.3125 - mae: 363.2103 - val_loss: 381665.1875 - val_mae: 293.1857 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 378438.9375 - mae: 300.1068 - val_loss: 269653.5625 - val_mae: 250.4721 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 258345.8125 - mae: 253.6782 - val_loss: 196584.0312 - val_mae: 220.7112 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 187861.2344 - mae: 222.0310 - val_loss: 159000.6719 - val_mae: 198.0562 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 148108.2344 - mae: 199.1371 - val_loss: 144060.7656 - val_mae: 190.7593 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 129985.1016 - mae: 186.6794 - val_loss: 139140.7188 - val_mae: 180.0296 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 118801.4062 - mae: 176.6743 - val_loss: 135742.5625 - val_mae: 179.7558 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 113757.2656 - mae: 170.5384 - val_loss: 135097.7812 - val_mae: 174.0903 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109439.1562 - mae: 165.3836 - val_loss: 127257.5859 - val_mae: 168.5006 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107596.4375 - mae: 162.1742 - val_loss: 135708.7344 - val_mae: 172.9964 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106504.1094 - mae: 160.5050 - val_loss: 121036.9297 - val_mae: 166.2716 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106152.2891 - mae: 159.6964 - val_loss: 129348.0312 - val_mae: 166.7221 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105356.0312 - mae: 158.3613 - val_loss: 127569.0938 - val_mae: 165.2633 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105419.3828 - mae: 158.2061 - val_loss: 125490.1641 - val_mae: 167.9498 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104768.9531 - mae: 157.1942 - val_loss: 122657.9375 - val_mae: 160.6959 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103825.1250 - mae: 156.2121 - val_loss: 123134.2969 - val_mae: 162.3515 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103712.2188 - mae: 155.9497 - val_loss: 125080.3594 - val_mae: 164.8903 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103846.1250 - mae: 156.0026 - val_loss: 121736.6797 - val_mae: 160.5182 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102754.8359 - mae: 154.9198 - val_loss: 129445.7812 - val_mae: 167.5470 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102265.9062 - mae: 154.2010 - val_loss: 122801.4141 - val_mae: 164.3433 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102556.0938 - mae: 153.8900 - val_loss: 123734.1641 - val_mae: 165.2132 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99120.0156 - mae: 150.0228 - val_loss: 118435.2109 - val_mae: 159.0122 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98830.7812 - mae: 149.4705 - val_loss: 118549.1172 - val_mae: 158.7493 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98725.3516 - mae: 149.0767 - val_loss: 118466.2656 - val_mae: 158.1768 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98696.9922 - mae: 149.0139 - val_loss: 117615.4609 - val_mae: 158.4793 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98469.8359 - mae: 148.8514 - val_loss: 118973.8281 - val_mae: 159.3051 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98465.7891 - mae: 148.5908 - val_loss: 120110.1250 - val_mae: 160.0442 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98403.3984 - mae: 148.6870 - val_loss: 120022.9922 - val_mae: 159.7507 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98331.4219 - mae: 148.2769 - val_loss: 118651.7031 - val_mae: 158.2662 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98288.0156 - mae: 148.2262 - val_loss: 118702.6016 - val_mae: 158.8693 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98228.0625 - mae: 148.2472 - val_loss: 118380.3594 - val_mae: 157.7263 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98227.9141 - mae: 148.0251 - val_loss: 117267.4688 - val_mae: 157.8078 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98146.5078 - mae: 148.0814 - val_loss: 116886.6172 - val_mae: 157.4071 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98130.2734 - mae: 147.8913 - val_loss: 117719.0703 - val_mae: 158.3713 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98066.0312 - mae: 147.9676 - val_loss: 117707.5938 - val_mae: 157.6191 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97900.1719 - mae: 147.8023 - val_loss: 117612.1875 - val_mae: 157.6906 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97901.4141 - mae: 147.5946 - val_loss: 119163.5469 - val_mae: 158.9996 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97878.3516 - mae: 147.3395 - val_loss: 117184.5234 - val_mae: 157.9468 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97880.7578 - mae: 147.5763 - val_loss: 116939.3984 - val_mae: 156.8809 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97786.7578 - mae: 147.3709 - val_loss: 116109.8125 - val_mae: 156.3347 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97785.5703 - mae: 147.3540 - val_loss: 117511.5000 - val_mae: 157.4725 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97769.5078 - mae: 147.4275 - val_loss: 117440.8125 - val_mae: 157.5059 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97730.9609 - mae: 147.1895 - val_loss: 116488.5469 - val_mae: 157.2119 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97760.0000 - mae: 147.3282 - val_loss: 118041.2812 - val_mae: 158.0979 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97643.3516 - mae: 147.1462 - val_loss: 116830.6250 - val_mae: 156.6806 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97678.2812 - mae: 147.1874 - val_loss: 116846.5000 - val_mae: 156.2893 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:57:40,445]\u001b[0m Trial 81 finished with value: 116846.48643955626 and parameters: {'feature_dim': 60, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1697855.2500 - mae: 724.1183 - val_loss: 1367577.7500 - val_mae: 612.6337 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1522216.7500 - mae: 665.3424 - val_loss: 1177839.3750 - val_mae: 548.3228 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1280118.3750 - mae: 591.4198 - val_loss: 956485.2500 - val_mae: 477.5748 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1023958.3750 - mae: 513.8245 - val_loss: 742205.8750 - val_mae: 413.7016 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 785206.9375 - mae: 439.7185 - val_loss: 556981.7500 - val_mae: 352.2613 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 581629.0000 - mae: 373.1492 - val_loss: 416099.2500 - val_mae: 309.4166 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 421192.0938 - mae: 319.2291 - val_loss: 311729.4375 - val_mae: 281.5724 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 305743.4062 - mae: 277.3131 - val_loss: 243539.1562 - val_mae: 259.2654 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 225503.1250 - mae: 243.2953 - val_loss: 187851.9219 - val_mae: 226.6790 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 174907.9219 - mae: 216.4083 - val_loss: 163909.7344 - val_mae: 210.1345 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 144022.8125 - mae: 197.1829 - val_loss: 143634.7969 - val_mae: 191.7484 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 127254.0859 - mae: 185.2308 - val_loss: 140936.6875 - val_mae: 187.8232 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 117537.7812 - mae: 176.5851 - val_loss: 126946.0625 - val_mae: 173.7118 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 112277.6250 - mae: 170.0576 - val_loss: 139068.2500 - val_mae: 183.1892 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108937.7812 - mae: 165.6784 - val_loss: 120514.3516 - val_mae: 171.4621 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107030.9531 - mae: 163.1996 - val_loss: 126837.1719 - val_mae: 170.2471 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105756.7500 - mae: 161.3759 - val_loss: 130378.5469 - val_mae: 174.4311 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105636.8594 - mae: 159.9765 - val_loss: 119395.8984 - val_mae: 163.1598 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105159.6797 - mae: 159.2532 - val_loss: 124322.7422 - val_mae: 165.3016 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103724.6875 - mae: 157.3211 - val_loss: 122829.2031 - val_mae: 166.1942 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103615.2500 - mae: 157.1568 - val_loss: 122717.1250 - val_mae: 164.8712 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103841.8984 - mae: 157.0767 - val_loss: 119950.0000 - val_mae: 161.4429 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102845.7266 - mae: 156.1109 - val_loss: 124692.8438 - val_mae: 163.3202 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102342.7500 - mae: 155.1208 - val_loss: 117428.9922 - val_mae: 161.9112 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102657.5625 - mae: 155.2047 - val_loss: 119032.2188 - val_mae: 159.4631 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101953.4141 - mae: 154.1268 - val_loss: 112388.2109 - val_mae: 158.5101 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101810.5469 - mae: 154.0752 - val_loss: 114509.2109 - val_mae: 157.6876 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101543.4297 - mae: 153.7831 - val_loss: 125793.2031 - val_mae: 170.8761 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101582.5703 - mae: 153.7154 - val_loss: 124209.1172 - val_mae: 169.7349 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101001.0312 - mae: 152.7110 - val_loss: 121090.8906 - val_mae: 163.0249 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101155.5938 - mae: 152.6942 - val_loss: 119426.0312 - val_mae: 158.4990 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100789.4531 - mae: 152.4078 - val_loss: 117752.4531 - val_mae: 157.2504 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100476.1484 - mae: 152.6289 - val_loss: 117449.0078 - val_mae: 159.1366 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100433.9453 - mae: 151.6458 - val_loss: 115790.3359 - val_mae: 156.5441 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100220.0625 - mae: 151.1388 - val_loss: 113634.0078 - val_mae: 156.2349 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100024.0391 - mae: 151.0585 - val_loss: 113100.2109 - val_mae: 155.6982 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97199.8125 - mae: 147.3052 - val_loss: 111113.2578 - val_mae: 151.8352 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96836.3281 - mae: 146.2475 - val_loss: 112173.8203 - val_mae: 153.4573 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96810.4062 - mae: 146.1499 - val_loss: 112324.8828 - val_mae: 152.6890 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96590.7188 - mae: 146.0636 - val_loss: 111842.9688 - val_mae: 152.4712 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96583.8359 - mae: 145.5648 - val_loss: 112892.7969 - val_mae: 152.4817 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96539.7969 - mae: 145.5963 - val_loss: 111623.9062 - val_mae: 153.9109 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96599.9844 - mae: 145.7401 - val_loss: 111608.9688 - val_mae: 152.6617 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96478.0938 - mae: 145.5295 - val_loss: 110810.0859 - val_mae: 150.8175 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96474.2109 - mae: 145.4683 - val_loss: 112039.3906 - val_mae: 152.9242 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96424.6484 - mae: 145.6653 - val_loss: 112324.4609 - val_mae: 153.5126 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96435.3359 - mae: 145.4318 - val_loss: 111835.8281 - val_mae: 153.1072 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96423.8516 - mae: 145.4863 - val_loss: 112944.0547 - val_mae: 154.1458 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96304.4375 - mae: 145.3538 - val_loss: 111523.5000 - val_mae: 152.3697 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96339.3438 - mae: 145.4037 - val_loss: 111633.3594 - val_mae: 151.9515 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:58:46,166]\u001b[0m Trial 82 finished with value: 111633.3994887821 and parameters: {'feature_dim': 57, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1679384.7500 - mae: 719.6416 - val_loss: 1321819.6250 - val_mae: 602.2044 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1426841.6250 - mae: 641.3717 - val_loss: 1057936.7500 - val_mae: 514.4312 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1104158.6250 - mae: 537.5410 - val_loss: 779342.6250 - val_mae: 421.9358 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 798332.2500 - mae: 441.6547 - val_loss: 545923.5625 - val_mae: 350.4798 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 550495.7500 - mae: 360.4395 - val_loss: 371401.4375 - val_mae: 289.6820 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 371324.6562 - mae: 297.0421 - val_loss: 265190.2500 - val_mae: 246.5977 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 254120.8750 - mae: 250.9492 - val_loss: 193368.3125 - val_mae: 218.5696 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 184847.4219 - mae: 219.0049 - val_loss: 156464.2812 - val_mae: 194.7692 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 145996.0312 - mae: 195.9409 - val_loss: 145392.1719 - val_mae: 186.3019 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 128516.1250 - mae: 183.2968 - val_loss: 140420.2812 - val_mae: 180.8949 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 117087.0781 - mae: 173.0834 - val_loss: 132545.2344 - val_mae: 176.1730 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111918.0859 - mae: 167.4905 - val_loss: 131940.7500 - val_mae: 170.7309 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108270.2578 - mae: 162.6302 - val_loss: 126641.4219 - val_mae: 166.2179 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106815.9375 - mae: 160.0727 - val_loss: 136434.2969 - val_mae: 174.0238 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105794.2969 - mae: 158.6001 - val_loss: 121396.4922 - val_mae: 162.9246 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105296.1172 - mae: 158.0691 - val_loss: 128146.4453 - val_mae: 166.0320 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104309.3047 - mae: 156.5798 - val_loss: 125430.6953 - val_mae: 164.3807 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104738.5547 - mae: 156.8732 - val_loss: 123960.5156 - val_mae: 164.6621 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104239.7656 - mae: 155.9767 - val_loss: 122023.7969 - val_mae: 160.7119 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103324.1719 - mae: 154.9561 - val_loss: 121449.5625 - val_mae: 160.4769 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102967.0781 - mae: 154.4805 - val_loss: 121569.8828 - val_mae: 161.9605 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103354.9609 - mae: 154.0668 - val_loss: 121880.2969 - val_mae: 160.0523 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102315.2891 - mae: 153.4675 - val_loss: 130039.0781 - val_mae: 169.3119 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101713.9453 - mae: 152.4173 - val_loss: 120623.2266 - val_mae: 163.0798 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102084.0938 - mae: 152.3179 - val_loss: 121546.9922 - val_mae: 160.9610 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101443.3828 - mae: 151.7068 - val_loss: 113325.8984 - val_mae: 154.9384 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101173.1172 - mae: 151.2678 - val_loss: 116696.9688 - val_mae: 156.2067 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100857.0000 - mae: 150.5551 - val_loss: 127613.2734 - val_mae: 167.7174 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100861.6328 - mae: 151.0436 - val_loss: 125599.3594 - val_mae: 167.2065 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100380.3516 - mae: 150.0547 - val_loss: 126145.9844 - val_mae: 165.3234 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100717.7969 - mae: 150.2951 - val_loss: 119550.9609 - val_mae: 157.4936 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100271.4062 - mae: 149.7629 - val_loss: 122925.7344 - val_mae: 162.4607 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100199.3203 - mae: 150.2528 - val_loss: 115582.6875 - val_mae: 154.3628 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100033.4609 - mae: 149.3340 - val_loss: 117125.1562 - val_mae: 154.6417 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99712.7188 - mae: 148.6859 - val_loss: 113867.4375 - val_mae: 155.7238 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99501.3672 - mae: 148.3050 - val_loss: 115511.9141 - val_mae: 154.6181 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96843.0312 - mae: 144.8663 - val_loss: 113643.2969 - val_mae: 152.5740 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96528.8750 - mae: 144.0576 - val_loss: 114996.1328 - val_mae: 154.6768 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96464.4844 - mae: 144.0769 - val_loss: 115501.1328 - val_mae: 154.8260 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96299.5938 - mae: 144.0220 - val_loss: 114547.5781 - val_mae: 153.8499 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96318.1641 - mae: 143.7427 - val_loss: 115705.4062 - val_mae: 154.8019 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96241.4453 - mae: 143.4895 - val_loss: 114710.1562 - val_mae: 154.9985 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96293.7969 - mae: 143.8770 - val_loss: 114185.6172 - val_mae: 153.2024 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96225.2031 - mae: 143.7072 - val_loss: 113972.8672 - val_mae: 152.7645 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96190.1484 - mae: 143.5739 - val_loss: 114775.8750 - val_mae: 154.2934 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96173.0938 - mae: 143.7782 - val_loss: 115134.7109 - val_mae: 154.5236 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 18:59:46,222]\u001b[0m Trial 83 finished with value: 115134.70406992073 and parameters: {'feature_dim': 63, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1654751.5000 - mae: 717.5499 - val_loss: 1280528.7500 - val_mae: 587.6902 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1355302.3750 - mae: 614.1603 - val_loss: 978029.1250 - val_mae: 487.9471 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 996575.0000 - mae: 502.8975 - val_loss: 680414.8125 - val_mae: 390.8342 - lr: 0.0010\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 680436.6250 - mae: 402.2368 - val_loss: 453281.1875 - val_mae: 317.6527 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 445856.2500 - mae: 323.9579 - val_loss: 302913.4688 - val_mae: 261.9440 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 289597.3438 - mae: 263.1556 - val_loss: 220185.0156 - val_mae: 226.2279 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 197707.2656 - mae: 221.0741 - val_loss: 163892.4375 - val_mae: 200.4409 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 151746.1406 - mae: 196.1372 - val_loss: 137893.0625 - val_mae: 176.3942 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 128236.6094 - mae: 180.1445 - val_loss: 126924.2969 - val_mae: 171.9335 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 118749.2344 - mae: 171.8013 - val_loss: 133204.0156 - val_mae: 169.9373 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 112434.8203 - mae: 165.4287 - val_loss: 127345.8828 - val_mae: 170.2901 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110612.1953 - mae: 162.8475 - val_loss: 125827.9844 - val_mae: 163.1998 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107044.2422 - mae: 159.3928 - val_loss: 119774.7500 - val_mae: 161.9481 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105633.8594 - mae: 156.9807 - val_loss: 129002.4141 - val_mae: 166.7953 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104460.6562 - mae: 155.6215 - val_loss: 115064.6016 - val_mae: 157.3423 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103744.6562 - mae: 154.9111 - val_loss: 122109.2656 - val_mae: 159.5172 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103072.8125 - mae: 153.7825 - val_loss: 120655.7734 - val_mae: 156.4671 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103743.3047 - mae: 154.1232 - val_loss: 119211.1406 - val_mae: 159.7038 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103399.2422 - mae: 153.6240 - val_loss: 119325.2500 - val_mae: 158.3571 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101982.3281 - mae: 152.0158 - val_loss: 119211.8047 - val_mae: 157.1745 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101923.1328 - mae: 151.8685 - val_loss: 120599.3594 - val_mae: 159.4910 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102311.2031 - mae: 151.7951 - val_loss: 121645.4453 - val_mae: 157.9653 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101236.4453 - mae: 150.7733 - val_loss: 131236.8750 - val_mae: 165.7063 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100574.5234 - mae: 149.8544 - val_loss: 121905.8984 - val_mae: 161.7087 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101023.4062 - mae: 150.0680 - val_loss: 116820.1719 - val_mae: 154.9630 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97389.1641 - mae: 145.8646 - val_loss: 115526.1875 - val_mae: 153.5675 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97168.5391 - mae: 145.3451 - val_loss: 117028.2734 - val_mae: 154.8790 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97095.1016 - mae: 145.0744 - val_loss: 117176.2578 - val_mae: 155.2674 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97097.8906 - mae: 145.0840 - val_loss: 115594.7031 - val_mae: 154.2708 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96852.2812 - mae: 144.9342 - val_loss: 117739.1719 - val_mae: 155.7538 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96870.0234 - mae: 144.7615 - val_loss: 118382.0938 - val_mae: 156.2321 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96870.0938 - mae: 144.8086 - val_loss: 118530.7422 - val_mae: 156.2996 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96763.5469 - mae: 144.7208 - val_loss: 116936.7188 - val_mae: 154.4403 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96748.6172 - mae: 144.5081 - val_loss: 116969.9297 - val_mae: 154.7283 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 96685.5156 - mae: 144.6088 - val_loss: 116979.0469 - val_mae: 154.3844 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 19:00:29,497]\u001b[0m Trial 84 finished with value: 116979.01765301205 and parameters: {'feature_dim': 58, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1707612.8750 - mae: 726.7270 - val_loss: 1375761.6250 - val_mae: 614.3044 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1527907.0000 - mae: 666.9229 - val_loss: 1178845.6250 - val_mae: 548.4046 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1276881.0000 - mae: 589.0719 - val_loss: 949098.8750 - val_mae: 474.6359 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1012376.6875 - mae: 507.3314 - val_loss: 730365.8750 - val_mae: 406.6779 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 768663.8125 - mae: 430.7084 - val_loss: 543181.8125 - val_mae: 346.2866 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 563669.8750 - mae: 364.3010 - val_loss: 396154.3125 - val_mae: 296.1286 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 404152.6250 - mae: 309.2261 - val_loss: 294649.0938 - val_mae: 262.6341 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 292025.8750 - mae: 266.5726 - val_loss: 233443.8906 - val_mae: 240.1157 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 214980.0781 - mae: 231.6526 - val_loss: 181839.8594 - val_mae: 220.2289 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 169563.2031 - mae: 208.0036 - val_loss: 161785.1719 - val_mae: 194.3953 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 143286.7188 - mae: 191.3136 - val_loss: 146237.9375 - val_mae: 186.1004 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 130000.7969 - mae: 180.9078 - val_loss: 146073.7812 - val_mae: 181.4467 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 123318.1250 - mae: 175.3951 - val_loss: 134878.0000 - val_mae: 176.3809 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 118452.9062 - mae: 169.8629 - val_loss: 141800.5156 - val_mae: 176.4193 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 114839.3984 - mae: 166.4020 - val_loss: 129437.4062 - val_mae: 171.9685 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111680.7812 - mae: 163.5025 - val_loss: 130997.1562 - val_mae: 166.8219 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109820.1953 - mae: 161.3584 - val_loss: 134281.0156 - val_mae: 170.1150 - lr: 0.0010\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109332.1562 - mae: 160.8489 - val_loss: 124701.1406 - val_mae: 166.8991 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108523.3359 - mae: 159.7219 - val_loss: 126290.7969 - val_mae: 161.7228 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106704.1562 - mae: 157.8477 - val_loss: 126807.6875 - val_mae: 163.3385 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106760.5547 - mae: 157.4802 - val_loss: 123499.2031 - val_mae: 161.9643 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106643.1094 - mae: 157.1220 - val_loss: 123483.1484 - val_mae: 163.2546 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105334.0625 - mae: 156.0899 - val_loss: 129650.3438 - val_mae: 165.3782 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104703.1406 - mae: 155.0626 - val_loss: 117298.3906 - val_mae: 159.4876 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105148.6250 - mae: 155.3635 - val_loss: 125464.3594 - val_mae: 162.0284 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104532.1172 - mae: 154.6039 - val_loss: 118265.0781 - val_mae: 160.3616 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103921.7578 - mae: 154.0550 - val_loss: 121205.7656 - val_mae: 155.7903 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103610.2891 - mae: 153.5441 - val_loss: 126261.1250 - val_mae: 166.1055 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103460.8594 - mae: 153.3756 - val_loss: 119914.6016 - val_mae: 158.4145 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102704.5547 - mae: 152.4110 - val_loss: 124764.6406 - val_mae: 163.6630 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103007.8438 - mae: 152.4086 - val_loss: 119256.2109 - val_mae: 155.5913 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102580.9219 - mae: 152.1568 - val_loss: 124194.9219 - val_mae: 160.0623 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102260.2188 - mae: 152.1618 - val_loss: 118892.9297 - val_mae: 153.6356 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102308.0000 - mae: 151.5826 - val_loss: 119629.2031 - val_mae: 157.4198 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99157.7031 - mae: 147.6793 - val_loss: 115977.8672 - val_mae: 152.7018 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98999.0938 - mae: 147.1664 - val_loss: 114825.0703 - val_mae: 151.8527 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98898.9922 - mae: 147.0346 - val_loss: 114194.2109 - val_mae: 151.6528 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98823.3906 - mae: 147.0125 - val_loss: 115563.1328 - val_mae: 153.5155 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98777.6562 - mae: 147.0183 - val_loss: 115042.5391 - val_mae: 152.2918 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98632.2891 - mae: 146.9025 - val_loss: 115185.7891 - val_mae: 151.9303 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98630.0859 - mae: 146.6512 - val_loss: 116168.3438 - val_mae: 153.0256 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98586.4297 - mae: 146.4350 - val_loss: 115015.3438 - val_mae: 152.8640 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98636.3672 - mae: 146.7289 - val_loss: 114482.7734 - val_mae: 151.3361 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98504.4531 - mae: 146.4863 - val_loss: 113422.0234 - val_mae: 150.5571 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98521.7969 - mae: 146.5151 - val_loss: 115028.0156 - val_mae: 152.6655 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98446.2188 - mae: 146.6475 - val_loss: 115351.6406 - val_mae: 153.0101 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98474.3438 - mae: 146.3343 - val_loss: 114542.5703 - val_mae: 152.9316 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98450.2578 - mae: 146.5396 - val_loss: 115686.4609 - val_mae: 153.2304 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98389.1484 - mae: 146.3920 - val_loss: 115062.3750 - val_mae: 152.4458 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98390.8516 - mae: 146.4337 - val_loss: 114971.3438 - val_mae: 151.8545 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 19:01:33,105]\u001b[0m Trial 85 finished with value: 114971.37357206171 and parameters: {'feature_dim': 63, 'output_dim': 5, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "[TabNet]: 41 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 4s 2ms/step - loss: 1659856.7500 - mae: 741.5210 - val_loss: 1297117.2500 - val_mae: 673.9716 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1417551.5000 - mae: 775.4635 - val_loss: 1115088.1250 - val_mae: 741.7966 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1259605.5000 - mae: 836.2848 - val_loss: 1068484.2500 - val_mae: 812.8466 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1222400.6250 - mae: 878.4323 - val_loss: 1073324.5000 - val_mae: 845.2888 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219364.8750 - mae: 892.8860 - val_loss: 1075305.6250 - val_mae: 850.6182 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219255.2500 - mae: 894.8162 - val_loss: 1076690.5000 - val_mae: 853.9255 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219223.0000 - mae: 895.0844 - val_loss: 1077845.7500 - val_mae: 856.4936 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219260.1250 - mae: 896.5714 - val_loss: 1076619.3750 - val_mae: 853.7611 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219202.5000 - mae: 895.1227 - val_loss: 1077784.3750 - val_mae: 856.3617 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219212.3750 - mae: 897.0424 - val_loss: 1075871.8750 - val_mae: 852.0008 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219179.8750 - mae: 896.4370 - val_loss: 1073209.3750 - val_mae: 844.9442 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219255.2500 - mae: 894.6981 - val_loss: 1076490.5000 - val_mae: 853.4593 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219203.8750 - mae: 895.1050 - val_loss: 1077321.5000 - val_mae: 855.3419 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219169.6250 - mae: 897.4346 - val_loss: 1077161.0000 - val_mae: 854.9850 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219163.5000 - mae: 897.0779 - val_loss: 1076961.6250 - val_mae: 854.5369 - lr: 1.0000e-04\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219160.2500 - mae: 896.7289 - val_loss: 1076880.2500 - val_mae: 854.3533 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219154.6250 - mae: 896.6284 - val_loss: 1076746.8750 - val_mae: 854.0500 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219153.6250 - mae: 896.3595 - val_loss: 1076673.1250 - val_mae: 853.8827 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219152.8750 - mae: 896.3408 - val_loss: 1076617.7500 - val_mae: 853.7541 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219153.1250 - mae: 896.1817 - val_loss: 1076549.2500 - val_mae: 853.5967 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219152.3750 - mae: 896.1665 - val_loss: 1076534.5000 - val_mae: 853.5631 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219148.5000 - mae: 896.0785 - val_loss: 1076484.1250 - val_mae: 853.4462 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 2s 2ms/step - loss: 1219157.3750 - mae: 895.7709 - val_loss: 1076511.3750 - val_mae: 853.5089 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 19:02:20,082]\u001b[0m Trial 86 finished with value: 1076511.0930152088 and parameters: {'feature_dim': 52, 'output_dim': 11, 'num_decision_steps': 2}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1708191.7500 - mae: 734.7270 - val_loss: 1364762.2500 - val_mae: 611.5712 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 1497683.1250 - mae: 657.5944 - val_loss: 1136917.3750 - val_mae: 535.5670 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 1212817.1250 - mae: 570.1103 - val_loss: 882689.3750 - val_mae: 454.6363 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 925662.3750 - mae: 481.4242 - val_loss: 653738.8750 - val_mae: 386.5749 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 675616.7500 - mae: 401.9908 - val_loss: 467917.4688 - val_mae: 319.5946 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 478198.1250 - mae: 335.5812 - val_loss: 338072.8438 - val_mae: 275.1022 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 336115.6562 - mae: 284.3291 - val_loss: 252513.6875 - val_mae: 244.9295 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 243578.8281 - mae: 247.1089 - val_loss: 198234.2812 - val_mae: 218.6863 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 184792.7344 - mae: 218.3684 - val_loss: 165928.6875 - val_mae: 211.6447 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 152246.4062 - mae: 199.6627 - val_loss: 158595.3281 - val_mae: 190.9085 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 134126.1719 - mae: 187.1681 - val_loss: 145135.1562 - val_mae: 181.3822 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 126157.1641 - mae: 180.1132 - val_loss: 146210.4844 - val_mae: 178.5280 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 120525.9766 - mae: 174.6967 - val_loss: 136019.9375 - val_mae: 183.1039 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 117241.6406 - mae: 170.4575 - val_loss: 146296.2969 - val_mae: 178.5569 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 113678.6562 - mae: 166.3288 - val_loss: 130169.3516 - val_mae: 173.4167 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 111738.3594 - mae: 164.4472 - val_loss: 133527.3594 - val_mae: 168.0232 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 109337.8594 - mae: 161.1663 - val_loss: 135606.0312 - val_mae: 171.1220 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 109026.3672 - mae: 160.7999 - val_loss: 126201.4219 - val_mae: 165.5447 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 108013.8984 - mae: 159.8073 - val_loss: 128822.2188 - val_mae: 165.2450 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 106431.8438 - mae: 157.9588 - val_loss: 126079.3516 - val_mae: 164.8752 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 106465.8203 - mae: 157.8694 - val_loss: 124027.7578 - val_mae: 161.3536 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 106226.5703 - mae: 157.4346 - val_loss: 122686.6953 - val_mae: 161.0444 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 105142.9766 - mae: 156.6291 - val_loss: 130109.3594 - val_mae: 165.1517 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 104293.1719 - mae: 155.8432 - val_loss: 117483.5234 - val_mae: 159.1667 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 104342.1797 - mae: 155.4167 - val_loss: 122077.1875 - val_mae: 161.3977 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 103980.8672 - mae: 155.1125 - val_loss: 115959.6094 - val_mae: 158.4394 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 103649.1719 - mae: 154.5592 - val_loss: 119158.5234 - val_mae: 156.9167 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 103427.3750 - mae: 154.2491 - val_loss: 122670.7812 - val_mae: 163.6919 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 103184.8047 - mae: 154.0899 - val_loss: 125537.6406 - val_mae: 164.4840 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 102891.7344 - mae: 153.4107 - val_loss: 122919.7422 - val_mae: 160.3337 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 102974.5938 - mae: 152.9776 - val_loss: 122731.0938 - val_mae: 161.1066 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 102751.0000 - mae: 152.8969 - val_loss: 126648.7969 - val_mae: 162.6362 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 102373.2500 - mae: 153.1048 - val_loss: 119493.5859 - val_mae: 155.6125 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 102482.7500 - mae: 152.5334 - val_loss: 119969.8125 - val_mae: 159.5769 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 102183.3516 - mae: 151.9620 - val_loss: 115420.9297 - val_mae: 154.7370 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 102099.7578 - mae: 151.9278 - val_loss: 116818.9922 - val_mae: 155.2683 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 101925.4688 - mae: 151.9648 - val_loss: 118966.4922 - val_mae: 156.4179 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 101914.8438 - mae: 152.2178 - val_loss: 115661.0156 - val_mae: 154.7376 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 101530.5312 - mae: 151.7608 - val_loss: 117546.1953 - val_mae: 158.0907 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 960us/step - loss: 101374.8750 - mae: 151.3560 - val_loss: 114415.9609 - val_mae: 154.9060 - lr: 0.0010\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 960us/step - loss: 100995.8281 - mae: 150.8578 - val_loss: 118804.1719 - val_mae: 156.2219 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 101026.6328 - mae: 150.7216 - val_loss: 114293.3359 - val_mae: 153.1969 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 961us/step - loss: 101390.8438 - mae: 150.9734 - val_loss: 126475.9844 - val_mae: 168.4097 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 100992.9219 - mae: 150.6705 - val_loss: 113010.9453 - val_mae: 154.1824 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 100779.7109 - mae: 150.1498 - val_loss: 118807.9375 - val_mae: 156.5563 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 100563.8203 - mae: 150.7929 - val_loss: 119204.2969 - val_mae: 156.9220 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 100551.6172 - mae: 150.3235 - val_loss: 116995.0469 - val_mae: 156.8102 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 100560.3516 - mae: 150.6664 - val_loss: 116824.4766 - val_mae: 153.4657 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 959us/step - loss: 100535.4297 - mae: 150.2063 - val_loss: 112151.2734 - val_mae: 152.3400 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 100376.8516 - mae: 150.3634 - val_loss: 113628.1094 - val_mae: 152.3896 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 19:03:13,386]\u001b[0m Trial 87 finished with value: 113628.09431400403 and parameters: {'feature_dim': 39, 'output_dim': 10, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "[TabNet]: 45 features will be used for decision steps.\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 6s 4ms/step - loss: 1458779.3750 - mae: 663.6163 - val_loss: 898521.0000 - val_mae: 472.3612 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 780239.7500 - mae: 458.5458 - val_loss: 429123.0000 - val_mae: 340.4789 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 394232.3750 - mae: 337.3631 - val_loss: 248169.8750 - val_mae: 261.4390 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 252164.8125 - mae: 280.2091 - val_loss: 185700.3750 - val_mae: 232.5638 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 212572.3906 - mae: 259.1301 - val_loss: 184028.0000 - val_mae: 227.1923 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 193034.2812 - mae: 247.0226 - val_loss: 194063.8906 - val_mae: 235.3904 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 186936.8906 - mae: 242.7273 - val_loss: 165886.4844 - val_mae: 218.5401 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 175612.2656 - mae: 235.4853 - val_loss: 163187.3281 - val_mae: 221.1215 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 175327.5469 - mae: 235.2079 - val_loss: 161181.1719 - val_mae: 223.0248 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 176147.8281 - mae: 234.4475 - val_loss: 161743.0000 - val_mae: 215.2285 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 168602.1562 - mae: 228.3517 - val_loss: 168420.7344 - val_mae: 217.2807 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 168782.0469 - mae: 228.3453 - val_loss: 160774.1719 - val_mae: 208.2709 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 167573.4844 - mae: 226.9901 - val_loss: 160707.4219 - val_mae: 217.0437 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 167869.0156 - mae: 227.1599 - val_loss: 161374.0156 - val_mae: 209.8961 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 163493.7031 - mae: 223.7968 - val_loss: 161240.0469 - val_mae: 213.4654 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 162213.7031 - mae: 222.4768 - val_loss: 173270.3594 - val_mae: 210.6775 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 160652.9844 - mae: 220.7505 - val_loss: 160221.5781 - val_mae: 207.6308 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 162180.7188 - mae: 221.9437 - val_loss: 161762.8281 - val_mae: 210.8203 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 162177.9219 - mae: 222.6107 - val_loss: 161272.6719 - val_mae: 206.3644 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 159268.2656 - mae: 219.2321 - val_loss: 159010.2969 - val_mae: 208.6535 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 159497.5000 - mae: 220.6331 - val_loss: 164821.5625 - val_mae: 209.6591 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 159526.8125 - mae: 220.1428 - val_loss: 157108.2969 - val_mae: 202.6920 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 159222.3750 - mae: 219.3465 - val_loss: 178860.6875 - val_mae: 218.0017 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 157338.0938 - mae: 218.3095 - val_loss: 162503.7656 - val_mae: 214.5896 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 156847.1406 - mae: 217.8618 - val_loss: 172334.4219 - val_mae: 211.6810 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 158270.3594 - mae: 218.7543 - val_loss: 154734.7969 - val_mae: 210.3492 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 157992.4531 - mae: 218.2563 - val_loss: 153425.7031 - val_mae: 204.3736 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 155968.5312 - mae: 217.4976 - val_loss: 174579.7344 - val_mae: 218.9205 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 156324.8438 - mae: 217.3989 - val_loss: 170739.8750 - val_mae: 215.3964 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 156013.5469 - mae: 217.3738 - val_loss: 154253.4219 - val_mae: 202.2701 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 155492.4844 - mae: 216.3221 - val_loss: 159026.3906 - val_mae: 209.4847 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 155206.8281 - mae: 216.0607 - val_loss: 160620.1719 - val_mae: 208.3556 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 155712.7188 - mae: 216.6281 - val_loss: 156425.9062 - val_mae: 203.8045 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 155501.3281 - mae: 216.6263 - val_loss: 162006.7656 - val_mae: 204.4958 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 155109.5156 - mae: 215.4414 - val_loss: 153316.9219 - val_mae: 206.9507 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 154357.2969 - mae: 215.4523 - val_loss: 157626.0781 - val_mae: 207.0361 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 154653.4219 - mae: 215.7226 - val_loss: 160423.8281 - val_mae: 205.3185 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 154207.0781 - mae: 215.1831 - val_loss: 158439.1875 - val_mae: 210.6016 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 154174.2188 - mae: 214.7649 - val_loss: 153233.5469 - val_mae: 205.1789 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 153509.6562 - mae: 214.3689 - val_loss: 151232.5469 - val_mae: 206.7689 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 154039.2812 - mae: 214.8148 - val_loss: 155601.3125 - val_mae: 204.9400 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 154813.1719 - mae: 214.9466 - val_loss: 169378.4219 - val_mae: 213.3929 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 154343.7500 - mae: 215.2380 - val_loss: 173529.2344 - val_mae: 213.8022 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 153431.0781 - mae: 214.4609 - val_loss: 152419.7812 - val_mae: 204.9428 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 152863.8438 - mae: 213.5101 - val_loss: 157656.5469 - val_mae: 205.3608 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 153454.6719 - mae: 214.1368 - val_loss: 158189.6094 - val_mae: 208.6475 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 153381.8438 - mae: 214.3456 - val_loss: 153525.5781 - val_mae: 204.3806 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 153448.1250 - mae: 213.6852 - val_loss: 162967.8281 - val_mae: 210.9558 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 153079.5469 - mae: 214.1837 - val_loss: 150576.4219 - val_mae: 204.0046 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 4s 3ms/step - loss: 152809.0781 - mae: 213.5007 - val_loss: 156557.5781 - val_mae: 209.1211 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 19:06:15,080]\u001b[0m Trial 88 finished with value: 156557.54268605378 and parameters: {'feature_dim': 56, 'output_dim': 11, 'num_decision_steps': 4}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1662851.0000 - mae: 715.8449 - val_loss: 1283785.5000 - val_mae: 583.3129 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1355369.5000 - mae: 614.0671 - val_loss: 973826.0625 - val_mae: 483.4157 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 990565.3125 - mae: 501.4067 - val_loss: 673490.9375 - val_mae: 388.0544 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 671072.2500 - mae: 399.7872 - val_loss: 445647.8438 - val_mae: 316.1634 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 436289.1875 - mae: 322.2914 - val_loss: 294980.5312 - val_mae: 262.5811 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 281589.1250 - mae: 262.7779 - val_loss: 212289.3594 - val_mae: 224.5715 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 193082.4219 - mae: 221.6937 - val_loss: 164705.7812 - val_mae: 200.2089 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 149160.9531 - mae: 197.0098 - val_loss: 138057.4219 - val_mae: 178.7166 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 127741.5156 - mae: 181.3963 - val_loss: 130021.5391 - val_mae: 177.5396 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 118512.8828 - mae: 172.3002 - val_loss: 132979.7500 - val_mae: 169.4452 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 112564.6719 - mae: 165.9720 - val_loss: 128317.0547 - val_mae: 169.2915 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109890.8906 - mae: 162.1222 - val_loss: 129959.0703 - val_mae: 164.9464 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106407.5000 - mae: 158.2160 - val_loss: 124049.6484 - val_mae: 164.2118 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105463.0469 - mae: 156.1697 - val_loss: 130154.3828 - val_mae: 164.6513 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104296.5000 - mae: 154.6890 - val_loss: 115298.7891 - val_mae: 155.7281 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103841.8828 - mae: 153.9185 - val_loss: 123523.2969 - val_mae: 159.1739 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103316.1172 - mae: 153.1824 - val_loss: 123013.4922 - val_mae: 159.4217 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103485.6172 - mae: 153.0944 - val_loss: 121538.7031 - val_mae: 159.6420 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103207.8984 - mae: 152.7409 - val_loss: 121420.9453 - val_mae: 157.4558 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102138.4766 - mae: 151.9830 - val_loss: 122357.8438 - val_mae: 159.3765 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101895.0391 - mae: 151.6874 - val_loss: 121402.1484 - val_mae: 160.9514 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102112.0703 - mae: 151.3305 - val_loss: 121261.5859 - val_mae: 155.9951 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101005.1719 - mae: 150.3949 - val_loss: 124578.7969 - val_mae: 159.4120 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100592.4141 - mae: 149.7208 - val_loss: 118054.8203 - val_mae: 157.1860 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100884.9219 - mae: 149.9087 - val_loss: 120106.0625 - val_mae: 157.1928 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97691.6484 - mae: 145.5748 - val_loss: 117123.0781 - val_mae: 154.0470 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97373.5703 - mae: 145.0816 - val_loss: 117566.7188 - val_mae: 154.0361 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97299.5234 - mae: 144.9124 - val_loss: 118018.1953 - val_mae: 154.3491 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97314.5938 - mae: 144.8716 - val_loss: 116336.1172 - val_mae: 153.6007 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97107.2969 - mae: 144.9613 - val_loss: 118509.0312 - val_mae: 154.7536 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97153.3906 - mae: 144.6278 - val_loss: 118792.0391 - val_mae: 155.2358 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97072.7969 - mae: 144.8022 - val_loss: 119016.3047 - val_mae: 155.2346 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97050.6094 - mae: 144.5849 - val_loss: 117758.3047 - val_mae: 154.5743 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97023.3594 - mae: 144.5207 - val_loss: 118245.4453 - val_mae: 154.6757 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97010.1641 - mae: 144.5753 - val_loss: 117673.8359 - val_mae: 153.7175 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 19:07:00,994]\u001b[0m Trial 89 finished with value: 117673.8069096987 and parameters: {'feature_dim': 61, 'output_dim': 12, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1649177.8750 - mae: 711.4963 - val_loss: 1254639.5000 - val_mae: 573.0428 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1291247.0000 - mae: 595.1247 - val_loss: 893630.8125 - val_mae: 457.6490 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 877916.9375 - mae: 466.5342 - val_loss: 571933.7500 - val_mae: 354.0844 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 549826.1875 - mae: 359.4031 - val_loss: 354730.1250 - val_mae: 283.9223 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 335153.9688 - mae: 282.2054 - val_loss: 231477.1094 - val_mae: 235.9303 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 214503.5312 - mae: 231.1784 - val_loss: 177484.3281 - val_mae: 204.6012 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 156773.9844 - mae: 200.9562 - val_loss: 148042.1562 - val_mae: 197.3566 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 131589.8906 - mae: 183.3357 - val_loss: 135455.0312 - val_mae: 173.0883 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 119758.8281 - mae: 173.2819 - val_loss: 132000.1875 - val_mae: 177.5724 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 115363.8125 - mae: 168.3521 - val_loss: 131392.9531 - val_mae: 166.5347 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111688.3203 - mae: 163.3786 - val_loss: 129062.9766 - val_mae: 168.8061 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109641.1875 - mae: 161.1132 - val_loss: 128822.3672 - val_mae: 165.2305 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106908.6094 - mae: 158.5391 - val_loss: 121196.1719 - val_mae: 161.6672 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105826.5000 - mae: 156.5280 - val_loss: 132878.6250 - val_mae: 167.8871 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105043.6250 - mae: 155.6686 - val_loss: 118508.3750 - val_mae: 159.0793 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105117.8125 - mae: 155.7995 - val_loss: 124156.1328 - val_mae: 159.7585 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104019.0000 - mae: 153.9895 - val_loss: 126116.5625 - val_mae: 162.9652 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104375.1484 - mae: 154.6629 - val_loss: 121371.8359 - val_mae: 161.2952 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104438.4609 - mae: 154.4681 - val_loss: 119206.4609 - val_mae: 156.3884 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103263.9922 - mae: 153.1897 - val_loss: 121160.6797 - val_mae: 158.1404 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103187.1797 - mae: 153.1698 - val_loss: 120390.4297 - val_mae: 158.1789 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103629.2109 - mae: 153.1702 - val_loss: 119493.5547 - val_mae: 156.6081 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102284.5000 - mae: 151.9078 - val_loss: 126855.5000 - val_mae: 162.8045 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101938.0312 - mae: 151.1798 - val_loss: 116651.7969 - val_mae: 157.6746 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102530.9375 - mae: 151.4745 - val_loss: 117304.8594 - val_mae: 156.7253 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101708.7812 - mae: 150.6879 - val_loss: 114116.2812 - val_mae: 154.1213 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101588.6406 - mae: 150.5184 - val_loss: 116157.1641 - val_mae: 153.0412 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101493.3516 - mae: 150.1454 - val_loss: 122144.3438 - val_mae: 160.8994 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101319.2188 - mae: 150.2103 - val_loss: 122533.5078 - val_mae: 161.4103 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100876.2656 - mae: 149.5971 - val_loss: 121423.5547 - val_mae: 159.4212 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101163.7266 - mae: 149.5432 - val_loss: 120896.3828 - val_mae: 156.3279 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100711.1172 - mae: 149.0658 - val_loss: 123175.3828 - val_mae: 158.3910 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100373.2812 - mae: 149.2513 - val_loss: 117542.0703 - val_mae: 153.4725 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100344.3828 - mae: 148.6443 - val_loss: 114916.7344 - val_mae: 151.2292 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100342.1484 - mae: 148.3500 - val_loss: 113734.0234 - val_mae: 151.1509 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99873.1797 - mae: 147.7863 - val_loss: 114430.0078 - val_mae: 152.8773 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100137.9453 - mae: 148.2609 - val_loss: 118254.0703 - val_mae: 156.2639 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100002.2734 - mae: 148.4620 - val_loss: 115734.7500 - val_mae: 154.8930 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99761.7891 - mae: 148.3309 - val_loss: 113541.8047 - val_mae: 151.2509 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99332.9688 - mae: 147.5179 - val_loss: 113122.5859 - val_mae: 151.6344 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99031.1172 - mae: 147.1306 - val_loss: 116844.0312 - val_mae: 153.7738 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99193.7812 - mae: 146.9240 - val_loss: 113075.1719 - val_mae: 152.6840 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99398.9375 - mae: 147.2558 - val_loss: 125249.3906 - val_mae: 166.5760 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98938.8359 - mae: 147.0137 - val_loss: 110694.2812 - val_mae: 149.2343 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98888.0859 - mae: 146.5561 - val_loss: 116301.1641 - val_mae: 151.4562 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98685.2188 - mae: 147.0668 - val_loss: 118900.2109 - val_mae: 154.8533 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98609.5234 - mae: 146.8156 - val_loss: 114454.7578 - val_mae: 154.2330 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98793.3906 - mae: 146.8468 - val_loss: 116415.6250 - val_mae: 150.6217 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98350.1094 - mae: 146.2408 - val_loss: 112051.7500 - val_mae: 150.5252 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98510.2578 - mae: 146.8012 - val_loss: 112462.4609 - val_mae: 149.8502 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 19:08:01,904]\u001b[0m Trial 90 finished with value: 112462.45856614015 and parameters: {'feature_dim': 54, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1762660.8750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.7500 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.0000 - mae: 737.2339 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.2500 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.1250 - mae: 737.2339 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.2500 - mae: 737.2347 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.8750 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.5000 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2333 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.5000 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.7500 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.6250 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2337 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.1250 - mae: 737.2337 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762658.8750 - mae: 737.2338 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.3750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.2500 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.7500 - mae: 737.2346 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.6250 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 19:08:27,798]\u001b[0m Trial 91 finished with value: 1487783.123857698 and parameters: {'feature_dim': 56, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1762661.1250 - mae: 737.2345 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.7500 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.0000 - mae: 737.2339 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.2500 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.1250 - mae: 737.2339 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.2500 - mae: 737.2347 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.8750 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.5000 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2333 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.5000 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.7500 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.6250 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2337 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.1250 - mae: 737.2337 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762658.8750 - mae: 737.2338 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.3750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.2500 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.7500 - mae: 737.2346 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.6250 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 19:08:57,651]\u001b[0m Trial 92 finished with value: 1487783.123857698 and parameters: {'feature_dim': 67, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1762662.2500 - mae: 737.2350 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.7500 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.0000 - mae: 737.2339 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.2500 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.1250 - mae: 737.2339 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.2500 - mae: 737.2347 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.8750 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.5000 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2333 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.5000 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.7500 - mae: 737.2343 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.6250 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2337 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.1250 - mae: 737.2337 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762658.8750 - mae: 737.2338 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.3750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762659.2500 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.7500 - mae: 737.2346 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762661.6250 - mae: 737.2341 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1762660.8750 - mae: 737.2344 - val_loss: 1487782.3750 - val_mae: 647.6166 - lr: 1.0000e-04\n",
      "\u001b[32m[I 2022-07-28 19:09:24,917]\u001b[0m Trial 93 finished with value: 1487783.123857698 and parameters: {'feature_dim': 57, 'output_dim': 5, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1696438.2500 - mae: 729.0853 - val_loss: 1356071.2500 - val_mae: 609.3179 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 1491399.7500 - mae: 656.2334 - val_loss: 1135366.2500 - val_mae: 537.4135 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 1214884.5000 - mae: 571.1050 - val_loss: 888506.8750 - val_mae: 456.8626 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 934262.3750 - mae: 483.8648 - val_loss: 661539.7500 - val_mae: 387.3976 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 686282.8750 - mae: 404.8365 - val_loss: 476535.6562 - val_mae: 323.9410 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 487509.3750 - mae: 338.6465 - val_loss: 344042.8125 - val_mae: 277.2819 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 341906.4688 - mae: 285.3724 - val_loss: 254465.1562 - val_mae: 243.6446 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 244824.0000 - mae: 245.1737 - val_loss: 199737.0625 - val_mae: 217.9053 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 933us/step - loss: 184229.7344 - mae: 216.1778 - val_loss: 164727.8438 - val_mae: 204.8193 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 150196.2344 - mae: 196.2574 - val_loss: 150092.2344 - val_mae: 184.8314 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 131903.2188 - mae: 183.2574 - val_loss: 139107.7969 - val_mae: 176.4431 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 123518.2656 - mae: 175.8227 - val_loss: 139434.9375 - val_mae: 175.0763 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 117711.0000 - mae: 170.3225 - val_loss: 128852.3828 - val_mae: 167.5591 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 114609.6875 - mae: 166.5255 - val_loss: 138822.9375 - val_mae: 171.0113 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 112144.4297 - mae: 162.9134 - val_loss: 126506.0000 - val_mae: 166.6859 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 110438.2266 - mae: 161.3488 - val_loss: 132263.5000 - val_mae: 167.6351 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 108853.9297 - mae: 158.9691 - val_loss: 131210.0938 - val_mae: 167.8140 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 108024.8281 - mae: 158.6755 - val_loss: 122883.3281 - val_mae: 160.6544 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 107222.1172 - mae: 157.9106 - val_loss: 125218.2500 - val_mae: 160.8008 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 105881.4297 - mae: 156.3716 - val_loss: 123057.9453 - val_mae: 163.2373 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 105795.4297 - mae: 156.1667 - val_loss: 122703.9766 - val_mae: 159.5481 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 105495.3281 - mae: 155.8379 - val_loss: 119492.5000 - val_mae: 157.0452 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 104264.6641 - mae: 154.3785 - val_loss: 128737.7031 - val_mae: 163.2838 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 103541.2344 - mae: 153.5149 - val_loss: 117779.4453 - val_mae: 158.6055 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 934us/step - loss: 103727.3281 - mae: 153.4195 - val_loss: 117580.9609 - val_mae: 155.5606 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 102549.2734 - mae: 152.1329 - val_loss: 114387.8359 - val_mae: 155.7016 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 102190.9531 - mae: 151.5690 - val_loss: 115369.1250 - val_mae: 152.8138 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 101985.5625 - mae: 151.1483 - val_loss: 120595.2188 - val_mae: 160.0619 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 101710.6094 - mae: 150.9010 - val_loss: 120979.4062 - val_mae: 160.1386 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 101350.6406 - mae: 150.3377 - val_loss: 120561.7500 - val_mae: 158.0155 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 101497.5469 - mae: 150.0816 - val_loss: 115645.9844 - val_mae: 151.2297 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 101020.1641 - mae: 149.7475 - val_loss: 121796.0000 - val_mae: 157.2968 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 939us/step - loss: 101054.3984 - mae: 150.2139 - val_loss: 114395.7734 - val_mae: 149.9224 - lr: 0.0010\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 939us/step - loss: 100782.6328 - mae: 149.3471 - val_loss: 116201.2188 - val_mae: 152.8818 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 935us/step - loss: 100599.8672 - mae: 148.8366 - val_loss: 112310.2031 - val_mae: 149.9284 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 100428.6953 - mae: 148.6440 - val_loss: 112727.2109 - val_mae: 151.1950 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 100269.2812 - mae: 148.6736 - val_loss: 116952.6641 - val_mae: 155.7162 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 100270.6016 - mae: 149.0807 - val_loss: 113522.2891 - val_mae: 151.5537 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 100179.6797 - mae: 148.8361 - val_loss: 113258.6406 - val_mae: 151.0361 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 99670.6719 - mae: 148.1026 - val_loss: 112601.0938 - val_mae: 150.9476 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 930us/step - loss: 99273.5391 - mae: 147.6248 - val_loss: 116006.8203 - val_mae: 151.5331 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 99537.6328 - mae: 147.7412 - val_loss: 112104.1328 - val_mae: 150.5202 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 99671.7500 - mae: 147.7853 - val_loss: 120745.0625 - val_mae: 161.2038 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 99460.1250 - mae: 147.8610 - val_loss: 113763.2188 - val_mae: 151.3195 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 99304.8594 - mae: 146.9966 - val_loss: 114042.2422 - val_mae: 150.7167 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 932us/step - loss: 98979.5078 - mae: 147.6744 - val_loss: 118136.1328 - val_mae: 154.1169 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 936us/step - loss: 99022.8594 - mae: 147.4018 - val_loss: 112321.6641 - val_mae: 150.2436 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 99153.7422 - mae: 147.5975 - val_loss: 115100.7891 - val_mae: 148.8624 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 98928.8281 - mae: 146.8702 - val_loss: 111308.9766 - val_mae: 148.6517 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 937us/step - loss: 98806.9766 - mae: 147.2590 - val_loss: 114577.6641 - val_mae: 151.3084 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 19:10:17,087]\u001b[0m Trial 94 finished with value: 114577.66253515422 and parameters: {'feature_dim': 36, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1656687.7500 - mae: 716.6136 - val_loss: 1300750.6250 - val_mae: 591.7818 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1406957.5000 - mae: 630.1159 - val_loss: 1045552.5625 - val_mae: 508.1497 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1096105.6250 - mae: 533.4198 - val_loss: 777460.3125 - val_mae: 418.9076 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 799515.1875 - mae: 439.3484 - val_loss: 548823.0625 - val_mae: 345.3274 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 555548.1250 - mae: 358.1757 - val_loss: 379850.0000 - val_mae: 289.9229 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 379393.0000 - mae: 297.5754 - val_loss: 272695.9688 - val_mae: 248.1287 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 262330.8438 - mae: 252.6419 - val_loss: 198363.1250 - val_mae: 218.4619 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 191897.7031 - mae: 220.9989 - val_loss: 159692.8438 - val_mae: 193.2863 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 151060.0625 - mae: 197.9650 - val_loss: 146996.1719 - val_mae: 189.5397 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 132561.3594 - mae: 185.3018 - val_loss: 143015.1562 - val_mae: 180.1049 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 121105.4531 - mae: 175.7552 - val_loss: 135353.7812 - val_mae: 177.0322 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 115753.6953 - mae: 170.5477 - val_loss: 135677.1875 - val_mae: 171.7033 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111380.3125 - mae: 165.5693 - val_loss: 129209.9297 - val_mae: 171.0223 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109664.8750 - mae: 162.6708 - val_loss: 141642.7188 - val_mae: 177.5892 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107903.2031 - mae: 160.3995 - val_loss: 123931.4375 - val_mae: 165.0835 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106986.9766 - mae: 159.0352 - val_loss: 131438.7812 - val_mae: 167.3909 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106148.4922 - mae: 157.7189 - val_loss: 127535.4219 - val_mae: 163.7720 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106215.6250 - mae: 157.3018 - val_loss: 127085.6562 - val_mae: 167.2442 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105873.8750 - mae: 156.6919 - val_loss: 125435.9297 - val_mae: 163.9758 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104934.8281 - mae: 155.6444 - val_loss: 123080.9531 - val_mae: 161.1969 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104507.3828 - mae: 155.0094 - val_loss: 125691.1562 - val_mae: 164.0532 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105051.6875 - mae: 154.9755 - val_loss: 123941.5000 - val_mae: 160.9019 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103710.0391 - mae: 153.7823 - val_loss: 130422.7422 - val_mae: 168.0061 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103166.7188 - mae: 152.9532 - val_loss: 121134.1875 - val_mae: 161.3891 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103681.3750 - mae: 153.0856 - val_loss: 120125.5938 - val_mae: 159.3862 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102940.9141 - mae: 152.2248 - val_loss: 116738.2656 - val_mae: 159.5027 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102593.9922 - mae: 152.3746 - val_loss: 118864.0312 - val_mae: 156.9486 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102277.4922 - mae: 151.5160 - val_loss: 127514.2969 - val_mae: 166.7908 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102185.1953 - mae: 151.7996 - val_loss: 123291.3594 - val_mae: 161.5659 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101995.8750 - mae: 150.9337 - val_loss: 124724.3438 - val_mae: 162.7673 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102161.3750 - mae: 151.0244 - val_loss: 121329.5469 - val_mae: 158.5623 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101658.8203 - mae: 150.5071 - val_loss: 123528.2031 - val_mae: 158.4624 - lr: 0.0010\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101334.1016 - mae: 150.8113 - val_loss: 117390.6953 - val_mae: 155.1466 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101344.1328 - mae: 149.8521 - val_loss: 118235.3359 - val_mae: 155.3277 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101080.2969 - mae: 149.3747 - val_loss: 115674.1641 - val_mae: 155.7811 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100833.5000 - mae: 149.0844 - val_loss: 116613.8281 - val_mae: 155.2500 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100740.5625 - mae: 149.2563 - val_loss: 119233.0312 - val_mae: 157.4014 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100579.5938 - mae: 149.3537 - val_loss: 117783.4141 - val_mae: 156.4431 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100295.8203 - mae: 149.0319 - val_loss: 116671.5938 - val_mae: 156.0379 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100003.4609 - mae: 148.2667 - val_loss: 115027.4453 - val_mae: 154.7264 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99672.7422 - mae: 147.9863 - val_loss: 118436.2422 - val_mae: 155.1158 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99706.3750 - mae: 147.8690 - val_loss: 113599.6016 - val_mae: 152.2953 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100018.8047 - mae: 148.0065 - val_loss: 126386.3984 - val_mae: 165.5092 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99574.8984 - mae: 147.6824 - val_loss: 111304.0312 - val_mae: 150.8112 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99501.6719 - mae: 147.2163 - val_loss: 118052.7422 - val_mae: 154.2338 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99173.8516 - mae: 147.5871 - val_loss: 123423.8906 - val_mae: 159.2571 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99091.2344 - mae: 147.3901 - val_loss: 116900.9922 - val_mae: 156.7946 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98836.0078 - mae: 146.9783 - val_loss: 114184.1250 - val_mae: 150.5667 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98895.6406 - mae: 146.6156 - val_loss: 112544.4766 - val_mae: 150.3516 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98845.7188 - mae: 147.0778 - val_loss: 114124.2031 - val_mae: 150.8671 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 19:11:19,654]\u001b[0m Trial 95 finished with value: 114124.19759994767 and parameters: {'feature_dim': 55, 'output_dim': 4, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1650425.0000 - mae: 715.3411 - val_loss: 1270013.2500 - val_mae: 581.1711 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1327319.6250 - mae: 605.8979 - val_loss: 939406.5625 - val_mae: 474.8386 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 940415.5000 - mae: 486.8754 - val_loss: 627119.5625 - val_mae: 374.8022 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 615640.0625 - mae: 382.4818 - val_loss: 402679.9375 - val_mae: 301.7381 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 388494.2812 - mae: 303.7531 - val_loss: 266386.8438 - val_mae: 251.3244 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 249609.3750 - mae: 247.5119 - val_loss: 194441.1250 - val_mae: 216.1776 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 175438.7812 - mae: 211.4333 - val_loss: 155954.5156 - val_mae: 197.9669 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 141085.7812 - mae: 190.5098 - val_loss: 140332.5938 - val_mae: 180.7690 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 124751.1797 - mae: 177.3485 - val_loss: 134826.4219 - val_mae: 185.6930 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 118642.6016 - mae: 171.3290 - val_loss: 138519.8125 - val_mae: 173.4851 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 114268.5234 - mae: 166.0762 - val_loss: 132002.7656 - val_mae: 174.4368 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 112624.0703 - mae: 163.8861 - val_loss: 135252.5312 - val_mae: 171.7416 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 110538.9219 - mae: 161.8574 - val_loss: 129545.6406 - val_mae: 176.9326 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108901.9844 - mae: 159.4544 - val_loss: 138821.3125 - val_mae: 174.2763 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106828.9141 - mae: 157.2606 - val_loss: 119816.1094 - val_mae: 165.4915 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105994.3281 - mae: 156.8184 - val_loss: 124325.5391 - val_mae: 163.1514 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104658.3359 - mae: 154.9738 - val_loss: 123213.6719 - val_mae: 164.2529 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104686.9766 - mae: 154.9381 - val_loss: 122020.7500 - val_mae: 164.3887 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104307.6328 - mae: 154.4311 - val_loss: 120631.1250 - val_mae: 161.0743 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103548.1875 - mae: 153.4582 - val_loss: 120087.7578 - val_mae: 160.8266 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103197.1172 - mae: 153.0595 - val_loss: 119451.4609 - val_mae: 158.3735 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103584.0625 - mae: 153.3132 - val_loss: 121691.4453 - val_mae: 162.5254 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102672.6875 - mae: 152.4623 - val_loss: 124803.3594 - val_mae: 163.1362 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102176.4688 - mae: 151.8441 - val_loss: 117140.8359 - val_mae: 161.3439 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102743.0469 - mae: 151.9563 - val_loss: 118444.6016 - val_mae: 158.9223 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101910.9922 - mae: 151.3617 - val_loss: 113951.2109 - val_mae: 157.4114 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101784.6719 - mae: 151.0217 - val_loss: 115858.4609 - val_mae: 153.9067 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101588.6172 - mae: 150.4126 - val_loss: 123390.0391 - val_mae: 164.8108 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101519.7734 - mae: 150.7016 - val_loss: 123202.8203 - val_mae: 162.4608 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101140.8906 - mae: 150.1228 - val_loss: 123080.4062 - val_mae: 160.2209 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101309.9219 - mae: 149.9174 - val_loss: 119125.6719 - val_mae: 155.3172 - lr: 0.0010\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100905.8438 - mae: 149.7062 - val_loss: 121656.1016 - val_mae: 156.6035 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100672.6562 - mae: 149.8214 - val_loss: 115030.8984 - val_mae: 151.8534 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100731.8281 - mae: 148.9475 - val_loss: 115870.2109 - val_mae: 153.5320 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100588.9688 - mae: 149.0378 - val_loss: 112539.2578 - val_mae: 151.0197 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100177.9688 - mae: 148.5215 - val_loss: 113040.5938 - val_mae: 151.0023 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100259.8750 - mae: 149.0321 - val_loss: 115586.9375 - val_mae: 151.6237 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100183.0391 - mae: 149.1285 - val_loss: 113620.8047 - val_mae: 152.2462 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99945.2188 - mae: 148.4390 - val_loss: 113916.5234 - val_mae: 153.8881 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99582.7812 - mae: 148.1382 - val_loss: 112404.4375 - val_mae: 151.9449 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99457.2109 - mae: 147.9976 - val_loss: 114984.3672 - val_mae: 152.3423 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99423.4453 - mae: 147.3933 - val_loss: 111017.8516 - val_mae: 149.5251 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99819.6094 - mae: 148.0100 - val_loss: 123326.8516 - val_mae: 163.2525 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99305.8203 - mae: 147.7992 - val_loss: 111450.3906 - val_mae: 151.3947 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99244.1328 - mae: 147.1979 - val_loss: 115480.0625 - val_mae: 151.6290 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98935.8750 - mae: 147.6033 - val_loss: 117905.6641 - val_mae: 154.1515 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98942.5391 - mae: 147.3269 - val_loss: 111525.5781 - val_mae: 151.3394 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98993.7891 - mae: 147.4292 - val_loss: 113709.8203 - val_mae: 149.7550 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98810.2422 - mae: 146.6106 - val_loss: 109943.5234 - val_mae: 148.9145 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98919.1094 - mae: 147.2620 - val_loss: 111883.1562 - val_mae: 149.0533 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 19:12:21,070]\u001b[0m Trial 96 finished with value: 111883.14465052083 and parameters: {'feature_dim': 53, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1688777.8750 - mae: 724.0946 - val_loss: 1342753.6250 - val_mae: 604.2027 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 1472479.6250 - mae: 650.6343 - val_loss: 1116548.8750 - val_mae: 530.8621 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 1192631.6250 - mae: 565.4412 - val_loss: 868223.1875 - val_mae: 448.9627 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 911609.6250 - mae: 478.8823 - val_loss: 643575.3750 - val_mae: 384.7980 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 666511.9375 - mae: 400.6591 - val_loss: 462709.3438 - val_mae: 322.6710 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 473017.3750 - mae: 336.5171 - val_loss: 336939.3125 - val_mae: 279.0291 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 333682.6562 - mae: 286.4359 - val_loss: 248624.3906 - val_mae: 248.3031 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 241891.5938 - mae: 249.3584 - val_loss: 198817.9844 - val_mae: 224.4870 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 183940.5625 - mae: 221.5610 - val_loss: 169075.2344 - val_mae: 218.5259 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 152140.9844 - mae: 203.4467 - val_loss: 158042.7812 - val_mae: 196.5979 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 133974.8125 - mae: 190.3170 - val_loss: 145315.5781 - val_mae: 186.1220 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 938us/step - loss: 125903.6172 - mae: 181.6913 - val_loss: 147207.6562 - val_mae: 182.6716 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 120507.8906 - mae: 175.7040 - val_loss: 139587.8125 - val_mae: 185.0545 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 117726.1875 - mae: 171.1962 - val_loss: 148478.3438 - val_mae: 178.3952 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 940us/step - loss: 115174.6094 - mae: 168.0859 - val_loss: 136110.3125 - val_mae: 177.2209 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 943us/step - loss: 113841.0312 - mae: 166.1590 - val_loss: 137012.7812 - val_mae: 171.8672 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 111786.7578 - mae: 163.4920 - val_loss: 137901.3906 - val_mae: 172.5965 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 945us/step - loss: 110310.7344 - mae: 162.3486 - val_loss: 128981.8984 - val_mae: 168.8329 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 108974.2656 - mae: 160.8457 - val_loss: 128766.2500 - val_mae: 166.6108 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 944us/step - loss: 106990.5000 - mae: 159.0196 - val_loss: 127896.3828 - val_mae: 167.9918 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 106437.9375 - mae: 157.3904 - val_loss: 129060.3594 - val_mae: 167.3096 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 945us/step - loss: 106461.6172 - mae: 157.4337 - val_loss: 126934.5938 - val_mae: 163.8470 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 105147.0000 - mae: 156.1191 - val_loss: 133014.5938 - val_mae: 167.7408 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 104467.7109 - mae: 155.5054 - val_loss: 120564.0000 - val_mae: 162.0226 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 946us/step - loss: 104726.8281 - mae: 155.4045 - val_loss: 125113.4219 - val_mae: 163.3009 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 942us/step - loss: 104092.0000 - mae: 154.7214 - val_loss: 119343.5469 - val_mae: 162.3339 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 941us/step - loss: 103448.8984 - mae: 154.1269 - val_loss: 120573.2109 - val_mae: 158.5489 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 947us/step - loss: 103623.8828 - mae: 153.9085 - val_loss: 125011.0391 - val_mae: 164.2084 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 951us/step - loss: 103216.9141 - mae: 153.5330 - val_loss: 124645.2109 - val_mae: 162.6787 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 948us/step - loss: 102968.7578 - mae: 153.1110 - val_loss: 122988.2656 - val_mae: 161.6446 - lr: 0.0010\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 953us/step - loss: 103109.2109 - mae: 152.6537 - val_loss: 122287.9844 - val_mae: 159.6537 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 950us/step - loss: 102527.1484 - mae: 152.2000 - val_loss: 125057.0703 - val_mae: 160.7544 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 102542.8438 - mae: 152.3172 - val_loss: 119137.9219 - val_mae: 154.9979 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 102312.9531 - mae: 151.3183 - val_loss: 118229.7266 - val_mae: 155.4985 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 102293.0234 - mae: 151.3698 - val_loss: 115868.8203 - val_mae: 153.7023 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 102032.2031 - mae: 150.8410 - val_loss: 120080.5469 - val_mae: 158.1883 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 101971.7109 - mae: 150.9693 - val_loss: 117652.2109 - val_mae: 155.4333 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 101757.2344 - mae: 150.8708 - val_loss: 117807.1094 - val_mae: 155.1204 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 956us/step - loss: 101420.1406 - mae: 150.4759 - val_loss: 117369.5703 - val_mae: 155.5917 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 101236.4297 - mae: 150.0834 - val_loss: 115859.0469 - val_mae: 153.4105 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 953us/step - loss: 100692.5625 - mae: 149.5799 - val_loss: 119221.5312 - val_mae: 155.7201 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 100803.9844 - mae: 149.2146 - val_loss: 113306.2500 - val_mae: 152.0335 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 101196.2812 - mae: 149.7254 - val_loss: 128682.2344 - val_mae: 168.7625 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 954us/step - loss: 100662.1953 - mae: 149.4136 - val_loss: 113112.6328 - val_mae: 151.4690 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 100525.0312 - mae: 148.7029 - val_loss: 119277.2344 - val_mae: 154.9846 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 100391.0781 - mae: 149.2879 - val_loss: 118944.6094 - val_mae: 155.8677 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 100231.2266 - mae: 149.1822 - val_loss: 115571.0625 - val_mae: 153.6731 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 952us/step - loss: 100396.1094 - mae: 149.2367 - val_loss: 116557.1172 - val_mae: 151.5589 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 958us/step - loss: 100160.5156 - mae: 148.4858 - val_loss: 112671.2422 - val_mae: 150.3894 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 957us/step - loss: 100243.5234 - mae: 148.9072 - val_loss: 114268.3594 - val_mae: 151.4112 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 19:13:13,857]\u001b[0m Trial 97 finished with value: 114268.35228697349 and parameters: {'feature_dim': 38, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1687532.6250 - mae: 722.9562 - val_loss: 1337057.3750 - val_mae: 604.3520 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1454981.6250 - mae: 645.3445 - val_loss: 1091373.3750 - val_mae: 519.4512 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1150933.3750 - mae: 550.8500 - val_loss: 824034.1875 - val_mae: 435.8540 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 852953.3125 - mae: 456.1635 - val_loss: 589642.6875 - val_mae: 358.7884 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 601535.0625 - mae: 373.1593 - val_loss: 410337.2500 - val_mae: 299.0273 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 413310.7812 - mae: 308.5597 - val_loss: 293025.2812 - val_mae: 254.3067 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 285229.2500 - mae: 260.1445 - val_loss: 211919.0938 - val_mae: 221.0361 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 205859.9375 - mae: 226.0141 - val_loss: 168496.9531 - val_mae: 197.9776 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 158574.1719 - mae: 200.6016 - val_loss: 151592.3594 - val_mae: 192.3258 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 135679.7500 - mae: 185.7590 - val_loss: 140828.0156 - val_mae: 176.6658 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 122327.9219 - mae: 174.9680 - val_loss: 135432.5625 - val_mae: 174.7729 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 116302.7031 - mae: 169.0071 - val_loss: 133544.2812 - val_mae: 170.0201 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 111893.7031 - mae: 164.5772 - val_loss: 129884.6094 - val_mae: 167.4148 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109055.5078 - mae: 160.7719 - val_loss: 136689.1250 - val_mae: 171.9873 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107100.2188 - mae: 158.4059 - val_loss: 124349.2578 - val_mae: 163.8490 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105925.5234 - mae: 157.0690 - val_loss: 128408.5938 - val_mae: 163.4254 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105047.0391 - mae: 155.4340 - val_loss: 122249.7109 - val_mae: 159.8938 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104948.7891 - mae: 155.1543 - val_loss: 123760.1797 - val_mae: 163.9250 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104336.8906 - mae: 154.2001 - val_loss: 119883.0859 - val_mae: 157.7065 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103446.0391 - mae: 153.0673 - val_loss: 121406.5000 - val_mae: 159.4977 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103379.6328 - mae: 153.0078 - val_loss: 119421.9531 - val_mae: 158.1696 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103323.2891 - mae: 152.1263 - val_loss: 121960.2422 - val_mae: 158.3192 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102441.2422 - mae: 151.6165 - val_loss: 126774.3438 - val_mae: 163.7795 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101742.7734 - mae: 150.5483 - val_loss: 123347.3047 - val_mae: 161.8165 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102098.6797 - mae: 150.4717 - val_loss: 120854.7188 - val_mae: 158.3450 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101428.6875 - mae: 149.9398 - val_loss: 113834.7266 - val_mae: 154.2554 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101228.7734 - mae: 149.9168 - val_loss: 115263.0000 - val_mae: 152.6770 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100971.2109 - mae: 149.4072 - val_loss: 125800.6641 - val_mae: 163.9648 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100722.4609 - mae: 149.1568 - val_loss: 124470.5469 - val_mae: 162.7053 - lr: 0.0010\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100490.0781 - mae: 148.6800 - val_loss: 122021.7500 - val_mae: 159.9740 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100740.9062 - mae: 148.8645 - val_loss: 119193.2891 - val_mae: 155.9403 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100170.2734 - mae: 148.2194 - val_loss: 120727.0000 - val_mae: 157.0236 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99980.1719 - mae: 148.7347 - val_loss: 114039.5938 - val_mae: 149.9245 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99814.1641 - mae: 147.4725 - val_loss: 116559.5703 - val_mae: 151.7974 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99866.5703 - mae: 147.5862 - val_loss: 113200.3203 - val_mae: 151.1515 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99579.4062 - mae: 147.3233 - val_loss: 116584.1562 - val_mae: 153.0598 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99395.0469 - mae: 147.0489 - val_loss: 115355.6641 - val_mae: 153.2900 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99333.8594 - mae: 147.5876 - val_loss: 116144.2031 - val_mae: 154.5332 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99158.6406 - mae: 147.5583 - val_loss: 114897.8984 - val_mae: 152.8910 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98609.8906 - mae: 146.5403 - val_loss: 111580.1172 - val_mae: 150.1192 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98544.9219 - mae: 146.6915 - val_loss: 117036.2188 - val_mae: 152.3311 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98618.1875 - mae: 146.2304 - val_loss: 111646.8125 - val_mae: 148.1664 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98943.1406 - mae: 146.6168 - val_loss: 120236.4141 - val_mae: 159.1795 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98413.9922 - mae: 146.3023 - val_loss: 110817.0156 - val_mae: 147.3494 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98382.4297 - mae: 145.8727 - val_loss: 116285.4453 - val_mae: 151.2992 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98125.3594 - mae: 146.2349 - val_loss: 122288.0938 - val_mae: 154.7862 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97977.6719 - mae: 145.9935 - val_loss: 113420.1797 - val_mae: 152.8724 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98195.2500 - mae: 146.2393 - val_loss: 113384.8438 - val_mae: 147.1317 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97749.6484 - mae: 145.4635 - val_loss: 112815.1250 - val_mae: 153.3848 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98164.4844 - mae: 146.2155 - val_loss: 115738.2656 - val_mae: 152.2219 - lr: 0.0010\n",
      "\u001b[32m[I 2022-07-28 19:14:14,368]\u001b[0m Trial 98 finished with value: 115738.23133857585 and parameters: {'feature_dim': 50, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n",
      "Epoch 1/50\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1655524.6250 - mae: 713.3864 - val_loss: 1281498.0000 - val_mae: 583.8576 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 1355979.8750 - mae: 614.4265 - val_loss: 977291.2500 - val_mae: 486.6936 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 994440.3750 - mae: 503.3345 - val_loss: 678083.4375 - val_mae: 388.9702 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 676172.1875 - mae: 402.4855 - val_loss: 449753.1250 - val_mae: 322.0825 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 441004.3438 - mae: 323.1554 - val_loss: 301334.8750 - val_mae: 263.8466 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 286909.5000 - mae: 263.9606 - val_loss: 219339.1250 - val_mae: 227.2451 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 198052.2031 - mae: 224.7430 - val_loss: 171373.7500 - val_mae: 214.8275 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 153464.3281 - mae: 199.7721 - val_loss: 147499.9375 - val_mae: 187.3002 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 131468.5156 - mae: 183.6629 - val_loss: 138228.7812 - val_mae: 186.4882 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 121830.1562 - mae: 174.9196 - val_loss: 135364.4062 - val_mae: 171.0738 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 114821.2344 - mae: 168.0092 - val_loss: 129310.8750 - val_mae: 170.3532 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 112227.0859 - mae: 164.7868 - val_loss: 134384.6094 - val_mae: 170.1969 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 109819.2188 - mae: 161.7238 - val_loss: 122057.7344 - val_mae: 163.8005 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 108806.8594 - mae: 160.2723 - val_loss: 133948.1406 - val_mae: 169.5582 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 107212.7109 - mae: 158.4096 - val_loss: 118623.1094 - val_mae: 159.7085 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 106946.9297 - mae: 158.3556 - val_loss: 129021.4844 - val_mae: 163.0331 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105650.2422 - mae: 156.8106 - val_loss: 125639.1094 - val_mae: 160.4617 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105609.3516 - mae: 156.9141 - val_loss: 121811.4766 - val_mae: 159.5381 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 105256.4141 - mae: 156.4973 - val_loss: 120882.8359 - val_mae: 156.6571 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104171.3516 - mae: 155.3635 - val_loss: 119397.8750 - val_mae: 156.6423 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103959.7891 - mae: 155.0764 - val_loss: 120712.8672 - val_mae: 158.1635 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 104445.2266 - mae: 155.0907 - val_loss: 119525.5625 - val_mae: 156.9601 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103372.1328 - mae: 154.3719 - val_loss: 132579.4062 - val_mae: 167.3287 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102721.2734 - mae: 153.3486 - val_loss: 119283.6016 - val_mae: 161.7715 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103384.2500 - mae: 153.7631 - val_loss: 118846.4766 - val_mae: 157.4075 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99723.8594 - mae: 149.4009 - val_loss: 117163.4531 - val_mae: 155.4744 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99354.8438 - mae: 148.9676 - val_loss: 118059.3594 - val_mae: 155.7774 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99311.0781 - mae: 148.6782 - val_loss: 118141.0234 - val_mae: 156.5288 - lr: 1.0000e-04\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99287.2812 - mae: 148.5709 - val_loss: 116820.9531 - val_mae: 155.5701 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99095.7578 - mae: 148.5998 - val_loss: 119165.6250 - val_mae: 157.4087 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99143.3359 - mae: 148.3886 - val_loss: 120290.3828 - val_mae: 157.7287 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99129.8047 - mae: 148.4542 - val_loss: 120646.4453 - val_mae: 158.1126 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99052.2656 - mae: 148.3175 - val_loss: 119255.7188 - val_mae: 156.0043 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 99038.7891 - mae: 148.1077 - val_loss: 119539.9453 - val_mae: 157.1401 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98972.0703 - mae: 148.1893 - val_loss: 118273.1406 - val_mae: 155.9712 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98965.1016 - mae: 148.1873 - val_loss: 118054.2266 - val_mae: 155.8355 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98919.2109 - mae: 148.2010 - val_loss: 116685.5000 - val_mae: 155.4019 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98879.7812 - mae: 148.1186 - val_loss: 118249.0703 - val_mae: 156.9140 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98833.9844 - mae: 148.1279 - val_loss: 119094.6484 - val_mae: 156.6820 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98679.3203 - mae: 148.1458 - val_loss: 117658.0547 - val_mae: 155.4834 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98722.3281 - mae: 147.8712 - val_loss: 120411.7891 - val_mae: 157.3675 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98675.7188 - mae: 147.7518 - val_loss: 117610.2500 - val_mae: 156.4024 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98721.7656 - mae: 147.9053 - val_loss: 117648.3594 - val_mae: 156.0116 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98582.2422 - mae: 147.7781 - val_loss: 117188.6250 - val_mae: 155.1731 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98606.3438 - mae: 147.7804 - val_loss: 118361.7031 - val_mae: 156.3896 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98607.4531 - mae: 147.9543 - val_loss: 119563.4922 - val_mae: 157.5571 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98601.2891 - mae: 147.6985 - val_loss: 117584.2109 - val_mae: 156.7950 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98207.6406 - mae: 147.7925 - val_loss: 119250.1172 - val_mae: 157.7208 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98155.6172 - mae: 147.4263 - val_loss: 118420.0312 - val_mae: 156.7959 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 98133.5703 - mae: 147.4091 - val_loss: 118623.7500 - val_mae: 156.7995 - lr: 1.0000e-05\n",
      "\u001b[32m[I 2022-07-28 19:15:20,891]\u001b[0m Trial 99 finished with value: 118623.75764697944 and parameters: {'feature_dim': 59, 'output_dim': 11, 'num_decision_steps': 1}. Best is trial 25 with value: 110640.79483212534.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Optuna for TabNet hyperparameter optimization\n",
    "\n",
    "import optuna\n",
    "import sklearn\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(69)\n",
    "np.random.seed(69)\n",
    "tf.random.set_seed(69)\n",
    "\n",
    "def optuna_create_model(trial):\n",
    "    # Do search for n_estimators, max_depth, reg_alpha and reg_lambda\n",
    "    #sug_layers = trial.suggest_int('num_layers', 1, 4)\n",
    "    sug_fdim = trial.suggest_int('feature_dim', 32, 72)\n",
    "    sug_odim = trial.suggest_int('output_dim', 4, 12)\n",
    "    sug_dsteps = trial.suggest_int('num_decision_steps', 1, 4)\n",
    "    \n",
    "    sug_model = StackedTabNetRegressor(feature_columns=None,\n",
    "                                       num_layers=1, #sug_layers,\n",
    "                                       num_regressors=1, \n",
    "                                       feature_dim=sug_fdim,\n",
    "                                       num_features=8, \n",
    "                                       output_dim=sug_odim,\n",
    "                                       num_decision_steps=sug_dsteps,\n",
    "                                       num_groups=1)\n",
    "    \n",
    "    return sug_model\n",
    "\n",
    "\n",
    "def optuna_create_training(model):\n",
    "    compile_and_fit(model, X_train['upac08'], y_train['upac08'],\n",
    "                    X_val['upac08'], y_val['upac08'],\n",
    "                    max_epochs=50, rlr_patience=10, es_patience=20)\n",
    "    \n",
    "    \n",
    "def optuna_create_evaluation(model):\n",
    "    temp_yhat = model.predict(X_val['upac08'])\n",
    "    return sklearn.metrics.mean_squared_error(y_val['upac08'], temp_yhat)\n",
    "    \n",
    "    \n",
    "def objective(trial):\n",
    "    # Instantiate the model\n",
    "    temp_model = optuna_create_model(trial)\n",
    "    \n",
    "    # Train the model\n",
    "    optuna_create_training(temp_model)\n",
    "    \n",
    "    # Evaluate model\n",
    "    metrics_val = optuna_create_evaluation(temp_model)\n",
    "    \n",
    "    return metrics_val\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd163b75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T08:31:57.047056Z",
     "start_time": "2022-08-01T08:31:57.034053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_dim': 39, 'output_dim': 11, 'num_decision_steps': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TabNet best params (all fetures)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b75914e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T09:33:28.240616Z",
     "start_time": "2022-08-01T08:40:50.724995Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Model: 10\n",
      "Epoch 1/1000\n",
      "1089/1089 [==============================] - 2s 1ms/step - loss: 1678902.2500 - mae: 718.8348 - val_loss: 1318731.3750 - val_mae: 596.4104 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 1420019.3750 - mae: 634.3806 - val_loss: 1051325.6250 - val_mae: 516.3365 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 1092781.1250 - mae: 534.1730 - val_loss: 768095.8750 - val_mae: 420.9233 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 784612.1875 - mae: 437.6797 - val_loss: 534634.0625 - val_mae: 350.9758 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 536865.1875 - mae: 357.1194 - val_loss: 365120.2188 - val_mae: 287.3880 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 358285.3438 - mae: 294.0498 - val_loss: 256781.6875 - val_mae: 247.8892 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 241888.2188 - mae: 247.4405 - val_loss: 195660.7812 - val_mae: 233.9885 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 176897.3906 - mae: 214.4757 - val_loss: 165632.9688 - val_mae: 199.8003 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 143047.5156 - mae: 193.6585 - val_loss: 151565.0781 - val_mae: 195.5551 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 129092.3203 - mae: 182.8031 - val_loss: 139955.9688 - val_mae: 175.5489 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 120068.8359 - mae: 174.5773 - val_loss: 135810.8750 - val_mae: 178.0730 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 116123.5938 - mae: 169.9923 - val_loss: 137120.2812 - val_mae: 171.4819 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 112121.0938 - mae: 165.6449 - val_loss: 128462.9766 - val_mae: 173.2862 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 110747.6016 - mae: 163.4924 - val_loss: 140020.3125 - val_mae: 172.4095 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 109077.4922 - mae: 161.4722 - val_loss: 125351.4062 - val_mae: 167.3061 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "1089/1089 [==============================] - 1s 982us/step - loss: 108551.5234 - mae: 161.2184 - val_loss: 133088.6094 - val_mae: 168.5814 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 107064.3438 - mae: 159.0151 - val_loss: 132273.3750 - val_mae: 169.1837 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 107048.6562 - mae: 159.1172 - val_loss: 124603.0547 - val_mae: 163.1843 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 106694.9219 - mae: 158.5433 - val_loss: 129175.3359 - val_mae: 164.7409 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 105216.8984 - mae: 157.1069 - val_loss: 124908.2344 - val_mae: 165.0708 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 105123.3672 - mae: 156.7572 - val_loss: 126805.6719 - val_mae: 166.1363 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 105296.3203 - mae: 156.8913 - val_loss: 122048.7500 - val_mae: 160.4688 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "1089/1089 [==============================] - 1s 992us/step - loss: 104145.4062 - mae: 156.0653 - val_loss: 132711.7344 - val_mae: 169.8135 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 103708.0000 - mae: 155.1912 - val_loss: 118703.9141 - val_mae: 161.4835 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 104019.5938 - mae: 155.3388 - val_loss: 123509.9688 - val_mae: 161.9966 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 103176.9531 - mae: 154.1951 - val_loss: 118201.9141 - val_mae: 159.6259 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 103016.1484 - mae: 153.9900 - val_loss: 121452.8359 - val_mae: 160.2748 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 102669.6641 - mae: 153.4266 - val_loss: 125765.5000 - val_mae: 165.6909 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 102536.5234 - mae: 153.0945 - val_loss: 128863.6328 - val_mae: 167.4280 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 102208.5156 - mae: 152.4402 - val_loss: 125683.3203 - val_mae: 163.5718 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 102392.7812 - mae: 152.2429 - val_loss: 122923.4688 - val_mae: 160.5116 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 101806.5469 - mae: 151.7901 - val_loss: 127631.5234 - val_mae: 163.6487 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 101698.8047 - mae: 151.9400 - val_loss: 122098.1641 - val_mae: 159.4652 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 101334.6328 - mae: 150.8590 - val_loss: 121086.0078 - val_mae: 160.4665 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 101230.6328 - mae: 150.8748 - val_loss: 117336.9688 - val_mae: 156.3392 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 100918.1641 - mae: 150.2802 - val_loss: 117549.0234 - val_mae: 157.1041 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 101161.2266 - mae: 150.7402 - val_loss: 122042.8828 - val_mae: 160.1941 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 100776.5312 - mae: 150.4210 - val_loss: 119538.1328 - val_mae: 160.8149 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 100709.0547 - mae: 150.2992 - val_loss: 117463.7969 - val_mae: 156.8535 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 100335.5859 - mae: 149.6105 - val_loss: 116522.6797 - val_mae: 155.4435 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 100089.8750 - mae: 149.4381 - val_loss: 119806.1953 - val_mae: 158.2888 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 100260.7734 - mae: 149.1990 - val_loss: 116248.1562 - val_mae: 155.6037 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 100449.8047 - mae: 149.5885 - val_loss: 126508.2812 - val_mae: 167.4195 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 100085.5547 - mae: 149.2520 - val_loss: 113665.6641 - val_mae: 153.1353 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 99727.1250 - mae: 148.6934 - val_loss: 120505.9531 - val_mae: 158.0140 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 99624.7422 - mae: 149.1256 - val_loss: 118827.4844 - val_mae: 156.6583 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 99539.0156 - mae: 148.5565 - val_loss: 115829.5391 - val_mae: 155.8240 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 99682.4922 - mae: 148.6725 - val_loss: 117092.1484 - val_mae: 152.6371 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 99237.9062 - mae: 147.7374 - val_loss: 113880.0156 - val_mae: 152.5031 - lr: 0.0010\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 983us/step - loss: 99649.2422 - mae: 148.7020 - val_loss: 115472.3594 - val_mae: 153.4647 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 99291.7344 - mae: 148.2803 - val_loss: 116304.1875 - val_mae: 154.1186 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 99103.1172 - mae: 147.6200 - val_loss: 116769.7500 - val_mae: 154.5076 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 98979.3203 - mae: 147.3172 - val_loss: 110608.2344 - val_mae: 149.7165 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 98993.3984 - mae: 147.1808 - val_loss: 113133.0625 - val_mae: 152.0357 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 98810.0234 - mae: 147.2133 - val_loss: 118903.9297 - val_mae: 157.3274 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "1089/1089 [==============================] - 1s 982us/step - loss: 98666.1953 - mae: 147.0026 - val_loss: 118129.5625 - val_mae: 157.3588 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 98736.3516 - mae: 147.2308 - val_loss: 113768.4375 - val_mae: 151.3783 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 98538.3359 - mae: 146.6998 - val_loss: 111920.9844 - val_mae: 150.3504 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 98668.3281 - mae: 147.1148 - val_loss: 113087.7734 - val_mae: 151.8109 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "1089/1089 [==============================] - 1s 963us/step - loss: 99221.9375 - mae: 148.0480 - val_loss: 116484.8906 - val_mae: 152.6883 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "1089/1089 [==============================] - 1s 967us/step - loss: 98501.6406 - mae: 147.2395 - val_loss: 113834.9844 - val_mae: 152.5386 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "1089/1089 [==============================] - 1s 962us/step - loss: 97888.3828 - mae: 146.4376 - val_loss: 113061.0156 - val_mae: 152.2772 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 98253.9062 - mae: 146.5755 - val_loss: 116219.1250 - val_mae: 153.6062 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 98115.5312 - mae: 146.3792 - val_loss: 115583.0938 - val_mae: 155.6873 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "1089/1089 [==============================] - 1s 964us/step - loss: 97967.1250 - mae: 146.5078 - val_loss: 115755.3516 - val_mae: 152.4632 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 97833.3438 - mae: 146.2013 - val_loss: 116256.3906 - val_mae: 154.3587 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 97744.5391 - mae: 145.8234 - val_loss: 113644.9297 - val_mae: 150.6060 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 97718.0156 - mae: 145.9064 - val_loss: 113546.4062 - val_mae: 152.8730 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "1089/1089 [==============================] - 1s 982us/step - loss: 97629.1328 - mae: 145.4827 - val_loss: 116408.4453 - val_mae: 154.8800 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 97295.4688 - mae: 145.7937 - val_loss: 123887.4297 - val_mae: 159.1892 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 97216.9219 - mae: 145.4029 - val_loss: 112889.2500 - val_mae: 150.6781 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "1089/1089 [==============================] - 1s 982us/step - loss: 97267.8672 - mae: 145.3444 - val_loss: 115412.5859 - val_mae: 154.0898 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 97082.5859 - mae: 145.3753 - val_loss: 115017.6562 - val_mae: 155.9117 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 97082.3906 - mae: 145.7259 - val_loss: 114798.0938 - val_mae: 152.0787 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "1089/1089 [==============================] - 1s 981us/step - loss: 97039.7422 - mae: 145.3293 - val_loss: 118254.0859 - val_mae: 155.5059 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 96995.8438 - mae: 145.6481 - val_loss: 116757.6328 - val_mae: 153.6928 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 96870.4766 - mae: 144.8563 - val_loss: 115763.4844 - val_mae: 154.8537 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 96734.4922 - mae: 144.8150 - val_loss: 112004.2109 - val_mae: 151.1076 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 96446.1328 - mae: 144.9771 - val_loss: 116831.0391 - val_mae: 156.2856 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 96526.2500 - mae: 144.9899 - val_loss: 114087.8047 - val_mae: 151.6484 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 96501.8125 - mae: 145.1670 - val_loss: 113672.0703 - val_mae: 151.8111 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 96003.0078 - mae: 144.6023 - val_loss: 117587.3984 - val_mae: 155.2318 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 96360.5078 - mae: 144.3523 - val_loss: 120163.3984 - val_mae: 156.6329 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 96132.8594 - mae: 144.4326 - val_loss: 116466.2500 - val_mae: 156.9512 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 96349.7266 - mae: 144.9940 - val_loss: 115053.1797 - val_mae: 152.7458 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 95986.3516 - mae: 144.2907 - val_loss: 113048.1641 - val_mae: 152.9257 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 95814.7031 - mae: 144.1285 - val_loss: 114518.4453 - val_mae: 154.5040 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "1089/1089 [==============================] - 1s 983us/step - loss: 95684.4922 - mae: 143.9819 - val_loss: 112830.4922 - val_mae: 150.4522 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 95840.3047 - mae: 144.2611 - val_loss: 110788.5625 - val_mae: 150.2943 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95315.3594 - mae: 144.1668 - val_loss: 119851.3359 - val_mae: 158.6603 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95414.3281 - mae: 143.9973 - val_loss: 116167.6562 - val_mae: 153.3880 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 94925.7344 - mae: 143.3244 - val_loss: 118899.0000 - val_mae: 156.1941 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 95609.8984 - mae: 144.0149 - val_loss: 112492.4531 - val_mae: 150.0518 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 94967.8359 - mae: 143.6745 - val_loss: 114858.0312 - val_mae: 153.2164 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 95123.3750 - mae: 143.6024 - val_loss: 118048.0625 - val_mae: 156.0107 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 94772.2422 - mae: 143.6013 - val_loss: 116989.9609 - val_mae: 154.6088 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 94801.1328 - mae: 143.4773 - val_loss: 114505.9062 - val_mae: 151.6329 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 94915.2344 - mae: 143.5907 - val_loss: 114614.1484 - val_mae: 153.4835 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 94620.0859 - mae: 143.6275 - val_loss: 113457.4531 - val_mae: 151.8409 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 94346.4844 - mae: 143.6755 - val_loss: 119764.6172 - val_mae: 156.1121 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 94530.9062 - mae: 143.3428 - val_loss: 115906.7500 - val_mae: 156.2811 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 94491.2734 - mae: 143.6053 - val_loss: 115250.8359 - val_mae: 153.2468 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 93872.4531 - mae: 142.5898 - val_loss: 114891.5000 - val_mae: 154.2710 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "1089/1089 [==============================] - 1s 993us/step - loss: 94325.4766 - mae: 142.9215 - val_loss: 111413.3828 - val_mae: 151.5546 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 94053.9297 - mae: 143.0326 - val_loss: 112785.2031 - val_mae: 152.6826 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 94148.4062 - mae: 143.0042 - val_loss: 116410.7656 - val_mae: 155.1395 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 93817.7734 - mae: 142.7503 - val_loss: 117293.9141 - val_mae: 153.7700 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 94317.0625 - mae: 143.0682 - val_loss: 112461.3828 - val_mae: 150.0242 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 93638.8438 - mae: 142.6711 - val_loss: 119114.8984 - val_mae: 159.2663 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 93430.2656 - mae: 142.6796 - val_loss: 115096.2578 - val_mae: 152.6138 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 93752.0234 - mae: 142.6189 - val_loss: 116031.6719 - val_mae: 154.2073 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "1089/1089 [==============================] - 1s 981us/step - loss: 93694.8906 - mae: 142.4201 - val_loss: 114452.1484 - val_mae: 151.4810 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 93166.6328 - mae: 142.2745 - val_loss: 112351.9609 - val_mae: 149.8948 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 93284.3438 - mae: 142.4052 - val_loss: 112636.1406 - val_mae: 149.6845 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 92896.7812 - mae: 141.7652 - val_loss: 117156.5000 - val_mae: 158.1150 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 92938.3672 - mae: 141.9068 - val_loss: 114118.2500 - val_mae: 151.4561 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 92781.7109 - mae: 141.9043 - val_loss: 116948.8828 - val_mae: 156.0209 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "1089/1089 [==============================] - 1s 971us/step - loss: 92766.8203 - mae: 141.8223 - val_loss: 116870.3828 - val_mae: 156.1977 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 92993.3203 - mae: 142.0255 - val_loss: 113665.6328 - val_mae: 152.2367 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 92431.5156 - mae: 141.5948 - val_loss: 115218.7266 - val_mae: 151.4629 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 92512.4297 - mae: 141.6574 - val_loss: 116985.0391 - val_mae: 154.4232 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 92345.0000 - mae: 141.9849 - val_loss: 115094.5703 - val_mae: 153.9153 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 92429.2109 - mae: 141.6996 - val_loss: 113909.4141 - val_mae: 153.5879 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "1089/1089 [==============================] - 1s 994us/step - loss: 92110.2109 - mae: 141.1474 - val_loss: 114476.1172 - val_mae: 151.8265 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 92293.4062 - mae: 141.3561 - val_loss: 113722.7891 - val_mae: 151.8138 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 92192.0938 - mae: 141.3398 - val_loss: 115059.4844 - val_mae: 153.8746 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 92048.5000 - mae: 141.1154 - val_loss: 115917.4375 - val_mae: 153.4601 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 92064.1719 - mae: 141.3792 - val_loss: 114411.8125 - val_mae: 152.3712 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "1089/1089 [==============================] - 1s 985us/step - loss: 91538.0312 - mae: 140.9620 - val_loss: 114493.1875 - val_mae: 153.4926 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 91570.2891 - mae: 140.9485 - val_loss: 114411.4141 - val_mae: 152.5783 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "1089/1089 [==============================] - 1s 991us/step - loss: 91667.9688 - mae: 140.9131 - val_loss: 115764.7969 - val_mae: 152.2792 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "1089/1089 [==============================] - 1s 979us/step - loss: 91441.5078 - mae: 140.7151 - val_loss: 116278.9062 - val_mae: 153.9982 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 91339.0156 - mae: 140.7763 - val_loss: 117596.4531 - val_mae: 152.9264 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "1089/1089 [==============================] - 1s 989us/step - loss: 91405.3125 - mae: 140.8461 - val_loss: 114322.9453 - val_mae: 151.0658 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 91398.7188 - mae: 140.7156 - val_loss: 115693.5000 - val_mae: 152.0870 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "1089/1089 [==============================] - 1s 987us/step - loss: 91714.7578 - mae: 141.0203 - val_loss: 115340.2734 - val_mae: 151.2294 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 91413.8281 - mae: 140.5444 - val_loss: 115083.0781 - val_mae: 154.7316 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 90791.2578 - mae: 139.7966 - val_loss: 114560.4062 - val_mae: 152.6381 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 90874.8750 - mae: 140.2046 - val_loss: 114089.9375 - val_mae: 150.9273 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 90499.1250 - mae: 139.6651 - val_loss: 113036.4688 - val_mae: 149.7824 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 90950.0469 - mae: 140.4529 - val_loss: 117312.2266 - val_mae: 152.8958 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 90550.2656 - mae: 140.0184 - val_loss: 121220.9141 - val_mae: 156.7561 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 90755.2812 - mae: 140.1234 - val_loss: 122353.0078 - val_mae: 158.9760 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 90480.3984 - mae: 140.0120 - val_loss: 116005.9453 - val_mae: 154.2264 - lr: 0.0010\n",
      "Epoch 145/1000\n",
      "1089/1089 [==============================] - 1s 965us/step - loss: 90392.2812 - mae: 140.0271 - val_loss: 115507.1641 - val_mae: 153.8073 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "1089/1089 [==============================] - 1s 966us/step - loss: 90435.9141 - mae: 139.9204 - val_loss: 121201.8281 - val_mae: 159.4368 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "1089/1089 [==============================] - 1s 984us/step - loss: 90271.6328 - mae: 139.5211 - val_loss: 116113.6641 - val_mae: 154.7213 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 90314.8281 - mae: 139.5690 - val_loss: 116828.0703 - val_mae: 154.8992 - lr: 0.0010\n",
      "Epoch 149/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 976us/step - loss: 89924.3672 - mae: 139.3241 - val_loss: 113403.7031 - val_mae: 150.3303 - lr: 0.0010\n",
      "Epoch 150/1000\n",
      "1089/1089 [==============================] - 1s 986us/step - loss: 90253.7969 - mae: 139.7027 - val_loss: 117415.7344 - val_mae: 155.0459 - lr: 0.0010\n",
      "Epoch 151/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 90084.6016 - mae: 139.4295 - val_loss: 115064.0938 - val_mae: 153.5325 - lr: 0.0010\n",
      "Epoch 152/1000\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 89949.9531 - mae: 139.2745 - val_loss: 115976.7500 - val_mae: 153.2559 - lr: 0.0010\n",
      "Epoch 153/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 89886.8203 - mae: 139.2757 - val_loss: 115388.9609 - val_mae: 152.8247 - lr: 0.0010\n",
      "Epoch 154/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 86661.6328 - mae: 135.5797 - val_loss: 115221.5000 - val_mae: 151.8311 - lr: 1.0000e-04\n",
      "Epoch 155/1000\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 86303.1094 - mae: 134.9761 - val_loss: 116827.9844 - val_mae: 153.0071 - lr: 1.0000e-04\n",
      "Epoch 156/1000\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 86197.2891 - mae: 134.9565 - val_loss: 115788.7812 - val_mae: 151.6596 - lr: 1.0000e-04\n",
      "Epoch 157/1000\n",
      "1089/1089 [==============================] - 1s 996us/step - loss: 86084.9609 - mae: 134.7151 - val_loss: 115407.4297 - val_mae: 151.7968 - lr: 1.0000e-04\n",
      "Epoch 158/1000\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 86019.4453 - mae: 134.8257 - val_loss: 116854.3906 - val_mae: 153.6246 - lr: 1.0000e-04\n",
      "Epoch 159/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 86015.3359 - mae: 134.8369 - val_loss: 117140.9297 - val_mae: 153.2298 - lr: 1.0000e-04\n",
      "Epoch 160/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 85944.2500 - mae: 134.7588 - val_loss: 116889.2266 - val_mae: 153.3875 - lr: 1.0000e-04\n",
      "Epoch 161/1000\n",
      "1089/1089 [==============================] - 1s 988us/step - loss: 85902.9688 - mae: 134.8343 - val_loss: 115937.3125 - val_mae: 151.8430 - lr: 1.0000e-04\n",
      "Epoch 162/1000\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 85889.9609 - mae: 134.7307 - val_loss: 117080.7578 - val_mae: 153.0954 - lr: 1.0000e-04\n",
      "Epoch 163/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 85773.1953 - mae: 134.5741 - val_loss: 116599.0859 - val_mae: 152.7435 - lr: 1.0000e-04\n",
      "Epoch 164/1000\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 85791.8906 - mae: 134.8688 - val_loss: 116512.0234 - val_mae: 152.1678 - lr: 1.0000e-04\n",
      "Epoch 165/1000\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 85717.7578 - mae: 134.6339 - val_loss: 115665.5703 - val_mae: 151.2674 - lr: 1.0000e-04\n",
      "Epoch 166/1000\n",
      "1089/1089 [==============================] - 1s 970us/step - loss: 85742.3281 - mae: 134.5802 - val_loss: 116310.7031 - val_mae: 152.6022 - lr: 1.0000e-04\n",
      "Epoch 167/1000\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 85665.5391 - mae: 134.4838 - val_loss: 117818.8359 - val_mae: 153.4400 - lr: 1.0000e-04\n",
      "Epoch 168/1000\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 85633.8906 - mae: 134.6515 - val_loss: 117958.2969 - val_mae: 153.8471 - lr: 1.0000e-04\n",
      "Epoch 169/1000\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 85587.1406 - mae: 134.4596 - val_loss: 116648.3594 - val_mae: 152.8380 - lr: 1.0000e-04\n",
      "Epoch 170/1000\n",
      "1089/1089 [==============================] - 1s 969us/step - loss: 85582.6641 - mae: 134.6488 - val_loss: 117010.9922 - val_mae: 152.7227 - lr: 1.0000e-04\n",
      "Epoch 171/1000\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 85521.6328 - mae: 134.5112 - val_loss: 116368.2500 - val_mae: 153.0508 - lr: 1.0000e-04\n",
      "Epoch 172/1000\n",
      "1089/1089 [==============================] - 1s 977us/step - loss: 85540.1094 - mae: 134.5220 - val_loss: 116685.8906 - val_mae: 152.7932 - lr: 1.0000e-04\n",
      "Epoch 173/1000\n",
      "1089/1089 [==============================] - 1s 975us/step - loss: 85517.9453 - mae: 134.5473 - val_loss: 116728.2578 - val_mae: 153.0237 - lr: 1.0000e-04\n",
      "Epoch 174/1000\n",
      "1089/1089 [==============================] - 1s 974us/step - loss: 85586.8906 - mae: 134.6315 - val_loss: 117092.0625 - val_mae: 152.9874 - lr: 1.0000e-04\n",
      "Epoch 175/1000\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 85459.8828 - mae: 134.4403 - val_loss: 116809.2344 - val_mae: 152.6885 - lr: 1.0000e-04\n",
      "Epoch 176/1000\n",
      "1089/1089 [==============================] - 1s 972us/step - loss: 85427.8750 - mae: 134.3977 - val_loss: 116814.6953 - val_mae: 153.0566 - lr: 1.0000e-04\n",
      "Epoch 177/1000\n",
      "1089/1089 [==============================] - 1s 976us/step - loss: 85439.6953 - mae: 134.5620 - val_loss: 116856.4219 - val_mae: 152.6196 - lr: 1.0000e-04\n",
      "Epoch 178/1000\n",
      "1089/1089 [==============================] - 1s 980us/step - loss: 85444.7109 - mae: 134.4380 - val_loss: 117023.0859 - val_mae: 153.5431 - lr: 1.0000e-04\n",
      "Epoch 179/1000\n",
      "1089/1089 [==============================] - 1s 978us/step - loss: 85391.2500 - mae: 134.6186 - val_loss: 117049.1641 - val_mae: 152.7369 - lr: 1.0000e-04\n",
      "Epoch 180/1000\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 85293.9141 - mae: 134.3855 - val_loss: 117380.2812 - val_mae: 152.7339 - lr: 1.0000e-04\n",
      "Epoch 181/1000\n",
      "1089/1089 [==============================] - 1s 973us/step - loss: 85401.9219 - mae: 134.3345 - val_loss: 117316.1172 - val_mae: 153.2573 - lr: 1.0000e-04\n",
      "Epoch 182/1000\n",
      "1089/1089 [==============================] - 1s 968us/step - loss: 85281.0312 - mae: 134.4775 - val_loss: 117190.0234 - val_mae: 152.8719 - lr: 1.0000e-04\n",
      "Epoch 183/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85242.7031 - mae: 134.3783 - val_loss: 116650.3516 - val_mae: 152.8989 - lr: 1.0000e-04\n",
      "Epoch 184/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85279.8047 - mae: 134.3873 - val_loss: 117140.6250 - val_mae: 152.9271 - lr: 1.0000e-04\n",
      "Epoch 185/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85181.3984 - mae: 134.4885 - val_loss: 116743.6953 - val_mae: 152.0744 - lr: 1.0000e-04\n",
      "Epoch 186/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85196.0391 - mae: 134.4238 - val_loss: 118172.1094 - val_mae: 153.7475 - lr: 1.0000e-04\n",
      "Epoch 187/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85172.2812 - mae: 134.1573 - val_loss: 117037.1250 - val_mae: 152.9633 - lr: 1.0000e-04\n",
      "Epoch 188/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85225.6719 - mae: 134.4417 - val_loss: 117636.1094 - val_mae: 153.0438 - lr: 1.0000e-04\n",
      "Epoch 189/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85126.8203 - mae: 134.2754 - val_loss: 117863.1094 - val_mae: 153.9540 - lr: 1.0000e-04\n",
      "Epoch 190/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85069.9375 - mae: 134.4135 - val_loss: 117805.4766 - val_mae: 153.3077 - lr: 1.0000e-04\n",
      "Epoch 191/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85056.0703 - mae: 134.1427 - val_loss: 118295.2109 - val_mae: 153.6867 - lr: 1.0000e-04\n",
      "Epoch 192/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85058.1094 - mae: 134.2237 - val_loss: 118061.6641 - val_mae: 153.1590 - lr: 1.0000e-04\n",
      "Epoch 193/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85029.7812 - mae: 134.2334 - val_loss: 117614.4141 - val_mae: 152.9877 - lr: 1.0000e-04\n",
      "Epoch 194/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84981.9453 - mae: 134.1175 - val_loss: 118588.2734 - val_mae: 153.9786 - lr: 1.0000e-04\n",
      "Epoch 195/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 85020.8047 - mae: 134.1747 - val_loss: 118539.4375 - val_mae: 154.5359 - lr: 1.0000e-04\n",
      "Epoch 196/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84916.1953 - mae: 134.1583 - val_loss: 118218.7188 - val_mae: 153.3438 - lr: 1.0000e-04\n",
      "Epoch 197/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84952.2109 - mae: 134.1184 - val_loss: 117575.1484 - val_mae: 153.1998 - lr: 1.0000e-04\n",
      "Epoch 198/1000\n",
      "1089/1089 [==============================] - 1s 990us/step - loss: 84919.3125 - mae: 134.0840 - val_loss: 117594.3281 - val_mae: 153.2823 - lr: 1.0000e-04\n",
      "Epoch 199/1000\n",
      "1089/1089 [==============================] - 1s 995us/step - loss: 84874.5625 - mae: 134.3660 - val_loss: 117663.4062 - val_mae: 152.3279 - lr: 1.0000e-04\n",
      "Epoch 200/1000\n",
      "1089/1089 [==============================] - 1s 998us/step - loss: 84866.3516 - mae: 134.0947 - val_loss: 118076.5000 - val_mae: 153.3569 - lr: 1.0000e-04\n",
      "Epoch 201/1000\n",
      "1089/1089 [==============================] - 1s 999us/step - loss: 84767.0547 - mae: 134.0033 - val_loss: 117847.3672 - val_mae: 153.4034 - lr: 1.0000e-04\n",
      "Epoch 202/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84884.2500 - mae: 134.1994 - val_loss: 117219.7969 - val_mae: 152.5290 - lr: 1.0000e-04\n",
      "Epoch 203/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84792.3281 - mae: 134.0932 - val_loss: 119053.5469 - val_mae: 154.1909 - lr: 1.0000e-04\n",
      "Epoch 204/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84799.7109 - mae: 133.9066 - val_loss: 117686.5156 - val_mae: 153.1421 - lr: 1.0000e-04\n",
      "Epoch 205/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84748.2109 - mae: 134.0694 - val_loss: 118107.5625 - val_mae: 153.3803 - lr: 1.0000e-04\n",
      "Epoch 206/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84706.6328 - mae: 133.9289 - val_loss: 118070.6875 - val_mae: 153.8750 - lr: 1.0000e-04\n",
      "Epoch 207/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84806.2734 - mae: 134.0175 - val_loss: 117390.6016 - val_mae: 153.1508 - lr: 1.0000e-04\n",
      "Epoch 208/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84636.0703 - mae: 134.1575 - val_loss: 117863.1875 - val_mae: 153.0387 - lr: 1.0000e-04\n",
      "Epoch 209/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84644.5859 - mae: 133.8699 - val_loss: 117911.1016 - val_mae: 153.1914 - lr: 1.0000e-04\n",
      "Epoch 210/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84585.7656 - mae: 134.0809 - val_loss: 118502.1641 - val_mae: 153.7131 - lr: 1.0000e-04\n",
      "Epoch 211/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84593.6641 - mae: 133.9813 - val_loss: 117882.1484 - val_mae: 152.7111 - lr: 1.0000e-04\n",
      "Epoch 212/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84649.6172 - mae: 134.0309 - val_loss: 118230.2109 - val_mae: 153.2588 - lr: 1.0000e-04\n",
      "Epoch 213/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84564.8672 - mae: 133.9532 - val_loss: 118168.3672 - val_mae: 153.5028 - lr: 1.0000e-04\n",
      "Epoch 214/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84525.6875 - mae: 133.8723 - val_loss: 119500.6562 - val_mae: 154.1276 - lr: 1.0000e-04\n",
      "Epoch 215/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84485.4609 - mae: 133.7459 - val_loss: 118754.5312 - val_mae: 154.2442 - lr: 1.0000e-04\n",
      "Epoch 216/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84545.2969 - mae: 133.9395 - val_loss: 117452.7031 - val_mae: 152.8083 - lr: 1.0000e-04\n",
      "Epoch 217/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84492.1484 - mae: 133.8234 - val_loss: 118791.6172 - val_mae: 154.3577 - lr: 1.0000e-04\n",
      "Epoch 218/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84475.7734 - mae: 133.6932 - val_loss: 117954.9062 - val_mae: 153.6849 - lr: 1.0000e-04\n",
      "Epoch 219/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84449.5625 - mae: 133.9634 - val_loss: 118282.2500 - val_mae: 153.3610 - lr: 1.0000e-04\n",
      "Epoch 220/1000\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 84390.6641 - mae: 133.8386 - val_loss: 118970.5078 - val_mae: 153.8521 - lr: 1.0000e-04\n",
      "Epoch 221/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84384.6484 - mae: 133.8521 - val_loss: 117697.4766 - val_mae: 152.9801 - lr: 1.0000e-04\n",
      "Epoch 222/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84369.9688 - mae: 133.7917 - val_loss: 118046.0625 - val_mae: 153.4832 - lr: 1.0000e-04\n",
      "Epoch 223/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84327.4453 - mae: 133.8397 - val_loss: 118703.5703 - val_mae: 153.5479 - lr: 1.0000e-04\n",
      "Epoch 224/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84267.7344 - mae: 133.7173 - val_loss: 118008.3516 - val_mae: 153.1694 - lr: 1.0000e-04\n",
      "Epoch 225/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84297.8359 - mae: 133.5923 - val_loss: 118391.4688 - val_mae: 153.5720 - lr: 1.0000e-04\n",
      "Epoch 226/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84359.7188 - mae: 133.8958 - val_loss: 118645.1094 - val_mae: 153.2485 - lr: 1.0000e-04\n",
      "Epoch 227/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84306.5938 - mae: 133.7666 - val_loss: 119253.9297 - val_mae: 154.4219 - lr: 1.0000e-04\n",
      "Epoch 228/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84322.0391 - mae: 133.6783 - val_loss: 119653.7578 - val_mae: 154.3547 - lr: 1.0000e-04\n",
      "Epoch 229/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84226.7422 - mae: 133.6536 - val_loss: 119319.9062 - val_mae: 154.3714 - lr: 1.0000e-04\n",
      "Epoch 230/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84169.3594 - mae: 133.7876 - val_loss: 119451.7578 - val_mae: 154.4306 - lr: 1.0000e-04\n",
      "Epoch 231/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84173.9141 - mae: 133.5542 - val_loss: 118355.0078 - val_mae: 153.2989 - lr: 1.0000e-04\n",
      "Epoch 232/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84148.3281 - mae: 133.6436 - val_loss: 118555.8750 - val_mae: 153.3899 - lr: 1.0000e-04\n",
      "Epoch 233/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84079.4062 - mae: 133.7159 - val_loss: 118860.2422 - val_mae: 153.3239 - lr: 1.0000e-04\n",
      "Epoch 234/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84139.1328 - mae: 133.4345 - val_loss: 118797.1484 - val_mae: 153.5893 - lr: 1.0000e-04\n",
      "Epoch 235/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84129.8750 - mae: 133.6956 - val_loss: 119261.5234 - val_mae: 154.1026 - lr: 1.0000e-04\n",
      "Epoch 236/1000\n",
      "1089/1089 [==============================] - 1s 997us/step - loss: 84052.4453 - mae: 133.5288 - val_loss: 118681.7344 - val_mae: 153.8376 - lr: 1.0000e-04\n",
      "Epoch 237/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84054.4688 - mae: 133.6795 - val_loss: 120005.6641 - val_mae: 154.7194 - lr: 1.0000e-04\n",
      "Epoch 238/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 84054.3828 - mae: 133.5959 - val_loss: 118570.1172 - val_mae: 153.4742 - lr: 1.0000e-04\n",
      "Epoch 239/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83955.8203 - mae: 133.6915 - val_loss: 119306.2031 - val_mae: 153.4326 - lr: 1.0000e-04\n",
      "Epoch 240/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83975.0000 - mae: 133.4302 - val_loss: 119222.1172 - val_mae: 153.7235 - lr: 1.0000e-04\n",
      "Epoch 241/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83907.7188 - mae: 133.5303 - val_loss: 118739.3906 - val_mae: 153.3119 - lr: 1.0000e-04\n",
      "Epoch 242/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83871.5625 - mae: 133.5972 - val_loss: 119720.0859 - val_mae: 154.1715 - lr: 1.0000e-04\n",
      "Epoch 243/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83910.1875 - mae: 133.3839 - val_loss: 119541.7422 - val_mae: 153.7591 - lr: 1.0000e-04\n",
      "Epoch 244/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83901.5078 - mae: 133.4873 - val_loss: 118844.8281 - val_mae: 153.4158 - lr: 1.0000e-04\n",
      "Epoch 245/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83786.2891 - mae: 133.4144 - val_loss: 119250.7891 - val_mae: 153.5259 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83858.8594 - mae: 133.2957 - val_loss: 119057.5000 - val_mae: 153.9637 - lr: 1.0000e-04\n",
      "Epoch 247/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83830.5156 - mae: 133.4184 - val_loss: 119636.1328 - val_mae: 154.1164 - lr: 1.0000e-04\n",
      "Epoch 248/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83733.1797 - mae: 133.3977 - val_loss: 118673.7891 - val_mae: 152.9655 - lr: 1.0000e-04\n",
      "Epoch 249/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83749.4375 - mae: 133.2712 - val_loss: 120053.7500 - val_mae: 154.0020 - lr: 1.0000e-04\n",
      "Epoch 250/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83734.3203 - mae: 133.3357 - val_loss: 120185.8984 - val_mae: 154.8595 - lr: 1.0000e-04\n",
      "Epoch 251/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83834.6875 - mae: 133.3761 - val_loss: 118730.9062 - val_mae: 154.1112 - lr: 1.0000e-04\n",
      "Epoch 252/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83666.9219 - mae: 133.5257 - val_loss: 119410.1094 - val_mae: 153.9247 - lr: 1.0000e-04\n",
      "Epoch 253/1000\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 83635.9609 - mae: 133.0937 - val_loss: 118571.6406 - val_mae: 153.3841 - lr: 1.0000e-04\n",
      "INFO:tensorflow:Assets written to: models/tabnet/upac08_ghi+gti/Model 10\\assets\n"
     ]
    }
   ],
   "source": [
    "# Train 10 Models for UPAC08 - Top k\n",
    "\n",
    "N_MODELS = 10\n",
    "upac08_GhiGti = {}\n",
    "\n",
    "for i in np.arange(N_MODELS):\n",
    "    IPython.display.clear_output()\n",
    "    print('Current Model: {:02d}'.format(i+1))\n",
    "    \n",
    "    tabnet_regressor = StackedTabNetRegressor(feature_columns=None,\n",
    "                                              num_layers=1, #study.best_params['num_layers'],\n",
    "                                              num_regressors=1, \n",
    "                                              feature_dim=study.best_params['feature_dim'],\n",
    "                                              num_features=4, \n",
    "                                              output_dim=study.best_params['output_dim'],\n",
    "                                              num_decision_steps=study.best_params['num_decision_steps'],\n",
    "                                              num_groups=1)\n",
    "    current_net_history = compile_and_fit(tabnet_regressor, \n",
    "                                          X_train['upac08'], y_train['upac08'],\n",
    "                                          X_val['upac08'], y_val['upac08'])\n",
    "    \n",
    "    tabnet_regressor.save('models/tabnet/upac08_ghi+gti/Model {:02d}'.format(i+1), save_format='tf')\n",
    "    upac08_GhiGti['Model {:02d}'.format(i+1)] = tabnet_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca03537e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T10:51:30.276395Z",
     "start_time": "2022-08-01T10:51:16.965959Z"
    }
   },
   "outputs": [],
   "source": [
    "# UPAC08 Predictions for all features\n",
    "\n",
    "predict_upacs(model_dictionary=upac08_GhiGti, \n",
    "              upac_name='upac08',\n",
    "              X_train=X_train, y_train=y_train,\n",
    "              X_val=X_val, y_val=y_val,\n",
    "              X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06dace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
